{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pittsburgh Steelers' 'San Francisco 49ers' 'Denver Broncos'\n",
      " 'Las Vegas Raiders' 'Washington Commanders' 'Los Angeles Chargers'\n",
      " 'Seattle Seahawks' 'Cincinnati Bengals' 'Cleveland Browns'\n",
      " 'Detroit Lions' 'Houston Texans' 'Jacksonville Jaguars' 'Miami Dolphins'\n",
      " 'New England Patriots' 'Tampa Bay Buccaneers' 'Los Angeles Rams'\n",
      " 'Arizona Cardinals' 'Atlanta Falcons' 'Buffalo Bills' 'Green Bay Packers'\n",
      " 'Indianapolis Colts' 'Minnesota Vikings' 'New York Giants'\n",
      " 'New Orleans Saints' 'New York Jets' 'Carolina Panthers' 'Dallas Cowboys'\n",
      " 'Baltimore Ravens' 'Philadelphia Eagles' 'Tennessee Titans'\n",
      " 'Chicago Bears' 'Kansas City Chiefs']\n",
      "Data(edge_index=[2, 246], edge_attr=[246, 2], num_nodes=32)\n"
     ]
    }
   ],
   "source": [
    "# process data\n",
    "# each node is a team (for a year), edges\n",
    "game_info = pd.read_csv(\"nfl-game-info.csv\")\n",
    "# team_info = pd.read_csv(\"team_stats_2003_2023.csv\")\n",
    "\n",
    "teams = pd.concat([game_info['Home Team'], game_info['Away Team']]).unique()\n",
    "teams = list(teams)\n",
    "teams.remove('San Diego Chargers')\n",
    "teams.remove('Washington Redskins')\n",
    "teams.remove('St. Louis Rams')\n",
    "teams.remove('Oakland Raiders')\n",
    "teams.remove('Washington Football Team')\n",
    "teams = np.array(teams)\n",
    "print(teams)\n",
    "team_to_idx = {team: i for i, team in enumerate(teams)}\n",
    "\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "for _, row in game_info.iterrows():\n",
    "  date = parse(row[\"Date\"])\n",
    "  if date < parse('2024-9-5'):\n",
    "    continue\n",
    "  # create an edge between two teams,\n",
    "  team1_idx = team_to_idx[row['Home Team']]\n",
    "  team2_idx = team_to_idx[row['Away Team']]\n",
    "\n",
    "  # Add an undirected edge (team1 -> team2 and team2 -> team1)\n",
    "  edge_index.append([team1_idx, team2_idx])\n",
    "  edge_index.append([team2_idx, team1_idx])\n",
    "\n",
    "  edge_attr.append([row[\"Home Score\"], row[\"Away Score\"]])\n",
    "  edge_attr.append([row[\"Away Score\"], row[\"Home Score\"]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(teams))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Embeddings:\n",
      "tensor([[ 9.8153e+00, -9.6728e+00, -1.1827e+01,  1.1813e+01,  1.3209e+01,\n",
      "          9.4814e+00, -1.2816e+01,  3.8839e+00,  1.9963e+00,  3.3772e+00,\n",
      "         -6.8188e+00, -2.8589e+01, -9.8338e+00, -2.0174e+01,  2.6742e+01,\n",
      "         -1.0816e+01],\n",
      "        [ 1.7525e-04,  3.3282e-04,  3.9908e-04,  8.4477e-04, -3.2050e-04,\n",
      "          1.1383e-03, -5.9212e-04, -6.2921e-05,  6.0867e-04, -4.5408e-04,\n",
      "          7.2130e-05, -4.8047e-04, -3.7052e-04,  9.1166e-05, -7.7439e-04,\n",
      "         -1.0674e-03],\n",
      "        [ 7.8230e+00,  7.2353e+00,  2.1517e-01, -1.4638e+01, -3.0630e+00,\n",
      "         -8.6688e+00, -1.2346e+01,  2.4580e+00, -1.7338e+00, -1.1567e+01,\n",
      "          2.0915e+00,  2.0049e+01, -5.5741e+00,  4.9452e+00,  6.3249e+00,\n",
      "          1.0937e+01],\n",
      "        [ 2.7676e-03,  4.8872e-03, -4.2966e-04,  1.4127e-03, -5.1647e-03,\n",
      "          1.0989e-03,  8.1883e-04,  7.1695e-03,  9.3181e-03, -2.1994e-03,\n",
      "          8.0086e-04, -4.7592e-05, -1.5120e-03, -5.9980e-04, -3.1372e-03,\n",
      "         -2.7662e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 5.1476e+00,  9.0902e+00, -7.9912e-01,  2.6275e+00, -9.6063e+00,\n",
      "          2.0438e+00,  1.5228e+00,  1.3335e+01,  1.7332e+01, -4.0907e+00,\n",
      "          1.4897e+00, -8.8600e-02, -2.8128e+00, -1.1157e+00, -5.8350e+00,\n",
      "         -5.1449e+00],\n",
      "        [ 1.0220e+01, -1.0184e+01, -1.2243e+01,  1.2238e+01,  1.3904e+01,\n",
      "          9.9610e+00, -1.3234e+01,  3.9950e+00,  2.2173e+00,  3.6264e+00,\n",
      "         -7.0906e+00, -2.9552e+01, -1.0102e+01, -2.0888e+01,  2.7838e+01,\n",
      "         -1.1454e+01],\n",
      "        [-9.4701e+00, -3.6324e+00,  1.1707e+00,  1.0237e+01,  5.9829e+00,\n",
      "          7.1015e+00,  1.5573e+00, -5.0098e+00, -8.7733e+00, -5.8277e+00,\n",
      "          1.2103e+00,  9.5357e+00,  1.1276e+01, -5.3645e+00,  2.7832e+00,\n",
      "         -5.8086e+00],\n",
      "        [-4.6324e-01, -1.7546e-01,  5.8505e-02,  4.9624e-01,  2.8862e-01,\n",
      "          3.5011e-01,  7.6176e-02, -2.4434e-01, -4.2590e-01, -2.7248e-01,\n",
      "          5.7729e-02,  4.6200e-01,  5.3987e-01, -2.5591e-01,  1.4004e-01,\n",
      "         -2.7906e-01],\n",
      "        [ 8.8565e+00,  1.8687e+00, -2.1772e+01,  1.1407e+01,  1.6122e+01,\n",
      "          2.4357e+01, -8.3611e+00,  4.9286e+00,  2.7552e+01, -1.3775e+01,\n",
      "          1.2809e+00, -1.2987e+01, -6.9421e+00,  1.6861e+01, -1.0040e+01,\n",
      "          6.0223e+00],\n",
      "        [ 1.9850e+00,  1.6898e+01, -2.4794e+01, -1.0259e+01, -4.0715e+00,\n",
      "          1.1209e+01,  6.9113e+00, -4.6246e+00, -3.2909e+00, -2.6422e-01,\n",
      "          3.6643e+00,  1.9136e+01,  5.3265e+00, -1.1321e+00,  1.3576e+01,\n",
      "          1.1228e+01],\n",
      "        [-4.8975e-01, -1.0705e+00,  5.9054e-01, -9.0307e-01,  1.4281e-01,\n",
      "          1.1894e+00, -1.8865e+00, -7.5042e-02, -5.3178e-01,  6.4701e-01,\n",
      "         -1.5059e+00,  9.9996e-01, -5.9819e-02,  3.0581e-01, -1.7444e+00,\n",
      "          7.9633e-01],\n",
      "        [ 2.0599e+00,  1.7533e+01, -2.5726e+01, -1.0645e+01, -4.2245e+00,\n",
      "          1.1630e+01,  7.1714e+00, -4.7985e+00, -3.4149e+00, -2.7441e-01,\n",
      "          3.8023e+00,  1.9856e+01,  5.5267e+00, -1.1746e+00,  1.4086e+01,\n",
      "          1.1650e+01],\n",
      "        [ 1.5054e-02,  1.9592e-02, -2.0658e-02,  1.8923e-02,  2.5095e-02,\n",
      "         -9.2177e-03,  3.0261e-02, -2.9871e-03, -1.7493e-02,  1.2469e-02,\n",
      "          4.8558e-02,  8.0047e-03, -2.4127e-02,  3.2169e-03,  5.0870e-03,\n",
      "          3.1010e-03],\n",
      "        [-2.1126e-01, -1.9043e-01,  5.1605e-01,  4.9712e-01, -5.2091e-02,\n",
      "          1.1770e-01, -3.8432e-01, -2.2190e-02, -2.4385e-01, -3.8589e-01,\n",
      "         -5.0842e-01,  2.4952e-01, -4.6930e-02, -1.2619e-01, -3.1638e-01,\n",
      "          4.0493e-02],\n",
      "        [ 2.1453e-04,  5.6419e-05, -3.1149e-04,  1.6871e-04,  4.0424e-04,\n",
      "         -1.3211e-04,  2.1965e-04, -3.6537e-05, -1.8042e-04,  1.8747e-04,\n",
      "          3.7247e-04,  7.0644e-05, -3.6340e-04,  3.3865e-04,  6.1853e-05,\n",
      "          1.5755e-04],\n",
      "        [-3.0773e-03, -5.3958e-03,  5.8889e-03, -6.0126e-03,  7.6966e-04,\n",
      "          9.4283e-03, -1.1243e-02, -8.5382e-04, -6.7639e-03,  2.5629e-03,\n",
      "         -7.2785e-03,  8.5315e-03, -1.3361e-05, -1.6394e-03, -1.1846e-02,\n",
      "          4.8085e-03],\n",
      "        [ 9.8819e-01,  1.1263e+00,  1.7990e+00, -2.0332e-01,  3.5938e-01,\n",
      "         -2.7579e+00,  2.1889e-01, -3.5054e-01, -5.2135e-01, -1.3251e-01,\n",
      "         -1.7567e+00, -1.0455e+00,  6.4737e-01, -2.0210e-01,  6.9278e-01,\n",
      "         -2.4341e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [-8.1439e-08, -1.2083e-07,  2.2519e-07,  2.6558e-08, -1.3111e-07,\n",
      "          1.2897e-09, -6.1736e-10, -2.4211e-07, -1.0267e-07,  3.1542e-08,\n",
      "          1.2386e-08, -3.8285e-08, -3.3491e-08, -1.3585e-07, -1.0369e-07,\n",
      "          1.7015e-08],\n",
      "        [ 8.8527e+00,  1.8681e+00, -2.1762e+01,  1.1402e+01,  1.6115e+01,\n",
      "          2.4346e+01, -8.3570e+00,  4.9264e+00,  2.7539e+01, -1.3769e+01,\n",
      "          1.2810e+00, -1.2981e+01, -6.9392e+00,  1.6853e+01, -1.0035e+01,\n",
      "          6.0197e+00],\n",
      "        [-5.3644e+00, -1.5791e+00,  1.8076e-01,  5.0541e+00,  5.0420e+00,\n",
      "          4.3013e+00,  4.8315e+00, -4.7127e+00, -6.8283e+00, -2.5944e+00,\n",
      "          3.1952e+00,  6.1131e+00,  7.8885e+00, -4.9932e+00,  5.5683e+00,\n",
      "         -6.0520e+00],\n",
      "        [ 7.8995e+00, -8.9652e+00, -1.0987e+01,  1.1584e+01,  1.2857e+01,\n",
      "          9.1718e+00, -1.1099e+01,  2.7738e+00,  9.0552e-01,  2.6679e+00,\n",
      "         -5.6318e+00, -2.5006e+01, -7.3962e+00, -1.9017e+01,  2.5060e+01,\n",
      "         -1.0678e+01],\n",
      "        [-2.1515e-04,  1.1066e-05,  1.9333e-04,  5.3430e-05,  1.1882e-04,\n",
      "         -9.0764e-04,  1.1584e-04, -7.1796e-04,  1.5880e-03,  1.0058e-03,\n",
      "          1.4150e-04, -5.6423e-04, -9.1913e-04,  4.2245e-04,  3.1207e-04,\n",
      "         -1.0402e-04],\n",
      "        [-1.8379e-02,  2.2335e-01,  7.6799e-02, -9.8409e-01,  1.1732e+00,\n",
      "          1.6616e+00,  1.0806e-01, -1.2715e+00, -1.2707e-01, -5.0569e-01,\n",
      "         -1.6067e-01,  2.0674e-01, -5.1847e-02, -2.8568e-02, -1.2439e+00,\n",
      "         -2.3131e+00],\n",
      "        [-2.0981e-01, -3.8066e+00,  3.6651e+00,  3.5286e+00,  9.9789e-01,\n",
      "          5.6241e+00, -2.5121e-01, -9.2786e-01, -2.9495e-01, -1.0060e+00,\n",
      "         -2.5502e+00,  4.1363e+00, -1.3251e+00, -1.9546e+00, -9.0691e-01,\n",
      "         -3.7975e+00],\n",
      "        [ 4.3860e-01,  8.2782e-01,  9.9319e-01,  2.1016e+00, -7.9950e-01,\n",
      "          2.8350e+00, -1.4718e+00, -1.5723e-01,  1.5133e+00, -1.1310e+00,\n",
      "          1.8051e-01, -1.1954e+00, -9.2274e-01,  2.2352e-01, -1.9261e+00,\n",
      "         -2.6618e+00],\n",
      "        [ 8.0544e+00, -5.8993e+00, -8.2969e+00,  6.0428e+00,  1.0516e+01,\n",
      "          7.2091e+00, -1.0442e+01,  1.7094e+00,  1.0415e+00,  7.3169e-01,\n",
      "         -5.1077e+00, -1.8770e+01, -7.5302e+00, -1.4407e+01,  1.8971e+01,\n",
      "         -9.3702e+00],\n",
      "        [ 8.0856e-03,  1.5409e-02,  8.6729e-03, -5.8630e-02, -3.3145e-02,\n",
      "          2.0432e-02,  4.2873e-02, -8.9560e-03, -9.4513e-03,  2.8347e-02,\n",
      "          2.8812e-03,  1.8493e-02,  3.2287e-02,  5.0932e-02, -2.9519e-02,\n",
      "          2.5033e-02],\n",
      "        [-1.9775e-05, -4.8351e-06,  1.5056e-06, -1.4430e-05, -2.3217e-05,\n",
      "          1.1836e-05, -1.2983e-05, -1.1858e-06,  2.7439e-05,  3.4313e-05,\n",
      "         -2.3055e-05, -7.4872e-08,  1.2109e-05, -9.3466e-07, -3.7429e-05,\n",
      "         -1.2484e-06],\n",
      "        [ 6.0955e-01,  5.2464e-01,  4.1921e-01, -1.1326e+00, -4.0071e-01,\n",
      "         -5.9746e-01, -1.7173e+00,  3.2070e-01, -4.3635e-01, -1.6601e+00,\n",
      "         -1.4146e-01,  2.5728e+00, -6.9109e-01,  5.0477e-01,  3.3664e-01,\n",
      "          1.3078e+00]])\n"
     ]
    }
   ],
   "source": [
    "num_nodes = len(teams)\n",
    "node_feature_dim = 64\n",
    "node_features = torch.randn((num_nodes, node_feature_dim), dtype=torch.float,)\n",
    "\n",
    "# # RESIDUALS!\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, heads=8, dropout=0.6):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.heads = heads\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # Define GAT layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GATConv(in_channels, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "\n",
    "        self.convs.append(GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout))\n",
    "\n",
    "        self.bns = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(hidden_channels * heads) for _ in range(num_layers - 1)\n",
    "        ])\n",
    "\n",
    "        # Linear projection for residual connections (if dimensions don't match)\n",
    "        self.residual_proj = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(in_channels if i == 0 else hidden_channels * heads, hidden_channels * heads) \n",
    "            for i in range(num_layers - 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            residual = x\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.elu(x)\n",
    "            if residual.size(-1) != x.size(-1):\n",
    "                residual = self.residual_proj[i](residual)\n",
    "\n",
    "            x = x + residual    # Add residual connection\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)  # Dropout\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        return self.forward(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        # Use dot product to predict if an edge exists\n",
    "        src, dst = edge_index\n",
    "        return (z[src] * z[dst]).sum(dim=1)\n",
    "\n",
    "model = GATModel(in_channels=node_feature_dim, hidden_channels=32, out_channels=16, num_layers=4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "node_features = node_features.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(node_features, data.edge_index)\n",
    "\n",
    "print(\"GAT Embeddings:\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7sAAAK9CAYAAADltHtfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1QUZ9sG8GvoZYEVRJoIKogIoihqBBVjCViIRo0NC5YYe0xCNL5J7D3Ye4mgvlhj79iwoLGDHUEpFixBQRGkPt8fvsznCggk1vX6nbPnODNPmwGXvfdpkhBCgIiIiIiIiEiNaLzvBhARERERERG9aQx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomI6I0JCQmBJEk4c+bMW68rICAA9vb2xaaLj4+HJEkICQmRz40ZMwaSJL29xr1D9vb2CAgIeN/NKNCO8PBwSJKE8PDwd9qO91UvERF9eBjsEhG9YXFxcRg8eDCqVKkCAwMDGBgYoFq1ahg0aBAuXLhQZL7hw4dDkiR06tRJ5bwkSSV6ve7Dvb29fZH5fH1939St07907tw5SJKEX3/9tcg0MTExkCQJP/zwwzts2YdnwYIFKl9gEBERvUrrfTeAiEid7NixA506dYKWlhb8/f1Ro0YNaGho4Nq1a9i0aRMWLlyIuLg42NnZqeQTQmDNmjWwt7fH9u3b8fTpUxgZGQEAVq1apZJ25cqV2LdvX4Hzzs7Or21bzZo18eOPPxY4b21t/U9u9aP266+/4ueff37fzSigVq1aqFq1KtasWYMJEyYUmmb16tUAgG7dugEAoqOjoaHx4X133ahRI2RkZEBHR+etlL9gwQKULVu2QK/2266XiIg+Hgx2iYjekBs3bqBz586ws7PDgQMHYGVlpXJ96tSpWLBgQaGBSXh4OG7fvo2DBw/Cx8cHmzZtQs+ePQH8f1CT76+//sK+ffsKnC+OjY1NqfOoKy0tLWhpfZh/Av39/fHbb7/hr7/+wmeffVbg+po1a1C1alXUqlULAKCrq/uum1giGhoa0NPT+2TqJSKiD8+H91UwEdFHatq0aXj27BmCg4MLBLrAiwBr6NChsLW1LXAtNDQU1apVw+eff45mzZohNDT0XTS5gICAACgUCiQmJqJ169ZQKBSwsbHB/PnzAQAXL15EkyZNYGhoCDs7O7mX8VXp6en49ttvYWZmBmNjY/To0QOPHz8ukG737t1o2LAhDA0NYWRkhFatWuHy5csF0m3ZsgWurq7Q09ODq6srNm/eXGi9KSkpCAgIgImJCZRKJXr27ImUlJQC6QqbsytJEgYPHizXpaurCxcXF+zZs6dA/vDwcHh4eEBPTw+VK1fG4sWLCy1z3759aNCgAZRKJRQKBZycnPCf//yn0Lbn8/f3B4BCn+3Zs2cRHR0tpwEKzpXNzs7G2LFj4ejoCD09PZiZmaFBgwbYt2+fnKZx48Zo3LhxgfILmwcdFBQET09PmJmZQV9fH7Vr18aff/752nsACs6dzZ/PXdjr5bYEBwejSZMmKFeuHHR1dVGtWjUsXLhQpWx7e3tcvnwZhw8fLlBGUXN2N2zYgNq1a0NfXx9ly5ZFt27dcOfOnQL3r1AocOfOHbRt2xYKhQLm5uYIDAxEbm5usfdMREQflg/za20ioo/Qjh074ODggHr16pUqX2ZmJjZu3CgPMe7SpQt69eqFe/fuwdLS8o21Lzs7G3///XeB84aGhtDX15ePc3Nz0aJFCzRq1AjTpk1DaGgoBg8eDENDQ/zyyy/w9/dHu3btsGjRIvTo0QP169dHxYoVVcocPHgwlEolxowZg+joaCxcuBAJCQlyIAK8GJ7ds2dP+Pj4YOrUqUhPT8fChQvRoEEDnD9/Xg66wsLC0L59e1SrVg2TJ09GcnIyevXqhfLly6vUKYRAmzZtcOzYMfTv3x/Ozs7YvHmz3ENeEseOHcOmTZswcOBAGBkZYc6cOWjfvj0SExNhZmYGADh//jx8fX1hZWWFsWPHIjc3F+PGjYO5ublKWZcvX0br1q3h5uaGcePGQVdXF7GxsYiIiHhtGypWrAhPT0+sX78eM2fOhKampnwtPwDu2rVrkfnHjBmDyZMno2/fvqhbty6ePHmCM2fO4Ny5c2jevHmJn0W+2bNn48svv4S/vz+ysrKwdu1afP3119ixYwdatWpV4nIaNWpUYOh9QkICfv31V5QrV04+t3DhQri4uODLL7+ElpYWtm/fjoEDByIvLw+DBg0CAMyaNQtDhgyBQqHAL7/8AgCwsLAosu6QkBD06tULderUweTJk3H//n3Mnj0bEREROH/+PJRKpZw2NzcXPj4+qFevHoKCgrB//35Mnz4dlStXxoABA0p8v0RE9AEQRET0r6WmpgoAom3btgWuPX78WDx8+FB+paenq1z/888/BQARExMjhBDiyZMnQk9PT8ycObPQugYNGiRK+/ZtZ2cnABT6mjx5spyuZ8+eAoCYNGmSSvv19fWFJEli7dq18vlr164JAGL06NHyueDgYAFA1K5dW2RlZcnnp02bJgCIrVu3CiGEePr0qVAqleKbb75Raee9e/eEiYmJyvmaNWsKKysrkZKSIp8LCwsTAISdnZ18bsuWLQKAmDZtmnwuJydHNGzYUAAQwcHB8vnRo0cXeIYAhI6OjoiNjZXPRUVFCQBi7ty58jk/Pz9hYGAg7ty5I5+LiYkRWlpaKmXOnDlTABAPHz4UpTV//nwBQOzdu1c+l5ubK2xsbET9+vVV0trZ2YmePXvKxzVq1BCtWrV6bfne3t7C29u7wPmePXuqPFMhRIHf16ysLOHq6iqaNGny2nYcOnRIABCHDh0qtA0ZGRmidu3awtraWiQlJRVZnxBC+Pj4iEqVKqmcc3FxKfQeXq03KytLlCtXTri6uoqMjAw53Y4dOwQAMWrUKPlc/u//uHHjVMp0d3cXtWvXLvQ+iIjow8VhzEREb8CTJ08AAAqFosC1xo0bw9zcXH7lDwnOFxoaCg8PDzg4OACAPJz3TQ9lrlevHvbt21fg1aVLlwJp+/btK/9bqVTCyckJhoaG6Nixo3zeyckJSqUSN2/eLJC/X79+0NbWlo8HDBgALS0t7Nq1C8CL4b0pKSno0qUL/v77b/mlqamJevXq4dChQwCApKQkREZGomfPnjAxMZHLa968OapVq6ZS565du6ClpaXS+6apqYkhQ4aU+Bk1a9YMlStXlo/d3NxgbGws32Nubi7279+Ptm3bqizs5eDggBYtWqiUld9buHXrVuTl5ZW4DQDQqVMnaGtrqwxlPnz4MO7cuaMyhLkwSqUSly9fRkxMTKnqLMrLvf6PHz9GamoqGjZsiHPnzv2rcgcOHIiLFy9i48aNKiMYXq4vNTUVf//9N7y9vXHz5k2kpqaWup4zZ87gwYMHGDhwoMpc3latWqFq1arYuXNngTz9+/dXOW7YsGGhv+dERPRh4zBmIqI3IH/l5LS0tALXFi9ejKdPn+L+/fsFFohKSUnBrl27MHjwYMTGxsrnvby8sHHjRly/fh1VqlR5I20sW7YsmjVrVmw6PT29AkNyTUxMUL58+QJzUk1MTAqdi+vo6KhyrFAoYGVlhfj4eACQA7EmTZoU2gZjY2MAL4a5FlYe8CLYfjngSkhIgJWVVYEvHJycnAqtozAVKlQocK5MmTLyPT548AAZGRnyFxMve/Vcp06dsGzZMvTt2xc///wzmjZtinbt2qFDhw7Frp5sZmYGHx8fbN68GYsWLYKenh5Wr14NLS0tlS8cCjNu3Di0adMGVapUgaurK3x9fdG9e3e4ubkVd/uF2rFjByZMmIDIyEhkZmbK5//NPsWLFy9GcHAwFi9eXGARroiICIwePRonTpxAenq6yrXU1FSVLz1KIv93qLDfg6pVq+LYsWMq5wr7/X/5d4CIiD4eDHaJiN4AExMTWFlZ4dKlSwWu5c/hzQ/0XrZhwwZkZmZi+vTpmD59eoHroaGhGDt27Btv7+u8PEe0JOeFEKWuI7+nc9WqVYXOS35fKyW/yXvU19fHkSNHcOjQIezcuRN79uzBunXr0KRJE4SFhRVZV75u3bphx44d2LFjB7788kts3LgRX3zxRYFA7FWNGjXCjRs3sHXrVoSFhWHZsmWYOXMmFi1aJPfYS5JU6D29ugjT0aNH8eWXX6JRo0ZYsGABrKysoK2tjeDg4CIXJyvOqVOn8N1336Fv377o16+fyrUbN26gadOmqFq1KmbMmAFbW1vo6Ohg165dmDlzZql7yP+J4n4uRET08WCwS0T0hrRq1QrLli3DqVOnULdu3RLlCQ0NhaurK0aPHl3g2uLFi7F69ep3Huy+CTExMfj888/l47S0NCQlJaFly5YAIA8VLleu3Gt7m/P3Iy5sSG50dHSBtAcOHEBaWppK7+6r6f6NcuXKQU9PT6UXPl9h5zQ0NNC0aVM0bdoUM2bMwKRJk/DLL7/g0KFDxfayf/nllzAyMsLq1auhra2Nx48fFzuEOZ+pqSl69eqFXr16IS0tDY0aNcKYMWPkYLdMmTKFDsvN7wXNt3HjRujp6WHv3r0qWxwFBweXqB2vevjwITp06ICaNWsWGM4PANu3b0dmZia2bdum0sueP6z9ZSXtWc7/HYqOji4wkiA6OrrAntdERKQ+OGeXiOgNGT58OAwMDNC7d2/cv3+/wPVXe9Ju3bqFI0eOoGPHjujQoUOBV69evRAbG4uTJ0++q1t4Y5YsWYLs7Gz5eOHChcjJyZHntfr4+MDY2BiTJk1SSZfv4cOHAAArKyvUrFkTK1asUJmvuW/fPly5ckUlT8uWLZGTk6OyTU1ubi7mzp37xu5LU1MTzZo1w5YtW3D37l35fGxsLHbv3q2S9tGjRwXy16xZEwBUhgMXRV9fH1999RV27dqFhQsXwtDQEG3atCk2X3JyssqxQqGAg4ODSp2VK1fGtWvX5OcMAFFRUQVWitbU1IQkSSo9vvHx8diyZUux7XhVbm4uOnfujKysLGzcuBE6OjoF0uT3qr78fyU1NbXQ4NrQ0LDQbaVe5eHhgXLlymHRokUqz2D37t24evVqqVaUJiKijwt7domI3hBHR0esXr0aXbp0gZOTE/z9/VGjRg0IIRAXF4fVq1dDQ0ND3jJn9erVEELgyy+/LLS8li1bQktLC6GhoaXezqgwd+7cwX//+98C5xUKBdq2bfuvy39ZVlYWmjZtio4dOyI6OhoLFixAgwYN5Hs1NjbGwoUL0b17d9SqVQudO3eGubk5EhMTsXPnTnh5eWHevHkAgMmTJ6NVq1Zo0KABevfujUePHmHu3LlwcXFRmSPt5+cHLy8v/Pzzz4iPj0e1atWwadOmf7So0euMGTMGYWFh8PLywoABA5Cbm4t58+bB1dUVkZGRcrpx48bhyJEjaNWqFezs7PDgwQMsWLAA5cuXR4MGDUpUV7du3bBy5Urs3bsX/v7+MDQ0LDZPtWrV0LhxY9SuXRumpqY4c+YM/vzzTwwePFhO07t3b8yYMQM+Pj7o06cPHjx4gEWLFsHFxUVebA14MVphxowZ8PX1RdeuXfHgwQPMnz8fDg4OuHDhQskfGoBFixbh4MGD6N+/f4GeWgsLCzRv3hxffPEFdHR04Ofnh2+//RZpaWlYunQpypUrh6SkJJU8tWvXxsKFCzFhwgQ4ODigXLlyhc4B19bWxtSpU9GrVy94e3ujS5cu8tZD9vb2+P7770t1H0RE9BF5jytBExGppdjYWDFgwADh4OAg9PT0hL6+vqhataro37+/iIyMlNNVr15dVKhQ4bVlNW7cWJQrV05kZ2fL59701kMvbzXTs2dPYWhoWCC/t7e3cHFxKbTcl7e5yd966PDhw6Jfv36iTJkyQqFQCH9/f5GcnFwg/6FDh4SPj48wMTERenp6onLlyiIgIECcOXNGJd3GjRuFs7Oz0NXVFdWqVRObNm0qdJuc5ORk0b17d2FsbCxMTExE9+7dxfnz50u89dCgQYMKvceXt9QRQogDBw4Id3d3oaOjIypXriyWLVsmfvzxR6Gnp6eSpk2bNsLa2lro6OgIa2tr0aVLF3H9+vUCdRQlJydHWFlZCQBi165dhaZ5tX0TJkwQdevWFUqlUv7dmzhxospWUEII8d///ldUqlRJ6OjoiJo1a4q9e/cW+kz/+OMP4ejoKHR1dUXVqlVFcHBwoc+vuK2H8vMU9np5C6Ft27YJNzc3oaenJ+zt7cXUqVPF8uXLBQARFxcnp7t3755o1aqVMDIyUimjqC2P1q1bJ9zd3YWurq4wNTUV/v7+4vbt2yppivr9L+x+iYjowycJ8Q9W3SAiIiIVbdu2faNb/hAREdG/wzm7REREpZSRkaFyHBMTg127dqFx48bvp0FERERUAHt2iYiISsnKygoBAQGoVKkSEhISsHDhQmRmZuL8+fOF7glMRERE7x4XqCIiIiolX19frFmzBvfu3YOuri7q16+PSZMmMdAlIiL6gLBnl4iIiIiIiNQO5+wSERERERGR2mGwS0RERERERGqHc3ZLKS8vD3fv3oWRkREkSXrfzSEiIiIiovdECIGnT5/C2toaGhrsR/zQMNgtpbt378LW1vZ9N4OIiIiIiD4Qt27dQvny5d93M+gVDHZLycjICMCLX2hjY+P33BoiIiIiInpfnjx5AltbWzlGoA8Lg91Syh+6bGxszGCXiIiIiIg4vfEDxYHlREREREREpHYY7BIREREREZHaYbBLREREREREaofBLhEREREREakdBrtERERERESkdhjsEhERERERkdphsEtERERERERqh8EuERERERERqR0Gu0RERERERKR2GOwSERERERGR2mGwS0RERERERGqHwS4RERERERGpHQa7REREREREpHYY7BIREREREZHaYbBLRESfpDFjxqBmzZrvuxlERET0ljDYJSL6RDx8+BADBgxAhQoVoKurC0tLS/j4+CAiIuKt1hsfHw9Jkgq8unXr9lbrLU5gYCAOHDjwXtsAAEIItGjRApIkYcuWLSrXDhw4AE9PTxgZGcHS0hIjRoxATk7O+2koERHRR0brfTeAiIjejfbt2yMrKwsrVqxApUqVcP/+fRw4cADJycnvpP79+/fDxcVFPtbX1y+QRgiB3NxcaGm9/T9PCoUCCoXirddTnFmzZkGSpALno6Ki0LJlS/zyyy9YuXIl7ty5g/79+yM3NxdBQUH/uL6srCzo6Oj8myYTERF9FNizS0SkxoQQePo8Gzdu38fRo0cxZcoUfP7557Czs0PdunUxcuRIfPnll3L6GTNmoHr16jA0NIStrS0GDhyItLQ0+XpISAiUSiX27t0LZ2dnKBQK+Pr6Iikpqdi2mJmZwdLSUn6ZmJggPDwckiRh9+7dqF27NnR1dXHs2DHcuHEDbdq0gYWFBRQKBerUqYP9+/erlGdvb49Jkyahd+/eMDIyQoUKFbBkyRKVNLdv30aXLl1gamoKQ0NDeHh44OTJkwAKDmMODw9H3bp1YWhoCKVSCS8vLyQkJMjXt2/fjjp16kBPTw9ly5bFV199JV97/PgxevTogTJlysDAwAAtWrRATExMsc8kMjIS06dPx/LlywtcW7duHdzc3DBq1Cg4ODjA29sb06ZNw/z58/H06VM53bFjx9CwYUPo6+vD1tYWQ4cOxbNnz1Se0/jx49GjRw8YGxujX79+yMrKwuDBg2FlZQU9PT3Y2dlh8uTJxbaXiIjoY8Jgl4hIDaVn5WDflfsI3BCFHn+cwncbr0JLVx8//r4MOyMTkZ5V+FBYDQ0NzJkzB5cvX8aKFStw8OBBDB8+XLXs9HQEBQVh1apVOHLkCBITExEYGPiv2vvzzz9jypQpuHr1Ktzc3JCWloaWLVviwIEDOH/+PHx9feHn54fExESVfNOnT4eHhwfOnz+PgQMHYsCAAYiOjgYApKWlwdvbG3fu3MG2bdsQFRWF4cOHIy8vr0D9OTk5aNu2Lby9vXHhwgWcOHEC/fr1k3tcd+7cia+++gotW7bE+fPnceDAAdStW1fOHxAQgDNnzmDbtm04ceIEhBBo2bIlsrOzi7zn9PR0dO3aFfPnz4elpWWB65mZmdDT01M5p6+vj+fPn+Ps2bMAgBs3bsDX1xft27fHhQsXsG7dOhw7dgyDBw9WyRcUFIQaNWrg/Pnz+O233zBnzhxs27YN69evR3R0NEJDQ2Fvb/+anxAREdFHSFCppKamCgAiNTX1fTeFiKhQF2+niJ7LT4qm08NFs+nhot38Y+LrhRGiXt8JQkvfSGho6QhzBzfRd/APIioq6rVlbdiwQZiZmcnHwcHBAoCIjY2Vz82fP19YWFgUWUZcXJwAIPT19YWhoaH8OnfunDh06JAAILZs2VLsfbm4uIi5c+fKx3Z2dqJbt27ycV5enihXrpxYuHChEEKIxYsXCyMjI5GcnFxoeaNHjxY1atQQQgiRnJwsAIjw8PBC09avX1/4+/sXeu369esCgIiIiJDP/f3330JfX1+sX7++yPvp16+f6NOnj3wMQGzevFk+3rt3r9DQ0BCrV68WOTk54vbt26Jhw4YCgFi9erUQQog+ffqIfv36qZR79OhRoaGhITIyMoQQL55T27ZtVdIMGTJENGnSROTl5RXZPiIiKh5jgw8be3aJiNTIpTupGLv9Cm49Soe1iR4qmBpAaaADIz1tuHh9ga6zd+HzIb9DUbk2Nu8KQ61atRASEiLn379/P5o2bQobGxsYGRmhe/fuSE5ORnp6upzGwMAAlStXlo+trKzw4MGDYtu2bt06REZGyq9q1arJ1zw8PFTSpqWlITAwEM7OzlAqlVAoFLh69WqBnl03Nzf535IkwdLSUm5LZGQk3N3dYWpqWmzbTE1NERAQAB8fH/j5+WH27NkqQ7MjIyPRtGnTQvNevXoVWlpaqFevnnzOzMwMTk5OuHr1aqF5tm3bhoMHD2LWrFlFtumLL77A77//jv79+0NXVxdVqlRBy5YtAbzogQdezOsNCQmR5x8rFAr4+PggLy8PcXFxclmvPt+AgABERkbCyckJQ4cORVhY2OsfEBER0UeIwS4RkZpIz8pBUFg0Hj3LhJ2pAbQ1C77Fa2nrws6tPhp36o8aA+eikmcrjBo9GsCLVZNbt24NNzc3bNy4EWfPnsX8+fMBvFjUKJ+2trZKmZIkQQhRbPtsbW3h4OAgv3R1deVrhoaGKmkDAwOxefNmTJo0CUePHkVkZCSqV6+u0o6i2pI/TLmwBbBeJzg4GCdOnICnpyfWrVuHKlWq4K+//vpHZRXn4MGDuHHjBpRKJbS0tOQFudq3b4/GjRvL6X744QekpKQgMTERf//9N9q0aQMAqFSpEoAXXwp8++23Kl8iREVFISYmRuULiVefb61atRAXF4fx48cjIyMDHTt2RIcOHd7oPRIREb1vXI2ZiEhNRMQm4/bjDNgo9Qtd3fdlkiTBRqmPW2XKI/XiMQDA2bNnkZeXh+nTp8s9h+vXr3/r7S5MREQEAgIC5EWg0tLSEB8fX6oy3NzcsGzZMjx69KhEvbsA4O7uDnd3d4wcORL169fH6tWr8dlnn8HNzQ0HDhxAr169CuRxdnZGTk4OTp48CU9PTwBAcnIyoqOjVXqvX/bzzz+jb9++KueqV6+OmTNnws/PT+W8JEmwtrYGAKxZswa2traoVasWgBdB65UrV+Dg4FCi+3uZsbExOnXqhE6dOqFDhw7w9fUt1bMiIiL60DHYJSJSA0II7Ln0YthtYT26z9NScGj+SDg2/BKmtg7Q1jPA3/FXkXBoDRw9GkEIAQcHB2RnZ2Pu3Lnw8/NDREQEFi1a9K5vBQDg6OiITZs2wc/PD5Ik4bfffit0YanX6dKlCyZNmoS2bdti8uTJsLKywvnz52FtbY369eurpI2Li8OSJUvw5ZdfwtraGtHR0YiJiUGPHj0AAKNHj0bTpk1RuXJldO7cGTk5Odi1axdGjBgBR0dHtGnTBt988w0WL14MIyMj/Pzzz7CxsZF7Yl+VvyL1qypUqICKFSvKx7///jt8fX2hoaGBTZs2YcqUKVi/fj00NTUBACNGjMBnn32GwYMHo2/fvjA0NMSVK1ewb98+zJs3r8hnM2PGDFhZWcHd3R0aGhrYsGEDLC0toVQqS/WMiYiIPmQcxkxEpAbSMnNw8+EzmOgV/h2mtq4BzCu54nLYGuya/C02/9oF5zYtRkWvL1HJbyieZeWiRo0amDFjBqZOnQpXV1eEhoa+t+1oZsyYgTJlysDT0xN+fn7w8fGRezNLSkdHB2FhYShXrhxatmyJ6tWrY8qUKXKg+DIDAwNcu3YN7du3R5UqVdCvXz8MGjQI3377LQCgcePG2LBhA7Zt24aaNWuiSZMmOHXqlJw/ODgYtWvXRuvWrVG/fn0IIbBr164Cw6xLa/fu3WjYsCE8PDywc+dObN26FW3btpWvu7m54fDhw7h+/ToaNmwId3d3jBo1Su4JLoqRkRGmTZsGDw8P1KlTB/Hx8di1a5fco09ERKQOJFGSiVYke/LkCUxMTJCamgpjY+P33RwiIgDA32mZ6B1yGnpaGjDSK3mA9fR5Np7n5GF5QB2UVegWn4GIiIhkjA0+bPwKl4hIDehqaUBTkpCbV7rvL3PzBDQlCXraBXs7iYiIiD5mDHaJiNSAQlcLlcwN8eR5TqnypT7PQSVzQxjqMNglIiIi9cJgl4hIDUiSBF9XKwgA2bklW8gpP10LV6tiV28mIiIi+tgw2CUiUhNeDmYoX0Yfd1Iyit33VgiBuynPUb6MPjwdzN5RC4mIiIjeHQa7REVo3Lgxhg0bpjb1AEB4eDgkSUJKSkqJ84wZMwY1a9Z8bZp3eQ9UNAMdLQR+4QQzhS4SHqUX2cObnZuHhEfpMFXoIPALJxjocBc6IiIiUj8MdumTERAQAEmS0L9//wLXBg0aBEmSEBAQIJ/btGkTxo8f/9bbVVw9ISEhkCQJkiRBU1MTZcqUQb169TBu3Dikpqa+9faVxLt6VlQ8VxsTjGpdDbamBrib+hwJj9KRkp6Fp8+zkZKehYRH6bib+hy2pgYY1boaXG1M3neTiYiIiN4KBrv0SbG1tcXatWuRkZEhn3v+/DlWr16NChUqqKQ1NTWFkZHRW29TSeoxNjZGUlISbt++jePHj6Nfv35YuXIlatasibt37771NhbnXT0rKhlXGxMs8K+Fn32rokZ5E+QJ4HlOHvIEUKO8CX72rYoF/rUY6BIREZFaY7BLak0IgafPs/F3Wiayc/NQq1Yt2NraYtOmTXKaTZs2oUKFCnB3d1fJ++rQ3FWrVsHDwwNGRkawtLRE165d8eDBA/l6/hDhvXv3wt3dHfr6+mjSpAkePHiA3bt3w9nZGcbGxujatSvS09OLrKcwkiTB0tISVlZWcHZ2Rp8+fXD8+HGkpaVh+PDhcrrMzEwMHToU5cqVg56eHho0aIDTp08XWW5ISAiUSiW2bNkCR0dH6OnpwcfHB7du3SqQdtWqVbC3t4eJiQk6d+6Mp0+fFnkP9vb2mDRpEnr37g0jIyNUqFABS5Yska9nZWVh8ODBsLKygp6eHuzs7DB58uTXPgMqHQMdLTSrZoGgr2tgVd96WB5QB6v61kPQ1zXQrJoFhy4TERGR2mOwS2opPSsH+67cR+CGKPT44xR6h5zG0Zi/celOKrxafo1lfyyX0y5fvhy9evUqtszs7GyMHz8eUVFR2LJlC+Lj41WGPecbM2YM5s2bh+PHj+PWrVvo2LEjZs2ahdWrV2Pnzp0ICwvD3Llz//U9litXDv7+/ti2bRtyc3MBAMOHD8fGjRuxYsUKnDt3Dg4ODvDx8cGjR4+KLCc9PR0TJ07EypUrERERgZSUFHTu3FklzY0bN7Blyxbs2LEDO3bswOHDhzFlypTXtm/69Onw8PDA+fPnMXDgQAwYMADR0dEAgDlz5mDbtm1Yv349oqOjERoaCnt7+3/3QKhQkiRBoauFsgpdKHS1uOoyERERfTL41T6pnUt3UhEUFo3bjzMgATDW04K2pgYkAE8ysnHFsAYijk5E2MmLcLI0RkREBNauXYvw8PDXltu7d2/535UqVcKcOXNQp04dpKWlQaFQyNcmTJgALy8vAECfPn0wcuRI3LhxA5UqVQIAdOjQAYcOHcKIESP+9b1WrVoVT58+RXJyMgwNDbFw4UKEhISgRYsWAIClS5di3759+OOPP/DTTz8VWkZ2djbmzZuHevXqAQBWrFgBZ2dnnDp1CnXr1gUA5OXlISQkRB6q3L17dxw4cAATJ04ssm0tW7bEwIEDAQAjRozAzJkzcejQITg5OSExMRGOjo5o0KABJEmCnZ3dv34WREREREQvY88uqZVLd1IxdvsV3HqUDmsTPVQwNYDSQAdGetrQ0dKAvo4m7G0sYeZcD99PmI2psxeiVatWKFu2bLFlnz17Fn5+fqhQoQKMjIzg7e0NAEhMTFRJ5+bmJv/bwsICBgYGcqCbf+7l4c//Rv72MpIk4caNG8jOzpYDbQDQ1tZG3bp1cfXq1SLL0NLSQp06deTjqlWrQqlUquSxt7dXmZNrZWVV7D28/Bzyh2Hn5wkICEBkZCScnJwwdOhQhIWFlfCOiYiIiIhKhsEuqY30rBwEhUXj0bNM2JkaQFuz8F9vbU0N1GjSFjcjdmLVqpXo2r1nsWU/e/YMPj4+MDY2RmhoKE6fPo3NmzcDeDH/VKV8bW3535IkqRznn8vLK3xLmNK6evUqjI2NYWb2dvdJ/Sf38Lo8tWrVQlxcHMaPH4+MjAx07NgRHTp0eLONJiIiIqJPGoNdUhsRscm4/TgDNkr9YucllnfzhCRykZ2dDcNKtYst+9q1a0hOTsaUKVPQsGFDVK1a9Y31zv5TDx48wOrVq9G2bVtoaGigcuXK0NHRQUREhJwmOzsbp0+fRrVq1YosJycnB2fOnJGPo6OjkZKSAmdn57fafmNjY3Tq1AlLly7FunXrsHHjxtfOLSYiIiIiKg3O2SW1IITAnktJAFBkj+7LNDQ00X7SOtx6nIGwqw/whavVa9NXqFABOjo6mDt3Lvr3749Lly69031lhRC4d+8ehBBISUnBiRMnMGnSJJiYmMgLRRkaGmLAgAH46aefYGpqigoVKmDatGlIT09Hnz59iixbW1sbQ4YMwZw5c6ClpYXBgwfjs88+k+frvg0zZsyAlZUV3N3doaGhgQ0bNsDS0hJKpfKt1UlEREREnxYGu6QW0jJzcPPhM5jolfxXWkdfATOhg5sPn+FZVu5r05qbmyMkJAT/+c9/MGfOHNSqVQtBQUH48ssv/23TS+TJkyewsrKCJEkwNjaGk5MTevbsie+++w7GxsZyuilTpiAvLw/du3fH06dP4eHhgb1796JMmTJFlm1gYIARI0aga9euuHPnDho2bIg//vjjrd6PkZERpk2bhpiYGGhqaqJOnTrYtWsXNDQ42ISIiIiI3gxJ5K9wQyXy5MkTmJiYIDU1VSXIoPfr77RM9A45DT0tDRjpaRef4X+ePs/G85w8LA+og7IK3bfYwg9TSEgIhg0bhpSUlPfdFCIiIqKPDmODDxu7UUgt6GppQFOSkJtXuu9ucvMENCUJetqab6llRERERET0PjDYJbWg0NVCJXNDPHmeU6p8qc9zUMncEIY6DHaJiIiIiNQJg11SC5IkwdfVCgJAdm7JtvXJT9fC1arY1ZvVVUBAAIcwExEREZFaYrBLasPLwQzly+jjTkoGipuKLoTA3ZTnKF9GH54Ob3ePWiIiIiIievcY7JLaMNDRQuAXTjBT6CLhUXqRPbzZuXlIeJQOU4UOAr9wgoEOFyUnIiIiIlI3/JRPasXVxgSjWldDUFg0bj/OAACY6GlBU+PF4lWp/5vTa2tqgMAvnOBqY/I+m0tERERERG8Jg11SO642JljgXwvHY5Ox+1ISbj58huycPGhKEmqUN0ELVyt4OpixR5eIiIiISI3x0z6pJQMdLTSrZoGmzuXwLCsXz7NzoaetCUMdzU92MSoiIiIiok8Jg11Sa5IkQaGrBYUuf9WJiIiIiD4lXKCKiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIiIiIitcNgl4iIiIiIiNQOg10iIiIiIiJSOwx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIioo9WQEAA2rZtW+B8eHg4JElCSkrKO2uLJEnYsmXLW60jPj4ekiS99hUSEvJW20D0sdB63w0gIiIiIqKSsbW1RVJSknwcFBSEPXv2YP/+/fI5ExOT99E0og8Oe3aJiIiI6KMihMDT59n4Oy0T2bl5Jc63ceNGuLi4QFdXF/b29pg+fbrK9cJ6ZpVKpdxTmpWVhcGDB8PKygp6enqws7PD5MmTAQD29vYAgK+++gqSJMnHALBw4UJUrlwZOjo6cHJywqpVqwrUu2zZMnz11VcwMDCAo6Mjtm3bVug9aGpqwtLSUn4pFApoaWnJx+XKlcOsWbNQsWJF6Ovro0aNGvjzzz/l59asWTP4+PhACAEAePToEcqXL49Ro0YBAHJzc9GnTx85v5OTE2bPnq3Shvze9KCgIFhZWcHMzAyDBg1Cdna2nGbBggVwdHSEnp4eLCws0KFDh2J+OkRv3kcV7B45cgR+fn6wtrYu9M1ICIFRo0bBysoK+vr6aNasGWJiYlTSPHr0CP7+/jA2NoZSqUSfPn2Qlpb2Du+CiIiIiP6J9Kwc7LtyH4EbotDjj1PoHXIaR2P+xqU7qdh35T7Ss3KKzHv27Fl07NgRnTt3xsWLFzFmzBj89ttvpRryO2fOHGzbtg3r169HdHQ0QkND5aD29OnTAIDg4GAkJSXJx5s3b8Z3332HH3/8EZcuXcK3336LXr164dChQypljx07Fh07dsSFCxfQsmVL+Pv749GjR6V7QAAmT56MlStXYtGiRbh8+TK+//57dOvWDYcPH4YkSVixYgVOnz6NOXPmAAD69+8PGxsbOdjNy8tD+fLlsWHDBly5cgWjRo3Cf/7zH6xfv16lnkOHDuHGjRs4dOgQVqxYgZCQEPlZnjlzBkOHDsW4ceMQHR2NPXv2oFGjRqW+F6J/66Maxvzs2TPUqFEDvXv3Rrt27QpcnzZtGubMmYMVK1agYsWK+O233+Dj44MrV65AT08PAODv74+kpCTs27cP2dnZ6NWrF/r164fVq1e/69shIiIiohK6dCcVQWHRuP04AxIAYz0taGtqQAJw89wRtHC3hyRJ0NbUgIb0oofyZTNmzEDTpk3x22+/AQCqVKmCK1eu4Pfff0dAQECJ2pCYmAhHR0c0aNAAkiTBzs5OvmZubg7gRU+wpaWlfD4oKAgBAQEYOHAgAOCHH37AX3/9haCgIHz++edyuoCAAHTp0gUAMGnSJMyZMwenTp2Cr69viZ9RZmYmJk2ahP3796N+/foAgEqVKuHYsWNYvHgxvL29YWNjg8WLF6NHjx64d+8edu3ahfPnz0NL60VYoK2tjbFjx8plVqxYESdOnMD69evRsWNH+XyZMmUwb948aGpqomrVqmjVqhUOHDiAb775BomJiTA0NETr1q1hZGQEOzs7uLu7l/g+iN6UjyrYbdGiBVq0aFHoNSEEZs2ahV9//RVt2rQBAKxcuRIWFhbYsmULOnfujKtXr2LPnj04ffo0PDw8AABz585Fy5YtERQUBGtr63d2L0RERERUMpfupGLs9it49CwTNkp9aGv+/+BEHS0NWFX1QB3/n3D/aSbKGOhg8OcOeJxwBd26dZPTXb16Vf6MmM/LywuzZs1Cbm4uNDU1i21HQEAAmjdvDicnJ/j6+qJ169b44osvXpvn6tWr6NevX4F6Xx0a7ObmJv/b0NAQxsbGePDgQbFtellsbCzS09PRvHlzlfNZWVkqwebXX3+NzZs3Y8qUKVi4cCEcHR1V0s+fPx/Lly9HYmIiMjIykJWVhZo1a6qkcXFxUXlmVlZWuHjxIgCgefPmsLOzQ6VKleDr6wtfX195iDbRu/RRDWN+nbi4ONy7dw/NmjWTz5mYmKBevXo4ceIEAODEiRNQKpVyoAsAzZo1g4aGBk6ePFlouZmZmXjy5InKi4iIiIjejfSsHASFRePRs0zYmRqoBLr5tHT1YGZtB+cqjsg0MMf6mGyYlbMspLTXkyRJnsua7+V5qLVq1UJcXBzGjx+PjIwMdOzY8Y3NRdXW1i7Qlry8ks9HBiBPzdu5cyciIyPl15UrV+R5uwCQnp6Os2fPQlNTs8CUv7Vr1yIwMBB9+vRBWFgYIiMj0atXL2RlZZW4vUZGRjh37hzWrFkDKysrjBo1CjVq1HinK2MTAWoU7N67dw8AYGFhoXLewsJCvnbv3j2UK1dO5bqWlhZMTU3lNK+aPHkyTExM5Jetre1baD0RERERFSYiNhm3H2fARqkPSZJem1aSJNgo9XH7cQYu30lVuebs7IyIiAjVsiMiUKVKFbmH0tzcXGWl45iYGKSnp6vkMTY2RqdOnbB06VKsW7cOGzdulOfWamtrFxg+XVS91apVK8Hdl061atWgq6uLxMREODg4qLxe/gz7448/QkNDA7t378acOXNw8OBBlbZ5enpi4MCBcHd3h4ODA27cuFHqtmhpaaFZs2aYNm0aLly4gPj4eJV6iN6Fj2oY8/swcuRI/PDDD/LxkydPGPASEdEHLSAgACkpKW99v8/iSJKEzZs3F7oHKlFJCCGw59KL4LOwHt3C5Kc7Gae6uNOPP/6IOnXqYPz48ejUqRNOnDiBefPmYcGCBXKaJk2aYN68eahfvz5yc3MxYsQIlR7MGTNmwMrKCu7u7tDQ0MCGDRtgaWkJpVIJ4MWKzAcOHICXlxd0dXVRpkwZ/PTTT+jYsSPc3d3RrFkzbN++HZs2bVLZKuhNMTIyQmBgIL7//nvk5eWhQYMGSE1NRUREBIyNjdGzZ0/s3LkTy5cvx4kTJ1CrVi389NNP6NmzJy5cuIAyZcrA0dERK1euxN69e1GxYkWsWrUKp0+fRsWKFUvcjh07duDmzZto1KgRypQpg127diEvLw9OTk5v/J6JXkdtenbzFwK4f/++yvn79+/L1ywtLQvMfcjJycGjR49UFhJ4ma6uLoyNjVVeRET04cvfGuNd8/HxgaamprwSq7q6d+8ehgwZgkqVKkFXVxe2trbw8/PDgQMH3nfTSI2kZebg5sNnMNErXf+MiZ4W7qZkqJyrVasW1q9fj7Vr18LV1RWjRo3CuHHjVBanmj59OmxtbdGwYUN07doVgYGBKvNMjYyMMG3aNHh4eKBOnTqIj4/Hrl27oKGhIefft28fbG1t5Tmybdu2xezZsxEUFAQXFxcsXrwYwcHBaNy48T97KMUYP348fvvtN0yePBnOzs7w9fXFzp07UbFiRTx8+BB9+vTBmDFjUKtWLQAvVoG2sLBA//79AQDffvst2rVrh06dOqFevXpITk6WF9cqKaVSiU2bNqFJkyZwdnbGokWLsGbNGri4uLzx+yV6HUm8OjHhI/Hqt8VCCFhbWyMwMBA//vgjgBe9sOXKlUNISIi8QFW1atVw5swZ1K5dGwAQFhYGX19f3L59u0QLVD158gQmJiZITU1l4EtE9IERQiAtMweZOXn4bsA3ePb0yTvt3UxMTISLiwt69+6NrKwsLFy48J3V/bK33bMbHx8PLy8vKJVKjBs3DtWrV0d2djb27t2LJUuW4Nq1awDeTs9uVlYWdHR03lh576ps+mf+TstE75DT0NPSgJGedvEZ/ufp82w8z8nD8oA6KKvQfYstpE8dY4MP20fVs5uWliZPtAdeLEoVGRmJxMRESJKEYcOGYcKECdi2bRsuXryIHj16wNraWv4jm//t1jfffINTp04hIiICgwcPRufOnbkSMxHRR+yf7L15+PBh1K1bF7q6urCyssLPP/+MnJz/T/fnn3+ievXq0NfXh5mZGZo1a4Znz569th3BwcFo3bo1BgwYgDVr1iAjQ7VnqXHjxhg6dCiGDx8OU1NTWFpaYsyYMSpprl27hgYNGkBPTw/VqlXD/v37C+wtf+vWLXTs2BFKpRKmpqZo06YN4uPji2xXXl4eJk+ejIoVK0JfXx81atRQWazm8ePH8Pf3h7m5OfT19eHo6Ijg4OAiyxs4cCAkScKpU6fQvn17VKlSBS4uLvKWKi/7+++/5VVYHR0dsW3bNvlabm4u+vTpI7fLycmpwAq1+T30EydOhLW1tTwM8vjx46hZsyb09PTg4eGBLVu2QJIk+TMCAFy6dAktWrSAQqGAhYUFunfvjr///lvl5zF48GAMGzYMZcuWhY+PD4QQGDNmDCpUqABdXV1YW1tj6NChRT6Ll40ZM6bAirUfmsaNG2PYsGHysb29PWbNmiUfv/q79r7pamlAU5KQm1e6vpncPAFNSYKedvErLBOR+vqo5uyeOXNGZT+y/Lm0PXv2REhICIYPH45nz56hX79+SElJQYMGDbBnzx55j10ACA0NxeDBg9G0aVNoaGigffv28qbaRET08Xnd3ptPMrIxdc81lC+jj8AvnOBqYwIAuHPnDlq2bImAgACsXLkS165dwzfffAM9PT2MGTMGSUlJ6NKlC6ZNm4avvvoKT58+xdGjRwus0voyIQSCg4Mxf/58VK1aFQ4ODvjzzz/RvXt3lXQrVqzADz/8gJMnT+LEiRMICAiAl5cXmjdvjtzcXLRt2xYVKlTAyZMn8fTpU3m0Ur7s7Gz4+Pigfv36OHr0KLS0tDBhwgT4+vriwoULhfZMTp48Gf/973+xaNEiODo64siRI+jWrRvMzc3h7e2N3377DVeuXMHu3btRtmxZxMbGFgjU8z169Ah79uzBxIkTYWhoWOB6/tzFfGPHjsW0adPw+++/Y+7cufD390dCQgJMTU2Rl5eH8uXLY8OGDTAzM8Px48fRr18/WFlZqezneeDAARgbG2Pfvn0AXvSk+Pn5oWXLlli9ejUSEhJUAjgASElJQZMmTdC3b1/MnDkTGRkZGDFiBDp27KiySM7ixYthb28vLyC0ceNGzJw5E2vXroWLiwvu3buHqKioQp/Fx2jTpk0FVtF9k+Lj41GxYkWcP3/+jQT+Cl0tVDI3xIXbqVAalLzXPfV5DmqUN4GhDoNdok/ZRxXsNm7c+LUfNCRJwrhx4zBu3Lgi05iammL16tVvo3lERPSOFbf3JnQ0YW2ih1uP0jFuxxWMal0NrjYmWLBgAWxtbTFv3jxIkoSqVavi7t27GDFiBEaNGoWkpCTk5OSgXbt2sLOzAwBUr179tW3Zv38/0tPT4ePjAwDo1q0b/vjjjwLBrpubG0aPHg0AcHR0xLx583DgwAE0b94c+/btw40bNxAeHi6vJTFx4kSVPTPXrVuHvLw8LFu2TF6ZNjg4GEqlEuHh4QX2/MzMzMSkSZOwf/9+1K9fHwBQqVIlHDt2DIsXL4a3tzcSExPh7u4ub81nb29f5H3GxsZCCIGqVau+9nnkCwgIQJcuXQAAkyZNwpw5c3Dq1Cn4+vpCW1sbY8eOldNWrFgRJ06cwPr161WCXUNDQyxbtkwO5BctWgRJkrB06VK5B/zOnTv45ptv5Dzz5s2Du7s7Jk2aJJ9bvnw5bG1tER0dDWu7SsjOzYORkRFcXFzkHuOdO3fC0tISzZo1g7a2NipUqIC6deuW6F4/Bqampu+7CaUiSRJ8Xa0QdTsV2bl5JVqkKjv3xfY3LVytXrt6c25uLiRJkufbEpH64f9uIiL6KJVk703gxcqsdqYGSE7LRFBYNNKzcnD16lXUr19f5YOwl5cX0tLScPv2bdSoUQNNmzZF9erV8fXXX2Pp0qV4/Pjxa9uzfPlydOrUCVpaL75H7tKlCyIiIgps2eHm5qZybGVlJS+eGB0dDVtbW5VFE18NtKKiohAbGwsjIyMoFAooFAqYmpri+fPnhW4PEhsbi/T0dDRv3lxOr1AosHLlSjn9gAEDsHbtWtSsWRPDhw/H8ePHi7zP0i718fL9GhoawtjYWGWxyPnz56N27dowNzeHQqHAkiVLkJiYqFJG9erVVXqso6Oj4ebmpjJyq7DndOjQIZV7zg/QR4bsQ48/TiH63lNkaRnKw923bN+JNWvWICYmBnp6eqhQoQIWLlyoMrz99u3b6NKlC0xNTWFoaAgPDw+cPHmy0Hu/ceMGKlWqhMGDB0MIgYSEBPj5+aFMmTIwNDSEi4sLdu3aJacvbmh9ccPgu3btik6dOqm0ITs7G2XLlsXKlSvlMl7tBX+d0g6Zf1VJhqrn5ORg6NChUCqVMDMzw4gRI9CzZ095GpqXgxn+mtQFf21bpfL7t2WUP85tWSIfX9obik2/dkHogMY4MaEj1s8eLe87CwAhISFQKpXYtm2byhY94eHhqFu3LgwNDaFUKuHl5YWEhIQS3yMRfbgY7BIR0Ufpn+69eTw2udiyNTU1sW/fPuzevRvVqlXD3Llz4eTkhLi4uELTP3r0CJs3b8aCBQugpaUFLS0t2NjYICcnB8uXL1dJ++oQUkmSkJeXV2yb8qWlpaF27dryGhb5r+vXr6Nr166Fpgde9Fi+nP7KlSvyvN0WLVogISEB33//Pe7evYumTZsiMDCw0PodHR0hSZK8CFVxXne/a9euRWBgIPr06YOwsDBERkaiV69eyMrKUslT2HDp4qSlpcHPz0++3/V7juKLX1eg/sj/IsXYARoSoCFJ0NDUlIe7z95zEf79huLChQuYMWMGtLS0MHToUDRs2BDZ2dlIS0uDt7c37ty5g23btiEqKgrDhw8v9Od34cIFNGjQAF27dpVHEAwaNAiZmZk4cuQILl68iKlTp0KhUAD4/6H1derUQVRUFBYuXIg//vgDEyZMUCl3xYoVMDQ0xMmTJzFt2jSMGzdOHt7t7++P7du3qwR4e/fuRXp6Or766qtSP8P8IfNGRkY4evQoIiIioFAo4OvrW+BnVJSXh6pfuXIFo0aNwn/+8x+sX79eTjN16lSEhoYiODgYERERePJEdWE5Ax0tmOhrwUBXCwmP0uWe2wJ1CQkV/QbBd3Qo5ixaiiOHwzF8+HCVNOnp6Zg6dSqWLVuGy5cvw9TUFG3btoW3tzcuXLiAEydOoF+/fsW+pxDRx+GjGsZMREQE/Lu9N3dfSkLVqlWxadMmCCHkD7UREREwMjJC+fLlAbwIyry8vODl5YVRo0bBzs4OmzdvVtl7PV9oaCjKly9fYGGfsLAwTJ8+HePGjYOmZvFzB52cnHDr1i3cv38fFhYWAFBgC6NatWph3bp1KFeuXIlW/ny5B8vb27vIdObm5ujZsyd69uyJhg0b4qeffkJQUFCBdKampvDx8cH8+fMxdOjQAoFoSkpKgXm7RYmIiICnp6fKtiaF9U6/ysnJCf/973+RmZkJXd0XK+0W9pw2btwIe3t7XLv/DMGXHiJV2wwOlf9/uLumhgQNSYL+/4a736n0GY7n6aJZGVt899138qJdf/31Fy5evIgzZ87g4cOHOH36tDwc2MHBoUD7jh8/jtatW+OXX35RmXOdmJiI9u3by0PiK1WqJF8rbmh9/lDb1w2D9/HxgaGhITZv3iwPn1+9ejW+/PJLGBkZFftcX1XaIfOFKclQ9blz52LkyJFyQD5v3jyVHm/gxf9fHxcL3Dc1wO3HL+aT5+YJZOXkISU9C6nPc2BSt63K/HwTjSz0799fZR/d7OxsLFiwADVq1ADw4ouq1NRUtG7dGpUrVwbwYkFTIlIP7NklIqKPTkn33szKeIbkxOvySzyMw6XrNxHQ91vcunULQ4YMwbVr17B161aMHj0aP/zwAzQ0NHDy5ElMmjQJZ86cQWJiIjZt2oSHDx8W+SH4jz/+QIcOHeDq6qry6tOnD/7++2/s2bOnRPfVvHlzVK5cGT179sSFCxcQERGBX3/9FQDkYMPf3x9ly5ZFmzZtcPToUcTFxSE8PBxDhw7F7du3C5RpZGSEwMBAfP/991ixYgVu3LiBc+fOYe7cuVixYgUAYNSoUdi6dStiY2Nx+fJl7Nix47Uf+OfPn4/c3FzUrVsXGzduRExMDK5evYo5c+bI84JLwtHREWfOnMHevXtx/fp1/PbbbyXan7hr167Iy8tDv379cPXqVezdu1cOzPOf06BBg/Do0SN07NQZPy/ejNsJN6F19wL+CpmAvLzcAmVqa2pAmf039k7qA4+q9lAoFPJ8bR0dHdjZ2SEyMhLu7u6vnfeamJiI5s2bY9SoUQUWFxs6dCgmTJgALy8vjB49GhcuXJCvFTe0Pt/rhsFraWmhY8eOCA0NBQA8e/YMW7duhb+/f7HPtDClHTJflNcNVU9NTcX9+/dVhqFramrKW0Sq3KuJPhb418LPvlVRo7wJBICcPIE8AdQob4IvTB4gfuXP8KlbDUZGRujevTuSk5ORnp4ul6Gjo6PyDE1NTREQEAAfHx/4+flh9uzZSEpK+gdPi4g+RAx2iYjoo5OZk4dcIaCp8fqhhveuncXW0d3k18EpvXBt13KYlrPErl27cOrUKdSoUQP9+/dHnz595MDS2NgYR44cQcuWLVGlShX8+uuvmD59Olq0aFGgjrNnzyIqKgrt27cvcM3ExARNmzbFH3/8UaL70tTUxJYtW5CWloY6deqgb9+++OWXXwBAnp9qYGCAI0eOoEKFCmjXrh2cnZ3Rp08fPH/+vMie3vHjx+O3337D5MmT5W34du7ciYoVKwJ4EQCMHDkSbm5uaNSoETQ1NbF27doi21mpUiWcO3cOn3/+OX788Ue4urqiefPmOHDgQKn2Fv7222/Rrl07dOrUCfXq1UNycrJKL29RjI2NsX37dkRGRqJmzZr45ZdfMGrUKJXnZG1tjYiICDx4koG9QUNwekYfnFwzEzoGCkhS4R9/DswOhKbIgaaBMXKFkOeH/vLLLzAzM4O+vn6xbTM3N0fdunWxZs0aPHnyROVa3759cfPmTXTv3h0XL16Eh4cH5s6dW2yZLytuGLy/vz8OHDiABw8eYMuWLdDX14evr2+p6shX2iHzhSnpUPXiaGhoQAgBAx0tNKtmgaCva8DaWAdtalpjVd96GFzHBKMGdYd7zRrYuHEjzp49i/nz5wOASl36+gWnPQQHB+PEiRPw9PTEunXrUKVKlQJbaBHRx4nDmImI6KNTkr03G/UdjUZ9R6ucS0nPQp4A9LQ14e3tjVOnThWa19nZucS9sbVr137tok0vD8cMDw8vcP3Voc9Vq1bFsWPH5OP8LXFeHi5raWkp98oWJiQkROVYkiR89913+O677wpN/+uvv8qBfklZWVlh3rx5mDdvXpFpCnsuKSkp8r91dXURHBxcYE/fyZMny/9+9V7yeXp6qmwJFBoaKq+enM/BwQH1vpkIvRapsDM1KFBGy58X4ciyschKf4rnaSlIvZeAliMXI7OsE2qUN0Fbq6do1KiR3BPo5uaGZcuW4dGjR0X27urr62PHjh1o2bIlfHx8EBYWpjKE2NbWFv3790f//v0xcuRILF26FEOGDIGzszM2btz42qH1JeHp6QlbW1usW7cOu3fvxtdff/2Ptxoq7ZD5whQ3VN3ExAQWFhY4ffo0GjVqBODFolbnzp1T2brI3Nxcpcf16dOnSIiPg4GOFhS6Wth77hzy8vIwffp0ecj3y/OCi+Pu7g53d3eMHDkS9evXx+rVq/HZZ5/9o3smog8He3aJiOijk7/35pPnOcUnfknq8xxUMjf8oPfe3Lx5M/bt24f4+Hjs378f/fr1g5eXlzyfkF5YuXIljh07hri4OGzZskXeQ/fl3teSDncHAF0DY+gqTBAdvgWaT+7h5LEj+P6V+dldunSBpaUl2rZti4iICNy8eRMbN27EiRMnVNIZGhpi586d0NLSQosWLeQFo4YNG4a9e/ciLi4O586dw6FDh+Th4gMHDnzt0PrS6Nq1KxYtWoR9+/b94yHMQOmHzBemJEPVhwwZgsmTJ2Pr1q2Ijo7Gd999h8ePH6v0wDZp0gSrVq3C0aNHcfHiRfTs2VNlHryDgwOys7Mxd+5c3Lx5E6tWrcKiRYuKbV9cXBxGjhyJEydOICEhAWFhYYiJieG8XSI1wWCXiIg+Ovl7bwqgyJVZX1XSvTfft6dPn2LQoEGoWrUqAgICUKdOHWzduvV9N+uDc+/ePXTr1g3Ozs74/vvv8fXXX2PJkiUqaUoy3F2IPGhoakHS0EDj/hORnHAN+yf2wMWNc/Db+EkqaXV0dBAWFoZy5cqhZcuWqF69OqZMmVLo4mMKhQK7d++GEAKtWrXCs2fPkJubi0GDBslDyatUqSIvnmRjY/PaofWl4e/vjytXrsDGxgZeXl6lzp/vnwyZzx9Snb8FV0mGqo8YMQJdunRBjx49UL9+fSgUCvj4+KhsLTVy5Eh4e3ujdevWaNWqFdq2bavyBVCNGjUwY8YMTJ06Fa6urggNDVUZIfC6e7x27Rrat2+PKlWqoF+/fhg0aBC+/fbbUj8vIvrwSKK0G+Z94p48eQITExOkpqb+4yE9RET076Vn5WBg6DncepQOO1OD1wawQggkPspAedMXC9wY6HAWz6fg6fNs9PjjFDQkQGmgU2iavdOHwricLep3/0k+lz/cfVXfelDo8nelNP766y/Ur18fDx8+RNmyZf9RGXl5eXB2dkbHjh0xfvz4N9xCojeLscGHjT27RET0UTLQ0ULgF04wU+i+du/N7Nw8JDxKh6lCB4FfODHQ/YS8brh75rMnSIw8invXzsHapY7KtY9huPuHJicnB7Gxsfj9999Ro0aNUgW6CQkJWLp0Ka5fv46LFy9iwIABiIuLK/EiWERERWGwS0REHy1XGxOMal0NtqYGuJv6HAmP0pGSnoWnz7ORkp6FhEfpuJv6HLamBhjVuhpcbUzed5PpHXrdcPejy8fj+MqpcPHtigru/7//8Mcy3P1Dc+nSJbi5uSEpKQkrV64sVV4NDQ2EhISgTp068PLywsWLF7F//37OmyWif43DmEuJQxWIiD486Vk5OB6bjN2XknDz4bMX8zQlCZXMDdHC1QqeDmbs0f1Ecbg7Eb1NjA0+bAx2S4m/0EREHy4hBJ5l5eJ5di70tDVhqKPJ3jnCpTupGLfjCpLTMmGj1Ie2ZsGBbdm5ebiTkgEzhS5HARBRiTE2+LDxK0siIlIbkiRBoavFRYVIRf5w96CwaNx+nAEAMNHTgqbGi72aU/83p9fW1ACBXzgx0CUiUhP8NEBERERqz9XGBAv8a6kMd8/OyYOmJKFGeRMOdyciUkN8RyciIqJPgoGOFppVs0BT53Ic7k5E9AlgsEtERESfFA53JyL6NHDrISIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIiIiIitcNgl4iIiIiIiNQOg10iIiIiIiJSOwx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiNSSJEmvfY0ZM+Z9N7HEQkJCVNquUChQu3ZtbNq06a3XPWbMGJW6TUxM0LBhQxw+fPit101ERET0bzDYJSK1IoTA0+fZuBQbj5i4RNy9exezZs2CsbExkpKS5FdgYOD7bmqpvNz+8+fPw8fHBx07dkR0dPRbr9vFxUWu+8SJE3B0dETr1q2Rmpr61uv+0GVlZb3vJhAREVERGOwSkVpIz8rBviv3EbghCj3+OIWRu2/hp52JCDp6H7fTXvT0WlpawtLSEs+ePYO/vz8sLCygUChQp04d7N+/X6U8e3t7TJgwAT169IBCoYCdnR22bduGhw8fok2bNlAoFHBzc8OZM2fkPCEhIVAqldiyZQscHR2hp6cHHx8f3Lp1S05z48YNtGnT5rV1F+bl9js6OmLChAnQ0NDAhQsX5DSrVq2Ch4cHjIyMYGlpia5du+LBgwcAXnwJ4ODggKCgIJVyIyMjIUkSYmNji6xbS0tLrrtatWoYN24c0tLScP36dQBAfHw8JElCZGSknCclJQWSJCE8PFw+d/nyZbRu3RrGxsYwMjJCw4YNcePGDfn68uXL4eLiAl1dXVhZWWHw4MHytRkzZqB69eowNDSEra0tBg4ciLS0tALPfu/evXB2doZCoYCvry+SkpJU7mXZsmVwdnaGnp4eqlatigULFqhcv3XrFjp27AilUglTU1O0adMG8fHx8vWAgAC0bdsWEydOhLW1NZycnAAACxYskH/mFhYW6NChQ5HPk4iIiN4NBrtE9NG7dCcVA0PPYeqea7hwOxUaEqCnpQENCbhwOxU7LyYhPSsXl+686IlMS0tDy5YtceDAAZw/fx6+vr7w8/NDYmKiSrkzZ86El5cXzp8/j1atWqF79+7o0aMHunXrhnPnzqFy5cro0aMHhBBynvT0dEycOBErV65EREQEUlJS0LlzZ/l6Set+ndzcXKxYsQIAUKtWLfl8dnY2xo8fj6ioKGzZsgXx8fEICAgA8CJY7t27N4KDg1XKCg4ORqNGjeDg4FCiujMzMxEcHAylUikHeiVx584dNGrUCLq6ujh48CDOnj2L3r17IycnBwCwcOFCDBo0CP369cPFixexbds2lTZpaGhgzpw5uHz5MlasWIGDBw9i+PDhKnWkp6cjKCgIq1atwpEjR5CYmKjSgx8aGopRo0Zh4sSJuHr1KiZNmoTffvtNfpbZ2dnw8fGBkZERjh49ioiICDlofrkH98CBA4iOjsa+ffuwY8cOnDlzBkOHDsW4ceMQHR2NPXv2oFGjRiV+NkRERPSWCCqV1NRUAUCkpqa+76YQkRDi4u0U0WHhcdEk6JDovuwv0Tv4VIGXZ69fhZaeofh60XFx8XZKoeW4uLiIuXPnysd2dnaiW7du8nFSUpIAIH777Tf53IkTJwQAkZSUJIQQIjg4WAAQf/31l5zm6tWrAoA4efJkkffwat2vyi/X0NBQGBoaCg0NDaGrqyuCg4Nf+2xOnz4tAIinT58KIYS4c+eO0NTUlNuSlZUlypYtK0JCQoosY/To0UJDQ0OuW5IkYWxsLHbv3i2niYuLEwDE+fPn5XOPHz8WAMShQ4eEEEKMHDlSVKxYUWRlZRVaj7W1tfjll19eez8v27BhgzAzM5OP859RbGysfG7+/PnCwsJCPq5cubJYvXq1Sjnjx48X9evXF0IIsWrVKuHk5CTy8vLk65mZmUJfX1/s3btXCCFEz549hYWFhcjMzJTTbNy4URgbG4snT56UuP1ERKQeGBt82NizS0QfrfSsHASFRePRs0zYmRpAW7PwtzRNDQ1oSBKS0zIRFBaNB49SEBgYCGdnZyiVSigUCly9erVA76qbm5v8bwsLCwBA9erVC5zLHyoMvBjyW6dOHfm4atWqUCqVuHr1KoAXPbslqftVRkZGiIyMRGRkJM6fP49Jkyahf//+2L59u5zm7Nmz8PPzQ4UKFWBkZARvb28AkMu2trZGq1atsHz5cgDA9u3bkZmZia+//vq1dTs5Ocl1nz17FgMGDMDXX3+tMoS7OJGRkWjYsCG0tbULXHvw4AHu3r2Lpk2bFpl///79aNq0KWxsbGBkZITu3bsjOTkZ6enpchoDAwNUrlxZPrayspJ/Ns+ePcONGzfQp08fKBQK+TVhwgR5KHVUVBRiY2NhZGQkXzc1NcXz589VhltXr14dOjo68nHz5s1hZ2eHSpUqoXv37ggNDVVpFxEREb0fWu+7AURE/1REbDJuP86AjVIfkiQVm95GqY/bjzPQe8B3uHrmGIKCguDg4AB9fX106NChwGJDLwdm+eUXdi4vL6/EbQ4MDMS+ffuKrftVGhoaKsN63dzcEBYWhqlTp8LPzw/Pnj2Dj48PfHx8EBoaCnNzcyQmJsLHx0el7L59+6J79+6YOXMmgoOD0alTJxgYGLy2bh0dHZW63d3dsWXLFsyaNQv//e9/oaHx4ksG8dJw7uzsbJUy9PX1iyz/ddeAF3OCW7dujQEDBmDixIkwNTXFsWPH0KdPH2RlZcntfzWQliRJblP+/N6lS5eiXr16Kuk0NTXlNLVr10ZoaGiBNpibm8v/NjQ0VLlmZGSEc+fOITw8HGFhYRg1ahTGjBmD06dPQ6lUvvbeiIiI6O1hsEtEHyUhBPZcerH4UFE9uq/KT/fXieMY2rcnvvrqKwAvgpyXFyH6N3JycnDmzBnUrVsXABAdHY2UlBQ4OzsDACIiIhAQEPBG6tbU1ERGRgYA4Nq1a0hOTsaUKVNga2sLAIX2vLZs2RKGhoZYuHAh9uzZgyNHjvzruvMDwaSkJLi7uwOAymJVwIvgfMWKFcjOzi4QlBoZGcHe3h4HDhzA559/XqCus2fPIi8vD9OnT5cD6/Xr15eqvRYWFrC2tsbNmzfh7+9faJpatWph3bp1KFeuHIyNjUtVvpaWFpo1a4ZmzZph9OjRUCqVOHjwINq1a1eqcoiIiOjN4TBmIvoopWXm4ObDZzDRK913diZ6WtAxtcbGTZsQGRmJqKgodO3atVS9s6+jra2NIUOG4OTJkzh79iwCAgLw2WefycGvo6MjNv2DuoUQuHfvHu7du4e4uDgsWbIEe/fuRZs2bQAAFSpUgI6ODubOnYubN29i27ZtGD9+fIFyNDU1ERAQgJEjR8LR0RH169cvtu6cnBy57piYGEyYMAFXrlyR69bX18dnn32GKVOm4OrVqzh8+DB+/fVXlTIGDx6MJ0+eoHPnzjhz5gxiYmKwatUqeeukMWPGYPr06ZgzZw5iYmJw7tw5zJ07FwDg4OCA7Oxs+d5WrVqFRYsWFdvuV40dOxaTJ0/GnDlzcP36dVy8eBHBwcGYMWMGAMDf3x9ly5ZFmzZtcPToUcTFxSE8PBxDhw7F7du3iyx3x44dmDNnDiIjI5GQkICVK1ciLy+vVAt4ERER0ZvHYJeIPkqZOXnIFQKaGsUPX36ZpoaEal8NhrGJEp6envDz84OPj4/Kqsb/hoGBAUaMGIGuXbvCy8sLCoUC69atk6/PmDEDZcqUKXXdT548gZWVFaysrODs7Izp06dj3Lhx+OWXXwC86F0NCQnBhg0bUK1aNUyZMqXANkP58of/9urVq0T3dPnyZbnumjVrYv369Vi4cCF69Oghp1m+fDlycnJQu3ZtDBs2DBMmTFApw8zMDAcPHkRaWhq8vb1Ru3ZtLF26VO7l7dmzJ2bNmoUFCxbAxcUFrVu3RkxMDACgRo0amDFjBqZOnQpXV1eEhoZi8uTJJWr7y/r27Ytly5YhODgY1atXh7e3N0JCQlCxYkUAL352R44cQYUKFdCuXTs4OzujT58+eP78+Wt7epVKJTZt2oQmTZrA2dkZixYtwpo1a+Di4lLqNhIREdGbI4mXJ1lRsZ48eQITExOkpqaWepgbEb05T59no8cfp6AhAUoDneIz/E9KehbyBLCqbz0odN/sTI6QkBAMGzYMKSkpb7TcN+3o0aNo2rQpbt26JS+yRURERKXH2ODDxp5dIvooKXS1UMncEE+e55QqX+rzHFQyN4ShjuZbatmHKzMzE7dv38aYMWPw9ddfM9AlIiIitcZgl4g+SpIkwdfVCgJAdm7J5tvmp2vhalWi1ZvVzZo1a2BnZ4eUlBRMmzbtfTeHiIiI6K3iMOZS4lAFog9HelYOBoaew61H6bAzNXhtACuEQOKjDJQ31ccC/1ow0OFi9ERERPTvMDb4sLFnl4g+WgY6Wgj8wglmCl0kPEovsoc3OzcPCY/SYarQQeAXTgx0iYiIiD4B/MRHRB81VxsTjGpdDUFh0bj9+MW+ryZ6WtDUkJCbJ5D6vzm9tqYGCPzCCa42Ju+zuURERET0jjDYJaKPnquNCRb418Lx2GTsvpSEmw+fITsnD5qShBrlTdDC1QqeDmbs0SUiIiL6hPCTHxGpBQMdLTSrZoGmzuXwLCsXz7NzoaetCUMdzU9yMSoiIiKiTx2DXSJSK5IkQaGr9cb30CUiIiKijwsXqCIiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIiIiIitcNgl4iIiIiIiNQOg10iIiIiIiJSOwx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIiIiIitcNgl4iIiIiIiNQOg10iIiIiIiJSOwx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIiIiIrXDYJeIiIiIiIjUDoNdIiIiIiIiUjsMdomIiIiIiEjtMNglIiIiIiIitcNgl4iIiIiIiNQOg10iIiIiIiJSOwx2iYiIiIiISO0w2CUiIiIiIiK1w2CXiIiIiIiI1A6DXSIiIiIiIlI7DHaJiIiIiIhI7TDYJSIiIqIPhiRJ2LJlyzut097eHrNmzXrr9QQEBKBt27ZvvR4ieoHBLhERERG9E/fu3cOQIUNQqVIl6OrqwtbWFn5+fjhw4MD7btoHITw8HJIkyS99fX24uLhgyZIl77tpRB8lrffdACIiIiJST0IIpGXmIDMnD/fuJMKnSWMolUr8/vvvqF69OrKzs7F3714MGjQI165de9/N/WBER0fD2NgYGRkZ2L59OwYMGIDKlSujadOmhabPysqCjo7OO24l0YePPbtERERE9EalZ+Vg35X7CNwQhR5/nELvkNNo1q4HnjzPweQV29HCrw2qVKkCFxcX/PDDD/jrr7+KLOvWrVvo2LEjlEolTE1N0aZNG8THxwMAwsLCoKenh5SUFJU83333HZo0aSIfHzt2DA0bNoS+vj5sbW0xdOhQPHv2rMg6Z8yYgerVq8PQ0BC2trYYOHAg0tLS5OshISFQKpXYu3cvnJ2doVAo4Ovri6SkJDlNbm4ufvjhByiVSpiZmWH48OEQQpTo+ZUrVw6WlpaoWLEihg4diooVK+LcuXPy9caNG2Pw4MEYNmwYypYtCx8fHwDA4cOHUbduXejq6sLKygo///wzcnJyAAA7duyAUqlEbm4uACAyMhKSJOHnn3+Wy+3bty+6detW4nsMDw9H3bp1YWhoCKVSCS8vLyQkJJToHoneBQa7RERERPTGXLqTioGh5zB1zzVcuJ0KDQnQyEzD/asnYfFZG8w5cgsDQ8/h0p1UOY9SqSy0rOzsbPj4+MDIyAhHjx5FRESEHHRlZWWhadOmUCqV2Lhxo5wnNzcX69atg7+/PwDgxo0b8PX1Rfv27XHhwgWsW7cOx44dw+DBg4u8Bw0NDcyZMweXL1/GihUrcPDgQQwfPlwlTXp6OoKCgrBq1SocOXIEiYmJCAwMlK9Pnz4dISEhWL58OY4dO4ZHjx5h8+bNpXqWQgjs2bMHiYmJqFevnsq1FStWQEdHBxEREVi0aBHu3LmDli1bok6dOoiKisLChQvxxx9/YMKECQCAhg0b4unTpzh//jyAF4Fx2bJlER4eLpd5+PBhNG7cuET3mJOTg7Zt28Lb2xsXLlzAiRMn0K9fP0iSVKp7JHqrBJVKamqqACBSU1Pfd1OIiIiIPigXb6eIDguPiyZBh0T3ZX+J3sGnRO/gU8Lvt2ABQDQZPFV0X/aXaBJ0SHy96Li4eDulQBkAxObNm4UQQqxatUo4OTmJvLw8+XpmZqbQ19cXe/fuFUII8d1334kmTZrI1/fu3St0dXXF48ePhRBC9OnTR/Tr10+ljqNHjwoNDQ2RkZEhhBDCzs5OzJw5s8j72rBhgzAzM5OPg4Nf3E9sbKx8bv78+cLCwkI+trKyEtOmTZOPs7OzRfny5UWbNm2KrOfQoUMCgDA0NBSGhoZCS0tLaGhoiAkTJqik8/b2Fu7u7irn/vOf/xR4VvPnzxcKhULk5uYKIYSoVauW+P3334UQQrRt21ZMnDhR6OjoiKdPn4rbt28LAOL69eslusfk5GQBQISHhxd5P58CxgYfNvbsEhEREdG/lp6Vg6CwaDx6lgk7UwNoa/7/x0zx0vBdbU0N2JkaIDktE0Fh0UjPyimyzKioKMTGxsLIyAgKhQIKhQKmpqZ4/vw5bty4AQDw9/dHeHg47t69CwAIDQ1Fq1at5N7iqKgohISEyPkVCgV8fHyQl5eHuLi4Quvdv38/mjZtChsbGxgZGaF79+5ITk5Genq6nMbAwACVK1eWj62srPDgwQMAQGpqKpKSklR6Y7W0tODh4VGiZ3n06FFERkYiMjISy5Ytw6RJk7Bw4UKVNLVr11Y5vnr1KurXr6/Ss+rl5YW0tDTcvn0bAODt7Y3w8HAIIXD06FG0a9cOzs7OOHbsGA4fPgxra2s4OjqW6B5NTU0REBAAHx8f+Pn5Yfbs2SpDnIk+BAx2iYiIiOhfi4hNxu3HGbBR6hcYympiYQtIElKTXsznlCQJNkp93H6cgeOxyUWWmZaWhtq1a8uBX/7r+vXr6Nq1KwCgTp06qFy5MtauXYuMjAxs3rxZHsKcX8a3336rkj8qKgoxMTEqgVy++Ph4tG7dGm5ubti4cSPOnj2L+fPnA3ixEFQ+bW1tlXySJJV4Tm5xKlasCAcHB7i4uKBXr17o3r07Jk6cqJLG0NCw1OU2btwYx44dQ1RUFLS1tVG1alU0btwY4eHhOHz4MLy9vVXSF3ePwcHBOHHiBDw9PbFu3TpUqVLltfOvid41BrtERERE9K8IIbDn0otevZd7dPPpKkxg4/oZrh78E9mZGSrpdl9KwuPHjwstt1atWoiJiUG5cuXg4OCg8jIxMZHT+fv7IzQ0FNu3b4eGhgZatWqlUsaVK1cK5HdwcCh0BeOzZ88iLy8P06dPx2effYYqVarIvcYlZWJiAisrK5w8eVI+l5OTg7Nnz5aqnHyamprIyMh4bRpnZ2ecOHFCJRiNiIiAkZERypcvD+D/5+3OnDlTDmzzg93w8HCV+bol5e7ujpEjR+L48eNwdXXF6tWrS10G0dvCYJeIiIiI/pW0zBzcfPgMJnpF72pZv9twiLxcbB8XgPgzB5F6LxFSym3s2xCCz+p7FprH398fZcuWRZs2bXD06FHExcUhPDwcQ4cOlYfm5qc7d+4cJk6ciA4dOkBXV1e+NmLECBw/fhyDBw9GZGQkYmJisHXr1iIXqHJwcEB2djbmzp2LmzdvYtWqVVi0aFGpn8l3332HKVOmYMuWLbh27RoGDhxYYNXoojx48AD37t1DQkICNmzYgFWrVqFNmzavzTNw4EDcunULQ4YMwbVr17B161aMHj0aP/zwAzQ0XnzkL1OmDNzc3BAaGioHto0aNcK5c+dw/fr1Aj27rxMXF4eRI0fixIkTSEhIQFhYGGJiYuDs7FziMojeNu6zS0RERET/SmZOHnKFKLRXN59xORu0GbMKUduDcWrtbKSn/g1dhRLGtk5YPHN2oXkMDAxw5MgRjBgxAu3atcPTp09hY2ODpk2bwtjYWE7n4OCAunXr4tSpU5g1a5ZKGW5ubjh8+DB++eUXNGzYEEIIVK5cGZ06dSq0zho1amDGjBmYOnUqRo4ciUaNGmHy5Mno0aNHqZ7Jjz/+iKSkJPTs2RMaGhro3bs3vvrqK6Smphab18nJCcCLeb62trb49ttvMWbMmNfmsbGxwa5du/DTTz+hRo0aMDU1RZ8+ffDrr7+qpPP29kZkZKQc7JqamqJatWq4f/++XG9JGBgY4Nq1a1ixYgWSk5NhZWWFQYMG4dtvvy1xGURvmyTe1OSCT8STJ09gYmKC1NRUlTdZIiIiok/V0+fZ6PHHKWhIgNKg4NDgoqSkZyFPAKv61oNCl30w9PFhbPBh4zBmIiIiIvpXFLpaqGRuiCfPi15ZuTCpz3NQydwQhjqab6llRPQpY7BLRERERP+KJEnwdbWCAJCdm1eiPPnpWrhaFVi9mYjoTWCwS0RERET/mpeDGcqX0cedlIxit+ARQuBuynOUL6MPTwezd9RCIvrUMNglIiIion/NQEcLgV84wUyhi4RH6UX28Gbn5iHhUTpMFToI/MIJBjqcq0tEbwffXYiIiIjojXC1McGo1tUQFBaN249f7AtroqcFTQ0JuXkCqf+b02traoDAL5zgamPyuuKIiP4VBrtERERE9Ma42phggX8tHI9Nxu5LSbj58Bmyc/KgKUmoUd4ELVyt4Olgxh5dInrr+C5DRERERG+UgY4WmlWzQFPncniWlYvn2bnQ09aEoY4mF6MioneGc3bpg2Nvb19gQ/gPUXh4OCRJQkpKyjurc8yYMahZs+Y7q4+IiOjfkCQJCl0tlFXoQqGrxUCXiN4pBrufuIcPH2LAgAGoUKECdHV1YWlpCR8fH0RERLzRegoLYENCQqBUKt9oPfkOHz6MJk2awNTUFAYGBnB0dETPnj2RlZX1VuojIiIiIqIPC4cxf+Lat2+PrKwsrFixApUqVcL9+/dx4MABJCcnv++m/WNXrlyBr68vhgwZgjlz5kBfXx8xMTHYuHEjcnNz33fziIiIiIjoHVCrnt0xY8ZAkiSVV9WqVeXrz58/x6BBg2BmZgaFQoH27dvj/v3777HF74cQAk+fZ+PG7fs4evQopkyZgs8//xx2dnaoW7cuRo4ciS+//FJOn5KSgr59+8Lc3BzGxsZo0qQJoqKi5Os3btxAmzZtYGFhAYVCgTp16mD//v3y9caNGyMhIQHff/+9/HMJDw9Hr169kJqaKp8bM2ZMoe0trv5XhYWFwdLSEtOmTYOrqysqV64MX19fLF26FPr6+nK6Y8eOoWHDhtDX14etrS2GDh2KZ8+eyddXrVoFDw8PGBkZwdLSEl27dsWDBw8K1Hf27Fl4eHjAwMAAnp6eiI6OLvGzmTdvHlxdXeXjLVu2QJIkLFq0SD7XrFkz/Prrr4Xe640bN1CpUiUMHjwYQggkJCTAz88PZcqUgaGhIVxcXLBr164inxURERERkbpSq2AXAFxcXJCUlCS/jh07Jl/7/vvvsX37dmzYsAGHDx/G3bt30a5du/fY2ncrPSsH+67cR+CGKPT44xS+23gVWrr6+PH3ZdgZmYj0rJxC83399dd48OABdu/ejbNnz6JWrVpo2rQpHj16BABIS0tDy5YtceDAAZw/fx6+vr7w8/NDYmIiAGDTpk0oX748xo0bJ/9cPD09MWvWLBgbG8vnAgMD/1H9r7K0tERSUhKOHDlS5LO4ceMGfH190b59e1y4cAHr1q3DsWPHMHjwYDlNdnY2xo8fj6ioKGzZsgXx8fEICAgoUNYvv/yC6dOn48yZM9DS0kLv3r3la8U9G29vb1y5cgUPHz4E8GL4ddmyZREeHi634cSJE2jcuHGBei9cuIAGDRqga9eumDdvHiRJwqBBg5CZmYkjR47g4sWLmDp1KhQKRZHPgYiIiIhIbQk1Mnr0aFGjRo1Cr6WkpAhtbW2xYcMG+dzVq1cFAHHixIkS15GamioAiNTU1H/b3Hfq4u0U0XP5SdF0erhoNj1ctJt/THy9MELU6ztBaOkbCQ0tHWHu4Cb6Dv5BREVFyfmOHj0qjI2NxfPnz1XKq1y5sli8eHGR9bm4uIi5c+fKx3Z2dmLmzJkqaYKDg4WJiUmBvC+n/Sf15+TkiICAAAFAWFpairZt24q5c+eq/Mz69Okj+vXrp5Lv6NGjQkNDQ2RkZBRa7unTpwUA8fTpUyGEEIcOHRIAxP79++U0O3fuFACKLEMI1WeTl5cnzMzM5N/LmjVrismTJwtLS0shhBDHjh0T2tra4tmzZ0KI//8dj4iIEGXKlBFBQUEqZVevXl2MGTOmyLqJiIiI6M35WGODT4Xa9ezGxMTA2toalSpVgr+/v9yDdvbsWWRnZ6NZs2Zy2qpVq6JChQo4ceJEkeVlZmbiyZMnKq+PzaU7qRi7/QpuPUqHtYkeKpgaQGmgAyM9bbh4fYGus3fh8yG/Q1G5NjbvCkOtWrUQEhICAIiKikJaWpo89Dv/FRcXhxs3bgB40XsZGBgIZ2dnKJVKKBQKXL16VX72/0ZJ6n+VpqYmgoODcfv2bUybNg02NjaYNGmS3OufX25ISIhKmT4+PsjLy0NcXByAF78zfn5+qFChAoyMjODt7Q0ABe7Lzc1N/reVlRUAyMOdi3s2kiShUaNGCA8PR0pKCq5cuYKBAwciMzMT165dw+HDh1GnTh0YGBjIdSQmJqJ58+YYNWoUfvzxR5W2DB06FBMmTICXlxdGjx6NCxcu/ONnT0RERET0MVOrBarq1auHkJAQODk5ISkpCWPHjkXDhg1x6dIl3Lt3Dzo6OgVW/7WwsMC9e/eKLHPy5MkYO3bsW27525OelYOgsGg8epYJO1ODQpf819LWhZ1bfVSo/hkSHvXAra0zMWr0aAQEBCAtLQ1WVlbysNqX5T/LwMBA7Nu3D0FBQXBwcIC+vj46dOjwRlY+Lkn9RbGxsUH37t3RvXt3jB8/HlWqVMGiRYswduxYpKWl4dtvv8XQoUML5KtQoQKePXsGHx8f+Pj4IDQ0FObm5khMTISPj0+B+9LW1pb/nf988/LyAJTs2TRu3BhLlizB0aNH4e7uDmNjYzkAPnz4sBxk5zM3N4e1tTXWrFmD3r17w9jYWL7Wt29f+Pj4YOfOnQgLC8PkyZMxffp0DBky5LXPioiIiIhI3ahVsNuiRQv5325ubqhXrx7s7Oywfv16lYWJSmPkyJH44Ycf5OMnT57A1tb2X7f1XYmITcbtxxmwUeoXu7edJEmwUerjVpnySL34Yq5zrVq1cO/ePWhpacHe3r7wOiIiEBAQgK+++grAiwA1Pj5eJY2Ojk6BlZALO/eqktRfEmXKlIGVlZW8AFWtWrVw5coVODg4FJr+4sWLSE5OxpQpU+Sf95kzZ0pdb0mejbe3N4YNG4YNGzbIc3MbN26M/fv3IyIiokDvrb6+Pnbs2IGWLVvCx8cHYWFhMDIykq/b2tqif//+6N+/P0aOHImlS5cy2CUiIiKiT47aDWN+mVKpRJUqVRAbGwtLS0tkZWUhJSVFJc39+/dhaWlZZBm6urowNjZWeX0shBDYc+nFsF1tzYI/6udpKdg9dQBij+/Go1sxePrwDm6fO4iEQ2tg694QQgg0a9YM9evXR9u2bREWFob4+HgcP34cv/zyixz8OTo6YtOmTYiMjERUVBS6du0q92zms7e3x5EjR3Dnzh38/fff8rm0tDQcOHAAf//9N9LT0wu0sST1v2rx4sUYMGAAwsLCcOPGDVy+fBkjRozA5cuX4efnBwAYMWIEjh8/jsGDByMyMhIxMTHYunWrvEBVhQoVoKOjg7lz5+LmzZvYtm0bxo8fX+qfQUmejZubG8qUKYPVq1erBLtbtmxBZmYmvLy8CpRraGiInTt3QktLCy1atEBaWhoAYNiwYdi7dy/i4uJw7tw5HDp0CM7OzqVuNxERERHRx06tg920tDTcuHEDVlZWqF27NrS1tXHgwAH5enR0NBITE1G/fv332Mq3Jy0zBzcfPoOJXuEd+Nq6BjCv5IrLYWuwa/K32PxrF5zbtBgVvb5EJb+heJaVC0mSsGvXLjRq1Ai9evVClSpV0LlzZyQkJMDCwgIAMGPGDJQpUwaenp7w8/ODj48PatWqpVLXuHHjEB8fj8qVK8Pc3BwA4Onpif79+6NTp04wNzfHtGnTCrSxJPW/qm7dukhLS0P//v3h4uICb29v/PXXX9iyZYs8JNjNzQ2HDx/G9evX0bBhQ7i7u2PUqFGwtrYG8GKocEhICDZs2IBq1aphypQpCAoKKvXPoCTPRpIkNGzYEJIkoUGDBnL7jI2N4eHhAUNDw0LLVigU2L17N4QQaNWqFZ49e4bc3FwMGjQIzs7O8PX1RZUqVbBgwYJSt5uIiIiI6GMnCSHE+27EmxIYGAg/Pz/Y2dnh7t27GD16NCIjI3HlyhWYm5tjwIAB2LVrF0JCQmBsbCwP7Tx+/HiJ63jy5AlMTEyQmpr6wffy/p2Wid4hp6GnpQEjPe3iM/zP0+fZeJ6Th+UBdVBWofsWW0hERERE9PH6mGKDT5Fazdm9ffs2unTpguTkZJibm6NBgwb466+/5J7EmTNnQkNDA+3bt0dmZiZ8fHzUutdLV0sDmpKE3LzSfZ+RmyegKUnQ09Z8Sy0jIiIiIiJ6u9SqZ/dd+Ji+vRFCIHBDFC7cTkUFU4PiM/xPwqN01ChvgqCvaxS7qBURERER0afqY4oNPkVqPWf3UydJEnxdrSAAZOfmFZseL6Vr4WrFQJeIiIiIiD5aDHbVnJeDGcqX0cedlAwU14kvhMDdlOcoX0Yfng5m76iFREREREREbx6DXTVnoKOFwC+cYKbQRcKj9CJ7eLNz85DwKB2mCh0EfuEEAx21ms5NRERERESfGEY0nwBXGxOMal0NQWHRuP04AwBgoqcFTY0Xi1elPs8BANiaGiDwCye42pi8z+YSERERERH9awx2PxGuNiZY4F8Lx2OTsftSEm4+fIbsnDxoShJqlDdBC1creDqYsUeXiIiIiIjUAiObT4iBjhaaVbNAU+dyeJaVi+fZudDT1oShjiYXoyIiIiIiIrXCYPcTJEkSFLpaUOjyx09EREREROqJC1QRERERERF9RAICAtC2bdv3Vr+9vT1mzZpV5PX4+HhIkoTIyMgSlymEQL9+/WBqalrqvEVhsEtEREQqQkJCoFQq30rZ/+QDEBFRYQoL+P7880/o6elh+vTp76dRb4AQAkuWLEG9evWgUCigVCrh4eGBWbNmIT09HQAwe/ZshISEyHkaN26MYcOGvZH6nzx5gl9++QVVq1aFnp4eLC0t0axZM2zatKnYrUzz2draIikpCa6uriWud8+ePQgJCcGOHTtKnbcoDHaJiIj+gYCAAEiShClTpqic37JlyztbB+H69eswMDDA6tWrVc7n5eXB09MTHTp0eCftyBcbG4vevXujQoUK0NXVhY2NDZo2bYrQ0FDk5Pxv5f9/8AGoJIrrZSAi9SCEwNPn2fg7LbPAlprLli2Dv78/Fi5ciB9//PE9tfDf6969O4YNG4Y2bdrg0KFDiIyMxG+//YatW7ciLCwMAGBiYvJWvpRMSUmBp6cnVq5ciZEjR+LcuXM4cuQIOnXqhOHDhyM1NbVE5WhqasLS0hJaWiWfNnnjxg1YWVnB09Oz1HmLJKhUUlNTBQCRmpr6vptCRETvUc+ePYWenp5QKpXi0aNH8vnNmzeLd/nndfbs2cLU1FTcvXtXPjdt2jRhYWEhHj58WOrysrKyRHBwsDAxMSlVvpMnTwojIyPx2WefiW3btonr16+L69evi9WrVwsvLy8RGRlZ6raUhp2dnZg5c+ZbrYOI3p9nmdki7PI98cO686LtvGPCb+5RYVuvhajs0ViEXb4nxk+cLPT09MSmTZtU8k2fPl24uroKAwMDUb58eTFgwADx9OlT+Xr++92ePXtE1apVhaGhofDx8VF5Tz106JCoU6eOMDAwECYmJsLT01PEx8cLIYQ4f/68ACDMzc2FoaGh8PDwEPv27VNpw/z584WDg4PQ1dUV5cqVE+3bty/yPtetWycAiC1bthS4lpeXJ1JSUoQQL/4GtWnTRv43AJXXzZs3ReXKlcXvv/+uUkZ+e2NiYgqtf8CAAcLQ0FDcuXOnwLWnT5+K7OxsIcSL99yJEyeKXr16CYVCIWxtbcXixYvltHFxcQKAOH/+vHzu4sWLwtfXVxgaGopy5cqJbt26yX+nXr0HOzs7IYQQGzZsEK6urkJPT0+YmpqKpk2birS0tCKf36vYs0tERFRC4pUehWbNmsHS0hKTJ09+bb5jx46hYcOG0NfXh62tLYYOHYpnz54BAObNm6fSy5nfM7xo0SL5XLNmzfDrr78WWvaQIUNQo0YNfPPNNwCAa9euYdSoUViyZAlMTU0xbtw4lC9fHrq6uqhZsyb27Nkj580fUrxu3Tp4e3tDT08PoaGhBep4+PAhPDw88NVXXyEzM7PQ5xIQEIAqVaogIiICfn5+cHR0hKOjI7p06YJjx47Bzc1Npc78Ycy5ubno06cPKlasCH19fTg5OWH27Nkq5ecPVQwKCoKVlRXMzMwwaNAgZGdnA3gxfC8hIQHff/89JEmSe9YTEhLg5+eHMmXKwNDQEC4uLti1a9drf1ZE9OG5dCcVA0PPYeqea7hwOxUaEqCnpQEJwJOMbHwz+HuMHTcec0PW4auvvlLJq6GhgTlz5uDy5ctYsWIFDh48iOHDh6ukSU9PR1BQEFatWoUjR44gMTERgYGBAICcnBy0bdsW3t7euHDhAk6cOIF+/frJ7zP57+Xbtm3D+fPn4evrCz8/PyQmJgIAzpw5g6FDh2LcuHGIjo7Gnj170KhRoyLvNTQ0FE5OTmjTpk2Ba5IkwcTEpMD52bNno379+vjmm2+QlJSEpKQkVKhQAb1790ZwcLBK2uDgYDRq1AgODg4FysnLy8PatWvh7+8Pa2vrAtcVCoVKb+v06dPh4eGB8+fPY+DAgRgwYACio6MLva+UlBQ0adIE7u7uOHPmDPbs2YP79++jY8eO8j3k/71KSkrC6dOnkZSUhC5duqB37964evUqwsPD0a5duxIPpQbAnt3SYs8uEdGn53U9CqNmLxd6enri1q1bQoiCPbuxsbHC0NBQzJw5U1y/fl1EREQId3d3ERAQIIQQ4sKFC0KSJPHgwQMhhBDDhg0TZcuWFZ06dRJCvOhpNTAwKNBT8LL4+HhhbGwslixZIurVqyeXPWPGDGFsbCzWrFkjrl27JoYPHy60tbXF9evXhRD//827vb292Lhxo7h586a4e/euSs9uYmKicHJyEj179hQ5OTmF1n/u3DkBQKxZs6bYZ/nqt/1ZWVli1KhR4vTp0+LmzZviv//9rzAwMBDr1q2T8/Ts2VMYGxuL/v37i6tXr4rt27cLAwMDsWTJEiGEEMnJyaJ8+fJi3LhxIikpSSQlJQkhhGjVqpVo3ry5uHDhgrhx44bYvn27OHz4cLFtJKIPx8XbKaLDwuOiSdAh0X3ZX6J38Cn55eDVSmhoaQsAoua308XXi46Li7dTXlvehg0bhJmZmXwcHBwsAIjY2Fj53Pz584WFhYUQ4sX7CwARHh5eaHmFxQYuLi5i7ty5QgghNm7cKIyNjcWTJ09KdL/Ozs7iyy+/LDbdyz27Qgjh7e0tvvvuO5U0d+7cEZqamuLkyZNCiBfvt2XLlhUhISGFlnn//n0BQMyYMaPY+u3s7ES3bt3k47y8PFGuXDmxcOFCIUTB9/rx48eLL774QqWMW7duCQAiOjpaCCHEzJkz5R5dIYQ4e/asACD3ov8T7NklIiJ6jeJ6FCJyKsHIxgFDA0cWmn/y5Mnw9/fHsGHD4OjoCE9PT8yZMwcrV67E8+fP4erqClNTUxw+fBgAEB4ejh9//FE+PnXqFLKzs+Hp6VlkG+3s7DBr1iz0798fSUlJcs9oUFAQRowYgc6dO8PJyQlTp05FzZo1C8xtHTZsGNq1a4eKFSvCyspKPh8dHQ0vLy/4+PggODgYmpqahdZ//fp1AICTk5N87sGDB1AoFPJrwYIFhebV1tbG2LFj4eHhgYoVK8Lf3x+9evXC+vXrVdKVKVMG8+bNQ9WqVdG6dWu0atUKBw4cAACYmppCU1MTRkZGsLS0hKWlJQAgMTERXl5eqF69OipVqoTWrVu/tkeFiD4s6Vk5CAqLxqNnmbAzNYC2ZsHQxbS8AxRlrZB0cCXuJ6cgKCwa6Vk58vX9+/ejadOmsLGxgZGREbp3747k5GR5oScAMDAwQOXKleVjKysrPHjw4EX5pqYICAiAj48P/Pz8MHv2bCQlJclp09LSAAB16tSBUqmEQqHA1atX5Z7d5s2bw87ODpUqVUL37t0RGhqqUverRGl6LYthbW2NVq1aYfny5QCA7du3IzMzE19//fUbqTt/xA7wotfZ0tJSfm6vioqKwqFDh1T+LlStWhXAi7m6halRowaaNm2K6tWr4+uvv8bSpUvx+PHjUrWRwS4REVERLt1JxdjtV3DrUTqsTfRQwdQASgMdGOlpQ0dLA/o6mrA20UP5L/piy4Y12BZ+qkAZUVFRCAkJUfkD7+Pjg7y8PMTFxUGSJDRq1Ajh4eFISUnBlStXMHDgQGRmZuLatWs4fPgw6tSpAwMDg9e2tVevXrCyssKQIUNgbGyMJ0+e4O7du/Dy8lJJ5+XlhatXr6qc8/DwKFBeRkYGGjZsiHbt2mH27NmlXnTLzMwMkZGRiIyMhFKpRFZWVpFp58+fj9q1a8Pc3BwKhQJLliyRPyjmc3FxUQm2X/4wWpShQ4diwoQJ8PLywujRo3HhwoVS3QMRvV8Rscm4/TgDNkr9It+DDMqYo+WIRXiW8hBXg39GfFIyjscmA3gxbaJ169Zwc3PDxo0bcfbsWcyfPx8AVN6TtLW1VcqUJEkl8AsODsaJEyfg6emJdevWoUqVKvjrr78AQJ5iMmrUKBw9ehSRkZGoXr26XL6RkRHOnTuHNWvWwMrKCqNGjUKNGjWQkpJS6P1UqVIF165d+wdPq3B9+/bF2rVrkZGRgeDgYHTq1KnIvyfm5uZQKpUlrr+w55aXl1do2rS0NPj5+cl/F/JfMTExRX4JqampiX379mH37t2oVq0a5s6dCycnJ8TFxZWofQCDXSIiokKVpEcBALQ1NVCzTn2YVvHA4B9+QmZ2rsr1tLQ0fPvttyp/3KOiohATEyP3JDRu3Bjh4eE4evQo3N3dYWxsLAfAhw8fhre3d4narKWl9Y9WrzQ0NCxwTldXF82aNcOOHTtw586d1+Z3dHQEAJW5WpqamnBwcICDg8Nr27R27VoEBgaiT58+CAsLQ2RkJHr16lUgOC7Nh6p8ffv2xc2bN9G9e3dcvHgRHh4emDt37mvzENGHQQiBPZde9KAW9f6bT1HWCi1HLMbzJ48QuXQ4tp6OhRACZ8+eRV5eHqZPn47PPvsMVapUwd27d/9Re9zd3TFy5EgcP34crq6u8ir4J0+eBAD4+fmhevXqsLS0RHx8vEpeLS0tNGvWDNOmTcOFCxcQHx+PgwcPFlpP165dcf36dWzdurXANSFEkash6+joIDc3t8D5li1bwtDQEAsXLsSePXvQu3fvIu9RQ0MDnTt3RmhoaKHPKS0tTV5Zv7Rq1aqFy5cvw97eXv7bkP8q7G9QPkmS4OXlhbFjx+L8+fPQ0dHB5s2bS1wvg10iIvpXJEnCli1birweHh4OSZKK/Bb7Q1WSHoV8kiShfuchuBV5DJv2HFK5VqtWLVy5cqXAH3cHBwfo6OgAALy9vXHlyhVs2LABjRs3BvAiAN6/fz8iIiLkc6VhbGwMa2trREREqN5XRASqVatWbH4NDQ2sWrUKtWvXxueff/7aD4ju7u6oWrUqgoKCig1AXxUREQFPT08MHDgQ7u7ucHBwKHJI2+sU9UHP1tYW/fv3x6ZNm/Djjz9i6dKlpS6b/r23uXczqae0zBzcfPgMJnol+wJPYWaBliMWIudZClaP7Y+kvx/DwcEB2dnZmDt3Lm7evIlVq1apLP5XEnFxcRg5ciROnDiBhIQEhIWFISYmBs7OzgCASpUqAQAuXLiAqKgodO3aVeV9cMeOHZgzZw4iIyORkJCAlStXIi8vT2Xax8s6duyITp06oUuXLpg0aRLOnDmDhIQE7Njxf+zdd3iN9/vA8ffJ3hNJRCTIkEhEbFIEQai0RlEUsVqbtqlRtbVo7dWhlbRoqVqt2ipG7JEYiZgRI2YIkZ3z/P7wy/k6MiQas/frus515Tzj87mfx0mc+/ms9QQGBrJjx458z3NxceHAgQPEx8dz+/ZtTQy6urqEhIQwatQo3NzcqFevXqHX++WXX+Lk5ESdOnX45ZdfiImJ4ezZsyxevBg/Pz9Nt+3iGjhwIElJSXTu3JlDhw5x/vx5Nm/eTM+ePfP92w2PHiTk3oOEhARWr17NrVu3NPe+KCTZFUIIUaDr168zePBgKlasiKGhIU5OTgQHB2vGShZF/fr1SUxMzHcGyVdJblKe+2pZzZn9X4dwfnfep+v5KePsjn31QFYt+VFr+4gRI9i7dy+DBg3SdNlat24dgwYN0hxTtWpVrK2t+fXXX7WS3bVr15KRkZGnK3JRffbZZ0ybNo0VK1YQFxfHyJEjiYqKYujQoUU6X1dXl2XLluHr60uTJk24fv16vsepVCrCwsI0Y3z//PNPzp49S0xMDN999x23bt0qcLyvm5sbhw8fZvPmzZw5c4YxY8Zw6NChYl+ri4sLu3bt4urVq9y+fRt4NBZ58+bNXLx4kaNHj7Jjx44ifUl6/HOQ32v8+PHFju9NFhAQUOj9CggIoFOnTpqx3QDjx4+nWrVqLy9o8crLyFaToyjo6hR9CIWpjR2NP5lPRso93n27FRUqVGDmzJlMmzYNb29vli1b9tTZ859kYmLC6dOnad++Pe7u7nz44YcMHDiQjz76CICvvvoKgObNmxMcHEyLFi2oXr265nwrKytWr15NkyZN8PT05LvvvuO3336jSpUq+danUqn49ddfmTlzJmvXrqVRo0ZUrVqV8ePH8+6779KiRYt8zwsNDUVXVxcvLy9Kly6tNRSkd+/eZGZm0rNnz6der42NDfv37+eDDz5g8uTJ+Pn50aBBA3777Te++eabZ/6/PPfha05ODs2bN8fHx4dhw4ZhZWWFjk7+KamFhQW7du2iVatWuLu788UXXzBjxgxatmxZ5HpVSkmOgv4PuH//PpaWliQnJ2NhYfGywxFCiBKlKAopGdlkZKu5fjWBFk0CsLKyYuLEifj4+JCVlcXmzZv54YcfNGN6VCoVa9asoU2bNi83+H8pIiKCxo0bExcXh46BMQN+3s+Nk5GcWDWPFqFzKetVW+v4XT9OIDP1AYFDpmu2Xb18ia0Tu6DOztIa73Xo0CFGjx7Nvn37UBSFSpUq0alTJz7//HPg0dixjh078vfff3P37l3MzMxQq9WUKlUKDw8P9u3bV6RrcHFxYdiwYQwbNgx4tIzEpEmTWLRoETdv3sTLy4upU6cSFBQEPBrPVqFCBY4dO6aVeISHhzNs2DBNa3x2djadOnXSLP1QpkyZfOs/c+YMX331Fdu3b+f69euYmpri6+tL165d6dWrF3p6ennqzMjIoF+/fqxZswaVSkXnzp2xtLRk48aNmuWJQkJCuHfvnlYPgmHDhhEVFUVERAQA+/fv56OPPiIuLo6MjAwURWHw4MFs3LiRK1euYGFhQVBQELNmzcLW1jbf+HM//wlXr2Goq4OpoR6///47Y8eO1eqinTv2WjySlJSk6XZ++fJlateuzbZt2zRf5g0MDLCxsdE6Z/z48axdu1bzbyzEkx6kZ9H9p4PoqMDKxKDI591LzUStwJI+dTAzLP6wjuJ6HXKD3bt307RpUy5fvoydnd3LDufFeuZ5nP+jZOkhIcSbKL+ldey86ipmNmWUdYfOKw8zsrSOv3v3ruZnQFm0aJHSpk0bxdjYWHF1dVXWrVun2b9jxw4F0Dpnz549SqNGjRRjY2PFyspKad68uZKUlKQoiqJs3LhR8ff3VywtLRUbGxvl7bff1loSQlEUJTIyUvH19VUMDQ2VGjVqaJb7eXzx+oiICKVWrVqKgYGBYm9vr4wYMULJytK+jsc9HuetB+lK8LzdSodvIxXzMuWUWh0Ha5a66PnTfqVG+wGKWSkHRVffULF2clUaD5ii9Ao7qHT4NlJpPSdC6dKth+Li4qIYGRkp7u7uyuzZs7Xqyl0yYvLkyYqDg4Pi4uKiKMqj5S5cXV0VQ0NDpUyZMkr79u2L9O8n/p38Pv9t5u9RPllxTAmdPFuzDFOuRYsWKZUrV1YMDQ0VDw8PZcGCBZp9ucttrFq1SgkICFCMjY2VqlWrKnv37tUck7u006ZNm5TKlSsrpqamSosWLZRr164VuZ6MjAxl4MCBir29vWJoaKiUL19e+eqrrxRFebQEyLhx4xQnJyfFwMBAcXBwUAYPHqw5Nz09Xfn000+VsmXLKiYmJkrt2rWVHTt2aNW9e/du5a233lKMjIyUcuXKKYMHD1ZSUlKeei+fXG7kyWvO/RnQeoWFhSmKoigzZsxQvL29FRMTE6VcuXJK//79lQcPHhTr3u3YsUOpVauWYmJiolhaWir169f/V0uXiJdDrVYrn6w4pgTOiNBabuhpr6YzIpRPVhxT1Gr1C4nzVc4N0tPTlcuXLytNmjRRunTp8rLDeSmkG7MQQvzH5be0jk5GCjdiD2BX913m7rrMgGVHOXn1f5NiPDn2bsKECXTs2JHjx4/TqlUrunbtSlJSUr71RUVF0bRpU7y8vNi3bx979uwhODhYM2bn4cOHfPLJJxw+fJjt27ejo6ND27ZtNeOP7t+/r5kI5OjRo0yaNIkRI0Zo1XH16lVatWpFrVq1iI6O5ttvv+Wnn35i8uTJRbonhno66ABXT+zj4Z3rlK74v+5m0X+Hc27vBup3H0nbycvxbt6FXT+MI/H0UXLUCjpAeScnVq5cSUxMDGPHjuXzzz/Ps5TO9u3biYuLY+vWraxfv57Dhw8zZMgQJk6cSFxcHJs2bZJlcl6AgpaW0lHB8SvJ/H0ikdTMHM3nf9myZYwdO5Yvv/yS2NhYvvrqK8aMGcPPP/+sVe7o0aMJDQ0lKioKd3d3OnfurDWxS2pqKtOnT2fJkiXs2rWLhIQEQkNDNfufVs/cuXP5888/+f3334mLi2PZsmW4uLgAsGrVKmbNmsX333/P2bNnWbt2LT4+PpqyBw0axL59+1i+fDnHjx+nQ4cOBAUFcfbsWeDRMiBBQUG0b9+e48ePs2LFCvbs2aPV9f7f6NSpE59++ilVqlQhMTGRxMREOnXqBDwaKz537lxOnTrFzz//zD///MPw4cO1zi/s3mVnZ9OmTRsaNWrE8ePH2bdvHx9++GGxZxMXL59KpSLI2wEFyMop2lwAuce19HaQf3Pgt99+w9nZmXv37vH111+/7HBeiuffti+EEOKVlbu0TtLDDBytjDUzXt66fh0UBeeKrpS1NOJyUioT18cwtrUX3o55x+uEhITQuXNn4NH4pblz53Lw4EFNd9nHff3119SsWVNr3dXHxy61b99e6/jFixdTunRpYmJiNDNgqlQqFi1ahJGREV5eXly9epW+fftqzlm4cCFOTk7Mnz8flUpF5cqVuXbtGiNGjGDs2LEFjg8CKFeuHABp6Rmo1Wqqt/0Qe49H469ysjI5vj6coM/mU8b10fqCFmUcuXEmiriI1VToWBnfcpZ8NXii5otWhQoV2LdvH7///jsdO3bU1GNqasqPP/6omaRq9erVmJqa0rp1a8zNzXF2dsbPz6/AOMW/V9DnP5eViQGpJvooiqL5/I8bN44ZM2bQrl074NG/b0xMDN9//z09evTQnBsaGsrbb78NPHoYVKVKFc6dO6dZVzIrK4vvvvtOMyP3oEGDmDhxoub8p9WTkJCAm5sbb731FiqVCmdnZ825CQkJ2NvbExgYiL6+PuXLl6d27dqafWFhYSQkJFC2bFlNrJs2bSIsLIyvvvpKa21oeDSueu7cuTRq1Ihvv/0WIyOjf3XfjY2NMTMzQ09PT7Mmcq7cOuFRt/zJkyfTr18/rb8Xhd27+/fvk5ycTOvWrTX7izOZjXi1+LvaUs7amMtJqTjbmBSawCqKwrV76ZSzMaa+a/5DFf5rQkJCCAkJedlhvFSS7AohxH/Uk0vrPP4lQnlsvKm+rg7ONiZcSkpl+pY4FnatjomB9n8fjy8sb2pqioWFRYFroEZFRRW4oD3A2bNnGTt2LAcOHNCaUTIhIQFvb2/i4uKoWrWq1hfu3C/yuWJjY6lXr57WNfn7+5OSksKVK1coX758gfXv3r0bc3NzdsRcZdavG4leMwdDUws8m7zH/ZuXyc5MZ9P0wVrnqLOzsC7vDjxqUVi4cCGLFy8mISGBtLQ0MjMz80zG4+Pjo0l0AZo1a4azszMVK1YkKCiIoKAg2rZt+9T1dcWzKezz/zhdHR10VCrupGQw5a8ozp8/T+/evbUermRnZ+eZtOXx3wkHBwcAbt68qUl2TUxMNMlY7jG5vzMPHz58aj0hISE0a9YMDw8PgoKCaN26Nc2bNwegQ4cOzJ49W/NZatWqFcHBwejp6XHixAlycnJwd3fXijcjI0Mzljk6Oprjx4+zbNkyzX5FUTRrQz/P5HHbtm1MmTKF06dPc//+fbKzs0lPTyc1NVXzu1DYvbOxsSEkJIQWLVrQrFkzAgMD6dixo+bfQLxeTAz0CG3uwcT1MVxKSs33oRQ8atG9ei8NWzNDQpt75Pk/Svx3ySdBCPGf8rTJlAqasOdNVNjSOpZ2TqBSkZx4CXh03xytjLlyN4295+4Q6KU9wUVx1kA1NjYuNK7g4GCcnZ1ZtGgRZcuWRa1W4+3tnWfd1eelQoUKWFlZUba8C5F3jEm+FEP0+jA8m7xHVnoaAM2GzcLUurTmHEVRuP5QTTlrY64e3UZoaCgzZsygXr16mJub880332jWYsz15LqC5ubmHD16lIiICLZs2cLYsWMZP348hw4dkiVbnoPiLC0F4GhlzMUrj5ZfWrRoEXXq1NHa/+Rs04//TuSW//jvRH6/M7kPmXKX9iisnurVq3Px4kU2btzItm3b6NixI4GBgfzxxx84OTkRFxfHtm3b2Lp1KwMGDOCbb75h586dpKSkoKury5EjR/LEnDvpVu7a0EOGDMlzHwp7UPRvxcfH07p1a/r378+XX36JjY0Ne/bs0cwkm5vsFnbvAMLCwhgyZAibNm1ixYoVfPHFF2zdupW6des+t9jF8+PtaMnY1l5M3xLHlbuP/gZbGumhq6MiR62QnP5oeICTjQmhzT3y7X0k/rtkzK4QL1lISMgLm8XWx8eHfv365btvyZIlGBoaapbseNW4uLholrEwMTHBx8eHH3/88eknPiExMbFYU9a/qRRFYdPJRIB8n5Ibmlni6F2X2H/+ICsjTeu4jScTuXv37jPXXbVq1QKXLrpz5w5xcXF88cUXNG3aFE9Pzzx1eXh4cOLECTIyMjTbnlyqxtPTUzPzca7IyEjMzc013ZSfJrdFwdhQn8yMDLJy1FiXrYCungEPk65jYeeEhZ0TxqUcuatvS9ly5Qht7sHhA/ufed1YPT09AgMD+frrrzl+/Djx8fH8888/RTpXFN3TPv/50dfVwdDcBlPr0pw/fz7PmskVKlQosfjs7OwoW7YsFy5cKLQeCwsLOnXqxKJFi1ixYgWrVq3SjJU3NjYmODiYuXPnEhERwb59+zhx4gR+fn7k5ORw8+bNPGXndikuytrQ/1Z+6yIfOXIEtVrNjBkzqFu3Lu7u7oWu71wYPz8/Ro0axd69ezXDH8Try9vRkoVdqzMy6NFQEbUC6dlq1Ar4lrNkZFBlFnatLomuyENadoV4CZTHlncp6qQLJaF3796MHz+eWbNm5WldCwsL45133qFUqVIvLJ7imjhxIn379iU1NZWVK1fSt29fHB0di5W8Pjk+7HnIzMwssS+Ez0tKRjYXbj3E0qjg/wbqfTCcv7/qw18TQ6je9iOsy7miSk1n6741rB+7mbjTsc9U96hRo/Dx8WHAgAH069cPAwMDduzYQYcOHbCxscHW1pYffvgBBwcHEhISGDlypNb5Xbp0YfTo0Xz44YeMHDmShIQEpk9/tPxPbgvagAEDmD17NoMHD2bQoEHExcUxbtw4Pvnkk0LH68Kjrqbp6elkZGQQe/Ag149sxaV6I64lpwMqXAPfZ/+vs3iYnoVBOS+y0x+iuhFHk1qV8Hash5ubG7/88gubN2+mQoUKLFmyhEOHDj01GVq/fj0XLlygYcOGWFtbs2HDBtRqNR4eHs90n0XBivL5z4+lkR5uLXsxdepUrKysCAoKIiMjg8OHD3P37l0++eSTEotxwoQJDBkyBEtLy3zrmTlzJg4ODvj5+aGjo8PKlSuxt7fHysqK8PBwcnJyqFOnDiYmJixduhRjY2OcnZ2xtbWla9eudO/enRkzZuDn58etW7fYvn07VatW5e2332bEiBHUrVuXQYMG0adPH0xNTYmJiWHr1q3Mnz+/RK7PxcWFixcvEhUVRbly5TA3N8fV1ZWsrCzmzZtHcHAwkZGRfPfdd8Uq9+LFi/zwww+88847lC1blri4OM6ePUv37t1LJG7x8pgY6BHoZUdTzzI8zMwhPSsHI31dTA10ZTIqUSBp2RXiBUrNzGZrzA1CV0bT/aeD9Ao/xO6ztzl5NZmtMTdIzczOc87MmTPx8fHB1NQUJycnBgwYoOniBnDp0iWCg4OxtrbG1NSUKlWqsGHDhnzr/+CDD0hLS2PVqlVa2y9evEhERAS9e/cGYN26dVSvXh0jIyMqVqzIhAkTtGYRPX36NG+99ZZmcqBt27ahUqm01sAcMWIE7u7umJiYULFiRcaMGUNWVpZmf3R0NI0bN8bc3BwLCwtq1KjB4cOHC71/5ubm2NvbU7FiRUaMGIGNjQ1bt27V7D906BDNmjWjVKlSWFpa0qhRI44ePapVxpNxHjx4ED8/P4yMjKhZsybHjh3LU+/Jkydp2bIlZmZm2NnZ0a1bN60W8ICAAAYNGsSwYcMoVaoULVq0QFEUxo8fT/ny5TE0NKRs2bL5dgl8WTKy1eQoCro6BX9BsCjjyLvjl+BQuSYHl89hzZjORM77mJtxR/h61pxnrtvd3Z0tW7YQHR1N7dq1qVevHuvWrUNPTw8dHR2WL1/OkSNH8Pb25uOPP+abb77RjsvCgr/++ouoqCiqVavG6NGjGTt2LIBmHK+joyMbNmzg4MGD+Pr60q9fP3r37s0XX3zx1Pg8PDxwcHDA1dWVESNG0L/fR+z9c6mmRaHy231xC+pB3JYlHPi6B2d/HoXFrRM0qP5okq2PPvqIdu3a0alTJ+rUqcOdO3cYMGDAU+u1srJi9erVNGnSBE9PT7777jt+++03rcm7RMkoyuc/P7o6KpzqtWbW/G8JCwvDx8eHRo0aER4eXqItuwB9+vThxx9/LLAec3NzzWRvtWrVIj4+ng0bNqCjo4OVlRWLFi3C39+fqlWrsm3bNv766y/NmNywsDC6d+/Op59+ioeHB23atOHQoUOaLspVq1Zl586dnDlzhgYNGuDn58fYsWM1E1qVhPbt2xMUFETjxo0pXbo0v/32G76+vsycOZNp06bh7e3NsmXLmDJlSrHKNTEx4fTp07Rv3x53d3c+/PBDBg4cyEcffVRisYuXS6VSYWaoRykzQ8wM9STRFYVSKY/38RJP9TosHC1eTSevJmvGm6gAi/8fb3IgfDJpKfep2utLylkb5xlvMnv2bHx9falQoQIXLlxgwIABNGnSRDMzZevWrcnMzGTGjBmap+8WFhYFLlnSsWNHbt++rdU1cty4cYSFhREfH09kZCStW7dm7ty5NGjQgPPnz/Phhx8SEhLCuHHjyMnJoUqVKpQvX55vvvmGBw8e8Omnn3Lw4EGtsbCTJ0+mSZMmlC1blhMnTtC3b18++eQTzRIS3t7e+Pn5MXr0aHR1dTXLc/j6+uYbt4uLC8OGDWPYsGGo1WrWrFlDhw4dGD58OFOnTgXgn3/+4dq1a9SsWRNFUZgxYwbr16/n7NmzmJubA9pjdlNSUqhYsSLNmjXj888/5+LFiwwdOpQLFy5oxuzeu3cPd3d3+vTpQ/fu3UlLS2PEiBFkZ2dr7mFAQABHjhyhf//+mgcGJ06coHfv3ixfvpwqVapw/fp1oqOjtSabeZkepGfR/aeD6KgezThbVPdSM1ErsKRPHcwMX53OQcuWLaNnz54kJyc/dUzwv6EoirQovAHetM+/EOLlkdzg1SbJbjHJB1o8i8KWt9j14wQyUx/QaODXmpkEC1reBeCPP/6gX79+mpbFqlWr0r59e8aNG1ekWDZv3kzLli05f/48FSpUQFEUKlSoQLdu3Zg0aRKBgYE0bdqUUaNGac5ZunQpw4cP59q1a2zatIng4GAuX76s6RK8bds2mjVrVujET9OnT2f58uWa1lsLCwvmzZuntVRHYVxcXEhMTERfX5+MjAyys7OxsbHhwIEDuLq65nuOWq3GysqKX3/9ldatWwPaye4PP/zA559/zpUrVzQtgt999x39+/fXJLuTJ09m9+7dbN68WVPulStXNBPAuLu7ExAQwP3797VakWfOnMn333/PyZMn80ym8ipQFIXQldEcv5JMeZuiz/Z7KSkV33KWTO/g+1KTvF9++YWKFSvi6OhIdHQ0gwYNIiAggKVLl760mMTr43X//AshXh2SG7zapBuzEM/Zk8tbFDQZSu7yLndSMpi+JU7TpXnbtm00bdoUR0dHzM3N6datG3fu3CE1NRWAIUOGMHnyZPz9/Rk3bhzHjx8vNJ5mzZpRrlw5wsLCANi+fTsJCQn07NkTeNS9eOLEiZiZmWleffv2JTExkdTUVOLi4nByctIa+/rksi8AK1aswN/fH3t7e8zMzPjiiy9ISEjQ7P/kk0/o06cPgYGBTJ06tUgT+Hz22WdERUXxzz//UKdOHWbNmqWV6N64cYO+ffvi5uaGpaUlFhYWpKSkaNX7uNjY2DxL2NSrV0/rmOjoaHbs2KF1P3KXDnk85ho1amid16FDB9LS0qhYsSJ9+/ZlzZo1Wl3BXzaVSkWQtwMKFHnceO5xLb0dXvoX/evXr/PBBx/g6enJxx9/TIcOHfjhhx9eakzi9fG6f/6FEEIUjSS7QjxnxVne4snlXXKXYahatSqrVq3iyJEjLFiwAECzDEufPn24cOEC3bp148SJE9SsWZN58+YVWIeOjg4hISH8/PPPqNVqwsLCaNy4MRUrVgQeLTkxYcIEoqKiNK8TJ05w9uxZraSwMPv27aNr1660atWK9evXc+zYMUaPHq21dMz48eM5deoUb7/9Nv/88w9eXl6sWbOm0HJLlSqFq6srDRo0YOXKlQwZMoSYmBjN/h49ehAVFcWcOXPYu3cvUVFR2Nra/qsla1JSUggODta6H1FRUZw9e1arq/iTy8jktvwuXLgQY2NjBgwYQMOGDbXGLb9s/q62j5bKuZfG0zr5KIrCtXvplLM2pr6r7QuKsGDDhw8nPj6e9PR0Ll68yKxZs2Q9WlEsr/PnXwghRNFIsivEc/Ssy1vAo+VdDh8+XKRlGJycnOjXrx+rV6/m008/ZdGiRYXW0bNnTy5fvszq1atZs2aNZpwpPFpyIi4uLt8lJ3R0dPDw8ODy5cvcuHFDc86Ty77s3bsXZ2dnRo8eTc2aNXFzc+PSpUt54nB3d+fjjz9my5YttGvXTtPaXBROTk506tRJq7t1ZGQkQ4YMoVWrVlSpUuWpSyl5enpy/Phx0tPTNdv279+vdUz16tU5deoULi4uee7Hkwnukwpa+uNVkbu0jq2ZIZeSUgts4crKUXMpKRUbMwNCm3tgYiBjFcXrTz7/Qgjx5pNkV4jnqKjLW2SmPeROwhnNS7l1kZNnLuDoXEGzDMOFCxdYsmRJnmUYhg0bxubNm7l48SJHjx5lx44deHp6FlpfhQoVaNKkCR9++CGGhoa0a9dOs2/s2LH88ssvTJgwgVOnThEbG8vy5cs1s9g2a9aMSpUq0aNHD44fP05kZKRmX27LtZubGwkJCSxfvpzz588zd+5crVbbtLQ0Bg0aREREBJcuXSIyMpJDhw49Ne4nDR06lL/++kszDtjNzY0lS5YQGxvLgQMH6Nq1a6GTFXXp0gWVSkXfvn2JiYlhw4YNmiVscg0cOJCkpCQ6d+7MoUOHOH/+PJs3b6Znz5551oh8XHh4OD/99BMnT57kwoULWkt/vEq8HS0Z29oLJxsTriWncykplXupmTxIz+JeaiaXklK5lpyOk41JoWPJhXgdyedfCCHebJLsCvEcFXV5i+unj7Bu3Aea1z9Te3J6w2LcPL2fugxDTk4OAwcOxNPTk6CgINzd3TUzNRemd+/e3L17ly5dumh1T27RogXr169ny5Yt1KpVi7p16zJr1ixNkqarq8vatWtJSUmhVq1a9OnTh9GjRwP/W/blnXfe4eOPP2bQoEFUq1aNvXv3MmbMGE0durq63Llzh+7du+Pu7k7Hjh1p2bIlEyZMKNqN/X9eXl40b95cs+zMTz/9xN27d6levTrdunVjyJAhlClTpsDzzczM+Ouvvzhx4oRmZuhp06ZpHVO2bFkiIyPJycmhefPm+Pj4MGzYMKysrApdr/VpS3+8SrwdLVnYtbpmaR21AunZatQK+JazZGRQZRZ2rS5f9MUbST7/Qgjx5pLZmItJZlwTxfFfWd4iMjKSt956i3PnzlGpUqWXHY74F2RpHfFfJp9/IURxSW7wanv1v0UL8RozM9SjYmlTjl9JLlaym5yejW85S0wNdJ9jdM9uzZo1mJmZ4ebmxrlz5xg6dCj+/v6S6L4BVCoVZoZ6r8VDFiFKmnz+hRDizSLdmIV4jt7U5S0ePHjAwIEDqVy5MiEhIdSqVYt169a97LCEEEIIIYTQkEeXQjxnuctbXE5KxdnGpNAEVrO8hc2rvbxF9+7d6d69+8sOQwghhBBCiAJJy64Qz5ksbyGEEEIIIcSLJ9+mhXgBcpe3mL4ljit30wCwNNJDV0dFjlohOT0bACcbE0Kbe8isn0IIIYQQQvxLkuwK8YLkLm+x99wdNp5M5MKth2Rlq9FVqfAtZ0lLbwfqu9pKi64QQgghhBAlQL5VC/ECmRjoEehlR1PPMrK8hRBCCCGEEM+RJLtCvASyvIUQQgghhBDPl0xQJYQQQgghhBDijSPJrhBCCCGEEEKIN44ku0IIIYQQQggh3jiS7AohhBBCCCGEeONIsiuEEEIIIYQQ4o0jya4QQgghhBBCiDeOJLtCCCGEEEIIId44kuwKIYQQQgghhHjjSLIrhBBCCCGEEOKNI8muEEIIIYQQQog3jiS7QgghhBBCCCHeOJLsCiGEEEK8oVQqFWvXri2x8gICAhg2bFiJlfdvREREoFKpuHfv3ssOpcSEhITQpk2blx2GEG8MSXaFEEIIIV5D169fZ/DgwVSsWBFDQ0OcnJwIDg5m+/btmmMSExNp2bJlidW5evVqJk2aVGLlFVV+SXb9+vVJTEzE0tKywPNcXFxQqVSoVCp0dXUpW7YsvXv35u7du885YiHEq6BYyW5aWhp79uwhJiYmz7709HR++eWXEgtMCCGEEELkLz4+nho1avDPP//wzTffcOLECTZt2kTjxo0ZOHCg5jh7e3sMDQ1LrF4bGxvMzc1LrLx/w8DAAHt7e1QqVaHHTZw4kcTERBISEli2bBm7du1iyJAhLyhKIcTLVORk98yZM3h6etKwYUN8fHxo1KgRiYmJmv3Jycn07NnzuQQphBBCCPFfpygKD9KzuJ2SwYf9+qNSqTh48CDt27fH3d2dKlWq8Mknn7B//37NOY93Y46Pj0elUrF69WoaN26MiYkJvr6+7Nu3T6ueyMhIAgICMDExwdramhYtWmhaQp9sYXVxceGrr76iV69emJubU758eX744QfN/qLUeefOHTp37oyjoyMmJib4+Pjw22+/afaHhISwc+dO5syZo2mljY+PL3I3ZnNzc+zt7XF0dKRx48b06NGDo0ePah2zZ88eGjRogLGxMU5OTgwZMoSHDx8W+ToB9u7dS7Vq1TAyMqJmzZqsXbsWlUpFVFQUADk5OfTu3ZsKFSpgbGyMh4cHc+bMKTT2P/74Ax8fH4yNjbG1tSUwMFArLiFE4Yqc7I4YMQJvb29u3rxJXFwc5ubm+Pv7k5CQ8DzjE0IIIYT4T0vNzGZrzA1CV0bT/aeDfLBgO1u3bKZCg7bsvZRCama21vFWVlaFljd69GhCQ0OJiorC3d2dzp07k539qIyoqCiaNm2Kl5cX+/btY8+ePQQHB5OTk1NgeTNmzKBmzZocO3aMAQMG0L9/f+Li4opcZ3p6OjVq1ODvv//m5MmTfPjhh3Tr1o2DBw8CMGfOHOrVq0ffvn1JTEwkMTERJyen4t5GAK5evcpff/1FnTp1NNvOnz9PUFAQ7du35/jx46xYsYI9e/YwaNCgIl/n/fv3CQ4OxsfHh6NHjzJp0iRGjBihdb5araZcuXKsXLmSmJgYxo4dy+eff87vv/+eb6yJiYl07tyZXr16ERsbS0REBO3atUNRlGe6diH+k5QiKlOmjHL8+HHNe7VarfTr108pX768cv78eeX69euKjo5OUYt7bSUnJyuAkpyc/LJDEUIIIcQb7sSVe0qPxQeUpjMilMAZEUq7BXuUpiMWKYBSNWSS0nRGhNJj8QHlxJV7+Z4PKGvWrFEURVEuXryoAMqPP/6o2X/q1CkFUGJjYxVFUZTOnTsr/v7+BcbTqFEjZejQoZr3zs7OygcffKB5r1arlTJlyijffvttkevMz9tvv618+umnBdarKIqyY8cOBVDu3r1bYDnOzs6KgYGBYmpqqhgZGSmAUqdOHa1zevfurXz44Yda5+3evVvR0dFR0tLSinSd3377rWJra6s5XlEUZdGiR/9Ox44dKzC+gQMHKu3bt9e879Gjh/Luu+8qiqIoR44cUQAlPj6+wPPFyye5wautyC27aWlp6Onpad6rVCq+/fZbgoODadSoEWfOnCmxBFwIIYQQ4r/u5NVkJvwVw+WkVMpaGlHexgQrEwOM9XUBKGVmQFlLIy4npTJxfQwnryYXqdyqVatqfnZwcADg5s2bwP9adovj8fJUKhX29vaa8opSZ05ODpMmTcLHxwcbGxvMzMzYvHlzifUe/Oyzz4iKiuL48eOaybvefvttTWt1dHQ04eHhmJmZaV4tWrRArVZz8eLFIl1nXFwcVatWxcjISHNM7dq188SyYMECatSoQenSpTEzM+OHH34o8Dp9fX1p2rQpPj4+dOjQgUWLFsnEWkIUU5GT3cqVK3P48OE82+fPn8+7777LO++8U6KBCSGEEEL8V6VmZjN9SxxJDzNwtjFBX/d/X9ks7ZxApSI58RL6ujo425hwJyWD6Vvi8nRpzo++vr7m59zJndRqNQDGxsbFjvXx8nLLzC2vKHV+8803zJkzhxEjRrBjxw6ioqJo0aIFmZmZxY4lP6VKlcLV1RU3NzeaNGnC7Nmz2bt3Lzt27AAgJSWFjz76iKioKM0rOjqas2fPUqlSpWJdZ2GWL19OaGgovXv3ZsuWLURFRdGzZ88Cr1NXV5etW7eyceNGvLy8mDdvHh4eHloJuBCicEVOdtu2bas1WcDj5s+fT+fOnWUMgRBCCCFECYg8d4crd9NwtDLOM9uwoZkljt51if3nD7Iy0lCpVDhaGXPlbhp7z935V+vOVq1aVWvpohchMjKSd999lw8++ABfX18qVqyYp8eggYFBoeOGi0NX91HLeFpaGgDVq1cnJiYGV1fXPC8DA4Milenh4cGJEyfIyMjQbDt06JDWMZGRkdSvX58BAwbg5+eHq6sr58+fL7RclUqFv78/EyZM4NixYxgYGLBmzZriXK4Q/2lFTnZHjRrFhg0bCty/cOHCYj3dEkIIIYQQeSmKwqaTj1a8eLxF93H1PhiOos7hr4khxB/+h9RbV3h44xJffjODevXqPXPdo0aN4tChQwwYMIDjx49z+vRpvv32W27fvv3MZT6Nm5sbW7duZe/evcTGxvLRRx9x48YNrWNcXFw4cOAA8fHx3L59u1jfOR88eMD169dJTEzk4MGDfPbZZ5QuXZr69esDjyZh3bt3L4MGDSIqKoqzZ8+ybt26PBNUFaZLly6o1Wo+/PBDYmNj2bx5M9OnTwf+15Lt5ubG4cOH2bx5M2fOnGHMmDF5EuLHHThwgK+++orDhw+TkJDA6tWruXXrFp6enkWOS4j/umKtsyuEEEIIIZ6vlIxsLtx6iKWRXoHHWJRx5N3xS3CoXJODy+ewZkxnon4I5fSRfcycM/+Z63Z3d2fLli1ER0dTu3Zt6tWrx7p167TmbSlpX3zxBdWrV6dFixYEBARgb29PmzZttI4JDQ1FV1cXLy8vSpcuXazxvGPHjsXBwYGyZcvSunVrTE1N2bJlC7a2tsCj1uydO3dy5swZGjRogJ+fH2PHjqVs2bJFrsPCwoK//vqLqKgoqlWrxujRoxk7diyAZhzvRx99RLt27ejUqRN16tThzp07DBgwoNAyd+3aRatWrXB3d+eLL75gxowZtGzZsshxCfFfp1Kk73Gx3L9/H0tLS5KTk7GwsHjZ4QghhBDiDXM7JYNe4Ycw0tPB3Ej/6Sf8vwfpWaRnq1kcUotSZobPMUJRFMuWLaNnz54kJyc/01ho8XqQ3ODV9vwe0wkhhBBCiGIz1NNBV6UiR1289ogctYKuSoXR/8/WLF6sX375hYoVK+Lo6Eh0dDQjRoygY8eOkugK8RJJsiuEEEII8QoxM9SjYmlTjl9JxsqkaBMkASSnZ+NbzhJTA0l2X4br168zduxYrl+/joODAx06dODLL7982WEJ8Z9W7DG7u3btIjs777T22dnZ7Nq1q0SCEkIIIYT4r1KpVAR5O6AAWTlFm4gp97iW3g55Zm8WL8bw4cOJj48nPT2dixcvMmvWLExMTF52WEL8pxU72W3cuDFJSUl5ticnJ9O4ceMSCUoIIYQQ4r/M39WWctbGXL2X9tSlHRVF4dq9dMpZG1Pf1fYFRSiEEK++Yie7iqLk+8Twzp07mJqalkhQQgghhBD/ZSYGeoQ298DWzJBLSakFtvBm5ai5lJSKjZkBoc09MDGQEWpCCJGryH8R27VrBzzqWhMSEoKh4f9m+cvJyeH48eOa9cqEEEIIIcS/4+1oydjWXkzfEseVu2kAWBrpoavzaPKq5PRHw8qcbEwIbe6Bt6PlywxXCCFeOUVOdi0tH/0BVRQFc3NzrZnlDAwMqFu3Ln379i35CIUQQggh/qO8HS1Z2LU6e8/dYePJRC7cekhWthpdlQrfcpa09HagvquttOgKIUQ+ivyXMSwsDAAXFxdCQ0Oly7IQQgghxAtgYqBHoJcdTT3L8DAzh/SsHIz0dTE10JXJqIQQohAq5WmzHggtsnC0EEIIIYQQAiQ3eNUVe4KqGzdu0K1bN8qWLYuenh66urpaLyGEEEIIIYQQ4mUr9gCPkJAQEhISGDNmDA4OspabEEIIIYQQQohXT7GT3T179rB7926qVav2HMIRQgghhBBCCCH+vWJ3Y3Zycnrq4uZCCCGEeLECAgIYNmzYc69n/Pjxr9QD75CQENq0afOywxBCCPEKKnayO3v2bEaOHEl8fPxzCEcIIYT490JCQlCpVEydOlVr+9q1a1/48BuVSpXva/ny5S80jhclPj5e6zptbW1p3rw5x44dK3IZLi4uzJ49u0jHzpkzh/Dw8CKXHRERgUql4t69e0U+RwghxOup2Mlup06diIiIoFKlSpibm2NjY6P1EkIIIV4FRkZGTJs2jbt3777sUAgLCyMxMVHr9aa3Rm7bto3ExEQ2b95MSkoKLVu2LNEEMycnB7VajaWlJVZWViVWrhBCiDfHM7Xs/vDDDyxevJj58+cza9YsrZcQQgjxMiiKwoP0LG6nZJCVoyYwMBB7e3umTJlS6Hl79uyhQYMGGBsb4+TkxJAhQ3j48CEA8+fPx9vbW3Nsbsvwd999p9kWGBjIF198UWgdVlZW2Nvba72MjIwACA8Px8rKis2bN+Pp6YmZmRlBQUEkJiZqzs/OzmbIkCFYWVlha2vLiBEj6NGjR6EJ85IlS6hZsybm5ubY29vTpUsXbt68qdmf28K5fft2atasiYmJCfXr1ycuLk6rnKlTp2JnZ4e5uTm9e/cmPT290GvNZWtri729PTVr1mT69OncuHGDAwcOcP78ed59913s7OwwMzOjVq1abNu2TXNeQEAAly5d4uOPP9a0Dj9+n/7880+8vLwwNDQkISEhTzfmjIwMhgwZQpkyZTAyMuKtt97i0KFDwKNW58aNGwNgbW2NSqUiJCQEgD/++AMfHx+MjY2xtbUlMDBQ8zkQQgjxeip2stujR49CX0IIIcSLlJqZzdaYG4SujKb7TwfpFX6I3WdvE3s9hY79hzNv3jyuXLmS77nnz58nKCiI9u3bc/z4cVasWMGePXsYNGgQAI0aNSImJoZbt24BsHPnTkqVKkVERAQAWVlZ7Nu3j4CAgH93DampTJ8+nSVLlrBr1y4SEhIIDQ3V7J82bRrLli0jLCyMyMhI7t+/z9q1awstMysri0mTJhEdHc3atWuJj4/XJHaPGz16NDNmzODw4cPo6enRq1cvzb7ff/+d8ePH89VXX3H48GEcHBxYuHBhsa/P2NgYgMzMTFJSUmjVqhXbt2/n2LFjBAUFERwcTEJCAgCrV6+mXLlyTJw4UdMK/vh9mjZtGj/++COnTp2iTJkyeeoaPnw4q1at4ueff+bo0aO4urrSokULkpKScHJyYtWqVQDExcWRmJjInDlzSExMpHPnzvTq1YvY2FgiIiJo166dzFEihBCvO+UZnDt3Thk9erTy/vvvKzdu3FAURVE2bNignDx58lmKe60kJycrgJKcnPyyQxFCiP+8E1fuKT0WH1CazohQAmdEKO0W7FE6fBuplK/TUildxV9pOiNCKV3JW2nb6QNFURRlzZo1yuP/9fXu3Vv58MMPtcrcvXu3oqOjo6SlpSlqtVqxtbVVVq5cqSiKolSrVk2ZMmWKYm9vryiKouzZs0fR19dXHj58WGCMgGJkZKSYmppqvS5duqQoiqKEhYUpgHLu3DnNOQsWLFDs7Ow07+3s7JRvvvlG8z47O1spX7688u6772q2NWrUSBk6dGiBcRw6dEgBlAcPHiiKoig7duxQAGXbtm2aY/7++28FUNLS0hRFUZR69eopAwYM0CqnTp06iq+vb4H1XLx4UQGUY8eOKYqiKHfv3lXatm2rmJmZKdevX8/3nCpVqijz5s3TvHd2dlZmzZqldUzufYqKitLa3qNHD819SElJUfT19ZVly5Zp9mdmZiply5ZVvv76a63rvnv3ruaYI0eOKIASHx9f4HUJIUR+JDd4tRW7ZXfnzp34+Phw4MABVq9eTUpKCgDR0dGMGzeuRBJwIYQQ4mlOXk1mwl8xXE5KpaylEeVtTLAyMcDcSB8DPR2MDXQpa2lEueZ9WLvyN/6MOJinjOjoaMLDwzEzM9O8WrRogVqt5uLFi6hUKho2bEhERAT37t0jJiaGAQMGkJGRwenTp9m5cye1atXCxMSk0FhnzZpFVFSU1qts2bKa/SYmJlSqVEnz3sHBQdPlODk5mRs3blC7dm3Nfl1dXWrUqFFonUeOHCE4OJjy5ctjbm5Oo0aNADQtqLmqVq2qVS+gqTs2NpY6depoHV+vXr1C681Vv359zMzMsLa2Jjo6mhUrVmBnZ0dKSgqhoaF4enpiZWWFmZkZsbGxeeLKj4GBgVa8Tzp//jxZWVn4+/trtunr61O7dm1iY2MLPM/X15emTZvi4+NDhw4dWLRo0Ssx1lsIIcS/U+xkd+TIkUyePJmtW7diYGCg2d6kSRP2799fosEJIYQQ+UnNzGb6ljiSHmbgbGOCvm7+/53p6+pQrVY9bNxrMuiTz8jIytHan5KSwkcffaSVhEZHR3P27FlN8hkQEEBERAS7d+/Gz88PCwsLTQK8c+dOTRJZGHt7e1xdXbVeenr/W+peX19f63iVSvWvutA+fPiQFi1aYGFhwbJlyzh06BBr1qwBHnUlftzjdeeOj1Wr1c9cd64VK1YQHR3N3bt3OX/+PK1atQIgNDSUNWvW8NVXX7F7926ioqLw8fHJE1d+jI2Nn8ts2rq6umzdupWNGzfi5eXFvHnz8PDw4OLFiyVelxBCiBen2MnuiRMnaNu2bZ7tZcqU4fbt2yUSlBBCCFGYyHN3uHI3DUerpyc/KpWKeu8P5nLUHlZv2qG1r3r16sTExORJRF1dXTUPdHPH7a5cuVIzNjcgIIBt27YRGRn5r8frPo2lpSV2dnaaSZbg0UzER48eLfCc06dPc+fOHaZOnUqDBg2oXLmy1uRUReXp6cmBAwe0thX1wbaTkxOVKlXKM1NyZGQkISEhtG3bFh8fH+zt7fMsZ2hgYEBOjvaDiaKoVKkSBgYGREZGarZlZWVx6NAhvLy8NGUDecpXqVT4+/szYcIEjh07hoGBgeYBgRBCiNdTsZNdKysrrckich07dgxHR8cSCUoIIYQoiKIobDr56P+hglp0n1TG2R376oGsWvKj1vYRI0awd+9eBg0aRFRUFGfPnmXdunWaCargUTdfa2trfv31V61kd+3atWRkZGh1mS3IvXv3uH79utarODP9Dh48mClTprBu3Tri4uIYOnQod+/eLTDRL1++PAYGBsybN48LFy7w559/MmnSpCLXl2vo0KEsXryYsLAwzpw5w7hx4zh16lSxy3mcm5sbq1ev1rSid+nSJU9LsouLC7t27eLq1avFepBuampK//79+eyzz9i0aRMxMTH07duX1NRUevfuDYCzszMqlYr169dz69YtUlJSOHDggGYSroSEBFavXs2tW7fw9PT8V9cqhBDi5Sp2svv+++8zYsQIrl+/jkqlQq1WExkZSWhoKN27d38eMQohhBAaKRnZXLj1EEsjvacf/Bjfd/uiKNpJVdWqVdm5cydnzpyhQYMG+Pn5MXbsWK3xtCqVigYNGqBSqXjrrbc051lYWFCzZk1MTU2fWnfPnj1xcHDQes2bN6/IsY8YMYLOnTvTvXt36tWrpxlbnLt80ZNKly5NeHg4K1euxMvLi6lTpzJ9+vQi15erU6dOjBkzhuHDh1OjRg0uXbpE//79i13O42bOnIm1tTX169cnODiYFi1aUL16da1jJk6cSHx8PJUqVaJ06dLFKn/q1Km0b9+ebt26Ub16dc6dO8fmzZuxtrYGwNHRkQkTJjBy5Ejs7OwYNGgQFhYW7Nq1i1atWuHu7s4XX3zBjBkzaNmy5b+6ViGEEC+XSinmoKDMzEwGDhxIeHg4OTk56OnpkZOTQ5cuXQgPD0dXV/d5xfpKuH//PpaWliQnJ2NhYfGywxFCiP+c2ykZ9Ao/hJGeDuZG+k8/4f89SM8iPVvN4pBalDIzfI4RPn9qtRpPT086duz4TC22QgghSobkBq+24j0W59FYl0WLFjFmzBhOnjxJSkoKfn5+uLm5PY/4hBBCCC2GejroqlTkqIs3gVOOWkFXpcJI//V7KHvp0iW2bNlCo0aNyMjIYP78+Vy8eJEuXbq87NCEEEKIV1axk91c5cuXp3z58iUZixBCCPFUZoZ6VCxtyvEryViZGDz9hP+XnJ6NbzlLTA1ev2RXR0eH8PBwQkNDURQFb29vtm3bJmNKhRBCiEIUO9nNyckhPDyc7du3c/PmzTyTSvzzzz8lFpwQQgjxJJVKRZC3A9FXksnKURdpkqqsnEf/V7X0dnguS9c8b05OTlozDAshhBDi6Yqd7A4dOpTw8HDefvttvL29X8svDUIIIV5v/q62lLM25nJSKs42JoX+X6QoCtfupVPOxpj6rrYvMEohhBBCvEzFTnaXL1/O77//rlkcXgghhHjRTAz0CG3uwcT1MVxKSsXRyjjfFt6sHDVX76Vha2ZIaHMPTAyeefSOEEIIIV4zzzRBlaur6/OIRQghhCgyb0dLxrb2YvqWOK7cTQPA0kgPXZ1Hk1clp2cD4GRjQmhzD7wdLV9muEIIIYR4wYq99NCMGTO4cOEC8+fP/092YZbpxYUQ4tWSmpnN3nN32HgykQu3HpKjPJp1uWJpU1p6O1Df1VZadIUQQjwXkhu82oqd7LZt25YdO3ZgY2NDlSpV0NfXXuNw9erVJRrgq0Y+0EII8WpSFIWHmTmkZ+VgpK+LqYHuf/KhrBBCiBdHcoNXW7EfdVtZWdG2bdvnEYsQQgjxzFQqFWaGepgZSiuuEEIIIZ4h2Q0LC3secQghhBBCCCGEECXmmR9/37p1i7i4OAA8PDwoXbp0iQUlhBBCCCGEEEL8G3nXaXiKhw8f0qtXLxwcHGjYsCENGzakbNmy9O7dm9TU1OcRoxBCCCGEEEIIUSzFTnY/+eQTdu7cyV9//cW9e/e4d+8e69atY+fOnXz66afPI0YhhBBCCCGEEKJYij0bc6lSpfjjjz8ICAjQ2r5jxw46duzIrVu3SjK+V47MuCaEEEIIIYQAyQ1edcVu2U1NTcXOzi7P9jJlykg3ZiGEEEIIIYQQr4RiJ7v16tVj3LhxpKena7alpaUxYcIE6tWrV6LBCSGEEEIIIYQQz6LYszHPmTOHFi1aUK5cOXx9fQGIjo7GyMiIzZs3l3iAQgghhBBCCCFEcRV7zC486sq8bNkyTp8+DYCnpyddu3bF2Ni4xAN81Ui/fCGEEEIIIQRIbvCqe6Z1dk1MTOjbt29JxyKEEEIIIYQQQpSIZ0p24+LimDdvHrGxscCjlt1BgwZRuXLlEg1OCCGEEEIIIYR4FsWeoGrVqlV4e3tz5MgRfH198fX15ejRo/j4+LBq1arnEeNzsWDBAlxcXDAyMqJOnTocPHjwZYckhBBCCCGEEKKEFHvMbqVKlejatSsTJ07U2j5u3DiWLl3K+fPnSzTA52HFihV0796d7777jjp16jB79mxWrlxJXFwcZcqUKfRc6ZcvhBBCCCGEAMkNXnXFTnZNTEw4fvw4rq6uWtvPnj2Lr6/va7HWbp06dahVqxbz588HQK1W4+TkxODBgxk5cqTWsRkZGWRkZGje379/HycnJ/lACyGEEEII8R8nye6rrdjdmAMCAti9e3ee7Xv27KFBgwYlEtTzlJmZyZEjRwgMDNRs09HRITAwkH379uU5fsqUKVhaWmpeTk5OLzJcIYQQQgghhBDPoNgTVL3zzjuMGDGCI0eOULduXQD279/PypUrmTBhAn/++afWsa+a27dvk5OTg52dndZ2Ozs7zVJKjxs1ahSffPKJ5n1uy64QQgghhBBCiFdXsZPdAQMGALBw4UIWLlyY7z4AlUpFTk7Ovwzv5TM0NMTQ0PBlhyGEEEIIIYQQohiKneyq1ernEccLU6pUKXR1dblx44bW9hs3bmBvb/+SohJCCCGEEEIIUZKKPWb3dWdgYECNGjXYvn27ZptarWb79u3Uq1fvJUYmhBDPRqVSsXbtWgDi4+NRqVRERUW91JielYuLC7Nnz9a8f/zaXpbw8HCsrKxeagxCCCGEKL5it+wCHDp0iB07dnDz5s08Lb0zZ84skcCep08++YQePXpQs2ZNateuzezZs3n48CE9e/Z82aEJIf5DQkJCuHfvXokmc05OTiQmJlKqVKkSK/NlSkxMxNra+pnPv3//PtOmTWPVqlXEx8djZWWFt7c3AwYMoG3btqhUqmKXOX78eNauXfvaPlAQQggh/iuKnex+9dVXfPHFF3h4eGBnZ6f1ReFZvjS8DJ06deLWrVuMHTuW69evU61aNTZt2pRn0iohhHjd6OrqvlFDMv7Ntdy7d4+33nqL5ORkJk+eTK1atdDT02Pnzp0MHz6cJk2aSIutEEII8QYrdjfmOXPmsHjxYmJjY4mIiGDHjh2a1z///PM8YnwuBg0axKVLl8jIyODAgQPUqVPnZYckhPgPUBSFB+lZ3E7JICtHu2dMQEAAQ4YMYfjw4djY2GBvb8/48eO1jjl79iwNGzbEyMgILy8vtm7dqrX/yW7MOTk59O7dmwoVKmBsbIyHhwdz5szROickJIQ2bdowffp0HBwcsLW1ZeDAgWRlZWmOWbJkCTVr1sTc3Bx7e3u6dOnCzZs3NfsjIiJQqVT8/fffVK1aFSMjI+rWrcvJkye16lq1ahVVqlTB0NAQFxcXZsyYUej9erwbc2ZmJoMGDcLBwQEjIyOcnZ2ZMmVKged+/vnnxMfHc+DAAXr06IGXlxfu7u707duXqKgozMzMALh79y7du3fH2toaExMTWrZsydmzZ/MtMzw8nAkTJhAdHY1KpUKlUhEeHo6iKIwfP57y5ctjaGhI2bJlGTJkSKHXJoQQQojnq9gtuzo6Ovj7+z+PWIQQ4o2VmplN5Lk7bDqZyIVbD8lRFKLO3sYgJ42tMTfwd7UF4Oeff+aTTz7hwIED7Nu3j5CQEPz9/WnWrBlqtZp27dphZ2fHgQMHSE5OZtiwYYXWq1arKVeuHCtXrsTW1pa9e/fy4Ycf4uDgQMeOHTXH7dixAwcHB3bs2MG5c+fo1KkT1apVo2/fvgBkZWUxadIkPDw8uHnzJp988gkhISFs2LBBq77PPvuMOXPmYG9vz+eff05wcDBnzpxBX1+fI0eO0LFjR8aPH0+nTp3Yu3cvAwYMwNbWlpCQkKfew7lz5/Lnn3/y+++/U758eS5fvszly5cLvO7ly5fTtWtXypYtm2d/bqILj5L9s2fP8ueff2JhYcGIESNo1aoVMTEx6Ovra53XqVMnTp48yaZNm9i2bRsAlpaWrFq1ilmzZrF8+XKqVKnC9evXiY6Ofuo1iadTqVSsWbOGNm3avOxQSpyLiwvDhg176u+xEEKIZ1PsZPfjjz9mwYIFWhOICCGEKNjJq8lM3xLHlbtpqAALIz30dXVQAffTspi26TTlrI15mJFN1apVGTduHABubm7Mnz+f7du306xZM7Zt28bp06fZvHmzJoH76quvaNmyZYF16+vrM2HCBM37ChUqsG/fPn7//XetZNfa2pr58+ejq6tL5cqVefvtt9m+fbsm2e3Vq5fm2IoVKzJ37lxq1apFSkqKVuI4btw4mjVrBjxK3MuVK8eaNWvo2LEjM2fOpGnTpowZMwYAd3d3YmJi+Oabb4qU7CYkJODm5sZbb72FSqXC2dm5wGNv377N3bt3qVy5cqFl5ia5kZGR1K9fH4Bly5bh5OTE2rVr6dChg9bxxsbGmJmZoaenp9XFOiEhAXt7ewIDA9HX16d8+fLUrl37qdf0X7Nv3z7eeustgoKC+Pvvv7X2vcix0AEBAVSrVu1ff5eJj4+nQoUKebZ37dqVpUuX/quyhRBC/HvF7sYcGhpKXFwclSpVIjg4mHbt2mm9hBBC/M/Jq8lM+CuGy0mplLU0oryNCVYmBpgb6WOgp4OxgS5lLY24nJTKpTupOFbSTs4cHBw03YVjY2NxcnLSaqksyizyCxYsoEaNGpQuXRozMzN++OEHEhIStI6pUqUKurq6+dYLcOTIEYKDgylfvjzm5uY0atQIIE85j8djY2ODh4cHsbGxmvif7Bnk7+/P2bNni7Que0hICFFRUXh4eDBkyBC2bNlS4LGKojy1vNyY9PT0tIay2NraasVdFB06dCAtLY2KFSvSt29f1qxZQ3Z2dpHPfxM93mX/QXoWiqLw008/MXjwYHbt2sW1a9dedoglZtu2bSQmJmpeCxYseNkhCSGE4BmS3SFDhrBjxw7c3d2xtbXF0tJS6yWEEOKR1Mxspm+JI+lhBs42Jujr5v8nV19XB2cbE7Jy1By/+oDUzP8lSSqV6l+tb758+XJCQ0Pp3bs3W7ZsISoqip49e5KZmakdwxPddR+v9+HDh7Ro0QILCwuWLVvGoUOHWLNmDUCecp6n6tWrc/HiRSZNmkRaWhodO3bkvffey/fY0qVLY2VlxenTp19IbE5OTsTFxbFw4UKMjY0ZMGAADRs21Br3/F+RmpnN1pgbhK6MpvtPB+kVfojuPx1kyJJ9/PrbckJ69+Xtt98mPDxcc05BY6HzM2LECNzd3TExMaFixYqMGTNG6z6PHz+eatWqsWTJElxcXLC0tOT999/nwYMHwKOHJjt37mTOnDmauuLj44s0vr0gtra22Nvba16WlpacP3+ed999Fzs7O8zMzKhVq5am63tB7t27x0cffYSdnR1GRkZ4e3uzfv16zf6njXl3cXHhq6++olevXpibm1O+fHl++OEHzf7ijnsXQojXXbG7Mf/888+sWrWKt99++3nEI4QQb4zIc3e4cjcNRyvjp85Wr1KpMNTTISUjm73n7hDolXd2eE9PTy5fvkxiYiIODg4A7N+/v/AY/r977oABAzTbzp8/X6zrOH36NHfu3GHq1Kk4OTkBcPjw4XyP3b9/P+XLlwceTfx05swZPD09NfFHRkbmic/d3V2rVbkwFhYWdOrUiU6dOvHee+8RFBREUlISNjY2Wsfp6Ojw/vvvs2TJEsaNG5dn3G5KSgpGRkZ4enqSnZ3NgQMHNN2Y79y5Q1xcHF5eXvnGYGBgkG9LtLGxMcHBwQQHBzNw4EAqV67MiRMnqF69epGu7U1QUJf9HLXC9r/XoWdbjtmHH9KgZVtmTRrNqFGjUKlUBY6Fzo+5uTnh4eGULVuWEydO0LdvX8zNzRk+fLjmmPPnz7N27VrWr1/P3bt36dixI1OnTuXLL79kzpw5nDlzBm9vbyZOnAg8ejhS1PHtRZWSkkKrVq348ssvMTQ05JdffiE4OJi4uDjN78jj1Go1LVu25MGDByxdupRKlSoRExOj+d0o6pj3GTNmMGnSJD7//HP++OMP+vfvT6NGjfDw8CjWuHchhHgTFDvZtbGxoVKlSs8jFiGEeGMoisKmk4kABbboPik3Id54MpGmnmXyJMiBgYG4u7vTo0cPvvnmG+7fv8/o0aMLLdPNzY1ffvmFzZs3U6FCBZYsWcKhQ4fyHWdYkPLly2NgYMC8efPo168fJ0+eZNKkSfkeO3HiRGxtbbGzs2P06NGUKlVKM7HQp59+Sq1atZg0aRKdOnVi3759zJ8/n4ULFxYpjpkzZ+Lg4ICfnx86OjqsXLkSe3v7ApcP+vLLL4mIiKBOnTp8+eWX1KxZE319fXbv3s2UKVM4dOgQbm5uvPvuu/Tt25fvv/8ec3NzRo4ciaOjI++++26+5bq4uHDx4kWioqIoV64c5ubm/Pbbb+Tk5FCnTh1MTExYunQpxsbGhY4rftPkdtlPepiBo5Vxns/9naOb8PBvxeWkVFKMy5J09x47d+4kICCgwLHQ+fniiy80P7u4uBAaGsry5cu1kl21Wk14eDjm5uYAdOvWje3bt/Pll19iaWmJgYEBJiYmWnXp6uoWaXx7furXr4+Ozv+ud/fu3fj5+eHr66vZNmnSJNasWcOff/7JoEGD8pSxbds2Dh48SGxsLO7u7sCj8fG5ijrmvVWrVpqHWyNGjGDWrFns2LEDDw+PYo17F0KIN0GxuzGPHz+ecePGkZqa+jziEUKIN0JKRjYXbj3E0qh4zxQN9HS4cOshDzPzthzq6OiwZs0a0tLSqF27Nn369OHLL78stLyPPvqIdu3a0alTJ+rUqcOdO3e0WnmLonTp0oSHh7Ny5Uq8vLyYOnUq06dPz/fYqVOnMnToUGrUqMH169f566+/MDAwAB51Q/79999Zvnw53t7ejB07lokTJxZpcip41KL39ddfU7NmTWrVqkV8fDwbNmzQSjIeZ2Njw/79+/nggw+YPHkyfn5+NGjQgN9++41vvvlG03IYFhZGjRo1aN26NfXq1UNRFDZs2JCna3eu9u3bExQUROPGjSldujS//fYbVlZWLFq0CH9/f6pWrcq2bdv466+/sLW1LdK1ve6e1mU/OfESty6ewq1eC5xtTLiblkOZao35ftGiYte1YsUK/P39sbe3x8zMjC+++CLP2HEXFxdNogt5x6AXpCjj2wuKKSoqSvPy8vIiJSWF0NBQPD09sbKywszMjNjY2ALLy314kpvoPqmoY96rVq2q+VmlUmFvb6+59uKMexdCiDdBsVt2586dy/nz57Gzs8PFxSXPl4GjR4+WWHBCCPG6yshWk6MohbbqNuwzTut9q5Hf8SA9i/RsNelZOZgZ6mnWmM3l7u7O7t27tbY9PhmTi4uL1ntDQ0PCwsIICwvTOufxcXr5jY18cpbazp0707lz5wLrzfXWW2/lWVv3ce3bt6d9+/YF7o+Pjy+wjr59+2pmhy4qS0tLpkyZUui4RGtra3755ZcC94eEhGgl5IaGhvzxxx95jnsTl8Ypqqd12T+zex1KTg7LP/7fEChFUYg3NCQ5ObnIc37s27ePrl27MmHCBFq0aIGlpSXLly/PM3a1sDHoBckd3z5jxgzq1auHubk533zzDQcOHHhqXE5OTri6umptGzp0KFu3bmX69Om4urpibGzMe++9V+A4d2Nj46fWUxSFXXvuuPeNGzeybds2OnbsSGBgYL6fZyGEeBMUO9n9L/9nLoQQRWWop4OuSkWOumizAufKUSvoqlQY6RdtDKsQL9vTuuyrc7I5F7mB2u8PxbFKXc32a8lpnF4yjl9//ZX+/fsXOBb6cXv37sXZ2Vmr+/6lS5eKHXN+dZXE+PYnywsJCaFt27bAozG8Tz7MeVzVqlW5cuUKZ86cybd1tyTGvEPRx70LIcSboNjJbu76j0IIIQpmZqhHxdKmHL+SjJWJQZHPS07PxrecJaYGkuyK18PTuuxfjt5DRuoD3Bu8i4HJ/9ZkVtlkkuTTgB9/+on+/fvnOxba0NBQqyw3NzcSEhJYvnw5tWrV4u+//9bMDF4cLi4uHDhwgPj4eMzMzLCxsSmR8e1Pxrp69WqCg4NRqVSMGTOm0NblRo0a0bBhQ9q3b8/MmTNxdXXl9OnTqFQqgoKC/vWYdyj+uHchhHjdFXvMbq4jR46wdOlSli5dyrFjx0oyJiGEeO2pVCqCvB1QgKycoi0dlHtcS2+Hp87e/KoJCAhAURT50vwflNtlX1cn/8/smV1/UtartlaiC6Cro8LOtxFHjxzh+PHj+Y6FftI777zDxx9/zKBBg6hWrRp79+7VTNhUHKGhoejq6uLl5UXp0qVJSEgokfHtj5s5cybW1tbUr1+f4OBgWrRo8dSZuVetWkWtWrXo3LkzXl5eDB8+XNMC/W/HvEPxx70LIcTrTqXkN+iqEDdv3uT9998nIiJC86Xm3r17NG7cmOXLl1O6dOnnEecr4/79+1haWpKcnIyFhcXLDkcI8QpLzcxmwLKjXE5KxdnGpNAEVlEUEpLSKGdjzMKu1TExKHbHGyFeigfpWXT/6SA6KorVi+FeaiZqBZb0qYOZoXzehRCvJ8kNXm3FfpQ3ePBgHjx4wKlTp0hKSiIpKYmTJ09y//59hgwZ8jxiFEKIV154eLhWq+b48eOpX7smoc09sDUz5FJSaoEtvFk5ai4lpWJjZkBoc49XOtF1cXHJM3mV+G/L7bJ/Pz27WOclp2dTsbSpdNkXQgjx3BQ72d20aRMLFy7E09NTs83Ly4sFCxawcePGEg1OCCGep5CQEFQqFSqVCn19fezs7GjWrBmLFy9+6sytReXtaMnY1l442ZhwLTmdS0mp3EvN5EF6FvdSM7mUlMq15HScbEwY29oLb8eizUoLkJmZyddff42vry8mJiaUKlUKf39/wsLCyMrKKpH4hXia/1qXfSGEEK+PYjcfqNXqfNce1NfXL7Evh0II8aIEBQURFhZGTk4ON27cYNOmTQwdOpQ//viDP//8Ez29f9/K6u1oycKu1dl77g4bTyZy4dZDsrLV6KpU+JazpKW3A/VdbYvVopuZmUmLFi2Ijo5m0qRJ+Pv7Y2Fhwf79+5k+fTp+fn5Uq1btX8cuRFH4u9pSztq4yF32r91Lp5yNMfVd/xvrEAshhHg5it2y26RJE4YOHcq1a9c0265evcrHH39M06ZNSzQ4IYQoaYqi8CA9i9spGWTlqDE0NMTe3h5HR0eqV6/O559/zrp169i4caPW+rMzZ87Ex8cHU1NTnJycGDBgACkpKUWu91T0MaYN/YCfBwTyz+etuL18FJ/W0Gd6B18Cveww1tdl/PjxlC9fHkNDQ8qWLVvo0JDZs2eza9cutm/fzsCBA6lWrRoVK1akS5cuHDhwADc3NwAyMjIYMmQIZcqUwcjIiLfeeotDhw5pyqlZsybTp0/XvG/Tpg36+vqaa7ty5QoqlYpz585pjnnw4AGdO3fG1NQUR0dHFixYoBVbQkIC7777LmZmZlhYWNCxY0du3LgBPFpHV0dHh8OHD+e5HmdnZ9RqNXfv3qVr166ULl0aY2Nj3Nzc8qwTLF4tJgZ6b1yXfSGEEK+/Yie78+fP5/79+7i4uFCpUiUqVapEhQoVuH//PvPmzXseMQohxL+WmpnN1pgbhK6MpvtPB+kVfojdZ29z8moyW2NukJr5v/GGTZo0wdfXl9WrV2u26ejoMHfuXE6dOsXPP//MP//8w/Dhw4tc/4MHD+jRowd79uxh//79eFX24L0272iSylWrVjFr1iy+//57zp49y9q1a/Hx8SmwvGXLlhEYGIifn1+effr6+piamgIwfPhwVq1axc8//8zRo0dxdXWlRYsWJCUlAY+WO4mIiAAePQjYvXs3VlZW7NmzB4CdO3fi6OiIq6urpvxvvvkGX19fjh07xsiRIxk6dChbt24FHvX+effdd0lKSmLnzp1s3bqVCxcu0KlTJ+DRmN/AwMA8yWtYWBghISHo6OgwZswYYmJi2LhxI7GxsXz77beUKlWqyPdavBzPs8u+EEII8SyK/UjVycmJo0ePsm3bNk6fPg08Wug8MDCwxIMTQoiScPJqMtO3xHHlbhoqwMJID31dHVTA/bQspm06TTlrY0Kbe2i+gFeuXJnjx49ryhg2bJjmZxcXFyZPnky/fv2KvMZlkyZNtN7/8MMPWFlZsXPnTlq3bk1CQgL29vYEBgair69P+fLlqV27doHlnT17loCAgELrfPjwId9++y3h4eG0bNkSgEWLFrF161Z++uknPvvsMwICAvjpp5/Iycnh5MmTGBgY0KlTJyIiIggKCiIiIoJGjRpplevv78/IkSMBcHd3JzIyklmzZtGsWTO2b9/OiRMnuHjxIk5OTgD88ssvVKlShUOHDlGrVi369OlDv379mDlzJoaGhhw9epQTJ06wbt064FHLsJ+fHzVr1tTcb/F6eB5d9oUQQohn9UwLq6lUKpo1a8bgwYMZPHiwJLpCiFfWyavJTPgrhstJqZS1NKK8jQlWJgaYG+ljoKeDsYEuZS2NuJyUysT1MZy8mgw8auV8fNzhtm3baNq0KY6Ojpibm9OtWzfu3LlDampqkeK4ceMGffv2xc3NDUtLSywsLEhJSSEhIQGADh06kJaWRsWKFenbty9r1qwhO7vg2W2Lsmrc+fPnycrKwt/fX7NNX1+f2rVrExsbC0CDBg148OABx44dY+fOnTRq1IiAgABNa+/OnTvzJNX16tXL8z63vNjYWJycnDSJLjyaxNDKykpzTJs2bdDV1WXNmjXAo5msGzdurElq+/fvz/Lly6lWrRrDhw9n7969T71W8eowMdAj0MuO6R18WdKnDotDarGkTx1Nl31JdIUQQrwoRU52//nnH7y8vLh//36efcnJyVSpUoXdu3eXaHBCCPFvpGZmM31LHEkPM3C2MUFfN/8/efq6OjjbmHAnJYPpW+JIzcwmNjaWChUqAI/GmbZu3ZqqVauyatUqjhw5ohmnmpmZWaRYevToQVRUFHPmzGHv3r1ERUVha2urOd/JyYm4uDgWLlyIsbExAwYMoGHDhgXOquzu7q7pXfNvWFlZ4evrS0REhCaxbdiwIceOHePMmTOcPXs2T8vuv2VgYED37t0JCwsjMzOTX3/9lV69emn2t2zZkkuXLvHxxx9z7do1mjZtSmhoaInGIJ4/lUqFmaEepcwMMTPUk1mXhRBCvHBFTnZnz55N3759810s2dLSko8++oiZM2eWaHBCCPFvRJ67w5W7aThaGT/1i7ZKpcLRypgrd9NYsHQdJ06coH379gAcOXIEtVrNjBkzqFu3Lu7u7lqT9BUplshIhgwZQqtWrahSpQqGhobcvn1b6xhjY2OCg4OZO3cuERER7Nu3jxMnTuRbXpcuXdi2bRvHjh3Lsy8rK4uHDx9SqVIlDAwMiIyM1Np36NAhvLy8NNsaNWrEjh072LVrFwEBAdjY2ODp6cmXX36Jg4MD7u7uWuXv378/z/vc5eg8PT25fPkyly9f1uyPiYnh3r17WnX26dOHbdu2sXDhQrKzs2nXrp1WmaVLl6ZHjx4sXbqU2bNn88MPP+R7H4QQQgghClLkZDc6OpqgoKAC9zdv3pwjR46USFBCCPFvKYrCppOJAAW26ALkZGeRmnybh3dvknz5DPHbljJ6YHdat25N9+7dAXB1dSUrK4t58+Zx4cIFlixZwnfffVeseNzc3FiyZAmxsbEcOHCArl27YmxsrNkfHh7OTz/9xMmTJ7lw4QJLly7F2NgYZ2fnfMsbNmwY/v7+NG3alAULFhAdHc2FCxf4/fffqVu3LmfPnsXU1JT+/fvz2WefsWnTJmJiYujbty+pqan07t1bU1ZAQACbN29GT0+PypUra7YtW7Ys31bdyMhIvv76a86cOcOCBQtYuXIlQ4cOBSAwMBAfHx+6du3K0aNHOXjwIN27d6dRo0aaMbjwKCmuW7cuI0aMoHPnzlr3YuzYsaxbt45z585x6tQp1q9fr7W2uxBCCCFEURQ52b1x40a+6+vm0tPT49atWyUSlBBC/FspGdlcuPUQS6PCxwdePbGP5cNa8ftn77Jl5lAeXIzCu/1Qlv2+Cl1dXQB8fX2ZOXMm06ZNw9vbm2XLljFlypRixfPTTz9x9+5dqlevTrdu3TTLAeWysrJi0aJF+Pv7U7VqVbZt28Zff/2FrW3+65AaGhqydetWhg8fzvfff0/dunWpVasWc+fOZciQIXh7ewMwdepU2rdvT7du3ahevTrnzp1j8+bNWFtba8pq0KABarVaK7ENCAggJycn30mwPv30Uw4fPoyfnx+TJ09m5syZtGjRAnjUQr5u3Tqsra1p2LAhgYGBVKxYkRUrVuQpp3fv3mRmZmp1YYZH3ZxHjRpF1apVadiwIbq6uixfvrzoN1sIIYQQAlApRZnlBKhUqRIzZsygTZs2+e5fvXo1oaGhXLhwoSTje+Xcv38fS0tLkpOT8+3SLYR4NdxOyaBX+CGM9HQwNyr4Qd2THqRnkZ6tZnFILUqZGT7HCMWkSZNYuXKl1qzXQgghxOtEcoNXW5Fbdlu1asWYMWNIT0/Psy8tLY1x48bRunXrEg1OCCGelaGeDroqFTnqIj3P08hRK+iqVBjp6z6nyERKSgonT55k/vz5DB48+GWHI4QQQog3VJGT3S+++IKkpCTc3d35+uuvWbduHevWrWPatGl4eHiQlJTE6NGjn2esQghRZGaGelQsbcr99IKX78lPcno2FUubYmogye7zMmjQIGrUqEFAQECeLsxCCCGEECWlyN2YAS5dukT//v3ZvHmzZo1HlUpFixYtWLBggWaZjjeZdFUQ4vWxNeYG0zadpqylUaGTVOXKylFzLTmdkUGVCfSyewERCiGEEOJ1JrnBq61YK7s7OzuzYcMG7t69y7lz51AUBTc3N62JToQQ4lXh72pLOWtjLiel4mxjUujyQ4qicO1eOuVsjKnvmv+kUEIIIYQQ4vVR5G7Mj7O2tqZWrVrUrl1bEl0hxCvLxECP0OYe2JoZcikplawcdb7HZeWouZSUio2ZAaHNPTAxKNZzQCGEEEII8QqSb3RCiDeat6MlY1t7MX1LHFfupgFgaaSHrs6jyauS/39Mr5ONCaHNPfB2tHyZ4QohhBBCiBIiya4Q4o3n7WjJwq7V2XvuDhtPJnLh1kOystXoqlT4lrOkpbcD9V1tpUVXCCGEEOINIt/shBD/CSYGegR62dHUswwPM3NIz8rBSF8XUwPdQsfyCiGEEEKI15Mku0KI/xSVSoWZoR5mhvLnTwghhBDiTfZME1QJIYQQQgghhBCvMkl2hRBCCCGEEEK8cSTZFUIIIYQQQgjxxpFkVwghhBBCCCHEG0eSXSGEEEIIIYQQbxxJdoUQQgghhBBCvHEk2RVCCCGEEEII8caRZFcIIYQQQoj/qPHjx1OtWrVCj4mPj0elUhEVFfVCYhKipEiyK4QQQgghxGsmJCQElUqledna2hIUFMTx48f/dblt2rTR2ubk5ERiYiLe3t7/quwXKSAgQHNvjIyMcHd3Z8qUKSiK8rJDEy+QJLtCCCGEEEK8BhRF4UF6FrdTMsjKURMUFERiYiKJiYls374dPT09WrduXeL16urqYm9vj56eXomXXRhFUcjOzn7m8/v27UtiYiJxcXGMGjWKsWPH8t1335VghOJVJ8muEEIIIYQQr7DUzGy2xtwgdGU03X86SK/wQ+w+e5uzt9M5kaTCwqYU1apVY+TIkVy+fJlbt25pzh0xYgTu7u6YmJhQsWJFxowZQ1ZWVr71jB8/np9//pl169ZpWkUjIiLydGOOiIhApVKxefNm/Pz8MDY2pkmTJty8eZONGzfi6emJhYUFXbp0ITU1VVN+RkYGQ4YMoUyZMhgZGfHWW29x6NAhzf7ccjdu3EiNGjUwNDRkz549qNVqpkyZQoUKFTA2NsbX15c//vjjqffNxMQEe3t7nJ2d6dmzJ1WrVmXr1q2a/efPn+fdd9/Fzs4OMzMzatWqxbZt2zT7P//8c+rUqZOnXF9fXyZOnKi1rVatWhgZGVG5cmUWLlyo2Z5771avXk3jxo0xMTHB19eXffv2aY65dOkSwcHBWFtbY2pqSpUqVdiwYcNTr0883Yt9PCOEEEIIIYQospNXk5m+JY4rd9NQARZGeujr6qAC7qdlMW3TacpZGzPA35GlS5fi6uqKra2t5nxzc3PCw8MpW7YsJ06coG/fvpibmzN8+PA8dYWGhhIbG8v9+/cJCwsDwMbGhmvXruUb2/jx45k/fz4mJiZ07NiRjh07YmhoyK+//kpKSgpt27Zl3rx5jBgxAoDhw4ezatUqfv75Z5ydnfn6669p0aIF586dw8bGRlPuyJEjmT59OhUrVsTa2popU6awdOlSvvvuO9zc3Ni1axcffPABpUuXplGjRk+9h4qisGfPHk6fPo2bm5tme0pKCq1ateLLL7/E0NCQX375heDgYOLi4ihfvjxdu3ZlypQpnD9/nkqVKgFw6tQpjh8/zqpVqwD4/fffARgzZgz+/v4cO3aMvn37YmpqSo8ePTR1jR49munTp+Pm5sbo0aPp3Lkz586dQ09Pj4EDB5KZmcmuXbswNTUlJiYGMzOzp16XKAJFFEtycrICKMnJyS87FCGEEEII8QY7ceWe8t63e5Um03co3X7cr/QKO6h5ufq/rah0dBU9Q2NF18BIAZTSdvbKkSNHCi3zm2++UWrUqKF5P27cOMXX11fzvkePHsq7776rdc7FixcVQDl27JiiKIqyY8cOBVC2bdumOWbKlCkKoJw/f16z7aOPPlJatGihKIqipKSkKPr6+sqyZcs0+zMzM5WyZcsqX3/9tVa5a9eu1RyTnp6umJiYKHv37tWKqXfv3krnzp0LvM5GjRop+vr6iqmpqaKvr68AipGRkRIZGVno/alSpYoyb948zXtfX19l4sSJmvejRo1S6tSpo3lfoUKFPLnBpEmTlHr16imK8r979+OPP2r2nzp1SgGU2NhYRVEUxcfHRxk/fnyhcYlnIy27QgghhBBCvGJSM7OZviWOpIcZONuYoFKp8hzjULkG9buPQFEULiXe4u6R9QS1bMmhgwdxdnYGYMWKFcydO5fz58+TkpJCdnY2FhYWJRJj1apVNT/b2dlpuko/vu3gwYPAoy7DWVlZ+Pv7a/br6+tTu3ZtYmNjtcqtWbOm5udz586RmppKs2bNtI7JzMzEz8+v0Pi6du3K6NGjuXv3LuPGjaN+/frUr19fsz8lJYXx48fz999/k5iYSHZ2NmlpaSQkJGiVsXjxYsaMGYOiKPz222988sknADx8+JCLFy8CULZsWc052dnZWFpaFnivHBwcALh58yaVK1dmyJAh9O/fny1bthAYGEj79u21jhfPTpJdIYQQQgghXjGR5+5w5W4ajlbG+Sa6AHqGRljYOQHgWbocV53c2Ts2mEWLFjF58mT27dtH165dmTBhAi1atMDS0pLly5czY8aMEolRX19f87NKpdJ6n7tNrVYXu1xTU1PNzykpKQD8/fffODo6ah1naGhYaDmWlpa4uroCj7obu7q6UrduXQIDA4FH3ba3bt3K9OnTcXV1xdjYmPfee4/MzExNGZ07d2bEiBEcPXqUtLQ0Ll++TKdOnbRiA9i9ezfm5uaa97q6ulqxPHmvAM296dOnDy1atODvv/9my5YtTJkyhRkzZjB48OBCr088nSS7QgghhBBCvEIURWHTyUQA9HWLNp/so+NUqFFpJoXau3cvzs7OjB49WnPcpUuXCi3HwMCAnJycZwu8EJUqVcLAwIDIyEhNq3NWVhaHDh1i2LBhBZ7n5eWFoaEhCQkJRRqfWxAzMzOGDh1KaGgox44dQ6VSERkZSUhICG3btgUeJa/x8fFa55UrV45GjRqxbNky0tLSaNasGWXKlAEetVw7ODiQmJhIpUqV/lWLuZOTE/369aNfv36MGjWKRYsWSbJbAmQ2ZiGEEEIIIV4hKRnZXLj1EEujwtulcrKzSE2+TWrybe5du0j8X/PITE+lWdDbALi5uZGQkMDy5cs5f/48c+fOZc2aNYWW6eLiwvHjx4mLi+P27dsFztxcXKampvTv35/PPvuMTZs2ERMTQ9++fUlNTaV3794Fnmdubk5oaCgff/wxP//8M+fPn+fo0aPMmzePn3/+uVgxfPTRR5w5c0YzuZSbmxurV68mKiqK6OhounTpkm9LdNeuXVm+fDkrV66ka9euWvtGjRoFwHfffceZM2c4ceIEYWFhzJw5s8hxDRs2jM2bN3Px4kWOHj3Kjh078PT0LNa1ifxJsiuEEEIIIcQrJCNbTY6ioKuTf/flXFdP7GP5sFYsH9aKvyb14u6l09ToNZFa9d8C4J133uHjjz9m0KBBVKtWjb179zJmzJhCy+zbty8eHh7UrFmT0qVLExkZWWLXNXXqVNq3b0+3bt2oXr06586dY/PmzVhbWxd63qRJkxgzZgxTpkzB09OToKAg/v77bypUqFCs+m1sbOjevTvjx49HrVYzc+ZMrK2tqV+/PsHBwbRo0YLq1avnOe+9997jzp07pKam0qZNG619uTMuL126FB8fHxo1akR4eHixYsvJyWHgwIGaa3N3d9davkg8O5WiKMrLDuJ1cv/+fSwtLUlOTi6xwf1CCCGEEELkepCeRfefDqKjAisTgyKfdy81E7UCS/rUwcxQRiu+CJIbvNqkZVcIIYQQQohXiJmhHhVLm3I/PbtY5yWnZ1OxtCmmBrpPP1iI/wBJdoUQQgghhHiFqFQqgrwdUICsnKLNZpx7XEtvhwJnbxbiv0aSXSFEsalUKtauXVuiZY4fP55q1aqVaJlCCCHE68rf1ZZy1sZcvZfG00YdKorCtXvplLM2pr6r7QuKUIhXnyS7QryiQkJCUKlUmnXr7OzsaNasGYsXLy72mnUlnUgmJibSsmVLAOLj41GpVERFRRV6ztOOCw0NZfv27SUWoxBCCPE6MzHQI7S5B7ZmhlxKSi2whTcrR82lpFRszAwIbe6BiYGM1RUilyS7QrzCgoKCSExMJD4+no0bN9K4cWOGDh1K69atyc4u3jieoijq8gL29vZPXci9uMzMzLC1lafRQgghRC5vR0vGtvbCycaEa8npXEpK5V5qJg/Ss7iXmsmlpFSuJafjZGPC2NZeeDtavuyQhXilSLIrxCtEURQepGdxOyWDrBw1hoaG2Nvb4+joSPXq1fn8889Zt24dGzduJDw8XHPevXv36NOnD6VLl8bCwoImTZoQHR0NQHh4OBMmTCA6OlrTUpx7rkql4ttvv+Wdd97B1NSUL7/8EoBvv/1Ws/i7h4cHS5Ys0Yrz8W7MuVPr+/n5oVKpCAgIeKZrf7L1Wa1WM3HiRMqVK4ehoSHVqlVj06ZNmv25LcWrV6+mcePGmJiY4Ovry759+zTHXLp0ieDgYKytrTE1NaVKlSps2LDhmeITQgghXgZvR0sWdq3OyKDK+JazRK1AerYatQK+5SwZGVSZhV2rS6IrRD6kn4MQr4DUzGwiz91h08lELtx6SI6iEHX2NgY5aWyNuYG/q62mW1KTJk3w9fVl9erV9OnTB4AOHTpgbGzMxo0bsbS05Pvvv6dp06acOXOGTp06cfLkSTZt2sS2bdsAsLT833+I48ePZ+rUqcyePRs9PT3WrFnD0KFDmT17NoGBgaxfv56ePXtSrlw5GjdunCf2gwcPUrt2bbZt20aVKlUwMCj6EgmFmTNnDjNmzOD777/Hz8+PxYsX884773Dq1Cnc3Nw0x40ePZrp06fj5ubG6NGj6dy5M+fOnUNPT4+BAweSmZnJrl27MDU1JSYmBjMzsxKJTwghhHhRTAz0CPSyo6lnGR5m5pCelYORvi6mBroyGZUQhZBkV4iX7OTVZKZviePK3TRUgIWRHvq6OqiA+2lZTNt0mnLWxoQ299A8ta1cuTLHjx8HYM+ePRw8eJCbN29quhZPnz6dtWvX8scff/Dhhx9iZmaGnp4e9vb2eerv0qULPXv21Lzv3LkzISEhDBgwAIBPPvmE/fv3M3369HyT3dKlSwNga2ubb/nPavr06YwYMYL3338fgGnTprFjxw5mz57NggULNMeFhoby9ttvAzBhwgSqVKnCuXPnqFy5MgkJCbRv3x4fHx8AKlasWGLxCSGEEC+aSqXCzFBP1tAVooikG7MQL9HJq8lM+CuGy0mplLU0oryNCVYmBpgb6WOgp4OxgS5lLY24nJTKxPUxnLyaDDzq7pz7JDc6OpqUlBRsbW0xMzPTvC5evMj58+efGkPNmjW13sfGxuLv76+1zd/fn9jY2BK66qe7f/8+165dK1IcVatW1fzs4OAAwM2bNwEYMmQIkydPxt/fn3HjxmkeEAghhBBCiDefJLtCvCSpmdlM3xJH0sMMnG1M0NfN/9dRX1cHZxsT7qRkMH1LHKmZ2cTGxmrGyqakpODg4EBUVJTWKy4ujs8+++ypcZiampbodb1o+vr6mp9zHwDkzlbdp08fLly4QLdu3Thx4gQ1a9Zk3rx5LyVOIYQQQgjxYkmyK8RLEnnuDlfupuFoZfzU8TYqlQpHK2Ou3E1jwdJ1nDhxgvbt2wNQvXp1rl+/jp6eHq6urlqvUqVKAWBgYEBOTk6R4vL09CQyMlI71shIvLy88j0+d4xuUcsvCgsLC8qWLVusOAri5OREv379WL16NZ9++imLFi0qsTiFEEIIIcSrSzr8C/ESKIrCppOJAAW26ALkZGeRmnwbRa0mLTmJ+IO7GL3jV1q3bk337t0BCAwMpF69erRp04avv/4ad3d3rl27xt9//03btm2pWbMmLi4uXLx4kaioKMqVK4e5uXmBSwd99tlndOzYET8/PwIDA/nrr79YvXq1ZnKrJ5UpUwZjY2M2bdpEuXLlMDIy0poA60lxcXF5tlWpUiXfOMaNG0elSpWoVq0aYWFhREVFsWzZsgLLftKwYcNo2bIl7u7u3L17lx07duDp6Vnk84UQQgghxOtLkl0hXoKUjGwu3HqIpVHhv4JXT+xj+bBWqHR1MTSxwMKxEt7th7Js0Xh0dXWBR62+GzZsYPTo0fTs2ZNbt25hb29Pw4YNsbOzA6B9+/aaJXru3btHWFgYISEh+dbZpk0b5syZw/Tp0xk6dCgVKlQgLCyswCWF9PT0mDt3LhMnTmTs2LE0aNCAiIiIAq8pd8Kpx12+fDnPtiFDhpCcnMynn37KzZs38fLy4s8//9SaiflpcnJyGDhwIFeuXMHCwoKgoCBmzZpV5POFEEIIIcTrS6UoivKyg3id3L9/H0tLS5KTk7GwsHjZ4YjX1O2UDHqFH8JITwdzI/2nn/D/HqRnkZ6tZnFILUqZ5d8yK4QQQgghXgzJDV5tMmZXiJfAUE8HXZWKHHXxnjXlqBV0VSqM9HWfU2RCCCGEEEK8GSTZFeIlMDPUo2JpU+6nZxfrvOT0bCqWNsXUQJJdIYQQ4lUQEhJCmzZtXptyX5f6iysiIgKVSsW9e/dedijiFSLJrhAvgUqlIsjbAQXIylEX6Zzc41p6Ozx19mYhhBBClIyQkBBUKhUqlQoDAwNcXV2ZOHEi2dmPHljPmTOH8PBwzfEBAQEMGzZMq4z/SiKWk5PD1KlTqVy5MsbGxtjY2FCnTh1+/PFHzTH53R8hnhdJdsUrLzw8HCsrq5cdRonzd7WlnLUxV++l8bSh84qicO1eOuWsjanvavuCIhRCCCEEQFBQEImJiZw9e5ZPP/2U8ePH88033wBgaWn5Wn1PycrKem5lT5gwgVmzZjFp0iRiYmLYsWMHH3744WuT5GdmZr7sEEQJk2T3DZH71HHq1Kla29euXfvCWgHPnDmDiYkJv/76q9Z2tVpN/fr1ee+9915IHFD8p4YvI6E2MdAjtLkHtmaGXEpKLbCFNytHzaWkVGzMDAht7oGJgUyiLoQQQjxPiqLwID2L2ykZZOWoMTQ0xN7eHmdnZ/r3709gYCB//vknoN3dNyQkhJ07dzJnzhxNa3B8fDyNGzcGwNraGpVKpVkR4Y8//sDHxwdjY2NsbW0JDAzk4cOHWrFMmDCB0qVLY2FhQb9+/bQSMhcXF2bPnq11fLVq1Rg/frzmvUql4ttvv+Wdd97B1NSUL7/8EoDJkydTpkwZzM3N6dOnDyNHjqRatWp57sX06dNxcHDA1taWgQMHFpos//nnnwwYMIAOHTpQoUIFfH196d27N6GhoYXeH4CTJ0/SsmVLzMzMsLOzo1u3bty+fVtTtlqtZsqUKVSoUAFjY2N8fX35448/CowFYM+ePTRo0ABjY2OcnJwYMmSI1v11cXFh0qRJdO/eHQsLCz788EMyMzMZNGgQDg4OGBkZ4ezszJQpUwqtR7y6JNl9jT35h9jIyIhp06Zx9+7dlxKPu7s7U6dOZfDgwSQmJmq2z5gxgwsXLvDdd98Vu8zn+fTxVeDtaMnY1l442ZhwLTmdS0mp3EvN5EF6FvdSM7mUlMq15HScbEwY29oLb8eC168VQgghxL+TmpnN1pgbhK6MpvtPB+kVfojdZ29z8moyW2NukJr5qOuysbFxvq2Ac+bMoV69evTt25fExEQSExNxcnJi1apVwKO15hMTE5kzZw6JiYl07tyZXr16ERsbS0REBO3atdPq7bV9+3bNvt9++43Vq1czYcKEYl/X+PHjadu2LSdOnKBXr14sW7aML7/8kmnTpnHkyBHKly/Pt99+m+e8HTt2cP78eXbs2MHPP/9MeHi4VpftJ9nb2/PPP/9w69atfPcXdH/u3btHkyZN8PPz4/Dhw2zatIkbN27QsWNHzblTpkzhl19+4bvvvuPUqVN8/PHHfPDBB+zcuTPfus6fP09QUBDt27fn+PHjrFixgj179jBo0CCt46ZPn46vry/Hjh1jzJgxzJ07lz///JPff/+duLg4li1bhouLy9NvsnglSbL7GiroD3FZr9qY25Rm4uQvCz2/sKdc8+fPx9vbW3Nsbsvw44lqYGAgX3zxRb5lDx48GF9fX/r27QvA6dOnGTt2LD/88AM2NjZMnDiRcuXKYWhoSLVq1di0aZPm3Pj4eFQqFStWrKBRo0YYGRmxbNmyPHXcunWLmjVr0rZtWzIyMop0zzIyMggNDcXR0RFTU1Pq1KmjWQs2IiKCnj17kpycrHnKmPtEdOHChbi5uWFkZISdnd1zaZ32drRkYdfqjAyqjG85S9QKpGerUSvgW86SkUGVWdi1uiS6QgghxHN08moyA5YdZdqm0xy/koyOCoz0dFAB99OymLbpNP2XHmHR8nVs3ryZJk2a5CnD0tISAwMDTExMsLe3x97eHl1dXWxsbAAoU6YM9vb2WFpakpiYSHZ2Nu3atcPFxQUfHx8GDBiAmZmZpjwDAwMWL15MlSpVePvtt5k4cSJz585FrS7afB+5unTpQs+ePalYsSLly5dn3rx59O7dm549e+Lu7s7YsWPx8fHJc561tTXz58+ncuXKtG7dmrfffpvt27cXWM/MmTO5desW9vb2VK1alX79+rFx48an3p/58+fj5+fHV199ReXKlfHz82Px4sXs2LGDM2fOkJGRwVdffcXixYtp0aIFFStWJCQkhA8++IDvv/8+31imTJlC165dGTZsGG5ubtSvX5+5c+fyyy+/kJ6erjmuSZMmfPrpp1SqVIlKlSqRkJCAm5sbb731Fs7Ozrz11lt07ty5WPdbvDqkP+Rr5uTVZKZviePK3TRUgIWRHvq6j/4QP8jIwb5hd+bNm8zb7/cisJZXnvNzn3JNnjyZxYsXc+vWLQYNGsSgQYMICwujUaNGDBkyhFu3blG6dGl27txJqVKliIiIoF+/fmRlZbFv3z5GjhyZb3wqlYqwsDCqVq3KokWL+Omnn3j//fd55513mDVrFjNmzOD777/X/BF75513OHXqFG5ubpoyRo4cyYwZM/Dz88PIyIjNmzdr9l2+fJlmzZpRt25dfvrpJ3R1izYr8aBBg4iJiWH58uWULVuWNWvWEBQUxIkTJ6hfvz6zZ89m7NixxMXFAWBmZsbhw4cZMmQIS5YsoX79+iQlJbF79+6i/2MVg4mBHoFedjT1LMPDzBzSs3Iw0tfF1EBXJqMSQgghnrOTV5OZ8FcMSQ8zcLQyRl/3f+1BBno6XI7dz87PW5KTnc0SRU1wuw5aXYWfha+vL02bNsXHx4cWLVrQvHlz3nvvPaytrbWOMTEx0byvV68eKSkpXL58GWdn5yLXVbNmTa33cXFxDBgwQGtb7dq1+eeff7S2ValSReu7loODAydOnCiwHi8vL06ePMmRI0eIjIxk165dBAcHExISojVJ1ZOio6PZsWOHVqKf6/z582RlZZGamkqzZs209mVmZuLn51dgmcePH9dqOFEUBbVazcWLF/H09ATy3puQkBCaNWuGh4cHQUFBtG7dmubNmxcYu3i1SbL7GnnaH2IMdKn2VjMu7fiNvsNG8NfvS/OU8fhTLgA3Nzfmzp1Lo0aN+Pbbb/H29sbGxoadO3fy3nvvERERwaeffsqcOXMAOHjwIFlZWdSvX7/AOJ2dnZk9ezZ9+vShXLlybNmyBXjUTWTEiBG8//77AEybNo0dO3Ywe/ZsFixYoDl/2LBhtGvXLk+5cXFxNGvWjLZt2zJ79uwiJ4EJCQmEhYWRkJBA2bJlAQgNDWXTpk2EhYXx1VdfYWlpiUqlwt7eXus8U1NTWrdujbm5Oc7OzgX+QS0pKpUKM0M9zAzlV1MIIYR4EVIzs5m+JY6khxk425jk+/3CoXIN6ncfgUpXj1tqU6xLm6PSN/xX9erq6rJ161b27t3Lli1bmDdvHqNHj+bAgQNUqFChSGXo6OjkmeQyvyFgpqamzxSjvr6+1nuVSvXUVmUdHR1q1apFrVq1GDZsGEuXLqVbt26MHj26wOtKSUkhODiYadOm5dnn4ODAyZMnAfj7779xdHTU2m9omP+/Q0pKCh999BFDhgzJs698+fKan5+8N9WrV+fixYts3LiRbdu20bFjRwIDA586Pli8mqQb82viyT/Ejye6j9PX1cH//SFc2r+BL8I3kZGVo7U/Ojqa8PBwzMzMNK8WLVponnKpVCoaNmxIREQE9+7dIyYmhgEDBpCRkcHp06fZuXMntWrV0nrKmJ+ePXvi4ODA4MGDsbCw4P79+1y7dg1/f3+t4/z9/YmNjdXa9uQTNoC0tDQaNGhAu3btNJMaFNWJEyfIycnB3d1d67p37tzJ+fPnCzyvWbNmODs7U7FiRbp168ayZctITU0tcr1CCCGEePVFnrvDlbtpOFoZF/j9Qs/QCAs7J8xLOeBka8aVu2nsPXcn32MNDAzIycnJsw3Is12lUuHv78+ECRM4duwYBgYGrFmzRrM/OjqatLQ0zfv9+/djZmaGk5MTAKVLl9aaJ+X+/ftcvHjxqdfs4eHBoUOHtLY9+b6keHk96mmYO2Quv/tTvXp1Tp06hYuLC66urlovU1NTvLy8MDQ0JCEhIc/+3HvxpOrVqxMTE5PneFdXV82/R0EsLCzo1KkTixYtYsWKFaxatYqkpKQSuBviRZPmo9dEUf4Q53KoXJ2yVeoS+ds8/D7qo7WvKE+5AgIC+OGHH9i9ezd+fn5YWFhoEuCdO3fSqFGjIsWsp6eHnl7xP2L5PX00NDQkMDCQ9evX89lnn+V5qleYlJQUdHV1OXLkSJ5uz/l1l8llbm7O0aNHiYiIYMuWLYwdO5bx48dz6NCh12qJASGEEELkT1EUNp18lCwW1JDwpNzjNp5MpKlnmTz7XVxcOHDgAPHx8ZiZmWFjY4OzszMqlYr169fTqlUrjI2NOXXqFNu3b6d58+aUKVOGAwcOcOvWLU33WnjUTbd379588cUXxMfHM27cOAYNGoSOzqMYmjRpQnh4OMHBwVhZWTF27NgiDfEaPHgwffv2pWbNmtSvX58VK1Zw/PhxKlasWKR7UJD33nsPf39/6tevj729PRcvXmTUqFG4u7tTuXLlAu/PwIEDWbRoEZ07d2b48OHY2Nhw7tw5li9fzo8//oi5uTmhoaF8/PHHqNVq3nrrLZKTk4mMjMTCwoIePXrkiWXEiBHUrVuXQYMG0adPH0xNTYmJiWHr1q3Mnz+/wGuYOXMmDg4O+Pn5oaOjw8qVK7G3t5fvfq8padl9DTzLH+JaHQZxO2Yf67dpz1BXlKdcjRo1IiYmhpUrVxIQEAA8SoC3bdtGZGSkZltxWFhYULZsWSIjI7W2R0ZGap74FUZHR4clS5ZQo0YNGjduzLVr14pct5+fHzk5Ody8eTPPNed2W87vKSM8StgDAwP5+uuvOX78OPHx8XnGswghhBDi9ZSSkc2FWw+xNCrew3lLIz0u3HrIw8y83x1CQ0PR1dXFy8uL0qVLk5CQgKOjIxMmTGDkyJHY2dkxaNAgLCws2LVrF61atcLd3Z0vvviCGTNm0LJlS01ZTZs2xc3NjYYNG9KpUyfeeecdrbHCo0aNolGjRprJo9q0aUOlSpWeGn/Xrl0ZNWoUoaGhmm67ISEhGBkZFes+PKlFixb89ddfBAcH4+7uTo8ePahcuTJbtmzRNIDkd39yvyPm5OTQvHlzfHx8GDZsGFZWVprEftKkSYwZM4YpU6bg6elJUFAQf//9d4Fdo6tWrcrOnTs5c+YMDRo0wM/Pj7Fjx2qGtBXE3Nycr7/+mpo1a1KrVi3i4+PZsGGDJg7xelEpT3b0F4W6f/8+lpaWJCcnY2Fh8ULqfJCeRfefDqKjAiuT/Ltd7PpxApmpDwgcMl2zbdu3Y7hybAfqrEzNeI7jx49Tt25devXqVeBTLkVRKFWqFMnJyaxfv56goCCioqKoWbMmKpWKe/fuFWnsh4uLC8OGDdOMD549ezbjxo3jhx9+oFq1aoSFhTFz5kzNBFXx8fFUqFCBY8eOaa3zFh4ezrBhw7h37x7Z2dl07tyZEydOEBERoTXG9nEBAQFUq1ZNs/bcBx98QGRkpGbiq1u3brF9Zf+qnwAAeDBJREFU+3aqVq3K22+/zd69e/H392fbtm2aySD++ecfLly4QMOGDbG2tmbDhg0MGjSI48ePU6VKladevxBCCCFebbdTMugVfggjPR3MjfSffsL/e5CeRXq2msUhtShl9u/G7r4qmjVrhr29PUuWLHnZobxWXkZuIIpOHlG8BjKy1eQoCro6xZuV1/udvvDEs4yiPOVSqVQ0aNAAlUrFW2+9pTnPwsKCmjVrPvMkB0OGDOGTTz7h008/xcfHh02bNvHnn39qzcT8NHp6evz2229UqVKFJk2acPPmzXyPU6vVWl2ow8LC6N69O59++ikeHh60adOGQ4cOabpu169fn379+tGpUydKly7N119/jZWVFatXr6ZJkyZ4enry3XffaeoWQgghxOvPUE8HXZWKHHXx2n5y1Aq6KhVG+kVbFeJVk5qaqmlwOH36NOPGjWPbtm35dgcW4nUmLbvF9Kq27ObnXmomagWW9Knzn5vdt/L/tXffYVFcbRvA79mlLksXBRFBBBEEUWxRE0s0goXXFmMMUbElscZC1ERjjb1Fk9gLxhhNjC2xK4oFDVawgFgRC1aagLTd8/3h58SVnqgg3r/r2ivOnDLPDJuFZ8/MOdWro2/fvggKCirpUIiIiKiUEkIgaEMkzt5KRmWrgifffN6NhHR4VzLH7C7eb+QSgU+ePIG/vz/OnDmDjIwMuLm5YezYsXmuhkEF48hu6fZ2ZUBvKLWhHpxtTHD2VnKxkt3kjBx4VzKHicGb+a3jv3H//n3s3LkTMTExaNGiRUmHQ0RERKWYJEnw87RD5K1kZGu0RZobJVvzdOmd1p52b2SiCwDGxsbYt29fSYdB9Mox2X0DvK0fxP+Gn58fEhMTsWDBgle+Ji4RERG9+Rq7WKOSpTFuJqTnu87uM0II3EnKQCUrYzRysX6NURLRv8Fk9w3BD+KiOX36dEmHQERERG8QlYEeglq5YdK2KNxISIe9hXGeAwvZGi1uJz2BtdoQQa3coDLgn9FEpR0nqHpDPPsgtlYb4kZCujxy+6JsjRY3EtJhpTbgBzERERFREXjam2NcOw84WKlwJzkDNxLSkZSehccZ2UhKz8KNhHTcSc6Ag5UK49p5wNPevKRDJqIi4ARVxVTSD6Gfv52M2XticCvxCYCn67wpFU9nEUzOyAEAVLI0RlArN34QExERERVDelYOjl55hJ3n43HtQdrT1TAkCc42JmjtaYdGLtYcSCAdJZ0bUMGY7BZTaXhD84OYiIiI6NURQiAtS4OMbA2M9JUwMVC+VXOgUNGVhtyA8seM6A2kMtBDS48KaOFenh/ERERERC+ZJElQG+q9dUs3EpU1/D/4DcYPYiIiIiIiorxxgioiIiIiIiIqc5jsEhERERERUZnDZJeIiIiIiIjKHCa7REREREREVOYw2SUiIiIiIqIyh8kuERERERERlTlMdomIiIiIiKjMYbJLREREREREZQ6TXSIiIiIiIipzmOwSERERERFRmcNkl4iIiIiIiMocJrtERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktERESvXXBwMCwsLOTtCRMmoFatWiUWz6sWGhoKSZKQlJRU0qEQEb01mOwSERG9pe7evYvBgwfD2dkZhoaGcHBwgL+/P0JCQl57LEFBQa/luM2aNYMkSZAkCUZGRvDw8MDChQtf+jGGDh36UvskIqLiY7JLRET0lhBC4HFGNh6mZuJ8zGXUqVMH+/fvx6xZs3Du3Dns2rULzZs3x8CBA//1MTQaDbRabbHbqdVqWFtb/+vjFke/fv0QHx+PqKgofPTRRxg4cCDWrVv3Wo79smVnZ5d0CEREpRaTXSIiojIuPSsHe6PuIWhDJHqsOI7ewSfQslMPpGTkYNrqv9Davz2qVauGGjVqYPjw4fj777/ltnPnzoWXlxdMTEzg4OCAAQMGIDU1VS5/djvyn3/+CQ8PDxgaGiIuLg6JiYno0aMHLC0toVKp0Lp1a1y+fDnfGF+8jTkwMBAdOnTA7NmzYWdnB2trawwcOFAnuVuzZg3q1q0LU1NT2Nra4pNPPsH9+/cLvR4qlQq2trZwdnbGhAkT4Orqij///BMAMGrUKFSrVg0qlQrOzs749ttvdY75LM41a9bAyckJ5ubm+Pjjj/H48WM57oMHD2L+/PnyCHJsbKzc/tSpU6hbty5UKhUaNWqEmJgYndi2bt0KHx8fGBkZwdnZGRMnTkROTo5cLkkSFi1ahP/9738wMTHBlClTkJiYiICAANjY2MDY2Biurq5YtWpVodeBiKisY7JLRERUhp2/nYwBa09jxq6LOHsrGQoJUGSm4l50OCq80x4LDt3EgLWncf52stzm+WdpFQoFFixYgAsXLmD16tXYv38/Ro4cqXOM9PR0zJgxA8uXL8eFCxdQvnx5BAYG4uTJk/jzzz9x7NgxCCHQpk2bYo1EHjhwAFevXsWBAwewevVqBAcHIzg4WC7Pzs7G5MmTERkZiS1btiA2NhaBgYHFvkbGxsbIysoCAJiamiI4OBhRUVGYP38+li1bhnnz5unUv3r1KrZs2YJt27Zh27ZtOHjwIKZPnw4AmD9/Pho2bCiPHsfHx8PBwUFuO2bMGMyZMwcnT56Enp4eevfuLZcdPnwYPXr0wJdffomoqCgsWbIEwcHBmDJlis7xJ0yYgI4dO+LcuXPo3bs3vv32W0RFRWHnzp2Ijo7GokWLUK5cuWJfByKiMkeUIY6OjgKAzmvatGk6dSIjI8W7774rDA0NRaVKlcSMGTOKdYzk5GQBQCQnJ7/M0ImIiF66c7eSxIeLjor3Zx8Q3Zf/LXqvOi56rzou/L9dJQCI9wfNEN2X/y3en31AdFl8VJy7lVRonxs2bBDW1tby9qpVT/uKiIiQ9126dEkAEGFhYfK+hw8fCmNjY/H777/L7czNzeXy8ePHC29vb3m7Z8+ewtHRUeTk5Mj7unTpIrp27ZpvbCdOnBAAxOPHj/Ot07RpU/Hll18KIYTIyckRa9asEQDEjz/+mGf9WbNmiTp16ujEqVKpREpKirzvq6++Eg0aNMjzGM8cOHBAABD79u2T923fvl0AEE+ePBFCCNGiRQsxdepUnXZr1qwRdnZ28jYAMXToUJ06/v7+olevXvmeMxG9OswNSje9kkiwX6VJkyahX79+8rapqan875SUFLRq1QotW7bE4sWL5W9ELSws8Nlnn5VEuERERK9EelYOZu+JQUJaJhytVJAkSS4TQsj/1lcq4Gilwo2EdMzeE4OFAT5QGfzz58G+ffswbdo0XLx4ESkpKcjJyUFGRgbS09OhUqkAAAYGBqhZs6bcJjo6Gnp6emjQoIG8z9raGm5uboiOji7yOdSoUQNKpVLetrOzw7lz5+TtU6dOYcKECYiMjERiYqL8rHBcXBw8PDzy7XfhwoVYvnw5srKyoFQqMWzYMPTv3x8A8Ntvv2HBggW4evUqUlNTkZOTAzMzM532Tk5OOn9f2NnZFen2aQA618nOzg4AcP/+fVSuXBmRkZEICwvTGcnVaDS5rnfdunV1+uzfvz86d+6M06dPo1WrVujQoQMaNWpUpHiIiMqyMncb87Pndp69TExM5LK1a9ciKysLK1euRI0aNfDxxx9jyJAhmDt3bglGTERE9PKFXXmEW4lPYG9hrJPoAoB5BQdAkpAcfwPA0+dA7S2McSvxCY5eeSTXi42NRbt27VCzZk1s3LgRp06dwk8//QQA8m2/wNPbgF88xsugr6+vsy1JkpzQpqWlwdfXF2ZmZli7di1OnDiBzZs354otLwEBAYiIiMD169eRlpaGuXPnQqFQ4NixYwgICECbNm2wbds2nDlzBmPGjMnVX0FxFeecnl2zZ21TU1MxceJEREREyK9z587h8uXLMDIykts9/7cNALRu3Ro3btzAsGHDcOfOHbRo0QJBQUFFioeIqCwrc8nu9OnTYW1tjdq1a2PWrFk6kzocO3YMTZo0gYGBgbzP19cXMTExSExMzLO/zMxMpKSk6LyIiIhKMyEEdp2PB/B05PZFhmpz2Hu+g+j9fyA784lOvZ3n4+XfiadOnYJWq8WcOXPwzjvvoFq1arhz506hx3d3d0dOTg7Cw8PlfY8ePUJMTEyBI67FcfHiRTx69AjTp0/He++9h+rVqxd5dNXc3BwuLi6wt7eHQvHP9Tl69CgcHR0xZswY1K1bF66urrhx40axYzMwMIBGoyl2Ox8fH8TExMDFxSXX6/k482JjY4OePXvil19+wffff4+lS5cW+/hERGVNmUp2hwwZgvXr1+PAgQP4/PPPMXXqVJ1JNO7evYsKFSrotHm2fffu3Tz7nDZtGszNzeXX85NMEBERlUapmTm49iAN5kb5P63U8NOREFoN/poUiNiT+5F8Nw5S0i3s3RCMdxo+vQXWxcUF2dnZ+OGHH3Dt2jWsWbMGixcvLvT4rq6uaN++Pfr164cjR44gMjISn376Kezt7dG+ffuXco6VK1eGgYGBHNuff/6JyZMn/6c+XV1dERcXh/Xr1+Pq1atYsGCBPFpcHE5OTggPD0dsbCwePnxY5FHfcePG4eeff8bEiRNx4cIFREdHY/369Rg7dmyh7bZu3YorV67gwoUL2LZtG9zd3YsdNxFRWVPqk93Ro0fLU/fn97p48SIAYPjw4WjWrBlq1qyJL774AnPmzMEPP/yAzMzMf338r7/+GsnJyfLr5s2bL+vUiIiIXonMHC00QkCpyP/WYrPy9mg/YQ3sqtfF8fXzsfnbbgj7YRjux5zCzHnzAQDe3t6YO3cuZsyYAU9PT6xduxbTpk0rUgyrVq1CnTp10K5dOzRs2BBCCOzYsSPXLcD/lo2NDYKDg7FhwwZ4eHhg+vTpmD179n/q83//+x+GDRuGQYMGoVatWjh69Ci+/fbbYvcTFBQEpVIJDw8P2NjYIC4urkjtfH19sW3bNuzZswf16tXDO++8g3nz5sHR0bHAdgYGBvj6669Rs2ZNNGnSBEqlEuvXry923EREZY0knp+lohR68OABHj16VGAdZ2dnnVuTn7lw4QI8PT1x8eJFuLm5oUePHkhJScGWLVvkOgcOHMD777+PhIQEWFpaFhpPSkoKzM3NkZycnGvCCiIiotLgcUY2eqw4DoUEWKhy/37MT1J6FrQCWNO3AdSGZW4OSyIqhgkTJmDLli2IiIgo6VBKldjYWFSpUgVnzpxBrVq1sH37drRr1w43btxA5cqVX9pxJEnC5s2b0aFDh5fW59uo1I/s2tjYoHr16gW+8kp0ASAiIgIKhQLly5cHADRs2BCHDh3SWeNv7969cHNzK1KiS0RE9CZQG+rB2cYEKRk5hVd+TnJGDpxtTGBioCy8MhG9MY4dOwalUom2bdsWuU1QUBBCQkJeYVQvz5kzZ9ClSxdUqFABRkZGcHV1Rb9+/XDp0qVXfuxns86bm5u/8mNR8ZX6ZLeojh07hu+//x6RkZG4du0a1q5di2HDhuHTTz+VE9lPPvkEBgYG6NOnDy5cuIDffvsN8+fPx/Dhw0s4eiIiopdHkiT4edpBAMjWFO150Wf1WnvavZKZlYno9RBC4HFGNh6mZuJxRjaEEFixYgUGDx6MQ4cOFTrJnBACOTk5UKvVsLa2fk1R/3vbtm3DO++8g8zMTKxduxbR0dH45ZdfYG5u/q8eQ3imsFndn3k26MbPzdKpzCS7hoaGWL9+PZo2bYoaNWpgypQpGDZsmM5shObm5tizZw+uX7+OOnXqYMSIERg3bhzX2CUiojKnsYs1Klka43bSExT2xJIQAneSMlDJ0hiNXEr/H7dElFt6Vg72Rt1D0IZI9FhxHL2DT6DHiuMYsuYYfl23HoF9+qFt27YIDg7WaRcaGgpJkrBz507UqVMHhoaGOHLkCCZMmIBatWrJ9fKaN8fJyUkuP3jwIOrXrw9DQ0PY2dlh9OjROquiNGvWDEOGDMHIkSNhZWUFW1tbTJgwQSeWuXPnwsvLCyYmJnBwcMCAAQOQmpqa/zmnp6NXr15o06YN/vzzT7Rs2RJVqlRBgwYNMHv2bCxZsgTA0/Wq+/TpgypVqsDY2Bhubm6YP3++Tl+BgYHo0KEDpkyZgooVK8LNzQ0AcPz4cdSuXRtGRkaoW7cuzpw5o9Pu8OHDAICkpCQAQHBwMCwsLLB79264u7tDrVbDz88P8fHxcpsTJ07ggw8+QLly5WBubo6mTZvi9OnT+Z5nVlYWBg0aBDs7OxgZGcHR0bHI8ye87crMAzk+Pj74+++/C61Xs2ZN+U1JRERUVqkM9BDUyg2TtkXhRkI67C2M81yGKFujxe2kJ7BWGyKolRtUBmXmTwOit8b528mYvScGtxKfQAJgZqQHfaUCGq1AyPat0LOuhO9PpuG91h0xb/IYfP3117lGIkePHo3Zs2fD2dkZlpaWCA0N1Sl/PllLS0uDn58fGjZsCAC4ffs22rRpg8DAQPz888+4ePEi+vXrByMjI52EdvXq1Rg+fDjCw8Nx7NgxBAYGonHjxvjggw8AAAqFAgsWLECVKlVw7do1DBgwACNHjsTChQvzPO/du3fj4cOHOquvPM/CwgLA07WsK1WqhA0bNsDa2hpHjx7FZ599Bjs7O3z00Udy/ZCQEJiZmWHv3r0Anq593a5dO3zwwQf45ZdfcP36dXz55ZeF/jzS09Mxe/ZsrFmzBgqFAp9++imCgoKwdu1aAMDjx4/Rs2dP/PDDDxBCYM6cOWjTpg0uX74MU1PTXP0tWLAAf/75J37//XdUrlwZN2/e5KS5RcTfaERERGWUp705xrXzkP8IBgBzIz0oFRI0WoHk/3+m18FKhaBWbvC05zNnRG+a87eTMfGvKCSkZeb5pdaj07vg1rgNbiakI9W4IhISk3Dw4EE0a9ZMp96kSZPkpDMvtra2AJ7eCdK5c2eYm5vLI6cLFy6Eg4MDfvzxR0iShOrVq+POnTsYNWoUxo0bJ68TXbNmTYwfPx7A06W+fvzxR4SEhMjHHTp0qHw8JycnfPfdd/jiiy/yTXYvX74MAKhevXqB10hfXx8TJ06Ut6tUqYJjx47h999/10l2TUxMsHz5cvnW5KVLl0Kr1WLFihUwMjJCjRo1cOvWLfTv37/A42VnZ2Px4sWoWrUqAGDQoEGYNGmSXP7+++/r1F+6dCksLCxw8OBBtGvXLld/cXFxcHV1xbvvvgtJkgqdoZ3+UWZuYyYiIqLcPO3NsTDAB6P9qsO7kjm0AsjI0UIrAO9K5hjtVx0LA3yY6BK9gdKzcjB7TwwS0jLhaKXKlegmx9/Ag+sX4NrQF45WKiQ+0aB8reZYsmxZrr7q1q1bpGN+8803OHbsGLZu3QpjY2MAQHR0NBo2bKgzWty4cWOkpqbi1q1b8r6aNWvq9GVnZ4f79+/L2/v27UOLFi1gb28PU1NTdO/eHY8ePUJ6enqesRRnUZmffvoJderUgY2NDdRqNZYuXZprWTAvLy+diW+jo6NRs2ZNGBkZyfuejWYXRKVSyYluXud579499OvXD66urjA3N4eZmRlSU1PzXaYsMDAQERERcHNzw5AhQ7Bnz54in/fbjiO7REREZZzKQA8tPSqghXt5pGVpkJGtgZG+EiYGSk6qQvQGC7vyCLcSn8DewjjP/5cvHd4KodFg/bB/ZmEWQiDW0BDJyck6MwibmJgUerxffvkF8+bNQ2hoKOzt7Ysd74vrbEuSBK326eR4sbGxaNeuHfr3748pU6bAysoKR44cQZ8+fZCVlQWVSpWrv2rVqgEALl68WGASun79egQFBWHOnDlo2LAhTE1NMWvWLISHh+vUK8o1KIq8zvP5xLxnz5549OgR5s+fD0dHRxgaGqJhw4b5Torl4+OD69evY+fOndi3bx8++ugjtGzZEn/88cdLibcsY7JLRET0lpAkCWpDPa6hS1QGCCGw6/zT52jzeh5fq8nBlbAdqP/xl7Cv8Y68/07yE1xcMx6//vprobfjPu/YsWPo27cvlixZgnfeeUenzN3dHRs3boQQQk66w8LCYGpqikqVKhWp/1OnTkGr1WLOnDnybc+///57gW1atWqFcuXKYebMmdi8eXOu8qSkJFhYWCAsLAyNGjXCgAED5LKrV68WGpO7uzvWrFmDjIwMeXS3KHMEFSYsLAwLFy5EmzZtAAA3b97Ew4cPC2xjZmaGrl27omvXrvjwww/h5+eHhIQEWFlZ/ed4yjLexkxERERE9IZJzczBtQdpMDfK+8urm5FHkJn+GNXeaw/LSlXll32Vaijv9R6Wr1hR5GPdvXsXHTt2xMcffwxfX1/cvXsXd+/exYMHDwAAAwYMwM2bNzF48GBcvHgRW7duxfjx4zF8+HA5cS2Mi4sLsrOz8cMPP+DatWtYs2YNFi9eXGCbZ8/Ybt++Hf/73/+wb98+xMbG4uTJkxg5ciS++OILAE+fDz558iR2796NS5cu4dtvv8WJEycKjemTTz6BJEno168foqKisGPHDsyePbtI51MQV1dXrFmzBtHR0QgPD0dAQIB8S3he5s6di3Xr1uHixYu4dOkSNmzYAFtbW3kCLsofk10iIiIiojdMZo4WGiGgVOT9KMKlQ3+iokd9GKjUOvuVCgkVvJvi9KlTOHv2bJGOdfHiRdy7dw+rV6+GnZ2d/KpXrx4AwN7eHjt27MDx48fh7e2NL774An369MHYsWOLfD7e3t6YO3cuZsyYAU9PT6xdu7ZIy+u0b98eR48ehb6+Pj755BNUr14d3bp1Q3JyMr777jsAwOeff45OnTqha9euaNCgAR49eqQzypsftVqNv/76C+fOnUPt2rUxZswYzJgxo8jnlJ8VK1YgMTERPj4+6N69O4YMGYLy5cvnW9/U1BQzZ85E3bp1Ua9ePcTGxmLHjh1F/iLhbSaJ4jzZTUhJSYG5uTmSk5NhZmZW0uEQERER0VvocUY2eqw4DoUEWKgMCm/w/5LSs6AVwJq+DfhIw0vA3KB049cBRERERERvGLWhHpxtTJDy/0uIFVVyRg6cbUxgYqB8RZERlR5MdomIiIiI3jCSJMHP0w4CQLZGW6Q2z+q19rTjTOz0VmCyS0RERET0BmrsYo1Klsa4nfSk0DVnhRC4k5SBSpbGaORi/ZoiJCpZTHaJiIiIiN5AKgM9BLVyg7XaEDcS0vMd4c3WaHEjIR1WagMEtXKDyoDP6tLbge90IiIiIqI3lKe9Oca188DsPTG4lfgEAGBupAelQoJGK5D8/8/0OlipENTKDZ725iUZLtFrxWSXiIiIiOgN5mlvjoUBPjh65RF2no/HtQdpyM7RQilJ8K5kjtaedmjkYs0RXXrr8B1PRERERPSGUxnooaVHBbRwL4+0LA0ysjUw0lfCxEDJyajorcVkl4iIiIiojJAkCWpDPa6hSwROUEVERERERERlEJNdIiIiIiIiKnOY7BIREREREVGZw2SXiIiIiIiIyhwmu0RERG+RLVu2wMXFBUqlEkOHDs1zX2xsLCRJQkRERL79VK9eHYaGhq883uDgYFhYWMjbEyZMQK1ateTtwMBAdOjQ4ZXH8aIX43jTFeVnTkT0pmGyS0REVIotXrwY+vr6kCQp10utVmPRokVIT08HAISGhkKSJFy9ejXf/j7//HN8+OGHuHnzJiZPnpzvvsKUL18ePXv2LLDOs3ievYyNjVGjRg0sXboUAODk5CSXKZVKVKxYEWq1GlOnTpX76Nq1Ky5dulSkmJ4XHBws961QKFCpUiX06tUL9+/f16l39+5dDB48GM7OzjA0NISDgwP8/f0REhJS7GMSEVHpwmSXiIioFGvevDlycnKgr68PFxcXLFmyBGPGjIGBgQHS0tLw559/Yt++fQCAAwcOoHLlyqhatarcPjs7W/53amoq7t+/D19fX1SsWBGmpqZ57isKhUIBlUpVpLoxMTGIj49HVFQUPv/8c/Tv319OJidNmoT4+HjExcVh7dq1yMzMxKZNm+S2xsbGKF++fJGO8yIzMzPEx8fj1q1bWLZsGXbu3Inu3bvL5bGxsahTpw7279+PWbNm4dy5c9i1axeaN2+OgQMH/qtj/lsajQZarfa1HvNly8rKKukQiIh0CSqW5ORkAUAkJyeXdChERFSG5eTkiMt3U8Tf1x4KhUIh9PT0RGpqqhBCiJEjR4qOHTsKAGLz5s1Cq9WKAwcOCAACgFi4cKGoXbu2kCRJABDlypUTXl5ecvmzV/PmzXPtMzc3FyYmJgKAMDMzEwqFQkiSJMzMzISrq6v4+eefhaOjo1AoFEKhUIiUlBQ5JktLS6FSqYQkSUKpVIoGDRoIACIxMVEIIURKSor45JNPhCRJwtTUVFhaWoqqVauK9u3bi8aNGwulUpkrnlWrVgmlUin8/PyEh4eHUCgUQl9fX0yYMEHo6+uLVq1aifbt2wtHR0cxZcoU0bx5c6FQKOT2LVq0kK/blClThEKhEOnp6WLnzp3C0tJSSJIkrKysRNu2bcWVK1fk65+YmChu3rwpPv74Y2Fubi6USqVQKBRCpVKJLl26iBEjRghvb28hhBDjx48X1atXF+XKlRNqtVqoVCrx2WefiWHDhgkzMzMBQOjp6YnevXvL/a9atUoAEP379xdqtVoAEM7OzuLHH38UNWvWlM/B1NRUHDx4UG535coV8b///U+UL19emJiYiLp164q9e/fqvHeeXYtevXoJtVotHBwcxJIlS3TqhIeHi1q1aglDQ0NRp04dsWnTJgFAnDlzRq5z7tw54efnJ0xMTET58uXFp59+Kh48eCCXN23aVAwcOFB8+eWXwtraWjRr1kxotVoxfvx44eDgIAwMDISdnZ0YPHjwv/y/gKj0Y25QunFkl4iIqBS5mZCGAWtPw2viXrT6/hC6fL8HWq0WGkmJr7bE4GZCGvbt24fU1FSYmZnh9OnTkCQJmZmZch/PnicdN24cAGDo0KGIiopCtWrVAADjxo2DWq1GVFQU/vjjDwBAlSpVUKtWLezcuROrVq0C8HQkeO7cuRgzZgxSUlJw5coVbN68Gdu2bYO9vT20Wi2mT58OANi6dSuSkpJQt25dbNiwAXXq1MGJEyd0zm3YsGHYt28flEolFixYgMzMTNy6dQvZ2dkYPnw4/vzzT+jp6cHMzAzu7u64ffs2AEBPTw+7du3Chx9+iAEDBsDW1hZTpkyBubk5bG1t5f5nzZqFgwcPYvTo0WjdujUAoHHjxhBCAHg6SqzVapGTk4O7d+8iMTERw4cPR0hICBQKBTp27CiPrurp6aFp06a4ffs2bGxsUKtWLUyZMgXz58/HtWvX5OsGAPfu3UNMTAzKlSuH8PBwrF+/HsuXL8eqVavQsmVL7NmzB506dcLKlSuxYcMGnWuyYsUKjBw5Ejt37oS7uzsGDx6MpKQkLF++HH/99RfKly8v/xyf/UzatGmDkJAQnDlzBn5+fvD390dcXJxOv3PmzEHdunVx5swZDBgwAP3790dMTIzcR7t27eDh4YFTp05hwoQJCAoK0mmflJSE999/H7Vr18bJkyexa9cu3Lt3Dx999JFOvdWrV8PAwABhYWFYvHgxNm7ciHnz5mHJkiW4fPkytmzZAi8vr1zvcyKi16Kks+03Db+9ISKiV2XBvkvC5ZvtwnHUNuE4apuoMmqbsOsxRx6llPSNhKRv+PTfkiQMDAyEQqEQI0eOFHPm/FNv6NChQgghzpw5IwCIxo0biwEDBsjlBw4cELVr1xbGxsYiMTFRABAmJiYiIyNDCCHE9evXBQBhY2Mjjwg6OjoKAOLkyZNCCCHc3NyEQqEQDRo0EJcuXRIAhKGhoTzS+/DhQ3l00sTERB4tliRJfPfdd0IIIRwcHAQAoa+vL4yMjAQAYWBgIMaMGSMAiHPnzolVq1YJPT09oaenJ3777Tcxfvx44e3tLWxsbISNjY3o2bOnPLLbunVrAUDExsaKlStXCkmSxKJFi4QQQly6dElUq1ZN1K1bVwjxdGQTgNi0aZMQQogHDx7IxxRCiCVLlghTU1Pxxx9/CKVSKeLi4uSf04ULFwQA4erqKsLCwoSRkZHQ19eXz/3GjRtCkiRRqVIlodFo5HYqlUo0a9ZMCPHPyG6/fv3k8l27dgkAYuTIkfK+devWCSMjowLfNzVq1BA//PCDvO3o6Cg+/fRTeVur1Yry5cvL12LJkiXC2tpaPHnyRK6zaNEinZHdyZMni1atWukc5+bNmwKAiImJEUI8HdmtXbu2Tp05c+aIatWqiaysrAJjJiormBuUbhzZJSIiKgV+CLmMefsuIVsjoJQAfaUEpVKCUvqnjk2bL2HZ4jMozSug5rutYGJiAiEE0tLSdGbRrVu3Lk6dOoUhQ4YAAMLCwrBw4UK5vHXr1rhw4QKePHmCxo0bAwDS09NhbW0NtVqNGjVqAAAePHiAIUOGQK1WyyOHaWlpcj+SJOH+/fuIjo6GQqGAs7Oz/MyvtbU1rKysAACHDx/GunXrAAAzZ87E1KlTsWjRIigUClSoUAHt2rVDixYtYGdnh6ysLHmCqmfHFEKgTp06WLlypRzro0ePkJiYKI/aAkDTpk3RokULeHl5YeHChRBCYMiQIVCpVHBzc0OFChWwdu1aAMCNGzcAAP3794eZmRmcnJx0jhkREYHatWvj9u3bcHBwgIODg3wcDw8PGBoa4s6dO/jggw/QtGlTuLq6yud+7tw5CCEQHx8PMzMzqNVqqNVqPHnyBHfu3NH5ubds2VL+97OR9++//x7+/v6YP38+9PT0kJGRgZSUFABPR2WDgoLg7u4OCwsLqNVqREdH5xrZrVmzps7PydbWVp6cKzo6GjVr1oSRkZFcp2HDhjrtIyMjceDAATl2tVqN6tWrA4DOBGh16tTRadelSxc8efIEzs7O6NevHzZv3oycnBwQEZUEJrtEREQl7GZCGhbsvwytAPQkQKH4J8PVt6z49B8KJXKS4qFJuA1j5zpIbTwQmVlZUCqViI+P10l2lUolfH195QmkDAwM0KdPH7l8+fLluHDhAv7++2/0798fwNOEsmvXroiIiEBAQACAp7cd79q1CxEREahSpQoA5JpE6fltfX39PM+vSpUqqFy5MgDgo48+Qvfu3TFlyhQAT28XDg0NRXZ2NtasWYNy5crJCezzEx75+Phg7969SElJQUJCAry8vCBJks5xDA0NsXfvXuzcuRMVK1aUr8XOnTuRlpaGQ4cOyQnlN998AwBo27YtwsPDER4ernNMY2PjPM/leaampqhfvz7Onz8PheKfP6lSU1MhSRKaNm2KiIgI+VWvXj00adJEpw8DAwP538/OZ/Xq1WjUqBF+++039OjRA8A/1zkoKAibN2/G1KlTcfjwYURERMDLyyvX5FAv/iwkSSrWBFipqanw9/fXiT8iIgKXL1/WOQcTExOddg4ODoiJicHChQthbGyMAQMGoEmTJjoTpRERvS5MdomIiErYtJ0x8oiupNBN4JQqMyjVVoAQSI+NQMbNc1BV9kK2FsjWPE2WYmNjcfHiRbnN7du38ejRIzRv3hwA4OXlhcuXL8vl9vb2cHFxQYMGDfDpp58CeJoM/fbbb3BxcZFH7nr06IFmzZrB2dkZiYmJ+cbv7u4OrVYrL4EEQB55fcbZ2Rn6+vo4ceIElEolnjx5Aq1Wi/v37yMxMRFjx45FixYt8kwyFQoFrly5Io9YJyUlwcHBAdWqVcuV8EqShMaNG6Njx45QKBTQ19fHqVOndPp99OgRrly5gvr162P37t2oXLlyrvNzcXFBREQE7O3tcfPmTdy8eVMui4qKQmZmJkxNTbFt2zbo6enh2rVrePz4MQCgdu3aEEIgKysLLi4u8svY2DhXcpiX6tWr4+uvv8bRo0flLxmeCQsLQ2BgIDp27AgvLy/Y2toiNja20D6f5+7ujrNnzyIjI0Pe9/fff+vU8fHxwYULF+Dk5KRzDi4uLoWeg7GxMfz9/bFgwQKEhobi2LFjOHfuXLFiJCJ6GZjsEhERlSCNRoPQmKe3lypeSHSfMaroBgDIuHEWmfFXILTZePjXHGRnpEGSJJw7dw7Z2dnyaKZGo4Genh5mzpwJAHj33Xdx6NAhub8bN26gU6dO+Oijj3Dt2jUAgFqthhACe/bsQbly5QAA3377LTZs2IDPP/9c5/blF7m6usLNzQ03b97EkSNHEBkZiU8//VROiu7fv4+0tDR06tQJAwYMQHBwMJo0aYJHjx4BeDoiO3/+fGzcuBGJiYlyAvvs1l1DQ0OEhITA1tYWR44cgRAC+/btyzWp0o0bNzB16lScPHkSjx49ghAC6enpcHd316lnaWkJa2trVKxYEZmZmahRowZ69eoFALh58yYWLFiA+fPnw9bWFvPnz0eVKlXQqVMnzJo1CytWrECPHj3g6OgIlUoFExMTfPLJJ5AkCa1bt0ZqaiqqVasGZ2dnnD59Gps2bcL169dx/PhxxMXF4fr16/lex2cJdWRkJG7cuIE9e/bg1q1bua71pk2bEBERgcjISHzyySfFXrLoWbz9+vVDVFQUduzYgdmzZ+vUGThwIBISEtCtWzecOHECV69exe7du9GrVy9oNJp8+w4ODsaKFStw/vx5XLt2Db/88guMjY3h6OhYrBiJiF4GJrtEREQl6PrDdGRkawr8hawwVAHiWUIj8OCvuUi/eAh6lnbo0bc/srOz4ebmht9//x0AMHbsWLi4uECpVAIADh06hAkTJsj9DRw4ECdOnMDhw4flZ3Y9PDzQpUsX9OrVS17ndufOnejfvz9sbW3h6upa4Hm0b98eKpUK7dq1Q8OGDSGEgL+/PwDAzc0NdnZ22LhxI9LS0pCVlYWjR4/C0NAQ2dnZyMzMxMaNG/Hhhx9Cq9XKSXvPnj0BPL0V+ffff8elS5fkxG7y5MkIDAzUicHIyAiHDh1CmzZtMHr0aAgh0KpVK3lmZvl6KhRYv349YmJi8PjxY6SmpsqjshMmTEBISAgWL16MPXv2oHz58rh37x7OnDmD0aNHY8iQIXB2dsaHH34o92dgYIAqVapACIG2bdsiLS0NjRs3hoODA0aMGAE3Nzd06NABjx8/LnAd42fP0AYFBaFatWr47LPP0KFDB506c+fOhaWlJRo1agR/f3/4+vrCx8enwJ/Ni9RqNf766y+cO3cOtWvXxpgxYzBjxgydOhUrVkRYWBg0Gg1atWoFLy8vDB06FBYWFjq3bL/IwsICy5YtQ+PGjVGzZk3s27cPf/31F6ytrYsVIxHRyyCJ52d2oEKlpKTA3NwcycnJMDMzK+lwiIjoDRd+/RE+XvI3JAlQ5jOymxeNVkAIYP3n76BBlTczkUhLS4O9vT3mzJmj80xxfmJjY1G1alWcOHGi2AkeEdGrwNygdNMr6QCIiIjeZtYqA0gSni4KVBwCkCTARm34KsJ6Jc6cOYOLFy+ifv36SE5OxqRJkwA8HRUuSHZ2Nh49eoSxY8finXfeYaJLRERFwmSXiIioBFUpp4KRvhLpWRooi9FOC0Clr4SjVeGzBpcms2fPRkxMDAwMDFCnTh0cPnxYfkY4P2FhYWjevDmqVauGP/744zVFSkREbzomu0RERCVIqVSimVt57DgXD61W5DtJ1fO02qfDwM3dysvP5b4JateujVOnThW7XbNmzcCnroiIqLg4QRUREVEJ+7q1G/SVEjQCENqCkzqhFdAIQF8pYXRrt9cUIRER0ZuHyS4REVEJc7AywZD3XaGUgBzxz8jti7RagRwBKCVgaEtXOFgVvmYrERHR24q3MRMREZUCg1s8Xdpnwf7LyNYIaDTi6TfS/z951bOFh/SVEoa2dMXA5gUvBURERPS2Y7JLRERUSgxu4YoOtSti+s4YHIi5j4xsDcT/z7qs0leiuVt5jG7txhFdIiKiImCyS0REVIo4WJngpwAfaDQa3Eh4ggepmbBRG8LRyviNmoyKiIiopDHZJSIiKoWUSiWcbdRwtlGXdChERERvJE5QRURERERERGUOk10iIiIiIiIqc5jsEhERERERUZnDZJeIiIiIiIjKHCa7REREREREVOYw2SUiIiIiIqIyh8kuERERERERlTlMdomIiIiIiKjMYbJLRPSaBAYGokOHDiUdBhEREdFbgckuEb1WJZXw+fr6QqlU4sSJE6/92K9LYGAgJEmCJEnQ19dHlSpVMHLkSGRkZJR0aERERESvHZNdIirz4uLicPToUQwaNAgrV64s6XBeKT8/P8THx+PatWuYN28elixZgvHjx5d0WERERESvHZNdInrlhBB4nJGNh6mZyNZoC6x78OBB1K9fH4aGhrCzs8Po0aORk5Mjl//xxx/w8vKCsbExrK2t0bJlS6SlpRXY56pVq9CuXTv0798f69atw5MnT3TKmzVrhiFDhmDkyJGwsrKCra0tJkyYoFPn4sWLePfdd2FkZAQPDw/s27cPkiRhy5Ytcp2bN2/io48+goWFBaysrNC+fXvExsbmG5dWq8W0adNQpUoVGBsbw9vbG3/88YdcnpiYiICAANjY2MDY2Biurq5YtWpVgedqaGgIW1tbODg4oEOHDmjZsiX27t0rlz969AjdunWDvb09VCoVvLy8sG7dulzXY/DgwRg6dCgsLS1RoUIFLFu2DGlpaejVqxdMTU3h4uKCnTt3/qdYiYiIiF4lJrtE9MqkZ+Vgb9Q9BG2IRI8Vx9E7+AQOX36I87eTsTfqHtKzcnTq3759G23atEG9evUQGRmJRYsWYcWKFfjuu+8AAPHx8ejWrRt69+6N6OhohIaGolOnThBC5BuDEAKrVq3Cp59+iurVq8PFxUUnoXxm9erVMDExQXh4OGbOnIlJkybJSaJGo0GHDh2gUqkQHh6OpUuXYsyYMTrts7Oz4evrC1NTUxw+fBhhYWFQq9Xw8/NDVlZWnrFNmzYNP//8MxYvXowLFy5g2LBh+PTTT3Hw4EEAwLfffouoqCjs3LkT0dHRWLRoEcqVK1fk63/+/HkcPXoUBgYG8r6MjAzUqVMH27dvx/nz5/HZZ5+he/fuOH78eK7rUa5cORw/fhyDBw9G//790aVLFzRq1AinT59Gq1at0L17d6Snp7+UWImIiIheOkHFkpycLACI5OTkkg6FqFQ7dytJ9FwZLlrMCRUt54SKTj8dEV0WhYnKDVoLmxqNRYs5oaLnynBx7laS3Oabb74Rbm5uQqvVyvt++uknoVarhUajEadOnRIARGxsbJHj2LNnj7CxsRHZ2dlCCCHmzZsnmjZtqlOnadOm4t1339XZV69ePTFq1CghhBA7d+4Uenp6Ij4+Xi7fu3evACA2b94shBBizZo1uWLPzMwUxsbGYvfu3UIIIXr27Cnat28vhBAiIyNDqFQqcfToUZ3j9unTR3Tr1k0IIYS/v7/o1atXkc+1Z8+eQqlUChMTE2FoaCgACIVCIf74448C27Vt21aMGDEi3+uRk5MjTExMRPfu3eV98fHxAoA4duzYv4qViIioLGBuULrplWSiTURl0/nbyZj4VxQS0jJhb2EMfeU/N5EY6CkAAyUqmhvhZkI6Jm2Lwrh2HvC0N0d0dDQaNmwISZLk+o0bN0Zqaipu3boFb29vtGjRAl5eXvD19UWrVq3w4YcfwtLSMt9YVq5cia5du0JP7+nHXbdu3fDVV1/h6tWrqFq1qlyvZs2aOu3s7Oxw//59AEBMTAwcHBxga2srl9evX1+nfmRkJK5cuQJTU1Od/RkZGbh69WquuK5cuYL09HR88MEHOvuzsrJQu3ZtAED//v3RuXNneSS1Q4cOaNSoUb7nCgDNmzfHokWLkJaWhnnz5kFPTw+dO3eWyzUaDaZOnYrff/8dt2/fRlZWFjIzM6FSqXT6ef56KJVKWFtbw8vLS95XoUIFAJCv0b+JlYiIiOhV4m3MRPRSpWflYPaeGCSkZcLRSqWT6D5PX6mAo5UKj1IzMXtPTK5bmvOiVCqxd+9e7Ny5Ex4eHvjhhx/g5uaG69ev51k/ISEBmzdvxsKFC6Gnpwc9PT3Y29sjJycn10RV+vr6OtuSJEGrLfj54uelpqaiTp06iIiI0HldunQJn3zySZ71AWD79u069aOiouTbrFu3bo0bN25g2LBhuHPnDlq0aIGgoKAC4zAxMYGLiwu8vb2xcuVKhIeHY8WKFXL5rFmzMH/+fIwaNQoHDhxAREQEfH19c91qndf1eH7fsy8knl2jfxMrERER0avEZJeIXqqwK49wK/EJ7C2MdUZo8yJJEuwtjHEr8QmOXnkEd3d3HDt2TOcZ3LCwMJiamqJSpUpym8aNG2PixIk4c+YMDAwMsHnz5jz7X7t2LSpVqoTIyEidhHLOnDkIDg6GRqMp0jm5ubnh5s2buHfvnrzvxSWMfHx8cPnyZZQvXx4uLi46L3Nz81x9enh4wNDQEHFxcbnqOzg4yPVsbGzQs2dP/PLLL/j++++xdOnSIsUMAAqFAt988w3Gjh0rT8oVFhaG9u3b49NPP4W3tzecnZ1x6dKlIvdZkP8SKxEREdHLxmSXiF4aIQR2nY8HgHxHdAEg60kaHsVdwqO4S0i5fQWPb1/G76Fn0L9/f9y8eRODBw/GxYsXsXXrVowfPx7Dhw+HQqFAeHg4pk6dipMnTyIuLg6bNm3CgwcP4O7unudxVqxYgQ8//BCenp46rz59+uDhw4fYtWtXkc7rgw8+QNWqVdGzZ0+cPXsWYWFhGDt2LIB/RjgDAgJQrlw5tG/fHocPH8b169cRGhqKIUOG4NatW7n6NDU1RVBQEIYNG4bVq1fj6tWrOH36NH744QesXr0aADBu3Dhs3boVV65cwYULF7Bt27Z8zzU/Xbp0gVKpxE8//QQAcHV1xd69e3H06FFER0fj888/10ni/62XESsRERHRy8RndonopUnNzMG1B2kwNyr4o+XuxVPYOv5TnX33GrbD3D6bsWPHDnz11Vfw9vaGlZUV+vTpIyeWZmZmOHToEL7//nukpKTA0dERc+bMQevWrXMd49SpU4iMjMSyZctylZmbm6NFixZYsWIF2rZtW+h5KZVKbNmyBX379kW9evXg7OyMWbNmwd/fH0ZGRgAAlUqFQ4cOYdSoUejUqRMeP34Me3t7tGjRAmZmZnn2O3nyZNjY2GDatGm4du0aLCws4OPjg2+++QYAYGBggK+//hqxsbEwNjbGe++9h/Xr1xca7/P09PQwaNAgzJw5E/3798fYsWNx7do1+Pr6QqVS4bPPPkOHDh2QnJxcrH5f9DJiJSIiInqZJCEKWLODcklJSYG5uTmSk5Pz/QOW6G31MDUTvYNPwEhPAVMj/cIb/L/HGdnIyNFiZWA9lFMbvsIIX56wsDC8++67uHLlis5EV0RUuk2YMAFbtmxBRERESYfyyjk5OWHo0KEYOnRoSYdCVGYxNyjdeBszEb00hnoKKCUJGm3xvkPTaAWUkgQjfeUriuy/27x5M/bu3YvY2Fjs27cPn332GRo3bsxEl94KgYGBkCQJ06dP19m/ZcuWQp/NfxW2bduGpk2bwtTUFCqVCvXq1UNwcPBrj+NV2rx5M9555x2Ym5vD1NQUNWrUKHbSeuLECXz22WdFrh8aGgpJkpCUlFS8YImISikmu0T00qgN9eBsY4KUjMJnVn5eckYOnG1MYGJQepPdx48fY+DAgahevToCAwNRr149bN26taTDInplhBB4nJGNh6mZyNZoYWRkhBkzZiAxMbFE4/rhhx/Qvn17NG7cGOHh4Th79iw+/vhjfPHFFwXOAC6EQE5O8T6bSkpISAi6du2Kzp074/jx4zh16hSmTJmC7OzsYvVjY2OTa1kxIqK3CZNdInppJEmCn6cdBIBsTdGW7XlWr7WnXYmMEBVVjx49cOnSJWRkZODWrVsIDg6GtbV1SYdF9NKlZ+Vgb9Q9BG2IRI8Vx9E7+AQOX36Iih71YWplg0nfTSmw/ZEjR/Dee+/B2NgYDg4OGDJkCNLS0gAAP/74Izw9PeW6z0aGFy9eLO9r2bKl/Jz+i27evIkRI0Zg6NChmDp1Kjw8PODi4oIRI0Zg1qxZmDNnDsLDwwH8M0q5c+dO1KlTB4aGhjhy5Eie/S5fvhzu7u4wMjJC9erVsXDhQp3yUaNGoVq1alCpVHB2dsa3336rk3hOmDABtWrVwpo1a+Dk5ARzc3N8/PHHePz4sVznjz/+gJeXF4yNjWFtbY2WLVvK1+VFf/31Fxo3boyvvvoKbm5uqFatGjp06CBPNAcAV69eRfv27VGhQgWo1WrUq1cP+/bt0+nHyckJ33//vbwtSRKWL1+Ojh07QqVSwdXVFX/++ScAIDY2Fs2bNwcAWFpaQpIkBAYGFjt2IqLShMkuEb1UjV2sUcnSGLeTnqCwKQGEELiTlIFKlsZo5MLEkaiknb+djAFrT2PGros4eysZCgkw0lNAAvA4UwOLJj3www8/Yt+JqDzbX716FX5+fujcuTPOnj2L3377DUeOHMGgQYMAAE2bNkVUVBQePHgAADh48CDKlSuH0NBQAEB2djaOHTuGZs2a5dn/H3/8gezs7DxHcD///HOo1WqsW7dOZ//o0aMxffp0REdHo2bNmrnarV27FuPGjcOUKVMQHR2NqVOn4ttvv5VnRQeezp4eHByMqKgozJ8/H8uWLcO8efNynfuWLVuwbds2bNu2DQcPHpRv+46Pj0e3bt3Qu3dvREdHIzQ0FJ06dcr3M9LW1hYXLlzA+fPn8ywHnq7V3aZNG4SEhODMmTPw8/ODv78/4uLi8m0DABMnTsRHH32Es2fPok2bNggICEBCQgIcHBywceNGAEBMTAzi4+Mxf/78YsdORFSaMNklopdKZaCHoFZusFYb4kZCer4jvNkaLW4kpMNKbYCgVm5QGXByeKKSdP52Mib+FYWbCemoaG6EylYqWKgMYGqkDwM9BYwNlKj17gcwqVgV/YaOwvnbuWfwnjZtGgICAjB06FC4urqiUaNGWLBgAX7++WdkZGTA09MTVlZWOHjwIICno68jRoyQt48fP47s7Gw0atQozxgvXboEc3Nz2NnZ5SozMDDIc93oSZMmycuHWVlZ5Wo3fvx4zJkzB506dUKVKlXQqVMnDBs2DEuWLJHrjB07Fo0aNYKTkxP8/f0RFBSE33//XacfrVaL4OBgeHp64r333kP37t0REhIC4Gmym5OTg06dOsHJyQleXl4YMGAA1Gp1nuc5ePBg1KtXD15eXnBycsLHH3+MlStXIjMzU67j7e2Nzz//HJ6ennB1dcXkyZNRtWpVeaQ2P4GBgejWrRtcXFwwdepUpKam4vjx41AqlfL1KV++PGxtbWFubl7s2ImIShMmu0T00nnam2NcOw84WKlwJzkDNxLSkZSehccZ2UhKz8KNhHTcSc6Ag5UK49p5wNPevKRDJnqrpWflYPaeGCSkZcLRSpXvOtn6SgUafzwEN/7egbHBu5CZrdEpj4yMRHBwMNRqtfzy9fWFVqvF9evXIUkSmjRpgtDQUCQlJSEqKgoDBgxAZmYmLl68iIMHD6JevXov9TnTunXr5luWlpaGq1evok+fPjoxf/fdd7h69apc77fffkPjxo1ha2sLtVqNsWPH5hpBdXJygqmpqbxtZ2eH+/fvA3iamLZo0QJeXl7o0qULli1bVuCzzyYmJti+fTuuXLmCsWPHQq1WY8SIEahfvz7S09MBPB3ZDQoKgru7OywsLKBWqxEdHV3oyO7zo9smJiYwMzOT48xLcWMnIipNmOwS0SvhaW+OhQE+GO1XHd6VzKEVQEaOFloBeFcyx2i/6lgY4MNEl6gUCLvyCLcSn8DewrjQZ+ftqvugYo13ELbuB1y8+1inLDU1FZ9//jkiIiLkV2RkJC5fvizPXN6sWTOEhobi8OHDqF27NszMzOQE+ODBg2jatGm+x65WrRqSk5Nx586dXGVZWVm4evUqqlWrprPfxMQk3/5SU1MBAMuWLdOJ+fz58/j7778BAMeOHUNAQADatGmDbdu24cyZMxgzZgyysrJ0+tLX111uTZIkaLVP72xRKpXYu3cvdu7cCQ8PD/zwww9wc3PD9evX840NAKpWrYq+ffti+fLlOH36NKKiovDbb78BAIKCgrB582ZMnToVhw8fRkREBLy8vHLF9aKC4szLv42diKg04H2DRPTKqAz00NKjAlq4l0dalgYZ2RoY6SthYqAs1ZNREb1NhBDYdT4eAPId0X1RvS6DsGX8p9i2z1Vnv4+PD6KiouDi4pJv26ZNm2Lo0KHYsGGD/Gxus2bNsG/fPoSFhWHEiBH5tu3cuTNGjRqFOXPmYM6cOTplixcvRlpaGrp161akcwCAChUqoGLFirh27RoCAgLyrHP06FE4OjpizJgx8r4bN24U+RjPSJKExo0bo3Hjxhg3bhwcHR2xefNmDB8+vEjtnZycoFKp5ImhwsLCEBgYiI4dOwJ4mrjHxsYWO67nGRgYAAA0Gt0R+/8aOxFRSWGyS0SvnCRJUBvqQW3Ijxyi0iY1MwfXHqTB3Kjo/39aObigcr0PcHrnrzr7R40ahXfeeQeDBg1C3759YWJigqioKOzduxc//vgjgKe30VpaWuLXX3/Ftm3bADxNdoOCguSkKj+VK1fGzJkzMWLECBgZGaF79+7Q19fH1q1b8c0332DEiBFo0KBBsc5/4sSJGDJkCMzNzeHn54fMzEycPHkSiYmJGD58OFxdXREXF4f169ejXr162L59OzZv3lysY4SHhyMkJAStWrVC+fLlER4ejgcPHsDd3T3P+hMmTEB6ejratGkDR0dHJCUlYcGCBcjOzsYHH3wAAHB1dcWmTZvg7+8PSZLw7bffFjhCWxSOjo6QJAnbtm1DmzZtYGxsjAsXLhQrdiKi0oS3MRMREb3FMnO00AgBpaJ4d1t4/q8f8MKMvDVr1sTBgwdx6dIlvPfee6hduzbGjRuHihUrynUkScJ7770HSZLw7rvvyu3MzMxQt27dAm87BoChQ4di8+bNOHz4MOrWrQtPT0/8+uuvWLRoEWbPnl2scwAg3ya8atUqeHl5oWnTpggODkaVKlUAAP/73/8wbNgwDBo0CLVq1cLRo0fx7bffFusYZmZmOHToENq0aYNq1aph7NixmDNnDlq3bp1n/aZNm+LatWvo0aMHqlevjtatW+Pu3bvYs2cP3NzcAABz586FpaUlGjVqBH9/f/j6+sLHx6fY5/88e3t7TJw4EaNHj0aFChUwaNCgYsdORFSaSIJzxxdLSkoKzM3NkZycDDMzs5IOh4iI6D95nJGNHiuOQyEBFiqDIrdLSs+CVgBr+jbgXRtE9NZiblC6cWSXiIjoLaY21IOzjQlSMnKK1S45IwfONiYwMVC+osiIiIj+Gya7REREbzFJkuDnaQcB5Lsu9oue1WvtacfJ5oiIqNRisktERPSWa+xijUqWxrid9ASFPd0khMCdpAxUsjRGIxfr1xQhERFR8THZJSIiesupDPQQ1MoN1mpD3EhIz3eEN1ujxY2EdFipDRDUyg0qAz6rS0REpRd/SxERERE87c0xrp0HZu+Jwa3EJwAAcyM9KBUSNFqB5P9/ptfBSoWgVm7wtDcvyXCJiIgKxWSXiIiIADxNeBcG+ODolUfYeT4e1x6kITtHC6UkwbuSOVp72qGRizVHdImI6I3A31ZEREQkUxnooaVHBbRwL4+0LA0ysjUw0lfCxEDJyaiIiOiNwmSXiIiIcpEkCWpDPa6hS0REbyxOUEVERERERERlDpNdIiIiIiIiKnOY7BIREREREVGZw2SXiIiIiIiIyhwmu0RERERERFTmMNklIiIiIiKiMofJLhEREREREZU5THaJiIiIiIiozGGyS0RERERERGUOk10iIiIiIiIqc5jsEhERERERUZnDZJeIiIiIiIjKHCa7REREREREVOYw2SUiIiIiIqIyh8kuERERERERlTlMdomIiIiIiKjMYbJLREREREREZQ6TXSIiIiIiIipzmOwSERERERFRmcNkl4iIiIiIiMocJrtERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktERERERERlDpNdIiIiIiIiKnOY7BIREREREVGZw2SXiIiIiIiIyhwmu0RERERERFTmMNklIiIiIiKiMueNSXanTJmCRo0aQaVSwcLCIs86cXFxaNu2LVQqFcqXL4+vvvoKOTk5OnVCQ0Ph4+MDQ0NDuLi4IDg4+NUHT0RUAgIDAyFJEiRJgr6+PipUqIAPPvgAK1euhFarLenw/pNmzZrJ5yZJEipUqIAuXbrgxo0bJR0aERERlRJvTLKblZWFLl26oH///nmWazQatG3bFllZWTh69ChWr16N4OBgjBs3Tq5z/fp1tG3bFs2bN0dERASGDh2Kvn37Yvfu3a/rNIiIXikhBB5nZONhaiayNVr4+fkhPj4esbGx2LlzJ5o3b44vv/wS7dq1y/VlYGmUnZ2db1m/fv0QHx+PO3fuYOvWrbh58yY+/fTTfOsLId6IcyYiIqKX441JdidOnIhhw4bBy8srz/I9e/YgKioKv/zyC2rVqoXWrVtj8uTJ+Omnn5CVlQUAWLx4MapUqYI5c+bA3d0dgwYNwocffoh58+a9zlMhInrp0rNysDfqHoI2RKLHiuPoHXwChy8/xOWHGTiXIMHSpgJ8fHzwzTffYOvWrdi5c6fOnS1JSUno27cvbGxsYGZmhvfffx+RkZFy+YQJE1CrVi2sWbMGTk5OMDc3x8cff4zHjx8DAJYuXYqKFSvmGjFu3749evfuLW9v3boVPj4+MDIygrOzMyZOnKiTgEqShEWLFuF///sfTExMMGXKlHzPWaVSwdbWFnZ2dnjnnXcwaNAgnD59Wi4PDQ2FJEnYuXMn6tSpA0NDQxw5cgSZmZkYMmQIypcvDyMjI7z77rs4ceJErnYhISGoW7cuVCoVGjVqhJiYGJ3j//XXX6hXrx6MjIxQrlw5dOzYUS5LTExEjx49YGlpCZVKhdatW+Py5cty+Y0bN+Dv7w9LS0uYmJigRo0a2LFjR77nSkRERMX3xiS7hTl27Bi8vLxQoUIFeZ+vry9SUlJw4cIFuU7Lli112vn6+uLYsWP59puZmYmUlBSdFxFRaXL+djIGrD2NGbsu4uytZCgkwEhPAQlAypNszNh1EQPWnsb528kAgPfffx/e3t7YtGmT3EeXLl1w//597Ny5E6dOnYKPjw9atGiBhIQEuc7Vq1exZcsWbNu2Ddu2bcPBgwcxffp0uf2jR49w4MABuX5CQgJ27dqFgIAAAMDhw4fRo0cPfPnll4iKisKSJUsQHBycK6GdMGECOnbsiHPnzukkygVJSEjA77//jgYNGuQqGz16NKZPn47o6GjUrFkTI0eOxMaNG7F69WqcPn0aLi4u8PX11TlXABgzZgzmzJmDkydPQk9PTyeW7du3o2PHjmjTpg3OnDmDkJAQ1K9fXy4PDAzEyZMn8eeff+LYsWMQQqBNmzbySPXAgQORmZmJQ4cO4dy5c5gxYwbUanWRzpWIiIiKSLxhVq1aJczNzXPt79evn2jVqpXOvrS0NAFA7NixQwghhKurq5g6dapOne3btwsAIj09Pc/jjR8/XgDI9UpOTn45J0RE9B+cu5UkPlx0VLw/+4Dovvxv0XvVcfnl0ritqFy7iei+/G/x/uwDosvio+LcrSQhhBBdu3YV7u7uQgghDh8+LMzMzERGRoZO31WrVhVLliwRQjz9LFSpVCIlJUUu/+qrr0SDBg3k7fbt24vevXvL20uWLBEVK1YUGo1GCCFEixYtcn0Gr1mzRtjZ2cnbAMTQoUMLPe+mTZsKfX19YWJiIlQqlQAgqlWrJq5fvy7XOXDggAAgtmzZIu9LTU0V+vr6Yu3atfK+rKwsUbFiRTFz5kyddvv27ZPrPPtd8eTJEyGEEA0bNhQBAQF5xnbp0iUBQISFhcn7Hj58KIyNjcXvv/8uhBDCy8tLTJgwodDzJCKi0i05OZm5QSlWoiO7o0eP1plgJK/XxYsXSzJEfP3110hOTpZfN2/eLNF4iIieSc/Kwew9MUhIy4SjlQr6yrw/0vWVCjhaqfAoNROz98QgPSsHQghIkgQAiIyMRGpqKqytraFWq+XX9evXcfXqVbkfJycnmJqaytt2dna4f/++vB0QEICNGzciMzMTALB27Vp8/PHHUCgU8nEmTZqkc4xnz92mp6fL/dStW7dI5x8QEICIiAhERkbiyJEjcHFxQatWreRbq/Pq7+rVq8jOzkbjxo3/uT76+qhfvz6io6N12tWsWVPnXAHI5xsREYEWLVrkGVd0dDT09PR0Rpmtra3h5uYmH2PIkCH47rvv0LhxY4wfPx5nz54t0jkTERFR0emV5MFHjBiBwMDAAus4OzsXqS9bW1scP35cZ9+9e/fksmf/fbbv+TpmZmYwNjbOs19DQ0MYGhoWKQYiotcp7Moj3Ep8AnsLYzlxzY8kSbC3MMatxCc4euURoqOjUaVKFQBAamoq7OzsEBoamqvd87Pf6+vr5+rz+Wd0/f39IYTA9u3bUa9ePRw+fFhnToTU1FRMnDgRnTp1ynUcIyMj+d8mJiYFnssz5ubmcHFxAQC4uLhgxYoVsLOzw2+//Ya+ffsWu78XPX++z67vs/PN73dGUfXt2xe+vr7Yvn079uzZg2nTpmHOnDkYPHjwf+qXiIiI/lGiya6NjQ1sbGxeSl8NGzbElClTcP/+fZQvXx4AsHfvXpiZmcHDw0Ou8+IEIHv37kXDhg1fSgxERK+LEAK7zscDQL4jui96Vm/J+q04d+4chg0bBgDw8fHB3bt3oaenBycnp38dk5GRETp16oS1a9fiypUrcHNzg4+Pj1zu4+ODmJgYOUF92ZRKJQDgyZMn+dapWrUqDAwMEBYWBkdHRwBPZ3w+ceIEhg4dWuRj1axZEyEhIejVq1euMnd3d+Tk5CA8PByNGjUCADx69AgxMTHy7yMAcHBwwBdffIEvvvgCX3/9NZYtW8Zkl4iI6CUq0WS3OOLi4pCQkIC4uDhoNBpEREQAePptvlqtRqtWreDh4YHu3btj5syZuHv3LsaOHYuBAwfKI7NffPEFfvzxR4wcORK9e/fG/v378fvvv2P79u0leGZERMWXmpmDaw/SYG5U8Me4Jicb6ckPIbRaPElOQPzpIzi4Zw382rRFjx49AAAtW7ZEw4YN0aFDB8ycORPVqlXDnTt35EmYinpbMfD01uJ27drhwoULuZYBGjduHNq1a4fKlSvjww8/hEKhQGRkJM6fP4/vvvuu2NcgPT0dd+/eBfD0Lp3JkyfDyMgIrVq1yreNiYkJ+vfvj6+++gpWVlaoXLkyZs6cifT0dPTp06fIxx4/fjxatGiBqlWr4uOPP0ZOTg527NiBUaNGwdXVFe3bt0e/fv2wZMkSmJqaYvTo0bC3t0f79u0BAEOHDkXr1q1RrVo1JCYm4sCBA3B3dy/2NSAiIqL8vTHJ7rhx47B69Wp5u3bt2gCAAwcOoFmzZlAqldi2bRv69++Phg0bwsTEBD179sSkSZPkNlWqVMH27dsxbNgwzJ8/H5UqVcLy5cvh6+v72s+HiOi/yMzRQiNEoaO6t88dw/qhbSAplTBUmcHMvipqfPglVi8cJ4+ESpKEHTt2YMyYMejVqxcePHgAW1tbNGnSRGeG+6J4//33YWVlhZiYGHzyySc6Zb6+vti2bRsmTZqEGTNmQF9fH9WrV9e55bg4li1bhmXLlgEALC0tUbNmTezYsQNubm4Ftps+fTq0Wi26d++Ox48fo27duti9ezcsLS2LfOxmzZphw4YNmDx5MqZPnw4zMzM0adJELl+1apW8nnFWVhaaNGmCHTt2yLdGazQaDBw4ELdu3YKZmRn8/Py4DB4REdFLJgkhREkH8SZJSUmBubk5kpOTYWZmVtLhENFb6nFGNnqsOA6FBFioDIrcLik9C1oBrOnbAGrDN+b7TiIiolKJuUHpVmbW2SUiepuoDfXgbGOClIycYrVLzsiBs40JTAyUrygyIiprgoODdSary0tgYCA6dOggbzdr1qxYz8HnJTQ0FJIkISkpqchtnJyc8P333xe5fmxsLCRJkh+Py0tRzr+0+DfXjKgsY7JLRPQGkiQJfp52EACyNdpC6+O5eq097QqdvZmI3h6BgYHyko8GBgZwcXHBpEmTkJNT9C/T5s+fj+Dg4FcXZAnq2rUrLl269J/6CA4OznOJzednoieil4/3sBERvaEau1ijkqUxbiakw9FKVWACK4TAnaQMVLIyRiMX69cYJRGVRkIIpGbmIDNHi2yNFn5+fli1ahUyMzOxY8cODBw4EPr6+vj666+L1J+5ufkrjrjkGBsb/+flxgDAzMwMMTExOvv4xSPRq8WRXSKiN5TKQA9BrdxgrTbEjYT0fEd4szVa3EhIh5XaAEGt3KAy4PecRG+r9Kwc7I26h6ANkeix4jh6B5/A4csPcflhBs4lSLCxs0f//v3RsmVL/Pnnnzptd+/eDXd3d6jVavj5+SE+Pl4ue/E25hetWbMGdevWhampKWxtbfHJJ5/g/v37OnV27NiBatWqwdjYGM2bN0dsbGyufo4cOYL33nsPxsbGcHBwwJAhQ5CWlpbvcSVJwqJFi9C6dWsYGxvD2dkZf/zxR656165dQ/PmzaFSqeDt7Y1jx47JZS/exnz16lW0b98eFSpUgFqtRr169bBv3758Y3g+FltbW53X85MA7tq1C++++y4sLCxgbW2Ndu3a4erVqzp9HD16FLVq1YKRkRHq1q2LLVu2FHobdmHXbOHChXB1dYWRkREqVKiADz/8sNBzIXpTMNklInqDedqbY1w7DzhYqXAnOQM3EtKRlJ6FxxnZSErPwo2EdNxJzoCDlQrj2nnA077sjr4QUcHO307GgLWnMWPXRZy9lQyFBBjpKSABSHmSjRm7LmLA2tM4fzsZxsbGyMrKktump6dj9uzZWLNmDQ4dOoS4uDgEBQUV+djZ2dmYPHkyIiMjsWXLFsTGxiIwMFAuv3nzJjp16gR/f39ERESgb9++GD16tE4fV69ehZ+fHzp37oyzZ8/it99+w5EjRzBo0KACj/3tt9+ic+fOiIyMREBAAD7++GNER0fr1BkzZgyCgoIQERGBatWqoVu3bvnexp2amoo2bdogJCQEZ86cgZ+fH/z9/REXF1fk65GXtLQ0DB8+HCdPnkRISAgUCgU6duwIrfbpF5kpKSnw9/eHl5cXTp8+jcmTJ2PUqFEF9lnYNTt58iSGDBmCSZMmISYmBrt27dKZWZ7oTcev94mI3nCe9uZYGOCDo1ceYef5eFx7kIbsHC2UkgTvSuZo7WmHRi7WHNEleoudv52MiX9FISEtE/YWxjrLlhnoKQADJSqaGyHuURoGzlqNv3fvxpDBg+U62dnZWLx4MapWrQoAGDRokM7yjoXp3bu3/G9nZ2csWLAA9erVQ2pqKtRqNRYtWoSqVatizpw5AAA3NzecO3cOM2bMkNtNmzYNAQEB8sRXrq6uWLBgAZo2bYpFixbl+/xrly5d5CXOJk+ejL179+KHH37AwoUL5TpBQUFo27YtAGDixImoUaMGrly5gurVq+fqz9vbG97e3vL25MmTsXnzZvz5558FJt7JyclQq9U6+9577z3s3LkTANC5c2edspUrV8LGxgZRUVHw9PTEr7/+CkmSsGzZMhgZGcHDwwO3b99Gv3798j1mYdcsLi4OJiYmaNeuHUxNTeHo6Cgv70lUFvAvHyKiMkBloIeWHhXQwr080rI0yMjWwEhfCRMDJZ8JI3rLpWflYPaeGCSkZeb7fP/NyDCsG9gcWk0OhFYL53d8MfKbsXK5SqWSE10AsLOzy3UbckFOnTqFCRMmIDIyEomJifJoZVxcHDw8PBAdHY0GDRrotGnYsKHOdmRkJM6ePYu1a9fK+4QQ0Gq1uH79Otzd3fM89ov9NGzYMNdtvzVr1tQ5NwC4f/9+nsluamoqJkyYgO3btyM+Ph45OTl48uRJoSO7pqamOH36tM6+558Fvnz5MsaNG4fw8HA8fPhQ5xp5enoiJiYGNWvW1Enq69evX+AxC7tmH3zwARwdHeHs7Aw/Pz/4+fmhY8eOUKlUBfZL9KZgsktEVIZIkgS1oR7X0CUiWdiVR7iV+AT2Fsb5fvllV70OGvUYBYWePvRNrXA3NQeR8Rloafn00Qd9fX2d+pIkQQhRpOOnpaXB19cXvr6+WLt2LWxsbBAXFwdfX1+dW6ULk5qais8//xxDhgzJVVa5cuUi95OX58/v2TV6lmy+KCgoCHv37sXs2bPh4uICY2NjfPjhh4Wei0KhgIuLS77l/v7+cHR0xLJly1CxYkVotVp4enoW6xq9qLBrZmBggNOnTyM0NBR79uzBuHHjMGHCBJw4ceKNWW6JqCD8a4iIiIiojBJCYNf5pxNJPX/r8ov0DI1gVsHhuT052Hk+Hi3cy//nGC5evIhHjx5h+vTpcHB4eoyTJ0/q1HF3d881Idbff/+ts+3j44OoqKgCE8a8/P333+jRo4fO9n+5VTcsLAyBgYHo2LEjgKcJZV6TaRXHo0ePEBMTg2XLluG9994D8HRiqee5ubnhl19+QWZmJgwNDQEAJ06cKLDfolwzPT09tGzZEi1btsT48eNhYWGB/fv3o1OnTv/pnIhKA05QRVQCmjVrJj8/Q3mbMGECatWqJW8XNtPni/WJiAhIzczBtQdpMDcq3viGuZEerj1IQ1qW5j/H8GwE8YcffsC1a9fw559/YvLkyTp1vvjiC1y+fBlfffUVYmJi8Ouvv+Zat3fUqFE4evQoBg0ahIiICFy+fBlbt24tdIKqDRs2YOXKlbh06RLGjx+P48ePF9qmIK6urti0aRMiIiIQGRmJTz75JN9R4OcJIXD37t1cL61WC0tLS1hbW2Pp0qW4cuUK9u/fj+HDh+u0f3aczz77DNHR0di9ezdmz54NIP8ljAq7Ztu2bcOCBQsQERGBGzdu4Oeff4ZWq4Wbm9u/vj5EpQmTXaKXIDAwEJIk4YsvvshVNnDgQEiSpDPr5KZNm3L9oi/tQkNDIUkSkpKS/lM//v7+8PPzy7Ps8OHDkCQJZ8+eRVBQEEJCQorcb3HrExG9DTJztNAIAaWieM/uKxUSNEIgI/u/J7s2NjYIDg7Ghg0b4OHhgenTp8tJ2jOVK1fGxo0bsWXLFnh7e2Px4sWYOnWqTp2aNWvi4MGDuHTpEt577z3Url0b48aNQ8WKFQs8/sSJE7F+/XrUrFkTP//8M9atWwcPD49/fT5z586FpaUlGjVqBH9/f/j6+sLHx6fQdikpKbCzs8v1un//PhQKBdavX49Tp07B09MTw4YNw6xZs3Tam5mZ4a+//kJERARq1aqFMWPGYNy4cQCQ7+RchV0zCwsLbNq0Ce+//z7c3d2xePFirFu3DjVq1PjX14eoNJFEUR+4IABPP6jMzc2RnJwMMzOzkg6HSonAwEDs378fKSkpiI+PlyecyMjIgJ2dHczMzNC8efNc31K/SUJDQ9G8eXMkJib+p+d4tmzZgs6dO+PGjRuoVKmSTlnv3r1x7ty5PG/LCgwMRFJSErZs2fKvj01E9LZ5nJGNHiuOQyEBFiqDIrdLSs+CVgBr+jZ4o+cAkCQJmzdvLvDOoDfZ2rVr0atXLyQnJ+tMdkWvD3OD0o0ju0T/khACjzOy8TA1E9kaLXx8fODg4IBNmzbJdTZt2oTKlSvnejboxduYnZycMHXqVPTu3RumpqaoXLkyli5dKpfHxsZCkiRs2rQp30Xvgf+2cHxmZiaGDBmC8uXLw8jICO+++66cdMbGxqJ58+YAAEtLS52R6l27duHdd9+FhYUFrK2t0a5dO1y9ejXf69auXTv5W/7npaamYsOGDejTpw+Awm9LPnHiBGxsbORlKfK77Xn27Nmws7ODtbU1Bg4ciOzsbLlOfHw82rZtC2NjY1SpUgW//vornJyc8P333wN4+jOeMGECKleuDENDQ1SsWDHPST6IiEortaEenG1MkJKR95qx+UnOyIGzjQlMDJSvKDL6N37++WccOXIE169fx5YtWzBq1Ch89NFHTHSJ8sFkl6iY0rNysDfqHoI2RKLHiuPoHXwChy8/xPnbyWjcpguWr1gp1125ciV69epVpH7nzJmDunXr4syZMxgwYAD69++PmJgYnToFLXr/XxeOHzlyJDZu3IjVq1fj9OnTcHFxga+vLxISEuDg4ICNGzcCAGJiYhAfH4/58+cDeDrL5vDhw3Hy5EmEhIRAoVCgY8eO+T6/pKenhx49eiA4OFhnJs8NGzZAo9GgW7duhV6r/fv344MPPsCUKVMwatSofOsdOHAAV69exYEDB7B69WoEBwfrJNk9evTAnTt3EBoaio0bN2Lp0qU6S2ls3LgR8+bNw5IlS3D58mVs2bIFXl5ehcZHRFRaSJIEP087CADZmsKfK8Vz9Vp72nHpslLm7t27+PTTT+Hu7o5hw4ahS5cuOl+OE5GuN/e+FKIScP52MmbvicGtxCeQAJgZ6UFfqYAEIOVJNqJMvBF2eAr2hJ+Dm60ZwsLCsH79eoSGhhbad5s2bTBgwAAATyeUmDdvHg4cOKAzSURBi97/l4Xj09LSsGjRIgQHB6N169YAgGXLlmHv3r1YsWIFvvrqK1hZWQEAypcvr3Mbc+fOnXXOY+XKlbCxsUFUVBQ8PT3zPNfevXtj1qxZOHjwIJo1awYAWLVqFTp37gxzc/MCr9PmzZvRo0cPLF++HF27di2wrqWlJX788UcolUpUr14dbdu2RUhICPr164eLFy9i3759OHHiBOrWrQsAWL58OVxdXeX2cXFxsLW1RcuWLaGvr4/KlSsXuqYhEVFp09jFGpUsjXEzIT3fdXafEULgTlIGKlkZo5GL9WuM8tUoa0/rjRw5EiNHjizpMIjeGBzZJSqi87eTMfGvKNxMSEdFcyNUtlLBQmUAUyN9GOgpYGyghJO9LazdG2DYd/MxY/4itG3bFuXKlStS/88vaC9JEmxtbXVGGV+s8/yi98DTheODg4OhVqvll6+vb54Lx3fv3h1r165Feno6gKejwtnZ2WjcuLHcv76+PurXr4/o6OgC4758+TK6desGZ2dnmJmZwcnJCcDTRDE/1atXR6NGjbBy5dNR8CtXruDw4cPyLcz5CQ8PR5cuXbBmzZpCE10AqFGjBpTKf27BezYRCPB0hFpPT09nUhEXFxdYWlrK2126dMGTJ0/g7OyMfv36YfPmzfJIOhHRm0JloIegVm6wVhviRkJ6viO82RotbiSkw0ptgKBWblAZcEyEiN5sTHaJiiA9Kwez98QgIS0TjlaqfNcq1Fcq4P1+B1wL2441a37GJ917FvkYzy9oDzxNeF+8FbigRe+fLRwfEREhvyIjI3H58mVUrVoVpqamOH36NNatWwc7OzuMGzcO3t7eL2V25YSEBCxbtgzh4eEIDw8HAGRlZRXYrk+fPti4cSMeP36MVatWoWrVqmjatGmBbapWrYrq1atj5cqVOs/e5qco17QgDg4OiImJwcKFC2FsbIwBAwagSZMmRTo2EVFp4mlvjnHtPOBgpcKd5AzcSEhHUnoWHmdkIyk9CzcS0nEnOQMOViqMa+cBT/uC77IhInoTMNklKoKwK49wK/EJ7C2MC31+qVLNRpCEBtnZ2TBxrvOaItRdOP7Fl4HB0xk4ny0cP3PmTJw9exaxsbHYv38/qlatCgMDA4SFhcn9ZWdn48SJE/LyDM/60Gj+WYbi0aNHiImJwdixY9GiRQu4u7sjMTGxSPF+9NFHUCgU+PXXX/Hzzz+jd+/ehV7bcuXKYf/+/bhy5Qo++uij/5R0urm5IScnB2fOnJH3XblyJVf8xsbG8Pf3x4IFCxAaGopjx47h3Llz//q4REQlxdPeHAsDfDDarzq8K5lDK4CMHC20AvCuZI7RftWxMMCHiS4RlRm8P4WoEEII7DofDwD5jug+T6FQovPU33Az8Qn2RN9HK0+7Vx0igKfP+b7zzjsYNGgQ+vbtCxMTE0RFRWHv3r348ccfsW3bNly7dg1NmjSBpaUlduzYIS8cb2Jigv79+8vP5lauXBkzZ85Eenq6fGuxo6MjJEnCtm3b0KZNGxgbG8PS0hLW1tZYunQp7OzsEBcXh9GjRxcpXrVaja5du+Lrr79GSkqKzjrEBSlfvjz279+P5s2bo1u3bli/fj309Ir/UVa9enW0bNkSn332GRYtWgR9fX2MGDECxsb/fKERHBwMjUaDBg0aQKVS4ZdffoGxsTEcHR2LfTwiotJAZaCHlh4V0MK9PNKyNMjI1sBIXwkTAyUnoyKiMocju0SFSM3MwbUHaTA3KnpCZWCshrWFOa49SENalqbwBi/Bf104fvr06ejcuTO6d+8OHx8fXLlyBbt375afYbW3t8fEiRMxevRoVKhQAYMGDYJCocD69etx6tQpeHp6YtiwYZg1a1aRY+7Tpw8SExPh6+srx1kUtra22L9/P86dO4eAgACd0ebi+Pnnn1GhQgU0adIEHTt2RL9+/WBqagojIyMAT6/ZsmXL0LhxY9SsWRP79u3DX3/9BWvrN3/SFiJ6u0mSBLWhHsqpDaE21GOiS0RlkiTK2jR1rxgXjn77PEzNRO/gEzDSU8DUSL/wBv/vcUY2MnK0WBlYD+XUhq8wQnpZbt26BQcHB+zbtw8tWrQo6XCIiIiolGNuULrxNmaiQhjqKaCUJGi0xfteSKMVUEoSjPSVhVemErF//36kpqbCy8sL8fHxGDlyJJycnHTWHyYiIiKiNxNvYyYqhNpQD842JkjJKN6SM8kZOXC2MYGJAZPd0io7OxvffPMNatSogY4dO8LGxgahoaG5ZnEmIiIiojcPR3aJCiFJEvw87RB5KxnZGm2RJql6toZha087PgdVivn6+sLX17ekwyAiIiKiV4Aju0RF0NjFGpUsjXE76QkKe8xdCIE7SRmoZGmMRi6cyIiIiIiIqCQw2SUqApWBHoJaucFabYgbCenyyO2LsjVa3EhIh5XaAEGt3KAy4M0TREREREQlgX+JExWRp705xrXzwOw9MbiV+AQAYG6kB6Xi6eRVyf//TK+DlQpBrdzgaW9ekuESEREREb3VmOwSFYOnvTkWBvjg6JVH2Hk+HtcepCE7RwulJMG7kjlae9qhkYs1R3SJiIiIiEoY/yInKiaVgR5aelRAC/fySMvSICNbAyN9JUwMlJyMioiIiIiolGCyS/QvSZIEtaEe1Ib834iIiIiIqLThBFVERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktERERERERlDpNdIiIiIiIiKnOY7BIREREREVGZw2SXiIiIiIiIyhwmu0RERERERFTmMNklIiIiIiKiMofJLhEREREREZU5THaJiIiIiIiozGGyS0RERERERGUOk10iIiIiIiIqc5jsEhERERERUZnDZJeIiIiIiIjKHCa7REREREREVObolXQAbxohBAAgJSWlhCMhIiIiIqKS9CwneJYjUOnCZLeYHj9+DABwcHAo4UiIiIiIiKg0ePz4MczNzUs6DHqBJPg1RLFotVrcuXMHpqamkCSppMOhfyklJQUODg64efMmzMzMSjocKmX4/qCC8P1BBeH7gwrC90fZI4TA48ePUbFiRSgUfEK0tOHIbjEpFApUqlSppMOgl8TMzIy/bChffH9QQfj+oILw/UEF4fujbOGIbunFrx+IiIiIiIiozGGyS0RERERERGUOk116KxkaGmL8+PEwNDQs6VCoFOL7gwrC9wcVhO8PKgjfH0SvFyeoIiIiIiIiojKHI7tERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktl2pQpU9CoUSOoVCpYWFjkWScuLg5t27aFSqVC+fLl8dVXXyEnJ0enTmhoKHx8fGBoaAgXFxcEBwe/+uCpRDg5OUGSJJ3X9OnTdeqcPXsW7733HoyMjODg4ICZM2eWULT0uv30009wcnKCkZERGjRogOPHj5d0SFQCJkyYkOtzonr16nJ5RkYGBg4cCGtra6jVanTu3Bn37t0rwYjpVTp06BD8/f1RsWJFSJKELVu26JQLITBu3DjY2dnB2NgYLVu2xOXLl3XqJCQkICAgAGZmZrCwsECfPn2Qmpr6Gs+CqGxisktlWlZWFrp06YL+/fvnWa7RaNC2bVtkZWXh6NGjWL16NYKDgzFu3Di5zvXr19G2bVs0b94cERERGDp0KPr27Yvdu3e/rtOg12zSpEmIj4+XX4MHD5bLUlJS0KpVKzg6OuLUqVOYNWsWJkyYgKVLl5ZgxPQ6/Pbbbxg+fDjGjx+P06dPw9vbG76+vrh//35Jh0YloEaNGjqfE0eOHJHLhg0bhr/++gsbNmzAwYMHcefOHXTq1KkEo6VXKS0tDd7e3vjpp5/yLJ85cyYWLFiAxYsXIzw8HCYmJvD19UVGRoZcJyAgABcuXMDevXuxbds2HDp0CJ999tnrOgWisksQvQVWrVolzM3Nc+3fsWOHUCgU4u7du/K+RYsWCTMzM5GZmSmEEGLkyJGiRo0aOu26du0qfH19X2nMVDIcHR3FvHnz8i1fuHChsLS0lN8fQggxatQo4ebm9hqio5JUv359MXDgQHlbo9GIihUrimnTppVgVFQSxo8fL7y9vfMsS0pKEvr6+mLDhg3yvujoaAFAHDt27DVFSCUFgNi8ebO8rdVqha2trZg1a5a8LykpSRgaGop169YJIYSIiooSAMSJEyfkOjt37hSSJInbt2+/ttiJyiKO7NJb7dixY/Dy8kKFChXkfb6+vkhJScGFCxfkOi1bttRp5+vri2PHjr3WWOn1mT59OqytrVG7dm3MmjVL57b2Y8eOoUmTJjAwMJD3+fr6IiYmBomJiSURLr0GWVlZOHXqlM5ngUKhQMuWLflZ8Ja6fPkyKlasCGdnZwQEBCAuLg4AcOrUKWRnZ+u8V6pXr47KlSvzvfIWun79Ou7evavzfjA3N0eDBg3k98OxY8dgYWGBunXrynVatmwJhUKB8PDw1x4zUVmiV9IBEJWku3fv6iS6AOTtu3fvFlgnJSUFT548gbGx8esJll6LIUOGwMfHB1ZWVjh69Ci+/vprxMfHY+7cuQCevh+qVKmi0+b594ylpeVrj5levYcPH0Kj0eT5WXDx4sUSiopKSoMGDRAcHAw3NzfEx8dj4sSJeO+993D+/HncvXsXBgYGueaJqFChgvx7hd4ez37meX12PP93Rvny5XXK9fT0YGVlxfcM0X/EZJfeOKNHj8aMGTMKrBMdHa0zWQi93Yrznhk+fLi8r2bNmjAwMMDnn3+OadOmwdDQ8FWHSkRvgNatW8v/rlmzJho0aABHR0f8/vvv/AKUiKgUYbJLb5wRI0YgMDCwwDrOzs5F6svW1jbXbKrPZsy0tbWV//viLJr37t2DmZkZ/6h5Q/yX90yDBg2Qk5OD2NhYuLm55ft+AP55z1DZU65cOSiVyjx/9vy5k4WFBapVq4YrV67ggw8+QFZWFpKSknRGd/leeTs9+5nfu3cPdnZ28v579+6hVq1acp0XJ7rLyclBQkIC3zNE/xGTXXrj2NjYwMbG5qX01bBhQ0yZMgX379+XbyHau3cvzMzM4OHhIdfZsWOHTru9e/eiYcOGLyUGevX+y3smIiICCoVCfn80bNgQY8aMQXZ2NvT19QE8fT+4ubnxFuYyzMDAAHXq1EFISAg6dOgAANBqtQgJCcGgQYNKNjgqcampqbh69Sq6d++OOnXqQF9fHyEhIejcuTMAICYmBnFxcfy98RaqUqUKbG1tERISIie3KSkpCA8Pl1eKaNiwIZKSknDq1CnUqVMHALB//35otVo0aNCgpEInKhtKeoYsolfpxo0b4syZM2LixIlCrVaLM2fOiDNnzojHjx8LIYTIyckRnp6eolWrViIiIkLs2rVL2NjYiK+//lru49q1a0KlUomvvvpKREdHi59++kkolUqxa9eukjotekWOHj0q5s2bJyIiIsTVq1fFL7/8ImxsbESPHj3kOklJSaJChQqie/fu4vz582L9+vVCpVKJJUuWlGDk9DqsX79eGBoaiuDgYBEVFSU+++wzYWFhoTObO70dRowYIUJDQ8X169dFWFiYaNmypShXrpy4f/++EEKIL774QlSuXFns379fnDx5UjRs2FA0bNiwhKOmV+Xx48fy3xcAxNy5c8WZM2fEjRs3hBBCTJ8+XVhYWIitW7eKs2fPivbt24sqVaqIJ0+eyH34+fmJ2rVri/DwcHHkyBHh6uoqunXrVlKnRFRmMNmlMq1nz54CQK7XgQMH5DqxsbGidevWwtjYWJQrV06MGDFCZGdn6/Rz4MABUatWLWFgYCCcnZ3FqlWrXu+J0Gtx6tQp0aBBA2Fubi6MjIyEu7u7mDp1qsjIyNCpFxkZKd59911haGgo7O3txfTp00soYnrdfvjhB1G5cmVhYGAg6tevL/7++++SDolKQNeuXYWdnZ0wMDAQ9vb2omvXruLKlSty+ZMnT8SAAQOEpaWlUKlUomPHjiI+Pr4EI6ZX6cCBA3n+rdGzZ08hxNPlh7799ltRoUIFYWhoKFq0aCFiYmJ0+nj06JHo1q2bUKvVwszMTPTq1Uv+Yp6I/j1JCCFKaFCZiIiIiIiI6JXgOrtERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktERERERERlDpNdIiIiIiIiKnOY7BIREREREVGZw2SXiIiIiIiIyhwmu0RERERERFTmMNklIqJS4e7duxg8eDCcnZ1haGgIBwcH+Pv7IyQkpKRDK1UCAwPRoUOHQusdOnQI/v7+qFixIiRJwpYtW155bERERKUJk10iIipxsbGxqFOnDvbv349Zs2bh3Llz2LVrF5o3b46BAweWdHhvpLS0NHh7e+Onn34q6VCIiIhKBJNdIiIqcQMGDIAkSTh+/Dg6d+6MatWqoUaNGhg+fDj+/vtvuV5cXBzat28PtVoNMzMzfPTRR7h3755cPmHCBNSqVQsrV65E5cqVoVarMWDAAGg0GsycORO2trYoX748pkyZonN8SZKwaNEitG7dGsbGxnB2dsYff/yhU+fcuXN4//33YWxsDGtra3z22WdITU2Vy5+NuM6ePRt2dnawtrbGwIEDkZ2dLdfJzMxEUFAQ7O3tYWJiggYNGiA0NFQuDw4OhoWFBXbv3g13d3eo1Wr4+fkhPj5ePr/Vq1dj69atkCQJkiTptH9e69at8d1336Fjx47F/nkQERGVBUx2iYioRCUkJGDXrl0YOHAgTExMcpVbWFgAALRaLdq3b4+EhAQcPHgQe/fuxbVr19C1a1ed+levXsXOnTuxa9curFu3DitWrEDbtm1x69YtHDx4EDNmzMDYsWMRHh6u0+7bb79F586dERkZiYCAAHz88ceIjo4G8HSU1NfXF5aWljhx4gQ2bNiAffv2YdCgQTp9HDhwAFevXsWBAwewevVqBAcHIzg4WC4fNGgQjh07hvXr1+Ps2bPo0qUL/Pz8cPnyZblOeno6Zs+ejTVr1uDQoUOIi4tDUFAQACAoKAgfffSRnADHx8ejUaNG//raExERlWmCiIioBIWHhwsAYtOmTQXW27Nnj1AqlSIuLk7ed+HCBQFAHD9+XAghxPjx44VKpRIpKSlyHV9fX+Hk5CQ0Go28z83NTUybNk3eBiC++OILneM1aNBA9O/fXwghxNKlS4WlpaVITU2Vy7dv3y4UCoW4e/euEEKInj17CkdHR5GTkyPX6dKli+jatasQQogbN24IpVIpbt++rXOcFi1aiK+//loIIcSqVasEAHHlyhW5/KeffhIVKlSQt3v27Cnat29f4LV6EQCxefPmYrUhIiJ60+mVaKZNRERvPSFEkepFR0fDwcEBDg4O8j4PDw9YWFggOjoa9erVAwA4OTnB1NRUrlOhQgUolUooFAqdfffv39fpv2HDhrm2IyIi5GN7e3vrjDw3btwYWq0WMTExqFChAgCgRo0aUCqVch07OzucO3cOwNPboDUaDapVq6ZznMzMTFhbW8vbKpUKVatW1enjxViJiIiocEx2iYioRLm6ukKSJFy8ePGl9Kevr6+zLUlSnvu0Wu1LOV5hx352nNTUVCiVSpw6dUonIQYAtVpdYB9F/UKAiIiI/sFndomIqERZWVnB19cXP/30E9LS0nKVJyUlAQDc3d1x8+ZN3Lx5Uy6LiopCUlISPDw8/nMcz0+E9Wzb3d1dPnZkZKROfGFhYVAoFHBzcytS/7Vr14ZGo8H9+/fh4uKi87K1tS1ynAYGBtBoNEWuT0RE9LZisktERCXup59+gkajQf369bFx40ZcvnwZ0dHRWLBggXx7ccuWLeHl5YWAgACcPn0ax48fR48ePdC0aVPUrVv3P8ewYcMGrFy5EpcuXcL48eNx/PhxeQKqgIAAGBkZoWfPnjh//jwOHDiAwYMHo3v37vItzIWpVq0aAgIC0KNHD2zatAnXr1/H8ePHMW3aNGzfvr3IcTo5OeHs2bOIiYnBw4cPdWZ7fl5qaioiIiLkW7GvX7+OiIgIxMXFFflYREREbzImu0REVOKcnZ1x+vRpNG/eHCNGjICnpyc++OADhISEYNGiRQCe3s67detWWFpaokmTJmjZsiWcnZ3x22+/vZQYJk6ciPXr16NmzZr4+eefsW7dOnnEWKVSYffu3UhISEC9evXw4YcfokWLFvjxxx+LdYxVq1ahR48eGDFiBNzc3NChQwecOHEClStXLnIf/fr1g5ubG+rWrQsbGxuEhYXlWe/kyZOoXbs2ateuDQAYPnw4ateujXHjxhUrZiIiojeVJPggEBERveUkScLmzZvRoUOHkg6FiIiIXhKO7BIREREREVGZw2SXiIiIiIiIyhwuPURERG89PtFDRERU9nBkl4iIiIiIiMocJrtERERERERU5jDZJSIiIiIiojKHyS4RERERERGVOUx2iYiIiIiIqMxhsktERERERERlDpNdIiIiIiIiKnOY7BIREREREVGZ839StvwTcA23HQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=0)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# Plot the reduced embeddings\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], s=100, alpha=0.7)\n",
    "plt.title(\"GAT Embeddings Visualization\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "\n",
    "for i, team in enumerate(teams):\n",
    "    plt.annotate(team, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import negative_sampling, train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "in_channels = node_features.size(1)  # Assuming you use random features as before\n",
    "hidden_channels = 32\n",
    "out_channels = 16\n",
    "model = GATModel(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, num_layers=4).to(device)\n",
    "\n",
    "data.edge_attr = None\n",
    "\n",
    "# Perform train/test split on edges\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "# You can still access `edge_attr` separately if needed\n",
    "edge_attr = data.edge_attr  # Store edge_attr separately if you need it later\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Training Loss: 75.27072143554688, Training Accuracy: 0.5294117647058824, Validation Loss: 0.6457369327545166, Validation Accuracy: 0.5\n",
      "Epoch 2/10000, Training Loss: 40.19029998779297, Training Accuracy: 0.5269607843137255, Validation Loss: 74.21609497070312, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3/10000, Training Loss: 184.91159057617188, Training Accuracy: 0.5196078431372549, Validation Loss: 161.7522430419922, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4/10000, Training Loss: 41.16419219970703, Training Accuracy: 0.48284313725490197, Validation Loss: 1.2063660621643066, Validation Accuracy: 0.5\n",
      "Epoch 5/10000, Training Loss: 87.22949981689453, Training Accuracy: 0.48284313725490197, Validation Loss: 3.905700922012329, Validation Accuracy: 0.75\n",
      "Epoch 6/10000, Training Loss: 79.09565734863281, Training Accuracy: 0.5980392156862745, Validation Loss: 2.4483683109283447, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7/10000, Training Loss: 281.43157958984375, Training Accuracy: 0.5073529411764706, Validation Loss: 5.513342380523682, Validation Accuracy: 0.5\n",
      "Epoch 8/10000, Training Loss: 61.615230560302734, Training Accuracy: 0.4950980392156863, Validation Loss: 2.471623659133911, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9/10000, Training Loss: 152.2936248779297, Training Accuracy: 0.5171568627450981, Validation Loss: 119.9435043334961, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 10/10000, Training Loss: 207.35313415527344, Training Accuracy: 0.5392156862745098, Validation Loss: 189.83985900878906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 11/10000, Training Loss: 76.56255340576172, Training Accuracy: 0.5220588235294118, Validation Loss: 70.75746154785156, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 12/10000, Training Loss: 54.78455352783203, Training Accuracy: 0.46568627450980393, Validation Loss: 0.5795848965644836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 13/10000, Training Loss: 139.1696014404297, Training Accuracy: 0.5343137254901961, Validation Loss: 365.04541015625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 14/10000, Training Loss: 52.80879592895508, Training Accuracy: 0.5318627450980392, Validation Loss: 0.6743867993354797, Validation Accuracy: 0.5\n",
      "Epoch 15/10000, Training Loss: 448.8399963378906, Training Accuracy: 0.5269607843137255, Validation Loss: 0.7016531825065613, Validation Accuracy: 0.5\n",
      "Epoch 16/10000, Training Loss: 81.55449676513672, Training Accuracy: 0.5367647058823529, Validation Loss: 0.731869637966156, Validation Accuracy: 0.5\n",
      "Epoch 17/10000, Training Loss: 124.47212219238281, Training Accuracy: 0.5196078431372549, Validation Loss: 104.9348373413086, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 18/10000, Training Loss: 97.32038879394531, Training Accuracy: 0.5, Validation Loss: 67.43118286132812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 19/10000, Training Loss: 149.05606079101562, Training Accuracy: 0.4950980392156863, Validation Loss: 44.35623550415039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 20/10000, Training Loss: 34.260765075683594, Training Accuracy: 0.5245098039215687, Validation Loss: 1.3336273431777954, Validation Accuracy: 0.5\n",
      "Epoch 21/10000, Training Loss: 90.57950592041016, Training Accuracy: 0.47549019607843135, Validation Loss: 15.450248718261719, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 22/10000, Training Loss: 136.79904174804688, Training Accuracy: 0.44362745098039214, Validation Loss: 51.70576477050781, Validation Accuracy: 0.5\n",
      "Epoch 23/10000, Training Loss: 99.40538024902344, Training Accuracy: 0.5416666666666666, Validation Loss: 85.88756561279297, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 24/10000, Training Loss: 130.7541046142578, Training Accuracy: 0.4803921568627451, Validation Loss: 2.727484941482544, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 25/10000, Training Loss: 204.0531005859375, Training Accuracy: 0.5, Validation Loss: 0.8684762120246887, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 26/10000, Training Loss: 108.19727325439453, Training Accuracy: 0.5147058823529411, Validation Loss: 75.15685272216797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 27/10000, Training Loss: 72.11486053466797, Training Accuracy: 0.4877450980392157, Validation Loss: 2.0324888229370117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 28/10000, Training Loss: 25.677698135375977, Training Accuracy: 0.5637254901960784, Validation Loss: 24.956565856933594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 29/10000, Training Loss: 51.276763916015625, Training Accuracy: 0.5294117647058824, Validation Loss: 41.24738311767578, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 30/10000, Training Loss: 29.599010467529297, Training Accuracy: 0.47794117647058826, Validation Loss: 0.5050626993179321, Validation Accuracy: 0.5\n",
      "Epoch 31/10000, Training Loss: 26.393688201904297, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7197359204292297, Validation Accuracy: 0.5\n",
      "Epoch 32/10000, Training Loss: 114.8402328491211, Training Accuracy: 0.49264705882352944, Validation Loss: 138.9617156982422, Validation Accuracy: 0.5\n",
      "Epoch 33/10000, Training Loss: 7.696858882904053, Training Accuracy: 0.5196078431372549, Validation Loss: 0.829136073589325, Validation Accuracy: 0.5\n",
      "Epoch 34/10000, Training Loss: 63.25508499145508, Training Accuracy: 0.5759803921568627, Validation Loss: 139.64512634277344, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 35/10000, Training Loss: 40.675933837890625, Training Accuracy: 0.5147058823529411, Validation Loss: 40.89680862426758, Validation Accuracy: 0.25\n",
      "Epoch 36/10000, Training Loss: 29.739242553710938, Training Accuracy: 0.5637254901960784, Validation Loss: 46.4173698425293, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 37/10000, Training Loss: 69.40779113769531, Training Accuracy: 0.5171568627450981, Validation Loss: 43.207061767578125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 38/10000, Training Loss: 111.59188079833984, Training Accuracy: 0.5, Validation Loss: 285.0760192871094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 39/10000, Training Loss: 47.63947677612305, Training Accuracy: 0.5024509803921569, Validation Loss: 20.773630142211914, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 40/10000, Training Loss: 50.531131744384766, Training Accuracy: 0.4852941176470588, Validation Loss: 67.3432846069336, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 41/10000, Training Loss: 45.65727996826172, Training Accuracy: 0.5294117647058824, Validation Loss: 0.7336307168006897, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 42/10000, Training Loss: 101.89506530761719, Training Accuracy: 0.5563725490196079, Validation Loss: 58.36790466308594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 43/10000, Training Loss: 61.35520553588867, Training Accuracy: 0.5245098039215687, Validation Loss: 2.774322509765625, Validation Accuracy: 0.75\n",
      "Epoch 44/10000, Training Loss: 135.03675842285156, Training Accuracy: 0.5220588235294118, Validation Loss: 72.9211196899414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 45/10000, Training Loss: 95.8905258178711, Training Accuracy: 0.47058823529411764, Validation Loss: 14.563430786132812, Validation Accuracy: 0.5\n",
      "Epoch 46/10000, Training Loss: 93.97667694091797, Training Accuracy: 0.4877450980392157, Validation Loss: 14.484684944152832, Validation Accuracy: 0.75\n",
      "Epoch 47/10000, Training Loss: 178.836181640625, Training Accuracy: 0.4950980392156863, Validation Loss: 0.6778376698493958, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 48/10000, Training Loss: 167.76124572753906, Training Accuracy: 0.5367647058823529, Validation Loss: 9.731226921081543, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 49/10000, Training Loss: 35.551151275634766, Training Accuracy: 0.46078431372549017, Validation Loss: 4.840038776397705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 50/10000, Training Loss: 291.8066101074219, Training Accuracy: 0.49019607843137253, Validation Loss: 263.6659240722656, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 51/10000, Training Loss: 28.583723068237305, Training Accuracy: 0.4583333333333333, Validation Loss: 24.806177139282227, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 52/10000, Training Loss: 55.113739013671875, Training Accuracy: 0.6151960784313726, Validation Loss: 156.70993041992188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 53/10000, Training Loss: 102.9779052734375, Training Accuracy: 0.5392156862745098, Validation Loss: 152.0618438720703, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 54/10000, Training Loss: 38.939788818359375, Training Accuracy: 0.49754901960784315, Validation Loss: 44.964996337890625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 55/10000, Training Loss: 36.543357849121094, Training Accuracy: 0.5612745098039216, Validation Loss: 7.925496578216553, Validation Accuracy: 0.25\n",
      "Epoch 56/10000, Training Loss: 33.61260223388672, Training Accuracy: 0.5759803921568627, Validation Loss: 160.35592651367188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 57/10000, Training Loss: 81.47937774658203, Training Accuracy: 0.5147058823529411, Validation Loss: 17.203380584716797, Validation Accuracy: 0.5\n",
      "Epoch 58/10000, Training Loss: 81.25755310058594, Training Accuracy: 0.5220588235294118, Validation Loss: 361.2895202636719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 59/10000, Training Loss: 69.55068969726562, Training Accuracy: 0.4730392156862745, Validation Loss: 41.4670295715332, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 60/10000, Training Loss: 106.98609924316406, Training Accuracy: 0.5196078431372549, Validation Loss: 45.44102096557617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 61/10000, Training Loss: 44.634822845458984, Training Accuracy: 0.46568627450980393, Validation Loss: 1.0210659503936768, Validation Accuracy: 0.5\n",
      "Epoch 62/10000, Training Loss: 45.9462890625, Training Accuracy: 0.5612745098039216, Validation Loss: 303.5481262207031, Validation Accuracy: 0.5\n",
      "Epoch 63/10000, Training Loss: 78.46415710449219, Training Accuracy: 0.5147058823529411, Validation Loss: 87.322021484375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 64/10000, Training Loss: 35.10676574707031, Training Accuracy: 0.5294117647058824, Validation Loss: 0.5108376741409302, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 65/10000, Training Loss: 89.54612731933594, Training Accuracy: 0.5024509803921569, Validation Loss: 0.8712403774261475, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 66/10000, Training Loss: 91.33322143554688, Training Accuracy: 0.5514705882352942, Validation Loss: 1.4271564483642578, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 67/10000, Training Loss: 83.92513275146484, Training Accuracy: 0.5416666666666666, Validation Loss: 807.1101684570312, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 68/10000, Training Loss: 48.43601608276367, Training Accuracy: 0.49754901960784315, Validation Loss: 31.016672134399414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 69/10000, Training Loss: 113.90689086914062, Training Accuracy: 0.4338235294117647, Validation Loss: 27.739051818847656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 70/10000, Training Loss: 71.72982025146484, Training Accuracy: 0.5024509803921569, Validation Loss: 7.3215413093566895, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 71/10000, Training Loss: 45.21123504638672, Training Accuracy: 0.5490196078431373, Validation Loss: 13.056187629699707, Validation Accuracy: 0.5\n",
      "Epoch 72/10000, Training Loss: 78.03942108154297, Training Accuracy: 0.5318627450980392, Validation Loss: 11.384810447692871, Validation Accuracy: 0.5\n",
      "Epoch 73/10000, Training Loss: 83.15065002441406, Training Accuracy: 0.46568627450980393, Validation Loss: 146.1427764892578, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 74/10000, Training Loss: 17.7274227142334, Training Accuracy: 0.5784313725490197, Validation Loss: 21.23154640197754, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 75/10000, Training Loss: 83.37191009521484, Training Accuracy: 0.5147058823529411, Validation Loss: 0.5729799270629883, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 76/10000, Training Loss: 97.9286117553711, Training Accuracy: 0.5122549019607843, Validation Loss: 17.61192512512207, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 77/10000, Training Loss: 44.325164794921875, Training Accuracy: 0.5318627450980392, Validation Loss: 13.648178100585938, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 78/10000, Training Loss: 46.35285949707031, Training Accuracy: 0.5269607843137255, Validation Loss: 1.2074576616287231, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 79/10000, Training Loss: 62.24802780151367, Training Accuracy: 0.5073529411764706, Validation Loss: 22.69651222229004, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 80/10000, Training Loss: 35.11030960083008, Training Accuracy: 0.4681372549019608, Validation Loss: 1.9702686071395874, Validation Accuracy: 0.5\n",
      "Epoch 81/10000, Training Loss: 57.85984802246094, Training Accuracy: 0.5318627450980392, Validation Loss: 46.468841552734375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 82/10000, Training Loss: 39.097923278808594, Training Accuracy: 0.46568627450980393, Validation Loss: 76.5833740234375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 83/10000, Training Loss: 121.29545593261719, Training Accuracy: 0.4950980392156863, Validation Loss: 529.5369262695312, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 84/10000, Training Loss: 48.97959899902344, Training Accuracy: 0.49019607843137253, Validation Loss: 108.88509368896484, Validation Accuracy: 0.5\n",
      "Epoch 85/10000, Training Loss: 103.50164031982422, Training Accuracy: 0.47549019607843135, Validation Loss: 8.35913372039795, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 86/10000, Training Loss: 24.415679931640625, Training Accuracy: 0.5563725490196079, Validation Loss: 22.886999130249023, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 87/10000, Training Loss: 33.35951614379883, Training Accuracy: 0.5147058823529411, Validation Loss: 33.633480072021484, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 88/10000, Training Loss: 66.28614807128906, Training Accuracy: 0.4338235294117647, Validation Loss: 58.276092529296875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 89/10000, Training Loss: 87.64307403564453, Training Accuracy: 0.5318627450980392, Validation Loss: 52.485591888427734, Validation Accuracy: 0.5\n",
      "Epoch 90/10000, Training Loss: 99.9013900756836, Training Accuracy: 0.4681372549019608, Validation Loss: 37.245216369628906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 91/10000, Training Loss: 43.56307601928711, Training Accuracy: 0.5024509803921569, Validation Loss: 229.0421600341797, Validation Accuracy: 0.5\n",
      "Epoch 92/10000, Training Loss: 38.527469635009766, Training Accuracy: 0.44362745098039214, Validation Loss: 96.72440338134766, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 93/10000, Training Loss: 53.019866943359375, Training Accuracy: 0.5, Validation Loss: 14.33083438873291, Validation Accuracy: 0.5\n",
      "Epoch 94/10000, Training Loss: 66.70915222167969, Training Accuracy: 0.5441176470588235, Validation Loss: 155.5712890625, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 95/10000, Training Loss: 34.62881088256836, Training Accuracy: 0.47549019607843135, Validation Loss: 12.310553550720215, Validation Accuracy: 0.5\n",
      "Epoch 96/10000, Training Loss: 56.42487335205078, Training Accuracy: 0.5318627450980392, Validation Loss: 3.6558854579925537, Validation Accuracy: 0.75\n",
      "Epoch 97/10000, Training Loss: 36.51456069946289, Training Accuracy: 0.49019607843137253, Validation Loss: 1.1233969926834106, Validation Accuracy: 0.5\n",
      "Epoch 98/10000, Training Loss: 53.724098205566406, Training Accuracy: 0.5073529411764706, Validation Loss: 1.1344083547592163, Validation Accuracy: 0.75\n",
      "Epoch 99/10000, Training Loss: 70.84347534179688, Training Accuracy: 0.5367647058823529, Validation Loss: 128.76296997070312, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 100/10000, Training Loss: 104.79601287841797, Training Accuracy: 0.5147058823529411, Validation Loss: 405.9132385253906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 101/10000, Training Loss: 108.28121185302734, Training Accuracy: 0.5049019607843137, Validation Loss: 453.1826171875, Validation Accuracy: 0.25\n",
      "Epoch 102/10000, Training Loss: 66.93209075927734, Training Accuracy: 0.5318627450980392, Validation Loss: 31.49735450744629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 103/10000, Training Loss: 70.33625793457031, Training Accuracy: 0.5588235294117647, Validation Loss: 199.22877502441406, Validation Accuracy: 0.5\n",
      "Epoch 104/10000, Training Loss: 40.46488571166992, Training Accuracy: 0.49754901960784315, Validation Loss: 11.445405006408691, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 105/10000, Training Loss: 101.72550201416016, Training Accuracy: 0.4877450980392157, Validation Loss: 186.5788116455078, Validation Accuracy: 0.5\n",
      "Epoch 106/10000, Training Loss: 61.13029479980469, Training Accuracy: 0.5049019607843137, Validation Loss: 74.5748291015625, Validation Accuracy: 0.5\n",
      "Epoch 107/10000, Training Loss: 48.21300506591797, Training Accuracy: 0.5661764705882353, Validation Loss: 26.172258377075195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 108/10000, Training Loss: 24.444164276123047, Training Accuracy: 0.4950980392156863, Validation Loss: 1.152013897895813, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 109/10000, Training Loss: 66.86041259765625, Training Accuracy: 0.47058823529411764, Validation Loss: 29.70098876953125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 110/10000, Training Loss: 41.24496078491211, Training Accuracy: 0.5661764705882353, Validation Loss: 54.69135665893555, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 111/10000, Training Loss: 66.57315826416016, Training Accuracy: 0.5686274509803921, Validation Loss: 80.11246490478516, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 112/10000, Training Loss: 11.443523406982422, Training Accuracy: 0.571078431372549, Validation Loss: 0.4648744761943817, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 113/10000, Training Loss: 53.00102996826172, Training Accuracy: 0.553921568627451, Validation Loss: 51.26491165161133, Validation Accuracy: 0.5\n",
      "Epoch 114/10000, Training Loss: 60.676605224609375, Training Accuracy: 0.5098039215686274, Validation Loss: 80.90314483642578, Validation Accuracy: 0.5\n",
      "Epoch 115/10000, Training Loss: 45.71717834472656, Training Accuracy: 0.5686274509803921, Validation Loss: 32.46897888183594, Validation Accuracy: 0.5\n",
      "Epoch 116/10000, Training Loss: 47.592864990234375, Training Accuracy: 0.47794117647058826, Validation Loss: 75.87913513183594, Validation Accuracy: 0.5\n",
      "Epoch 117/10000, Training Loss: 124.8004379272461, Training Accuracy: 0.5147058823529411, Validation Loss: 793.9475708007812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 118/10000, Training Loss: 35.30009078979492, Training Accuracy: 0.5343137254901961, Validation Loss: 43.77482223510742, Validation Accuracy: 0.5\n",
      "Epoch 119/10000, Training Loss: 97.93917846679688, Training Accuracy: 0.46568627450980393, Validation Loss: 316.8410339355469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 120/10000, Training Loss: 140.11558532714844, Training Accuracy: 0.5073529411764706, Validation Loss: 68.0105972290039, Validation Accuracy: 0.75\n",
      "Epoch 121/10000, Training Loss: 71.84745788574219, Training Accuracy: 0.5833333333333334, Validation Loss: 398.3147888183594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 122/10000, Training Loss: 41.611629486083984, Training Accuracy: 0.5073529411764706, Validation Loss: 12.298736572265625, Validation Accuracy: 0.75\n",
      "Epoch 123/10000, Training Loss: 122.2746810913086, Training Accuracy: 0.6200980392156863, Validation Loss: 122.77587890625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 124/10000, Training Loss: 7.561141490936279, Training Accuracy: 0.5563725490196079, Validation Loss: 13.711394309997559, Validation Accuracy: 0.5\n",
      "Epoch 125/10000, Training Loss: 79.69400024414062, Training Accuracy: 0.5171568627450981, Validation Loss: 16.986894607543945, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 126/10000, Training Loss: 50.92816162109375, Training Accuracy: 0.5441176470588235, Validation Loss: 137.06410217285156, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 127/10000, Training Loss: 196.95986938476562, Training Accuracy: 0.5392156862745098, Validation Loss: 733.8724975585938, Validation Accuracy: 0.5\n",
      "Epoch 128/10000, Training Loss: 80.75961303710938, Training Accuracy: 0.5171568627450981, Validation Loss: 0.6114203333854675, Validation Accuracy: 0.5\n",
      "Epoch 129/10000, Training Loss: 154.57908630371094, Training Accuracy: 0.5049019607843137, Validation Loss: 2.91986346244812, Validation Accuracy: 0.5\n",
      "Epoch 130/10000, Training Loss: 43.37934494018555, Training Accuracy: 0.5441176470588235, Validation Loss: 22.449844360351562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 131/10000, Training Loss: 155.45159912109375, Training Accuracy: 0.5098039215686274, Validation Loss: 404.361572265625, Validation Accuracy: 0.75\n",
      "Epoch 132/10000, Training Loss: 39.12327575683594, Training Accuracy: 0.5245098039215687, Validation Loss: 42.29106140136719, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 133/10000, Training Loss: 34.42726135253906, Training Accuracy: 0.4362745098039216, Validation Loss: 2.5259461402893066, Validation Accuracy: 0.75\n",
      "Epoch 134/10000, Training Loss: 16.383323669433594, Training Accuracy: 0.4877450980392157, Validation Loss: 0.7029868960380554, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 135/10000, Training Loss: 59.486576080322266, Training Accuracy: 0.5367647058823529, Validation Loss: 132.50477600097656, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 136/10000, Training Loss: 46.77874755859375, Training Accuracy: 0.5833333333333334, Validation Loss: 110.56670379638672, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 137/10000, Training Loss: 38.81476593017578, Training Accuracy: 0.5147058823529411, Validation Loss: 0.8898630738258362, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 138/10000, Training Loss: 73.1773681640625, Training Accuracy: 0.47794117647058826, Validation Loss: 730.5857543945312, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 139/10000, Training Loss: 64.8169937133789, Training Accuracy: 0.5220588235294118, Validation Loss: 22.590333938598633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 140/10000, Training Loss: 6.557224750518799, Training Accuracy: 0.49019607843137253, Validation Loss: 0.5125868916511536, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 141/10000, Training Loss: 19.04472541809082, Training Accuracy: 0.5563725490196079, Validation Loss: 0.4634968936443329, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 142/10000, Training Loss: 190.35418701171875, Training Accuracy: 0.5073529411764706, Validation Loss: 377.6632995605469, Validation Accuracy: 0.25\n",
      "Epoch 143/10000, Training Loss: 76.24837493896484, Training Accuracy: 0.45098039215686275, Validation Loss: 32.43001937866211, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 144/10000, Training Loss: 14.673896789550781, Training Accuracy: 0.5808823529411765, Validation Loss: 12.97821044921875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 145/10000, Training Loss: 46.10674285888672, Training Accuracy: 0.5857843137254902, Validation Loss: 321.24658203125, Validation Accuracy: 0.75\n",
      "Epoch 146/10000, Training Loss: 80.3130874633789, Training Accuracy: 0.6053921568627451, Validation Loss: 277.8472595214844, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 147/10000, Training Loss: 96.12665557861328, Training Accuracy: 0.5220588235294118, Validation Loss: 3.9098265171051025, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 148/10000, Training Loss: 27.546236038208008, Training Accuracy: 0.5514705882352942, Validation Loss: 10.016663551330566, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 149/10000, Training Loss: 40.914573669433594, Training Accuracy: 0.5343137254901961, Validation Loss: 17.800464630126953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 150/10000, Training Loss: 75.02322387695312, Training Accuracy: 0.4877450980392157, Validation Loss: 41.465641021728516, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 151/10000, Training Loss: 65.23992156982422, Training Accuracy: 0.5833333333333334, Validation Loss: 79.59957122802734, Validation Accuracy: 0.25\n",
      "Epoch 152/10000, Training Loss: 23.279953002929688, Training Accuracy: 0.48284313725490197, Validation Loss: 294.3918151855469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 153/10000, Training Loss: 20.055788040161133, Training Accuracy: 0.5661764705882353, Validation Loss: 16.463895797729492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 154/10000, Training Loss: 71.28263092041016, Training Accuracy: 0.4950980392156863, Validation Loss: 166.65750122070312, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 155/10000, Training Loss: 186.59921264648438, Training Accuracy: 0.5049019607843137, Validation Loss: 0.45415353775024414, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 156/10000, Training Loss: 23.426570892333984, Training Accuracy: 0.571078431372549, Validation Loss: 9.35360050201416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 157/10000, Training Loss: 59.07071304321289, Training Accuracy: 0.5049019607843137, Validation Loss: 193.51300048828125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 158/10000, Training Loss: 80.89320373535156, Training Accuracy: 0.5318627450980392, Validation Loss: 53.8807487487793, Validation Accuracy: 0.5\n",
      "Epoch 159/10000, Training Loss: 3.929851531982422, Training Accuracy: 0.5490196078431373, Validation Loss: 1.5536142587661743, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 160/10000, Training Loss: 64.39242553710938, Training Accuracy: 0.5588235294117647, Validation Loss: 48.997589111328125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 161/10000, Training Loss: 110.21282196044922, Training Accuracy: 0.5049019607843137, Validation Loss: 145.38279724121094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 162/10000, Training Loss: 41.2317008972168, Training Accuracy: 0.5465686274509803, Validation Loss: 48.78523635864258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 163/10000, Training Loss: 111.45993041992188, Training Accuracy: 0.5833333333333334, Validation Loss: 110.64493560791016, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 164/10000, Training Loss: 48.469268798828125, Training Accuracy: 0.5367647058823529, Validation Loss: 127.52328491210938, Validation Accuracy: 0.5\n",
      "Epoch 165/10000, Training Loss: 49.607872009277344, Training Accuracy: 0.5098039215686274, Validation Loss: 304.49884033203125, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 166/10000, Training Loss: 82.3172607421875, Training Accuracy: 0.5147058823529411, Validation Loss: 218.02195739746094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 167/10000, Training Loss: 46.426063537597656, Training Accuracy: 0.49019607843137253, Validation Loss: 0.5855556726455688, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 168/10000, Training Loss: 37.104347229003906, Training Accuracy: 0.5098039215686274, Validation Loss: 51.043853759765625, Validation Accuracy: 0.5\n",
      "Epoch 169/10000, Training Loss: 132.57276916503906, Training Accuracy: 0.6176470588235294, Validation Loss: 112.4929428100586, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 170/10000, Training Loss: 53.49129867553711, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9084088206291199, Validation Accuracy: 0.5\n",
      "Epoch 171/10000, Training Loss: 51.11724853515625, Training Accuracy: 0.5465686274509803, Validation Loss: 23.41901397705078, Validation Accuracy: 0.5\n",
      "Epoch 172/10000, Training Loss: 31.721162796020508, Training Accuracy: 0.5588235294117647, Validation Loss: 41.465789794921875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 173/10000, Training Loss: 31.77394676208496, Training Accuracy: 0.5514705882352942, Validation Loss: 68.12510681152344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 174/10000, Training Loss: 54.23571014404297, Training Accuracy: 0.47794117647058826, Validation Loss: 13.225040435791016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 175/10000, Training Loss: 69.17648315429688, Training Accuracy: 0.5024509803921569, Validation Loss: 38.30410385131836, Validation Accuracy: 0.5\n",
      "Epoch 176/10000, Training Loss: 12.752023696899414, Training Accuracy: 0.5637254901960784, Validation Loss: 13.874117851257324, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 177/10000, Training Loss: 33.84852600097656, Training Accuracy: 0.5220588235294118, Validation Loss: 0.5465635061264038, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 178/10000, Training Loss: 122.30187225341797, Training Accuracy: 0.5563725490196079, Validation Loss: 39.33298110961914, Validation Accuracy: 0.5\n",
      "Epoch 179/10000, Training Loss: 58.046531677246094, Training Accuracy: 0.4852941176470588, Validation Loss: 39.022457122802734, Validation Accuracy: 0.5\n",
      "Epoch 180/10000, Training Loss: 32.90511703491211, Training Accuracy: 0.5490196078431373, Validation Loss: 71.1279525756836, Validation Accuracy: 0.75\n",
      "Epoch 181/10000, Training Loss: 111.88893127441406, Training Accuracy: 0.5073529411764706, Validation Loss: 119.34768676757812, Validation Accuracy: 0.5\n",
      "Epoch 182/10000, Training Loss: 58.822532653808594, Training Accuracy: 0.5661764705882353, Validation Loss: 116.50469207763672, Validation Accuracy: 0.5\n",
      "Epoch 183/10000, Training Loss: 74.62627410888672, Training Accuracy: 0.5735294117647058, Validation Loss: 435.8981018066406, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 184/10000, Training Loss: 21.960739135742188, Training Accuracy: 0.49754901960784315, Validation Loss: 0.6746756434440613, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 185/10000, Training Loss: 32.5187873840332, Training Accuracy: 0.5098039215686274, Validation Loss: 2.2015128135681152, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 186/10000, Training Loss: 42.257694244384766, Training Accuracy: 0.5759803921568627, Validation Loss: 1.350277304649353, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 187/10000, Training Loss: 25.111616134643555, Training Accuracy: 0.5245098039215687, Validation Loss: 40.63436508178711, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 188/10000, Training Loss: 50.91100311279297, Training Accuracy: 0.49019607843137253, Validation Loss: 117.96410369873047, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 189/10000, Training Loss: 24.779991149902344, Training Accuracy: 0.553921568627451, Validation Loss: 2.9098570346832275, Validation Accuracy: 0.5\n",
      "Epoch 190/10000, Training Loss: 42.19334030151367, Training Accuracy: 0.5294117647058824, Validation Loss: 37.853675842285156, Validation Accuracy: 0.5\n",
      "Epoch 191/10000, Training Loss: 174.4000701904297, Training Accuracy: 0.5343137254901961, Validation Loss: 201.2423858642578, Validation Accuracy: 0.5\n",
      "Epoch 192/10000, Training Loss: 41.58574676513672, Training Accuracy: 0.5784313725490197, Validation Loss: 301.3835754394531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 193/10000, Training Loss: 66.63276672363281, Training Accuracy: 0.5171568627450981, Validation Loss: 15.396583557128906, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 194/10000, Training Loss: 45.4891242980957, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7924317717552185, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 195/10000, Training Loss: 57.250282287597656, Training Accuracy: 0.5024509803921569, Validation Loss: 58.30623245239258, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 196/10000, Training Loss: 45.658565521240234, Training Accuracy: 0.5049019607843137, Validation Loss: 0.734036922454834, Validation Accuracy: 0.75\n",
      "Epoch 197/10000, Training Loss: 26.503036499023438, Training Accuracy: 0.47058823529411764, Validation Loss: 0.6822887063026428, Validation Accuracy: 0.5\n",
      "Epoch 198/10000, Training Loss: 10.658884048461914, Training Accuracy: 0.5441176470588235, Validation Loss: 18.661062240600586, Validation Accuracy: 0.5\n",
      "Epoch 199/10000, Training Loss: 43.9213981628418, Training Accuracy: 0.5220588235294118, Validation Loss: 24.99468421936035, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 200/10000, Training Loss: 69.50666046142578, Training Accuracy: 0.4950980392156863, Validation Loss: 207.30384826660156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 201/10000, Training Loss: 41.16836166381836, Training Accuracy: 0.5098039215686274, Validation Loss: 77.40221405029297, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 202/10000, Training Loss: 41.264251708984375, Training Accuracy: 0.5465686274509803, Validation Loss: 2.892470121383667, Validation Accuracy: 0.5\n",
      "Epoch 203/10000, Training Loss: 36.20212173461914, Training Accuracy: 0.5441176470588235, Validation Loss: 61.36662292480469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 204/10000, Training Loss: 58.557029724121094, Training Accuracy: 0.5318627450980392, Validation Loss: 133.23731994628906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 205/10000, Training Loss: 50.42938995361328, Training Accuracy: 0.5269607843137255, Validation Loss: 82.13910675048828, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 206/10000, Training Loss: 32.3226203918457, Training Accuracy: 0.5147058823529411, Validation Loss: 22.48551368713379, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 207/10000, Training Loss: 30.2445125579834, Training Accuracy: 0.5024509803921569, Validation Loss: 0.5169933438301086, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 208/10000, Training Loss: 350.1271057128906, Training Accuracy: 0.5441176470588235, Validation Loss: 337.8288879394531, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 209/10000, Training Loss: 20.125028610229492, Training Accuracy: 0.5392156862745098, Validation Loss: 4.803040981292725, Validation Accuracy: 0.25\n",
      "Epoch 210/10000, Training Loss: 51.045310974121094, Training Accuracy: 0.4730392156862745, Validation Loss: 11.210288047790527, Validation Accuracy: 0.5\n",
      "Epoch 211/10000, Training Loss: 9.25603199005127, Training Accuracy: 0.5318627450980392, Validation Loss: 30.709928512573242, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 212/10000, Training Loss: 39.287139892578125, Training Accuracy: 0.5735294117647058, Validation Loss: 54.50528335571289, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 213/10000, Training Loss: 47.4986686706543, Training Accuracy: 0.5073529411764706, Validation Loss: 23.440353393554688, Validation Accuracy: 0.5\n",
      "Epoch 214/10000, Training Loss: 80.96908569335938, Training Accuracy: 0.5514705882352942, Validation Loss: 17.864511489868164, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 215/10000, Training Loss: 68.00959014892578, Training Accuracy: 0.5122549019607843, Validation Loss: 388.2288513183594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 216/10000, Training Loss: 73.24916076660156, Training Accuracy: 0.5686274509803921, Validation Loss: 59.523406982421875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 217/10000, Training Loss: 49.376914978027344, Training Accuracy: 0.5220588235294118, Validation Loss: 1.5401759147644043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 218/10000, Training Loss: 33.98796081542969, Training Accuracy: 0.45098039215686275, Validation Loss: 1.4613746404647827, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 219/10000, Training Loss: 71.65090942382812, Training Accuracy: 0.5269607843137255, Validation Loss: 62.82639694213867, Validation Accuracy: 0.5\n",
      "Epoch 220/10000, Training Loss: 28.08502960205078, Training Accuracy: 0.5147058823529411, Validation Loss: 12.479660034179688, Validation Accuracy: 0.75\n",
      "Epoch 221/10000, Training Loss: 21.46993064880371, Training Accuracy: 0.625, Validation Loss: 58.73977279663086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 222/10000, Training Loss: 36.29985427856445, Training Accuracy: 0.5392156862745098, Validation Loss: 1.7183023691177368, Validation Accuracy: 0.75\n",
      "Epoch 223/10000, Training Loss: 75.95170593261719, Training Accuracy: 0.5171568627450981, Validation Loss: 113.38522338867188, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 224/10000, Training Loss: 39.257537841796875, Training Accuracy: 0.5465686274509803, Validation Loss: 76.48580169677734, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 225/10000, Training Loss: 58.01747131347656, Training Accuracy: 0.5171568627450981, Validation Loss: 6.934991359710693, Validation Accuracy: 0.5\n",
      "Epoch 226/10000, Training Loss: 30.90888023376465, Training Accuracy: 0.5563725490196079, Validation Loss: 37.34404373168945, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 227/10000, Training Loss: 30.20109748840332, Training Accuracy: 0.5367647058823529, Validation Loss: 2.5264999866485596, Validation Accuracy: 0.5\n",
      "Epoch 228/10000, Training Loss: 177.51998901367188, Training Accuracy: 0.5294117647058824, Validation Loss: 377.3474426269531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 229/10000, Training Loss: 133.4435577392578, Training Accuracy: 0.4852941176470588, Validation Loss: 26.278968811035156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 230/10000, Training Loss: 16.601911544799805, Training Accuracy: 0.4730392156862745, Validation Loss: 1.3088496923446655, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 231/10000, Training Loss: 64.4049072265625, Training Accuracy: 0.5220588235294118, Validation Loss: 153.20477294921875, Validation Accuracy: 0.5\n",
      "Epoch 232/10000, Training Loss: 51.99184799194336, Training Accuracy: 0.5490196078431373, Validation Loss: 3.1440773010253906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 233/10000, Training Loss: 42.78269958496094, Training Accuracy: 0.5367647058823529, Validation Loss: 13.308812141418457, Validation Accuracy: 0.5\n",
      "Epoch 234/10000, Training Loss: 65.15255737304688, Training Accuracy: 0.5196078431372549, Validation Loss: 0.7301179766654968, Validation Accuracy: 0.5\n",
      "Epoch 235/10000, Training Loss: 77.80562591552734, Training Accuracy: 0.5269607843137255, Validation Loss: 119.95259857177734, Validation Accuracy: 0.25\n",
      "Epoch 236/10000, Training Loss: 63.792205810546875, Training Accuracy: 0.5416666666666666, Validation Loss: 151.68605041503906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 237/10000, Training Loss: 24.176698684692383, Training Accuracy: 0.5784313725490197, Validation Loss: 12.339607238769531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 238/10000, Training Loss: 27.65366554260254, Training Accuracy: 0.5416666666666666, Validation Loss: 17.05868148803711, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 239/10000, Training Loss: 110.7529525756836, Training Accuracy: 0.553921568627451, Validation Loss: 4.582464218139648, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 240/10000, Training Loss: 25.79930877685547, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3692539930343628, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 241/10000, Training Loss: 57.51090621948242, Training Accuracy: 0.5147058823529411, Validation Loss: 47.9539909362793, Validation Accuracy: 0.5\n",
      "Epoch 242/10000, Training Loss: 49.059844970703125, Training Accuracy: 0.5857843137254902, Validation Loss: 256.2803039550781, Validation Accuracy: 0.25\n",
      "Epoch 243/10000, Training Loss: 34.270137786865234, Training Accuracy: 0.5612745098039216, Validation Loss: 24.72667694091797, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 244/10000, Training Loss: 13.76258373260498, Training Accuracy: 0.5122549019607843, Validation Loss: 5.405315399169922, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 245/10000, Training Loss: 65.2494125366211, Training Accuracy: 0.5073529411764706, Validation Loss: 109.22643280029297, Validation Accuracy: 0.5\n",
      "Epoch 246/10000, Training Loss: 38.17607116699219, Training Accuracy: 0.5882352941176471, Validation Loss: 4.260972499847412, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 247/10000, Training Loss: 68.16635131835938, Training Accuracy: 0.5318627450980392, Validation Loss: 21.386125564575195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 248/10000, Training Loss: 38.48866271972656, Training Accuracy: 0.5441176470588235, Validation Loss: 10.881302833557129, Validation Accuracy: 0.25\n",
      "Epoch 249/10000, Training Loss: 25.0555362701416, Training Accuracy: 0.5588235294117647, Validation Loss: 14.33877182006836, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 250/10000, Training Loss: 25.273296356201172, Training Accuracy: 0.5563725490196079, Validation Loss: 30.66938591003418, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 251/10000, Training Loss: 73.7322998046875, Training Accuracy: 0.4852941176470588, Validation Loss: 23.45613670349121, Validation Accuracy: 0.5\n",
      "Epoch 252/10000, Training Loss: 30.670700073242188, Training Accuracy: 0.5563725490196079, Validation Loss: 16.191850662231445, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 253/10000, Training Loss: 68.10089874267578, Training Accuracy: 0.48284313725490197, Validation Loss: 143.6047821044922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 254/10000, Training Loss: 60.943546295166016, Training Accuracy: 0.46078431372549017, Validation Loss: 338.5389099121094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 255/10000, Training Loss: 36.79508590698242, Training Accuracy: 0.571078431372549, Validation Loss: 7.444817066192627, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 256/10000, Training Loss: 24.409421920776367, Training Accuracy: 0.49754901960784315, Validation Loss: 2.983943223953247, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 257/10000, Training Loss: 46.74663162231445, Training Accuracy: 0.5367647058823529, Validation Loss: 1.3808211088180542, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 258/10000, Training Loss: 70.58195495605469, Training Accuracy: 0.5367647058823529, Validation Loss: 0.666296124458313, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 259/10000, Training Loss: 58.8316764831543, Training Accuracy: 0.5784313725490197, Validation Loss: 118.97595977783203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 260/10000, Training Loss: 32.70442581176758, Training Accuracy: 0.45588235294117646, Validation Loss: 39.64297866821289, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 261/10000, Training Loss: 49.06612777709961, Training Accuracy: 0.5024509803921569, Validation Loss: 1.1917957067489624, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 262/10000, Training Loss: 16.905261993408203, Training Accuracy: 0.5196078431372549, Validation Loss: 12.835967063903809, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 263/10000, Training Loss: 61.79933547973633, Training Accuracy: 0.5220588235294118, Validation Loss: 27.276823043823242, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 264/10000, Training Loss: 17.79966926574707, Training Accuracy: 0.45588235294117646, Validation Loss: 8.800923347473145, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 265/10000, Training Loss: 23.40160369873047, Training Accuracy: 0.571078431372549, Validation Loss: 13.731730461120605, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 266/10000, Training Loss: 25.03486442565918, Training Accuracy: 0.47549019607843135, Validation Loss: 50.85600662231445, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 267/10000, Training Loss: 71.97855377197266, Training Accuracy: 0.6200980392156863, Validation Loss: 143.85240173339844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 268/10000, Training Loss: 12.766432762145996, Training Accuracy: 0.5490196078431373, Validation Loss: 53.48320388793945, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 269/10000, Training Loss: 96.3219985961914, Training Accuracy: 0.47058823529411764, Validation Loss: 22.937162399291992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 270/10000, Training Loss: 34.87181091308594, Training Accuracy: 0.5171568627450981, Validation Loss: 37.66449737548828, Validation Accuracy: 0.5\n",
      "Epoch 271/10000, Training Loss: 31.98406219482422, Training Accuracy: 0.5833333333333334, Validation Loss: 23.42436981201172, Validation Accuracy: 0.5\n",
      "Epoch 272/10000, Training Loss: 73.33565521240234, Training Accuracy: 0.5073529411764706, Validation Loss: 0.9376007914543152, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 273/10000, Training Loss: 13.7587308883667, Training Accuracy: 0.5220588235294118, Validation Loss: 0.6413455605506897, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 274/10000, Training Loss: 48.2320671081543, Training Accuracy: 0.5269607843137255, Validation Loss: 160.78738403320312, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 275/10000, Training Loss: 63.385982513427734, Training Accuracy: 0.5465686274509803, Validation Loss: 179.6398162841797, Validation Accuracy: 0.5\n",
      "Epoch 276/10000, Training Loss: 26.529449462890625, Training Accuracy: 0.5343137254901961, Validation Loss: 2.3897478580474854, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 277/10000, Training Loss: 45.016788482666016, Training Accuracy: 0.553921568627451, Validation Loss: 37.877628326416016, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 278/10000, Training Loss: 34.15530776977539, Training Accuracy: 0.5318627450980392, Validation Loss: 0.6357102394104004, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 279/10000, Training Loss: 39.204437255859375, Training Accuracy: 0.5735294117647058, Validation Loss: 50.72296142578125, Validation Accuracy: 0.75\n",
      "Epoch 280/10000, Training Loss: 40.16742706298828, Training Accuracy: 0.5196078431372549, Validation Loss: 60.91018295288086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 281/10000, Training Loss: 31.626909255981445, Training Accuracy: 0.5416666666666666, Validation Loss: 134.45167541503906, Validation Accuracy: 0.5\n",
      "Epoch 282/10000, Training Loss: 47.385711669921875, Training Accuracy: 0.5563725490196079, Validation Loss: 134.1360321044922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 283/10000, Training Loss: 68.8414535522461, Training Accuracy: 0.5563725490196079, Validation Loss: 14.260939598083496, Validation Accuracy: 0.5\n",
      "Epoch 284/10000, Training Loss: 32.94224548339844, Training Accuracy: 0.5735294117647058, Validation Loss: 65.01676940917969, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 285/10000, Training Loss: 30.839628219604492, Training Accuracy: 0.5465686274509803, Validation Loss: 21.27337646484375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 286/10000, Training Loss: 47.38649368286133, Training Accuracy: 0.5416666666666666, Validation Loss: 30.659269332885742, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 287/10000, Training Loss: 89.3282699584961, Training Accuracy: 0.553921568627451, Validation Loss: 207.27587890625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 288/10000, Training Loss: 99.3115234375, Training Accuracy: 0.4852941176470588, Validation Loss: 0.5314647555351257, Validation Accuracy: 0.75\n",
      "Epoch 289/10000, Training Loss: 10.431458473205566, Training Accuracy: 0.5, Validation Loss: 14.967209815979004, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 290/10000, Training Loss: 31.430831909179688, Training Accuracy: 0.5441176470588235, Validation Loss: 11.334202766418457, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 291/10000, Training Loss: 102.1214828491211, Training Accuracy: 0.5294117647058824, Validation Loss: 98.78449249267578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 292/10000, Training Loss: 73.54003143310547, Training Accuracy: 0.46568627450980393, Validation Loss: 167.52293395996094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 293/10000, Training Loss: 61.211875915527344, Training Accuracy: 0.5490196078431373, Validation Loss: 9.870128631591797, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 294/10000, Training Loss: 51.29267120361328, Training Accuracy: 0.5563725490196079, Validation Loss: 80.57048034667969, Validation Accuracy: 0.25\n",
      "Epoch 295/10000, Training Loss: 57.94245529174805, Training Accuracy: 0.4730392156862745, Validation Loss: 0.598417341709137, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 296/10000, Training Loss: 27.082538604736328, Training Accuracy: 0.6004901960784313, Validation Loss: 0.5987929105758667, Validation Accuracy: 0.75\n",
      "Epoch 297/10000, Training Loss: 34.640220642089844, Training Accuracy: 0.5294117647058824, Validation Loss: 23.855688095092773, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 298/10000, Training Loss: 44.69963455200195, Training Accuracy: 0.4852941176470588, Validation Loss: 11.515277862548828, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 299/10000, Training Loss: 27.895544052124023, Training Accuracy: 0.571078431372549, Validation Loss: 47.138004302978516, Validation Accuracy: 0.25\n",
      "Epoch 300/10000, Training Loss: 37.04491424560547, Training Accuracy: 0.4950980392156863, Validation Loss: 4.992335796356201, Validation Accuracy: 0.5\n",
      "Epoch 301/10000, Training Loss: 50.3109016418457, Training Accuracy: 0.5049019607843137, Validation Loss: 19.006383895874023, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 302/10000, Training Loss: 37.855167388916016, Training Accuracy: 0.5147058823529411, Validation Loss: 33.924903869628906, Validation Accuracy: 0.5\n",
      "Epoch 303/10000, Training Loss: 87.5010986328125, Training Accuracy: 0.5416666666666666, Validation Loss: 151.69175720214844, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 304/10000, Training Loss: 41.226314544677734, Training Accuracy: 0.5147058823529411, Validation Loss: 0.6288740038871765, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 305/10000, Training Loss: 97.46920013427734, Training Accuracy: 0.5196078431372549, Validation Loss: 58.00114440917969, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 306/10000, Training Loss: 24.84993553161621, Training Accuracy: 0.5294117647058824, Validation Loss: 54.1125602722168, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 307/10000, Training Loss: 35.892478942871094, Training Accuracy: 0.5147058823529411, Validation Loss: 3.3417508602142334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 308/10000, Training Loss: 19.54561996459961, Training Accuracy: 0.5514705882352942, Validation Loss: 58.329803466796875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 309/10000, Training Loss: 38.79762649536133, Training Accuracy: 0.5514705882352942, Validation Loss: 0.734187126159668, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 310/10000, Training Loss: 28.869300842285156, Training Accuracy: 0.4534313725490196, Validation Loss: 17.839811325073242, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 311/10000, Training Loss: 23.891563415527344, Training Accuracy: 0.5196078431372549, Validation Loss: 10.804577827453613, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 312/10000, Training Loss: 19.7009334564209, Training Accuracy: 0.5612745098039216, Validation Loss: 35.35598373413086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 313/10000, Training Loss: 101.3362045288086, Training Accuracy: 0.48284313725490197, Validation Loss: 23.70427703857422, Validation Accuracy: 0.5\n",
      "Epoch 314/10000, Training Loss: 68.70703125, Training Accuracy: 0.5465686274509803, Validation Loss: 217.6377410888672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 315/10000, Training Loss: 20.677989959716797, Training Accuracy: 0.49754901960784315, Validation Loss: 27.0190486907959, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 316/10000, Training Loss: 111.40850067138672, Training Accuracy: 0.5, Validation Loss: 114.88556671142578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 317/10000, Training Loss: 13.623003959655762, Training Accuracy: 0.5220588235294118, Validation Loss: 6.240790843963623, Validation Accuracy: 0.25\n",
      "Epoch 318/10000, Training Loss: 51.89984893798828, Training Accuracy: 0.5245098039215687, Validation Loss: 73.00390625, Validation Accuracy: 0.25\n",
      "Epoch 319/10000, Training Loss: 16.795085906982422, Training Accuracy: 0.5392156862745098, Validation Loss: 18.254045486450195, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 320/10000, Training Loss: 65.7508316040039, Training Accuracy: 0.5147058823529411, Validation Loss: 36.75738525390625, Validation Accuracy: 0.5\n",
      "Epoch 321/10000, Training Loss: 53.19080352783203, Training Accuracy: 0.5171568627450981, Validation Loss: 62.845218658447266, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 322/10000, Training Loss: 30.09072494506836, Training Accuracy: 0.5073529411764706, Validation Loss: 3.5129287242889404, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 323/10000, Training Loss: 24.13149642944336, Training Accuracy: 0.5122549019607843, Validation Loss: 11.32779312133789, Validation Accuracy: 0.25\n",
      "Epoch 324/10000, Training Loss: 33.04754638671875, Training Accuracy: 0.5294117647058824, Validation Loss: 34.381141662597656, Validation Accuracy: 0.25\n",
      "Epoch 325/10000, Training Loss: 55.97710418701172, Training Accuracy: 0.5588235294117647, Validation Loss: 72.0735092163086, Validation Accuracy: 0.5\n",
      "Epoch 326/10000, Training Loss: 13.658271789550781, Training Accuracy: 0.5122549019607843, Validation Loss: 29.37415313720703, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 327/10000, Training Loss: 62.092796325683594, Training Accuracy: 0.47549019607843135, Validation Loss: 7.960381984710693, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 328/10000, Training Loss: 10.7567720413208, Training Accuracy: 0.5588235294117647, Validation Loss: 20.75953483581543, Validation Accuracy: 0.5\n",
      "Epoch 329/10000, Training Loss: 38.58729553222656, Training Accuracy: 0.5637254901960784, Validation Loss: 72.419677734375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 330/10000, Training Loss: 51.357303619384766, Training Accuracy: 0.5147058823529411, Validation Loss: 31.02159881591797, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 331/10000, Training Loss: 24.957395553588867, Training Accuracy: 0.5171568627450981, Validation Loss: 0.5484562516212463, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 332/10000, Training Loss: 62.04435729980469, Training Accuracy: 0.5318627450980392, Validation Loss: 51.03465270996094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 333/10000, Training Loss: 34.18441390991211, Training Accuracy: 0.49754901960784315, Validation Loss: 1.5045342445373535, Validation Accuracy: 0.5\n",
      "Epoch 334/10000, Training Loss: 20.638748168945312, Training Accuracy: 0.46078431372549017, Validation Loss: 46.89426040649414, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 335/10000, Training Loss: 24.761259078979492, Training Accuracy: 0.5073529411764706, Validation Loss: 0.5260744094848633, Validation Accuracy: 0.75\n",
      "Epoch 336/10000, Training Loss: 40.94075012207031, Training Accuracy: 0.5367647058823529, Validation Loss: 5.108275890350342, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 337/10000, Training Loss: 80.37025451660156, Training Accuracy: 0.5514705882352942, Validation Loss: 68.81755065917969, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 338/10000, Training Loss: 32.15803146362305, Training Accuracy: 0.49754901960784315, Validation Loss: 6.655371189117432, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 339/10000, Training Loss: 28.837146759033203, Training Accuracy: 0.5343137254901961, Validation Loss: 34.67550277709961, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 340/10000, Training Loss: 31.169328689575195, Training Accuracy: 0.5147058823529411, Validation Loss: 61.18502426147461, Validation Accuracy: 0.25\n",
      "Epoch 341/10000, Training Loss: 8.429996490478516, Training Accuracy: 0.5196078431372549, Validation Loss: 0.47625604271888733, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 342/10000, Training Loss: 39.393882751464844, Training Accuracy: 0.5318627450980392, Validation Loss: 32.67265319824219, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 343/10000, Training Loss: 41.70769119262695, Training Accuracy: 0.5416666666666666, Validation Loss: 9.99084186553955, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 344/10000, Training Loss: 37.22745895385742, Training Accuracy: 0.5759803921568627, Validation Loss: 47.955474853515625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 345/10000, Training Loss: 60.490699768066406, Training Accuracy: 0.5759803921568627, Validation Loss: 0.3957204520702362, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 346/10000, Training Loss: 44.19353103637695, Training Accuracy: 0.5, Validation Loss: 242.96311950683594, Validation Accuracy: 0.5\n",
      "Epoch 347/10000, Training Loss: 24.377517700195312, Training Accuracy: 0.5220588235294118, Validation Loss: 15.541243553161621, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 348/10000, Training Loss: 27.03572654724121, Training Accuracy: 0.5269607843137255, Validation Loss: 11.865486145019531, Validation Accuracy: 0.5\n",
      "Epoch 349/10000, Training Loss: 48.394996643066406, Training Accuracy: 0.5735294117647058, Validation Loss: 81.5037612915039, Validation Accuracy: 0.5\n",
      "Epoch 350/10000, Training Loss: 179.48487854003906, Training Accuracy: 0.5808823529411765, Validation Loss: 45.25446701049805, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 351/10000, Training Loss: 36.242916107177734, Training Accuracy: 0.571078431372549, Validation Loss: 13.691058158874512, Validation Accuracy: 0.5\n",
      "Epoch 352/10000, Training Loss: 83.29207611083984, Training Accuracy: 0.5637254901960784, Validation Loss: 94.01797485351562, Validation Accuracy: 0.25\n",
      "Epoch 353/10000, Training Loss: 14.612007141113281, Training Accuracy: 0.5171568627450981, Validation Loss: 5.69386100769043, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 354/10000, Training Loss: 38.73005294799805, Training Accuracy: 0.5171568627450981, Validation Loss: 0.6881207823753357, Validation Accuracy: 0.5\n",
      "Epoch 355/10000, Training Loss: 56.81987380981445, Training Accuracy: 0.4803921568627451, Validation Loss: 13.351055145263672, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 356/10000, Training Loss: 20.76226043701172, Training Accuracy: 0.5343137254901961, Validation Loss: 6.849863529205322, Validation Accuracy: 0.5\n",
      "Epoch 357/10000, Training Loss: 27.65628433227539, Training Accuracy: 0.5220588235294118, Validation Loss: 53.06979751586914, Validation Accuracy: 0.25\n",
      "Epoch 358/10000, Training Loss: 58.4892463684082, Training Accuracy: 0.5808823529411765, Validation Loss: 62.01045227050781, Validation Accuracy: 0.5\n",
      "Epoch 359/10000, Training Loss: 62.689796447753906, Training Accuracy: 0.5098039215686274, Validation Loss: 61.27199172973633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 360/10000, Training Loss: 28.438779830932617, Training Accuracy: 0.5220588235294118, Validation Loss: 9.736642837524414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 361/10000, Training Loss: 33.590213775634766, Training Accuracy: 0.5416666666666666, Validation Loss: 39.905696868896484, Validation Accuracy: 0.5\n",
      "Epoch 362/10000, Training Loss: 50.98029327392578, Training Accuracy: 0.4950980392156863, Validation Loss: 8.030070304870605, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 363/10000, Training Loss: 30.863523483276367, Training Accuracy: 0.5024509803921569, Validation Loss: 16.736215591430664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 364/10000, Training Loss: 43.103302001953125, Training Accuracy: 0.5171568627450981, Validation Loss: 17.111637115478516, Validation Accuracy: 0.25\n",
      "Epoch 365/10000, Training Loss: 45.57908248901367, Training Accuracy: 0.553921568627451, Validation Loss: 28.563011169433594, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 366/10000, Training Loss: 72.4731674194336, Training Accuracy: 0.5294117647058824, Validation Loss: 120.2559585571289, Validation Accuracy: 0.25\n",
      "Epoch 367/10000, Training Loss: 33.4187126159668, Training Accuracy: 0.5857843137254902, Validation Loss: 54.30022048950195, Validation Accuracy: 0.5\n",
      "Epoch 368/10000, Training Loss: 24.552915573120117, Training Accuracy: 0.5196078431372549, Validation Loss: 5.3437819480896, Validation Accuracy: 0.5\n",
      "Epoch 369/10000, Training Loss: 39.56827926635742, Training Accuracy: 0.5784313725490197, Validation Loss: 89.08319091796875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 370/10000, Training Loss: 46.07177734375, Training Accuracy: 0.5245098039215687, Validation Loss: 19.21569061279297, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 371/10000, Training Loss: 71.42689514160156, Training Accuracy: 0.5416666666666666, Validation Loss: 14.366180419921875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 372/10000, Training Loss: 87.6888656616211, Training Accuracy: 0.5367647058823529, Validation Loss: 136.21385192871094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 373/10000, Training Loss: 71.09288024902344, Training Accuracy: 0.5882352941176471, Validation Loss: 98.45877075195312, Validation Accuracy: 0.5\n",
      "Epoch 374/10000, Training Loss: 74.09210205078125, Training Accuracy: 0.5147058823529411, Validation Loss: 56.39589309692383, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 375/10000, Training Loss: 51.68096923828125, Training Accuracy: 0.5049019607843137, Validation Loss: 26.495574951171875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 376/10000, Training Loss: 62.373321533203125, Training Accuracy: 0.5147058823529411, Validation Loss: 58.09084701538086, Validation Accuracy: 0.75\n",
      "Epoch 377/10000, Training Loss: 30.11049461364746, Training Accuracy: 0.5857843137254902, Validation Loss: 0.3920498788356781, Validation Accuracy: 0.75\n",
      "Epoch 378/10000, Training Loss: 61.41155242919922, Training Accuracy: 0.5392156862745098, Validation Loss: 70.71163177490234, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 379/10000, Training Loss: 10.682439804077148, Training Accuracy: 0.5049019607843137, Validation Loss: 24.614532470703125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 380/10000, Training Loss: 44.10821533203125, Training Accuracy: 0.47058823529411764, Validation Loss: 10.342857360839844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 381/10000, Training Loss: 37.51749801635742, Training Accuracy: 0.4534313725490196, Validation Loss: 40.16755676269531, Validation Accuracy: 0.5\n",
      "Epoch 382/10000, Training Loss: 48.961151123046875, Training Accuracy: 0.5122549019607843, Validation Loss: 46.476444244384766, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 383/10000, Training Loss: 64.36012268066406, Training Accuracy: 0.4877450980392157, Validation Loss: 11.719807624816895, Validation Accuracy: 0.5\n",
      "Epoch 384/10000, Training Loss: 110.3099365234375, Training Accuracy: 0.47549019607843135, Validation Loss: 565.3953857421875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 385/10000, Training Loss: 36.33692932128906, Training Accuracy: 0.5661764705882353, Validation Loss: 44.32795715332031, Validation Accuracy: 0.5\n",
      "Epoch 386/10000, Training Loss: 22.116453170776367, Training Accuracy: 0.5416666666666666, Validation Loss: 20.800443649291992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 387/10000, Training Loss: 32.37309646606445, Training Accuracy: 0.49019607843137253, Validation Loss: 50.72369384765625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 388/10000, Training Loss: 24.507278442382812, Training Accuracy: 0.6568627450980392, Validation Loss: 39.49979019165039, Validation Accuracy: 0.25\n",
      "Epoch 389/10000, Training Loss: 41.39445495605469, Training Accuracy: 0.5269607843137255, Validation Loss: 12.905320167541504, Validation Accuracy: 0.5\n",
      "Epoch 390/10000, Training Loss: 67.60151672363281, Training Accuracy: 0.4950980392156863, Validation Loss: 15.112338066101074, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 391/10000, Training Loss: 11.298056602478027, Training Accuracy: 0.5980392156862745, Validation Loss: 12.82235336303711, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 392/10000, Training Loss: 41.62956619262695, Training Accuracy: 0.5073529411764706, Validation Loss: 80.29574584960938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 393/10000, Training Loss: 45.833290100097656, Training Accuracy: 0.5196078431372549, Validation Loss: 19.285669326782227, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 394/10000, Training Loss: 39.321807861328125, Training Accuracy: 0.5122549019607843, Validation Loss: 70.74725341796875, Validation Accuracy: 0.5\n",
      "Epoch 395/10000, Training Loss: 12.633318901062012, Training Accuracy: 0.5808823529411765, Validation Loss: 0.5487415790557861, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 396/10000, Training Loss: 60.3414192199707, Training Accuracy: 0.5343137254901961, Validation Loss: 185.4136199951172, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 397/10000, Training Loss: 49.89566421508789, Training Accuracy: 0.5759803921568627, Validation Loss: 26.196365356445312, Validation Accuracy: 0.25\n",
      "Epoch 398/10000, Training Loss: 15.654912948608398, Training Accuracy: 0.5367647058823529, Validation Loss: 4.858180999755859, Validation Accuracy: 0.5\n",
      "Epoch 399/10000, Training Loss: 32.120845794677734, Training Accuracy: 0.4632352941176471, Validation Loss: 25.847511291503906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 400/10000, Training Loss: 13.773502349853516, Training Accuracy: 0.5588235294117647, Validation Loss: 7.520237445831299, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 401/10000, Training Loss: 34.849483489990234, Training Accuracy: 0.5931372549019608, Validation Loss: 69.67571258544922, Validation Accuracy: 0.25\n",
      "Epoch 402/10000, Training Loss: 28.851625442504883, Training Accuracy: 0.5661764705882353, Validation Loss: 34.71037673950195, Validation Accuracy: 0.25\n",
      "Epoch 403/10000, Training Loss: 61.973514556884766, Training Accuracy: 0.5171568627450981, Validation Loss: 21.651268005371094, Validation Accuracy: 0.5\n",
      "Epoch 404/10000, Training Loss: 48.952606201171875, Training Accuracy: 0.5098039215686274, Validation Loss: 19.804039001464844, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 405/10000, Training Loss: 14.29585075378418, Training Accuracy: 0.5955882352941176, Validation Loss: 83.5447769165039, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 406/10000, Training Loss: 27.460540771484375, Training Accuracy: 0.5857843137254902, Validation Loss: 8.655083656311035, Validation Accuracy: 0.5\n",
      "Epoch 407/10000, Training Loss: 32.95838928222656, Training Accuracy: 0.5563725490196079, Validation Loss: 35.96073532104492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 408/10000, Training Loss: 30.57452964782715, Training Accuracy: 0.5490196078431373, Validation Loss: 68.61500549316406, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 409/10000, Training Loss: 19.118322372436523, Training Accuracy: 0.5416666666666666, Validation Loss: 6.925582408905029, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 410/10000, Training Loss: 69.49374389648438, Training Accuracy: 0.553921568627451, Validation Loss: 7.156096935272217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 411/10000, Training Loss: 81.5284194946289, Training Accuracy: 0.4852941176470588, Validation Loss: 31.913969039916992, Validation Accuracy: 0.25\n",
      "Epoch 412/10000, Training Loss: 76.31767272949219, Training Accuracy: 0.5343137254901961, Validation Loss: 62.01609802246094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 413/10000, Training Loss: 35.798892974853516, Training Accuracy: 0.4681372549019608, Validation Loss: 21.24842643737793, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 414/10000, Training Loss: 37.5466194152832, Training Accuracy: 0.5294117647058824, Validation Loss: 150.9182891845703, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 415/10000, Training Loss: 37.12308883666992, Training Accuracy: 0.5392156862745098, Validation Loss: 21.17363166809082, Validation Accuracy: 0.25\n",
      "Epoch 416/10000, Training Loss: 6.342324733734131, Training Accuracy: 0.5759803921568627, Validation Loss: 1.400288701057434, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 417/10000, Training Loss: 17.16543960571289, Training Accuracy: 0.44607843137254904, Validation Loss: 4.0187249183654785, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 418/10000, Training Loss: 53.48274612426758, Training Accuracy: 0.48284313725490197, Validation Loss: 29.444717407226562, Validation Accuracy: 0.75\n",
      "Epoch 419/10000, Training Loss: 36.29867172241211, Training Accuracy: 0.5318627450980392, Validation Loss: 48.363399505615234, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 420/10000, Training Loss: 54.7079963684082, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7527279257774353, Validation Accuracy: 0.5\n",
      "Epoch 421/10000, Training Loss: 27.86632537841797, Training Accuracy: 0.5196078431372549, Validation Loss: 24.380868911743164, Validation Accuracy: 0.5\n",
      "Epoch 422/10000, Training Loss: 37.84321975708008, Training Accuracy: 0.5980392156862745, Validation Loss: 174.27259826660156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 423/10000, Training Loss: 12.872872352600098, Training Accuracy: 0.5318627450980392, Validation Loss: 55.92402648925781, Validation Accuracy: 0.75\n",
      "Epoch 424/10000, Training Loss: 88.42227935791016, Training Accuracy: 0.5441176470588235, Validation Loss: 149.246337890625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 425/10000, Training Loss: 31.3232479095459, Training Accuracy: 0.5049019607843137, Validation Loss: 10.999783515930176, Validation Accuracy: 0.5\n",
      "Epoch 426/10000, Training Loss: 14.96649169921875, Training Accuracy: 0.5122549019607843, Validation Loss: 6.2594475746154785, Validation Accuracy: 0.75\n",
      "Epoch 427/10000, Training Loss: 36.43980407714844, Training Accuracy: 0.5196078431372549, Validation Loss: 18.820451736450195, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 428/10000, Training Loss: 53.12932205200195, Training Accuracy: 0.5147058823529411, Validation Loss: 87.4166030883789, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 429/10000, Training Loss: 25.906248092651367, Training Accuracy: 0.4950980392156863, Validation Loss: 12.215709686279297, Validation Accuracy: 0.25\n",
      "Epoch 430/10000, Training Loss: 25.179737091064453, Training Accuracy: 0.6029411764705882, Validation Loss: 22.487272262573242, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 431/10000, Training Loss: 19.714035034179688, Training Accuracy: 0.6200980392156863, Validation Loss: 52.61451721191406, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 432/10000, Training Loss: 14.654476165771484, Training Accuracy: 0.4730392156862745, Validation Loss: 1.3591227531433105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 433/10000, Training Loss: 50.203277587890625, Training Accuracy: 0.5220588235294118, Validation Loss: 83.23410034179688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 434/10000, Training Loss: 45.38462829589844, Training Accuracy: 0.5392156862745098, Validation Loss: 1.6515742540359497, Validation Accuracy: 0.5\n",
      "Epoch 435/10000, Training Loss: 63.142967224121094, Training Accuracy: 0.5955882352941176, Validation Loss: 1.6709446907043457, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 436/10000, Training Loss: 18.699024200439453, Training Accuracy: 0.5465686274509803, Validation Loss: 232.70867919921875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 437/10000, Training Loss: 28.82579803466797, Training Accuracy: 0.5833333333333334, Validation Loss: 57.082157135009766, Validation Accuracy: 0.25\n",
      "Epoch 438/10000, Training Loss: 22.079376220703125, Training Accuracy: 0.5833333333333334, Validation Loss: 2.8097410202026367, Validation Accuracy: 0.5\n",
      "Epoch 439/10000, Training Loss: 53.84283447265625, Training Accuracy: 0.5294117647058824, Validation Loss: 2.2164902687072754, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 440/10000, Training Loss: 28.55535316467285, Training Accuracy: 0.49754901960784315, Validation Loss: 2.919335126876831, Validation Accuracy: 0.75\n",
      "Epoch 441/10000, Training Loss: 22.357311248779297, Training Accuracy: 0.571078431372549, Validation Loss: 3.5646636486053467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 442/10000, Training Loss: 59.382179260253906, Training Accuracy: 0.5490196078431373, Validation Loss: 39.34660720825195, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 443/10000, Training Loss: 24.5819034576416, Training Accuracy: 0.553921568627451, Validation Loss: 22.268484115600586, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 444/10000, Training Loss: 23.071645736694336, Training Accuracy: 0.5612745098039216, Validation Loss: 9.31025218963623, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 445/10000, Training Loss: 8.872359275817871, Training Accuracy: 0.49264705882352944, Validation Loss: 32.14369201660156, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 446/10000, Training Loss: 32.424381256103516, Training Accuracy: 0.49019607843137253, Validation Loss: 39.453922271728516, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 447/10000, Training Loss: 23.285541534423828, Training Accuracy: 0.5784313725490197, Validation Loss: 5.028443336486816, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 448/10000, Training Loss: 17.591238021850586, Training Accuracy: 0.5735294117647058, Validation Loss: 12.588324546813965, Validation Accuracy: 0.5\n",
      "Epoch 449/10000, Training Loss: 36.78135681152344, Training Accuracy: 0.5171568627450981, Validation Loss: 24.753530502319336, Validation Accuracy: 0.5\n",
      "Epoch 450/10000, Training Loss: 27.64665412902832, Training Accuracy: 0.5073529411764706, Validation Loss: 17.521081924438477, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 451/10000, Training Loss: 75.23440551757812, Training Accuracy: 0.5, Validation Loss: 63.678707122802734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 452/10000, Training Loss: 40.49850082397461, Training Accuracy: 0.5318627450980392, Validation Loss: 4.947070598602295, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 453/10000, Training Loss: 14.33643913269043, Training Accuracy: 0.5220588235294118, Validation Loss: 15.532793998718262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 454/10000, Training Loss: 41.847225189208984, Training Accuracy: 0.4411764705882353, Validation Loss: 28.996339797973633, Validation Accuracy: 0.5\n",
      "Epoch 455/10000, Training Loss: 22.974668502807617, Training Accuracy: 0.5196078431372549, Validation Loss: 9.43698787689209, Validation Accuracy: 0.5\n",
      "Epoch 456/10000, Training Loss: 33.386138916015625, Training Accuracy: 0.5343137254901961, Validation Loss: 21.147958755493164, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 457/10000, Training Loss: 25.776744842529297, Training Accuracy: 0.6078431372549019, Validation Loss: 28.556886672973633, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 458/10000, Training Loss: 17.72260093688965, Training Accuracy: 0.5686274509803921, Validation Loss: 9.446249961853027, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 459/10000, Training Loss: 86.34310150146484, Training Accuracy: 0.5392156862745098, Validation Loss: 77.14226531982422, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 460/10000, Training Loss: 14.244390487670898, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8725994229316711, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 461/10000, Training Loss: 38.14664077758789, Training Accuracy: 0.5196078431372549, Validation Loss: 33.08815002441406, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 462/10000, Training Loss: 10.194108963012695, Training Accuracy: 0.5196078431372549, Validation Loss: 10.39461612701416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 463/10000, Training Loss: 63.785099029541016, Training Accuracy: 0.5073529411764706, Validation Loss: 13.166706085205078, Validation Accuracy: 0.5\n",
      "Epoch 464/10000, Training Loss: 9.97586727142334, Training Accuracy: 0.5759803921568627, Validation Loss: 5.986653804779053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 465/10000, Training Loss: 49.549461364746094, Training Accuracy: 0.5612745098039216, Validation Loss: 133.6269073486328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 466/10000, Training Loss: 23.749004364013672, Training Accuracy: 0.5122549019607843, Validation Loss: 7.097709655761719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 467/10000, Training Loss: 24.098344802856445, Training Accuracy: 0.5465686274509803, Validation Loss: 48.383182525634766, Validation Accuracy: 0.5\n",
      "Epoch 468/10000, Training Loss: 29.57672691345215, Training Accuracy: 0.5318627450980392, Validation Loss: 16.87407112121582, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 469/10000, Training Loss: 81.9808349609375, Training Accuracy: 0.553921568627451, Validation Loss: 71.77239227294922, Validation Accuracy: 0.25\n",
      "Epoch 470/10000, Training Loss: 24.08694839477539, Training Accuracy: 0.5392156862745098, Validation Loss: 16.58725929260254, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 471/10000, Training Loss: 29.51321029663086, Training Accuracy: 0.47058823529411764, Validation Loss: 62.4970703125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 472/10000, Training Loss: 39.65854263305664, Training Accuracy: 0.5588235294117647, Validation Loss: 0.612518310546875, Validation Accuracy: 0.5\n",
      "Epoch 473/10000, Training Loss: 14.419289588928223, Training Accuracy: 0.47549019607843135, Validation Loss: 6.553271770477295, Validation Accuracy: 0.25\n",
      "Epoch 474/10000, Training Loss: 13.44796085357666, Training Accuracy: 0.5343137254901961, Validation Loss: 2.163395881652832, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 475/10000, Training Loss: 43.12994384765625, Training Accuracy: 0.5392156862745098, Validation Loss: 107.25943756103516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 476/10000, Training Loss: 56.632450103759766, Training Accuracy: 0.5637254901960784, Validation Loss: 187.6457061767578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 477/10000, Training Loss: 19.293960571289062, Training Accuracy: 0.5245098039215687, Validation Loss: 112.41632080078125, Validation Accuracy: 0.25\n",
      "Epoch 478/10000, Training Loss: 20.501953125, Training Accuracy: 0.49754901960784315, Validation Loss: 1.4099589586257935, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 479/10000, Training Loss: 14.785550117492676, Training Accuracy: 0.6176470588235294, Validation Loss: 16.18486213684082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 480/10000, Training Loss: 56.27337646484375, Training Accuracy: 0.5637254901960784, Validation Loss: 52.31645584106445, Validation Accuracy: 0.5\n",
      "Epoch 481/10000, Training Loss: 17.985315322875977, Training Accuracy: 0.5661764705882353, Validation Loss: 28.936691284179688, Validation Accuracy: 0.5\n",
      "Epoch 482/10000, Training Loss: 20.67751121520996, Training Accuracy: 0.5563725490196079, Validation Loss: 29.9564208984375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 483/10000, Training Loss: 50.7729377746582, Training Accuracy: 0.6078431372549019, Validation Loss: 15.519886016845703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 484/10000, Training Loss: 24.228456497192383, Training Accuracy: 0.5343137254901961, Validation Loss: 8.28411865234375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 485/10000, Training Loss: 67.08792877197266, Training Accuracy: 0.5, Validation Loss: 22.00065803527832, Validation Accuracy: 0.5\n",
      "Epoch 486/10000, Training Loss: 149.23765563964844, Training Accuracy: 0.5735294117647058, Validation Loss: 8.953346252441406, Validation Accuracy: 0.5\n",
      "Epoch 487/10000, Training Loss: 41.95503616333008, Training Accuracy: 0.5294117647058824, Validation Loss: 144.88499450683594, Validation Accuracy: 0.5\n",
      "Epoch 488/10000, Training Loss: 57.45218276977539, Training Accuracy: 0.5441176470588235, Validation Loss: 16.829896926879883, Validation Accuracy: 0.5\n",
      "Epoch 489/10000, Training Loss: 49.78302764892578, Training Accuracy: 0.571078431372549, Validation Loss: 194.9064483642578, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 490/10000, Training Loss: 21.63355255126953, Training Accuracy: 0.5416666666666666, Validation Loss: 120.02845001220703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 491/10000, Training Loss: 49.96514129638672, Training Accuracy: 0.5269607843137255, Validation Loss: 77.59053802490234, Validation Accuracy: 0.5\n",
      "Epoch 492/10000, Training Loss: 6.38547945022583, Training Accuracy: 0.5318627450980392, Validation Loss: 2.805911064147949, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 493/10000, Training Loss: 24.809110641479492, Training Accuracy: 0.5588235294117647, Validation Loss: 17.1092472076416, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 494/10000, Training Loss: 62.5141487121582, Training Accuracy: 0.5147058823529411, Validation Loss: 72.2083740234375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 495/10000, Training Loss: 25.4334774017334, Training Accuracy: 0.49754901960784315, Validation Loss: 0.8059527277946472, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 496/10000, Training Loss: 48.55466842651367, Training Accuracy: 0.5612745098039216, Validation Loss: 51.15512466430664, Validation Accuracy: 0.5\n",
      "Epoch 497/10000, Training Loss: 32.287845611572266, Training Accuracy: 0.6004901960784313, Validation Loss: 52.05631637573242, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 498/10000, Training Loss: 50.08591842651367, Training Accuracy: 0.5465686274509803, Validation Loss: 10.372310638427734, Validation Accuracy: 0.5\n",
      "Epoch 499/10000, Training Loss: 27.21410369873047, Training Accuracy: 0.5735294117647058, Validation Loss: 17.652254104614258, Validation Accuracy: 0.75\n",
      "Epoch 500/10000, Training Loss: 23.35303497314453, Training Accuracy: 0.5637254901960784, Validation Loss: 22.549530029296875, Validation Accuracy: 0.25\n",
      "Epoch 501/10000, Training Loss: 22.02141761779785, Training Accuracy: 0.5735294117647058, Validation Loss: 20.356895446777344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 502/10000, Training Loss: 46.67262268066406, Training Accuracy: 0.5637254901960784, Validation Loss: 15.240477561950684, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 503/10000, Training Loss: 22.299861907958984, Training Accuracy: 0.5343137254901961, Validation Loss: 4.500046730041504, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 504/10000, Training Loss: 89.15785217285156, Training Accuracy: 0.5269607843137255, Validation Loss: 43.40401840209961, Validation Accuracy: 0.5\n",
      "Epoch 505/10000, Training Loss: 33.68211364746094, Training Accuracy: 0.6029411764705882, Validation Loss: 36.82062530517578, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 506/10000, Training Loss: 55.58979415893555, Training Accuracy: 0.5563725490196079, Validation Loss: 27.35279083251953, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 507/10000, Training Loss: 15.417231559753418, Training Accuracy: 0.6029411764705882, Validation Loss: 5.268286228179932, Validation Accuracy: 0.5\n",
      "Epoch 508/10000, Training Loss: 46.27193069458008, Training Accuracy: 0.5049019607843137, Validation Loss: 28.902572631835938, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 509/10000, Training Loss: 37.196414947509766, Training Accuracy: 0.5318627450980392, Validation Loss: 10.057690620422363, Validation Accuracy: 0.5\n",
      "Epoch 510/10000, Training Loss: 35.39207077026367, Training Accuracy: 0.5416666666666666, Validation Loss: 7.1938910484313965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 511/10000, Training Loss: 40.375205993652344, Training Accuracy: 0.5612745098039216, Validation Loss: 20.873674392700195, Validation Accuracy: 0.5\n",
      "Epoch 512/10000, Training Loss: 22.226768493652344, Training Accuracy: 0.5612745098039216, Validation Loss: 56.51362991333008, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 513/10000, Training Loss: 36.091651916503906, Training Accuracy: 0.5392156862745098, Validation Loss: 48.21481704711914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 514/10000, Training Loss: 29.731035232543945, Training Accuracy: 0.47058823529411764, Validation Loss: 69.08919525146484, Validation Accuracy: 0.5\n",
      "Epoch 515/10000, Training Loss: 31.722917556762695, Training Accuracy: 0.5024509803921569, Validation Loss: 5.986353397369385, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 516/10000, Training Loss: 39.0800666809082, Training Accuracy: 0.5735294117647058, Validation Loss: 8.683784484863281, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 517/10000, Training Loss: 47.291839599609375, Training Accuracy: 0.5367647058823529, Validation Loss: 8.376498222351074, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 518/10000, Training Loss: 22.579145431518555, Training Accuracy: 0.5122549019607843, Validation Loss: 25.508630752563477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 519/10000, Training Loss: 20.038068771362305, Training Accuracy: 0.4534313725490196, Validation Loss: 15.549372673034668, Validation Accuracy: 0.5\n",
      "Epoch 520/10000, Training Loss: 61.32207107543945, Training Accuracy: 0.5049019607843137, Validation Loss: 2.910602569580078, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 521/10000, Training Loss: 17.4167423248291, Training Accuracy: 0.49264705882352944, Validation Loss: 27.718673706054688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 522/10000, Training Loss: 30.289661407470703, Training Accuracy: 0.5514705882352942, Validation Loss: 11.145174980163574, Validation Accuracy: 0.5\n",
      "Epoch 523/10000, Training Loss: 19.217147827148438, Training Accuracy: 0.49019607843137253, Validation Loss: 0.493054062128067, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 524/10000, Training Loss: 35.63005828857422, Training Accuracy: 0.5465686274509803, Validation Loss: 23.44142723083496, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 525/10000, Training Loss: 12.737393379211426, Training Accuracy: 0.5906862745098039, Validation Loss: 31.916540145874023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 526/10000, Training Loss: 27.75857162475586, Training Accuracy: 0.5269607843137255, Validation Loss: 0.991656482219696, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 527/10000, Training Loss: 42.5970344543457, Training Accuracy: 0.5588235294117647, Validation Loss: 1.8259979486465454, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 528/10000, Training Loss: 40.506317138671875, Training Accuracy: 0.5906862745098039, Validation Loss: 147.0286407470703, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 529/10000, Training Loss: 32.59568786621094, Training Accuracy: 0.49754901960784315, Validation Loss: 27.00425910949707, Validation Accuracy: 0.5\n",
      "Epoch 530/10000, Training Loss: 55.35330581665039, Training Accuracy: 0.5098039215686274, Validation Loss: 40.717613220214844, Validation Accuracy: 0.5\n",
      "Epoch 531/10000, Training Loss: 23.322052001953125, Training Accuracy: 0.6151960784313726, Validation Loss: 73.63956451416016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 532/10000, Training Loss: 32.207298278808594, Training Accuracy: 0.4950980392156863, Validation Loss: 50.19148635864258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 533/10000, Training Loss: 6.940948486328125, Training Accuracy: 0.5367647058823529, Validation Loss: 49.405696868896484, Validation Accuracy: 0.25\n",
      "Epoch 534/10000, Training Loss: 28.09067153930664, Training Accuracy: 0.5220588235294118, Validation Loss: 20.149518966674805, Validation Accuracy: 0.25\n",
      "Epoch 535/10000, Training Loss: 32.51893615722656, Training Accuracy: 0.5220588235294118, Validation Loss: 56.86209487915039, Validation Accuracy: 0.5\n",
      "Epoch 536/10000, Training Loss: 67.54564666748047, Training Accuracy: 0.5490196078431373, Validation Loss: 43.5951042175293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 537/10000, Training Loss: 17.537084579467773, Training Accuracy: 0.5490196078431373, Validation Loss: 95.99020385742188, Validation Accuracy: 0.5\n",
      "Epoch 538/10000, Training Loss: 99.55535888671875, Training Accuracy: 0.5024509803921569, Validation Loss: 47.760799407958984, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 539/10000, Training Loss: 20.82761001586914, Training Accuracy: 0.5833333333333334, Validation Loss: 9.845768928527832, Validation Accuracy: 0.25\n",
      "Epoch 540/10000, Training Loss: 27.25249671936035, Training Accuracy: 0.48284313725490197, Validation Loss: 23.100311279296875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 541/10000, Training Loss: 7.682344436645508, Training Accuracy: 0.5661764705882353, Validation Loss: 6.847374439239502, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 542/10000, Training Loss: 33.586307525634766, Training Accuracy: 0.5049019607843137, Validation Loss: 9.476146697998047, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 543/10000, Training Loss: 17.025800704956055, Training Accuracy: 0.5245098039215687, Validation Loss: 5.135395050048828, Validation Accuracy: 0.5\n",
      "Epoch 544/10000, Training Loss: 10.92243766784668, Training Accuracy: 0.5318627450980392, Validation Loss: 7.653613567352295, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 545/10000, Training Loss: 14.981998443603516, Training Accuracy: 0.49754901960784315, Validation Loss: 14.326507568359375, Validation Accuracy: 0.5\n",
      "Epoch 546/10000, Training Loss: 16.715499877929688, Training Accuracy: 0.5931372549019608, Validation Loss: 10.595547676086426, Validation Accuracy: 0.5\n",
      "Epoch 547/10000, Training Loss: 31.671743392944336, Training Accuracy: 0.5784313725490197, Validation Loss: 20.053430557250977, Validation Accuracy: 0.25\n",
      "Epoch 548/10000, Training Loss: 25.70920753479004, Training Accuracy: 0.5931372549019608, Validation Loss: 120.33483123779297, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 549/10000, Training Loss: 23.42330551147461, Training Accuracy: 0.5171568627450981, Validation Loss: 4.935429096221924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 550/10000, Training Loss: 33.23020935058594, Training Accuracy: 0.5294117647058824, Validation Loss: 9.467432022094727, Validation Accuracy: 0.5\n",
      "Epoch 551/10000, Training Loss: 12.212364196777344, Training Accuracy: 0.5049019607843137, Validation Loss: 11.945960998535156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 552/10000, Training Loss: 55.056678771972656, Training Accuracy: 0.5637254901960784, Validation Loss: 42.18729782104492, Validation Accuracy: 0.5\n",
      "Epoch 553/10000, Training Loss: 48.607662200927734, Training Accuracy: 0.5245098039215687, Validation Loss: 77.89954376220703, Validation Accuracy: 0.5\n",
      "Epoch 554/10000, Training Loss: 26.128400802612305, Training Accuracy: 0.5122549019607843, Validation Loss: 72.51715850830078, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 555/10000, Training Loss: 21.516576766967773, Training Accuracy: 0.6078431372549019, Validation Loss: 4.49424934387207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 556/10000, Training Loss: 27.59547996520996, Training Accuracy: 0.5318627450980392, Validation Loss: 13.754591941833496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 557/10000, Training Loss: 29.74277687072754, Training Accuracy: 0.49264705882352944, Validation Loss: 6.62995719909668, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 558/10000, Training Loss: 25.667552947998047, Training Accuracy: 0.5759803921568627, Validation Loss: 94.51580810546875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 559/10000, Training Loss: 16.628501892089844, Training Accuracy: 0.5269607843137255, Validation Loss: 19.606948852539062, Validation Accuracy: 0.5\n",
      "Epoch 560/10000, Training Loss: 39.81405258178711, Training Accuracy: 0.5, Validation Loss: 1.4854539632797241, Validation Accuracy: 0.25\n",
      "Epoch 561/10000, Training Loss: 43.958160400390625, Training Accuracy: 0.5955882352941176, Validation Loss: 47.149322509765625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 562/10000, Training Loss: 22.07442855834961, Training Accuracy: 0.5588235294117647, Validation Loss: 55.8067626953125, Validation Accuracy: 0.5\n",
      "Epoch 563/10000, Training Loss: 31.40619468688965, Training Accuracy: 0.47794117647058826, Validation Loss: 28.945770263671875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 564/10000, Training Loss: 24.957382202148438, Training Accuracy: 0.5367647058823529, Validation Loss: 16.86326789855957, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 565/10000, Training Loss: 39.40636444091797, Training Accuracy: 0.571078431372549, Validation Loss: 16.238130569458008, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 566/10000, Training Loss: 14.849831581115723, Training Accuracy: 0.5906862745098039, Validation Loss: 14.465991020202637, Validation Accuracy: 0.75\n",
      "Epoch 567/10000, Training Loss: 15.47056770324707, Training Accuracy: 0.5833333333333334, Validation Loss: 7.855377674102783, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 568/10000, Training Loss: 31.826520919799805, Training Accuracy: 0.5906862745098039, Validation Loss: 12.037208557128906, Validation Accuracy: 0.75\n",
      "Epoch 569/10000, Training Loss: 19.453811645507812, Training Accuracy: 0.5833333333333334, Validation Loss: 13.435202598571777, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 570/10000, Training Loss: 36.386573791503906, Training Accuracy: 0.553921568627451, Validation Loss: 22.474027633666992, Validation Accuracy: 0.5\n",
      "Epoch 571/10000, Training Loss: 11.810884475708008, Training Accuracy: 0.5465686274509803, Validation Loss: 8.46944522857666, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 572/10000, Training Loss: 55.42401885986328, Training Accuracy: 0.5416666666666666, Validation Loss: 81.46006774902344, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 573/10000, Training Loss: 15.554067611694336, Training Accuracy: 0.5612745098039216, Validation Loss: 5.000529766082764, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 574/10000, Training Loss: 11.791608810424805, Training Accuracy: 0.6078431372549019, Validation Loss: 70.45105743408203, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 575/10000, Training Loss: 22.30466079711914, Training Accuracy: 0.5637254901960784, Validation Loss: 12.863247871398926, Validation Accuracy: 0.5\n",
      "Epoch 576/10000, Training Loss: 55.26267623901367, Training Accuracy: 0.5563725490196079, Validation Loss: 24.57988929748535, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 577/10000, Training Loss: 20.956375122070312, Training Accuracy: 0.5, Validation Loss: 57.07416915893555, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 578/10000, Training Loss: 7.011586666107178, Training Accuracy: 0.5661764705882353, Validation Loss: 11.204361915588379, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 579/10000, Training Loss: 22.14858055114746, Training Accuracy: 0.5196078431372549, Validation Loss: 19.04585838317871, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 580/10000, Training Loss: 8.022051811218262, Training Accuracy: 0.5245098039215687, Validation Loss: 1.1899052858352661, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 581/10000, Training Loss: 28.814802169799805, Training Accuracy: 0.5073529411764706, Validation Loss: 30.07195472717285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 582/10000, Training Loss: 28.504348754882812, Training Accuracy: 0.5269607843137255, Validation Loss: 40.9892692565918, Validation Accuracy: 0.5\n",
      "Epoch 583/10000, Training Loss: 55.67427444458008, Training Accuracy: 0.47549019607843135, Validation Loss: 12.417162895202637, Validation Accuracy: 0.5\n",
      "Epoch 584/10000, Training Loss: 9.67541790008545, Training Accuracy: 0.5931372549019608, Validation Loss: 39.52354049682617, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 585/10000, Training Loss: 23.271575927734375, Training Accuracy: 0.5245098039215687, Validation Loss: 18.963855743408203, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 586/10000, Training Loss: 19.914995193481445, Training Accuracy: 0.5343137254901961, Validation Loss: 13.6646146774292, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 587/10000, Training Loss: 23.92865753173828, Training Accuracy: 0.5318627450980392, Validation Loss: 7.370835781097412, Validation Accuracy: 0.5\n",
      "Epoch 588/10000, Training Loss: 21.385366439819336, Training Accuracy: 0.5514705882352942, Validation Loss: 134.0839080810547, Validation Accuracy: 0.5\n",
      "Epoch 589/10000, Training Loss: 12.578034400939941, Training Accuracy: 0.5465686274509803, Validation Loss: 12.567683219909668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 590/10000, Training Loss: 46.51164245605469, Training Accuracy: 0.5416666666666666, Validation Loss: 17.379968643188477, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 591/10000, Training Loss: 16.999826431274414, Training Accuracy: 0.5686274509803921, Validation Loss: 7.0621819496154785, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 592/10000, Training Loss: 30.64280128479004, Training Accuracy: 0.5686274509803921, Validation Loss: 26.726959228515625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 593/10000, Training Loss: 13.999784469604492, Training Accuracy: 0.49264705882352944, Validation Loss: 34.9086799621582, Validation Accuracy: 0.5\n",
      "Epoch 594/10000, Training Loss: 40.84925079345703, Training Accuracy: 0.5490196078431373, Validation Loss: 164.65115356445312, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 595/10000, Training Loss: 39.37027359008789, Training Accuracy: 0.49264705882352944, Validation Loss: 166.17845153808594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 596/10000, Training Loss: 11.473445892333984, Training Accuracy: 0.5686274509803921, Validation Loss: 22.10448455810547, Validation Accuracy: 0.5\n",
      "Epoch 597/10000, Training Loss: 28.37190818786621, Training Accuracy: 0.5343137254901961, Validation Loss: 10.278251647949219, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 598/10000, Training Loss: 49.72598648071289, Training Accuracy: 0.5122549019607843, Validation Loss: 42.95649719238281, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 599/10000, Training Loss: 47.48738098144531, Training Accuracy: 0.47549019607843135, Validation Loss: 105.4432144165039, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 600/10000, Training Loss: 64.48223114013672, Training Accuracy: 0.5759803921568627, Validation Loss: 78.29076385498047, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 601/10000, Training Loss: 31.711620330810547, Training Accuracy: 0.5343137254901961, Validation Loss: 13.64090633392334, Validation Accuracy: 0.25\n",
      "Epoch 602/10000, Training Loss: 24.643768310546875, Training Accuracy: 0.5514705882352942, Validation Loss: 10.77392578125, Validation Accuracy: 0.5\n",
      "Epoch 603/10000, Training Loss: 21.09861183166504, Training Accuracy: 0.5563725490196079, Validation Loss: 17.877588272094727, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 604/10000, Training Loss: 29.65987777709961, Training Accuracy: 0.5024509803921569, Validation Loss: 101.318603515625, Validation Accuracy: 0.25\n",
      "Epoch 605/10000, Training Loss: 11.576461791992188, Training Accuracy: 0.5906862745098039, Validation Loss: 2.6587746143341064, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 606/10000, Training Loss: 19.30149269104004, Training Accuracy: 0.5171568627450981, Validation Loss: 18.08220100402832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 607/10000, Training Loss: 41.59977340698242, Training Accuracy: 0.5220588235294118, Validation Loss: 78.02030944824219, Validation Accuracy: 0.25\n",
      "Epoch 608/10000, Training Loss: 35.44447326660156, Training Accuracy: 0.5073529411764706, Validation Loss: 28.80138397216797, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 609/10000, Training Loss: 46.29706954956055, Training Accuracy: 0.4803921568627451, Validation Loss: 28.356096267700195, Validation Accuracy: 0.5\n",
      "Epoch 610/10000, Training Loss: 23.17452049255371, Training Accuracy: 0.571078431372549, Validation Loss: 70.51026153564453, Validation Accuracy: 0.5\n",
      "Epoch 611/10000, Training Loss: 17.810359954833984, Training Accuracy: 0.5686274509803921, Validation Loss: 15.13765811920166, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 612/10000, Training Loss: 29.93899154663086, Training Accuracy: 0.5661764705882353, Validation Loss: 47.21977615356445, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 613/10000, Training Loss: 27.587921142578125, Training Accuracy: 0.5196078431372549, Validation Loss: 10.53747272491455, Validation Accuracy: 0.5\n",
      "Epoch 614/10000, Training Loss: 41.822566986083984, Training Accuracy: 0.5098039215686274, Validation Loss: 9.088946342468262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 615/10000, Training Loss: 18.469701766967773, Training Accuracy: 0.5416666666666666, Validation Loss: 51.90407180786133, Validation Accuracy: 0.5\n",
      "Epoch 616/10000, Training Loss: 33.84278869628906, Training Accuracy: 0.46568627450980393, Validation Loss: 15.359416961669922, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 617/10000, Training Loss: 37.54341125488281, Training Accuracy: 0.5269607843137255, Validation Loss: 74.76211547851562, Validation Accuracy: 0.5\n",
      "Epoch 618/10000, Training Loss: 28.835010528564453, Training Accuracy: 0.6102941176470589, Validation Loss: 30.511011123657227, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 619/10000, Training Loss: 49.92011642456055, Training Accuracy: 0.5171568627450981, Validation Loss: 35.132511138916016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 620/10000, Training Loss: 18.99883270263672, Training Accuracy: 0.5269607843137255, Validation Loss: 8.264883995056152, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 621/10000, Training Loss: 15.786978721618652, Training Accuracy: 0.47058823529411764, Validation Loss: 179.69708251953125, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 622/10000, Training Loss: 30.150537490844727, Training Accuracy: 0.5245098039215687, Validation Loss: 22.826894760131836, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 623/10000, Training Loss: 26.697246551513672, Training Accuracy: 0.5245098039215687, Validation Loss: 6.8709797859191895, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 624/10000, Training Loss: 20.7200984954834, Training Accuracy: 0.5686274509803921, Validation Loss: 119.1662368774414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 625/10000, Training Loss: 42.39651870727539, Training Accuracy: 0.5073529411764706, Validation Loss: 59.27778625488281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 626/10000, Training Loss: 55.928184509277344, Training Accuracy: 0.5171568627450981, Validation Loss: 19.891695022583008, Validation Accuracy: 0.5\n",
      "Epoch 627/10000, Training Loss: 13.845039367675781, Training Accuracy: 0.5, Validation Loss: 5.42362642288208, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 628/10000, Training Loss: 37.195743560791016, Training Accuracy: 0.5220588235294118, Validation Loss: 30.801284790039062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 629/10000, Training Loss: 20.786054611206055, Training Accuracy: 0.49754901960784315, Validation Loss: 1.895220160484314, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 630/10000, Training Loss: 34.11314392089844, Training Accuracy: 0.5906862745098039, Validation Loss: 11.99325942993164, Validation Accuracy: 0.25\n",
      "Epoch 631/10000, Training Loss: 13.891544342041016, Training Accuracy: 0.5147058823529411, Validation Loss: 1.108228087425232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 632/10000, Training Loss: 31.5835018157959, Training Accuracy: 0.5588235294117647, Validation Loss: 41.65217971801758, Validation Accuracy: 0.5\n",
      "Epoch 633/10000, Training Loss: 53.57649612426758, Training Accuracy: 0.46568627450980393, Validation Loss: 66.61212921142578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 634/10000, Training Loss: 20.41797637939453, Training Accuracy: 0.5931372549019608, Validation Loss: 74.81514739990234, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 635/10000, Training Loss: 15.873469352722168, Training Accuracy: 0.5490196078431373, Validation Loss: 5.623767375946045, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 636/10000, Training Loss: 26.39694595336914, Training Accuracy: 0.5612745098039216, Validation Loss: 102.26703643798828, Validation Accuracy: 0.5\n",
      "Epoch 637/10000, Training Loss: 18.504085540771484, Training Accuracy: 0.5147058823529411, Validation Loss: 79.21651458740234, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 638/10000, Training Loss: 28.06432342529297, Training Accuracy: 0.5367647058823529, Validation Loss: 22.06922721862793, Validation Accuracy: 0.5\n",
      "Epoch 639/10000, Training Loss: 18.339990615844727, Training Accuracy: 0.5563725490196079, Validation Loss: 4.329333782196045, Validation Accuracy: 0.5\n",
      "Epoch 640/10000, Training Loss: 19.167381286621094, Training Accuracy: 0.5318627450980392, Validation Loss: 6.3598809242248535, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 641/10000, Training Loss: 15.228315353393555, Training Accuracy: 0.47794117647058826, Validation Loss: 5.477788925170898, Validation Accuracy: 0.5\n",
      "Epoch 642/10000, Training Loss: 57.061527252197266, Training Accuracy: 0.5465686274509803, Validation Loss: 37.76913070678711, Validation Accuracy: 0.75\n",
      "Epoch 643/10000, Training Loss: 13.295928001403809, Training Accuracy: 0.5171568627450981, Validation Loss: 38.733402252197266, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 644/10000, Training Loss: 25.912185668945312, Training Accuracy: 0.5514705882352942, Validation Loss: 2.7267723083496094, Validation Accuracy: 0.5\n",
      "Epoch 645/10000, Training Loss: 38.8434944152832, Training Accuracy: 0.5318627450980392, Validation Loss: 1.9980820417404175, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 646/10000, Training Loss: 11.988446235656738, Training Accuracy: 0.5955882352941176, Validation Loss: 22.9509334564209, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 647/10000, Training Loss: 18.29433822631836, Training Accuracy: 0.5686274509803921, Validation Loss: 140.6679229736328, Validation Accuracy: 0.5\n",
      "Epoch 648/10000, Training Loss: 13.07451057434082, Training Accuracy: 0.5465686274509803, Validation Loss: 12.168312072753906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 649/10000, Training Loss: 34.70585250854492, Training Accuracy: 0.5147058823529411, Validation Loss: 46.30522537231445, Validation Accuracy: 0.25\n",
      "Epoch 650/10000, Training Loss: 40.705562591552734, Training Accuracy: 0.5245098039215687, Validation Loss: 26.404518127441406, Validation Accuracy: 0.5\n",
      "Epoch 651/10000, Training Loss: 20.125864028930664, Training Accuracy: 0.5416666666666666, Validation Loss: 3.803316116333008, Validation Accuracy: 0.5\n",
      "Epoch 652/10000, Training Loss: 15.914588928222656, Training Accuracy: 0.4950980392156863, Validation Loss: 1.3094865083694458, Validation Accuracy: 0.75\n",
      "Epoch 653/10000, Training Loss: 19.94858741760254, Training Accuracy: 0.5122549019607843, Validation Loss: 68.28221893310547, Validation Accuracy: 0.5\n",
      "Epoch 654/10000, Training Loss: 17.256799697875977, Training Accuracy: 0.5857843137254902, Validation Loss: 51.72047805786133, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 655/10000, Training Loss: 40.29302978515625, Training Accuracy: 0.4534313725490196, Validation Loss: 19.29890251159668, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 656/10000, Training Loss: 37.204185485839844, Training Accuracy: 0.49754901960784315, Validation Loss: 46.97291946411133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 657/10000, Training Loss: 18.56001853942871, Training Accuracy: 0.5343137254901961, Validation Loss: 5.274665355682373, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 658/10000, Training Loss: 8.191512107849121, Training Accuracy: 0.5269607843137255, Validation Loss: 73.93407440185547, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 659/10000, Training Loss: 16.113245010375977, Training Accuracy: 0.5686274509803921, Validation Loss: 111.7428207397461, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 660/10000, Training Loss: 48.2822380065918, Training Accuracy: 0.5196078431372549, Validation Loss: 74.36795806884766, Validation Accuracy: 0.5\n",
      "Epoch 661/10000, Training Loss: 46.16268539428711, Training Accuracy: 0.46568627450980393, Validation Loss: 182.50067138671875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 662/10000, Training Loss: 24.493757247924805, Training Accuracy: 0.4852941176470588, Validation Loss: 25.472457885742188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 663/10000, Training Loss: 16.173532485961914, Training Accuracy: 0.5367647058823529, Validation Loss: 21.63667869567871, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 664/10000, Training Loss: 18.039735794067383, Training Accuracy: 0.5343137254901961, Validation Loss: 24.814908981323242, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 665/10000, Training Loss: 21.935028076171875, Training Accuracy: 0.5882352941176471, Validation Loss: 58.079837799072266, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 666/10000, Training Loss: 39.48516845703125, Training Accuracy: 0.5294117647058824, Validation Loss: 24.155302047729492, Validation Accuracy: 0.5\n",
      "Epoch 667/10000, Training Loss: 11.633513450622559, Training Accuracy: 0.5686274509803921, Validation Loss: 28.128793716430664, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 668/10000, Training Loss: 69.830078125, Training Accuracy: 0.48284313725490197, Validation Loss: 13.477852821350098, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 669/10000, Training Loss: 24.188125610351562, Training Accuracy: 0.5220588235294118, Validation Loss: 8.71738338470459, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 670/10000, Training Loss: 16.61374282836914, Training Accuracy: 0.5441176470588235, Validation Loss: 34.841346740722656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 671/10000, Training Loss: 13.610069274902344, Training Accuracy: 0.5931372549019608, Validation Loss: 5.645599842071533, Validation Accuracy: 0.5\n",
      "Epoch 672/10000, Training Loss: 26.081188201904297, Training Accuracy: 0.5245098039215687, Validation Loss: 1.5297932624816895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 673/10000, Training Loss: 23.095380783081055, Training Accuracy: 0.5392156862745098, Validation Loss: 20.66526222229004, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 674/10000, Training Loss: 7.620225429534912, Training Accuracy: 0.553921568627451, Validation Loss: 27.583402633666992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 675/10000, Training Loss: 46.63899230957031, Training Accuracy: 0.5367647058823529, Validation Loss: 26.590538024902344, Validation Accuracy: 0.25\n",
      "Epoch 676/10000, Training Loss: 27.249618530273438, Training Accuracy: 0.5563725490196079, Validation Loss: 37.31367111206055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 677/10000, Training Loss: 33.656925201416016, Training Accuracy: 0.5343137254901961, Validation Loss: 4.624717712402344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 678/10000, Training Loss: 25.711530685424805, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8428803086280823, Validation Accuracy: 0.5\n",
      "Epoch 679/10000, Training Loss: 8.918054580688477, Training Accuracy: 0.5465686274509803, Validation Loss: 80.8616714477539, Validation Accuracy: 0.5\n",
      "Epoch 680/10000, Training Loss: 44.41950225830078, Training Accuracy: 0.5882352941176471, Validation Loss: 43.637908935546875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 681/10000, Training Loss: 18.161056518554688, Training Accuracy: 0.5588235294117647, Validation Loss: 98.20807647705078, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 682/10000, Training Loss: 37.09568405151367, Training Accuracy: 0.5196078431372549, Validation Loss: 68.98612213134766, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 683/10000, Training Loss: 20.108808517456055, Training Accuracy: 0.5073529411764706, Validation Loss: 29.339048385620117, Validation Accuracy: 0.5\n",
      "Epoch 684/10000, Training Loss: 10.044658660888672, Training Accuracy: 0.4681372549019608, Validation Loss: 6.1444478034973145, Validation Accuracy: 0.5\n",
      "Epoch 685/10000, Training Loss: 64.93112182617188, Training Accuracy: 0.47794117647058826, Validation Loss: 65.16463470458984, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 686/10000, Training Loss: 16.471851348876953, Training Accuracy: 0.5490196078431373, Validation Loss: 16.944948196411133, Validation Accuracy: 0.25\n",
      "Epoch 687/10000, Training Loss: 16.127025604248047, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8696863055229187, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 688/10000, Training Loss: 16.347335815429688, Training Accuracy: 0.6004901960784313, Validation Loss: 41.733856201171875, Validation Accuracy: 0.5\n",
      "Epoch 689/10000, Training Loss: 42.227806091308594, Training Accuracy: 0.5563725490196079, Validation Loss: 33.40843200683594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 690/10000, Training Loss: 20.262678146362305, Training Accuracy: 0.6029411764705882, Validation Loss: 9.475756645202637, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 691/10000, Training Loss: 16.398298263549805, Training Accuracy: 0.5367647058823529, Validation Loss: 75.73482513427734, Validation Accuracy: 0.5\n",
      "Epoch 692/10000, Training Loss: 12.326912879943848, Training Accuracy: 0.5808823529411765, Validation Loss: 11.328417778015137, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 693/10000, Training Loss: 24.318967819213867, Training Accuracy: 0.5049019607843137, Validation Loss: 13.505400657653809, Validation Accuracy: 0.5\n",
      "Epoch 694/10000, Training Loss: 21.32537078857422, Training Accuracy: 0.5784313725490197, Validation Loss: 79.3880386352539, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 695/10000, Training Loss: 30.976825714111328, Training Accuracy: 0.5367647058823529, Validation Loss: 32.364784240722656, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 696/10000, Training Loss: 27.90911102294922, Training Accuracy: 0.47549019607843135, Validation Loss: 14.833842277526855, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 697/10000, Training Loss: 47.9443244934082, Training Accuracy: 0.5857843137254902, Validation Loss: 14.404898643493652, Validation Accuracy: 0.5\n",
      "Epoch 698/10000, Training Loss: 44.767730712890625, Training Accuracy: 0.5147058823529411, Validation Loss: 52.84233474731445, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 699/10000, Training Loss: 29.447555541992188, Training Accuracy: 0.5588235294117647, Validation Loss: 37.90557098388672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 700/10000, Training Loss: 24.347715377807617, Training Accuracy: 0.5441176470588235, Validation Loss: 1.1024523973464966, Validation Accuracy: 0.5\n",
      "Epoch 701/10000, Training Loss: 38.26568603515625, Training Accuracy: 0.5073529411764706, Validation Loss: 71.23629760742188, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 702/10000, Training Loss: 19.135360717773438, Training Accuracy: 0.5784313725490197, Validation Loss: 16.94827651977539, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 703/10000, Training Loss: 23.97376251220703, Training Accuracy: 0.5588235294117647, Validation Loss: 90.5419921875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 704/10000, Training Loss: 24.735376358032227, Training Accuracy: 0.571078431372549, Validation Loss: 14.905259132385254, Validation Accuracy: 0.25\n",
      "Epoch 705/10000, Training Loss: 32.1754264831543, Training Accuracy: 0.5857843137254902, Validation Loss: 34.130062103271484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 706/10000, Training Loss: 15.627514839172363, Training Accuracy: 0.6495098039215687, Validation Loss: 9.641436576843262, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 707/10000, Training Loss: 24.728015899658203, Training Accuracy: 0.5, Validation Loss: 44.484195709228516, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 708/10000, Training Loss: 27.985795974731445, Training Accuracy: 0.5661764705882353, Validation Loss: 23.096220016479492, Validation Accuracy: 0.5\n",
      "Epoch 709/10000, Training Loss: 13.376408576965332, Training Accuracy: 0.5049019607843137, Validation Loss: 10.344508171081543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 710/10000, Training Loss: 21.872241973876953, Training Accuracy: 0.49754901960784315, Validation Loss: 24.79932975769043, Validation Accuracy: 0.5\n",
      "Epoch 711/10000, Training Loss: 16.599271774291992, Training Accuracy: 0.5514705882352942, Validation Loss: 5.78582239151001, Validation Accuracy: 0.5\n",
      "Epoch 712/10000, Training Loss: 9.185254096984863, Training Accuracy: 0.6225490196078431, Validation Loss: 64.56769561767578, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 713/10000, Training Loss: 16.411672592163086, Training Accuracy: 0.5171568627450981, Validation Loss: 22.163835525512695, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 714/10000, Training Loss: 13.157622337341309, Training Accuracy: 0.5784313725490197, Validation Loss: 2.965237855911255, Validation Accuracy: 0.5\n",
      "Epoch 715/10000, Training Loss: 10.565401077270508, Training Accuracy: 0.5612745098039216, Validation Loss: 19.189393997192383, Validation Accuracy: 0.75\n",
      "Epoch 716/10000, Training Loss: 18.95812225341797, Training Accuracy: 0.49264705882352944, Validation Loss: 5.32912015914917, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 717/10000, Training Loss: 28.080474853515625, Training Accuracy: 0.5122549019607843, Validation Loss: 20.666187286376953, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 718/10000, Training Loss: 18.098901748657227, Training Accuracy: 0.4877450980392157, Validation Loss: 31.33470344543457, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 719/10000, Training Loss: 17.626537322998047, Training Accuracy: 0.571078431372549, Validation Loss: 42.792606353759766, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 720/10000, Training Loss: 36.694610595703125, Training Accuracy: 0.4632352941176471, Validation Loss: 45.680233001708984, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 721/10000, Training Loss: 19.346044540405273, Training Accuracy: 0.5318627450980392, Validation Loss: 9.875378608703613, Validation Accuracy: 0.75\n",
      "Epoch 722/10000, Training Loss: 38.77411651611328, Training Accuracy: 0.5857843137254902, Validation Loss: 48.945796966552734, Validation Accuracy: 0.25\n",
      "Epoch 723/10000, Training Loss: 14.536498069763184, Training Accuracy: 0.6078431372549019, Validation Loss: 42.92423629760742, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 724/10000, Training Loss: 9.656925201416016, Training Accuracy: 0.5980392156862745, Validation Loss: 18.45641326904297, Validation Accuracy: 0.25\n",
      "Epoch 725/10000, Training Loss: 39.608516693115234, Training Accuracy: 0.47549019607843135, Validation Loss: 4.441668510437012, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 726/10000, Training Loss: 26.854576110839844, Training Accuracy: 0.5171568627450981, Validation Loss: 137.22410583496094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 727/10000, Training Loss: 16.686307907104492, Training Accuracy: 0.5147058823529411, Validation Loss: 2.16162371635437, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 728/10000, Training Loss: 22.27855682373047, Training Accuracy: 0.6151960784313726, Validation Loss: 41.7994270324707, Validation Accuracy: 0.5\n",
      "Epoch 729/10000, Training Loss: 38.7193489074707, Training Accuracy: 0.5171568627450981, Validation Loss: 30.705842971801758, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 730/10000, Training Loss: 19.84563446044922, Training Accuracy: 0.5245098039215687, Validation Loss: 34.55195999145508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 731/10000, Training Loss: 21.13796615600586, Training Accuracy: 0.553921568627451, Validation Loss: 4.806522369384766, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 732/10000, Training Loss: 53.111114501953125, Training Accuracy: 0.5588235294117647, Validation Loss: 78.92150115966797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 733/10000, Training Loss: 17.575220108032227, Training Accuracy: 0.5588235294117647, Validation Loss: 15.23578929901123, Validation Accuracy: 0.25\n",
      "Epoch 734/10000, Training Loss: 26.573389053344727, Training Accuracy: 0.5588235294117647, Validation Loss: 14.146934509277344, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 735/10000, Training Loss: 35.31892395019531, Training Accuracy: 0.5049019607843137, Validation Loss: 32.09815216064453, Validation Accuracy: 0.25\n",
      "Epoch 736/10000, Training Loss: 8.71467399597168, Training Accuracy: 0.5612745098039216, Validation Loss: 8.588692665100098, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 737/10000, Training Loss: 16.97635269165039, Training Accuracy: 0.49019607843137253, Validation Loss: 14.861132621765137, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 738/10000, Training Loss: 19.63690185546875, Training Accuracy: 0.571078431372549, Validation Loss: 18.01869010925293, Validation Accuracy: 0.5\n",
      "Epoch 739/10000, Training Loss: 22.173601150512695, Training Accuracy: 0.5343137254901961, Validation Loss: 12.663037300109863, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 740/10000, Training Loss: 38.80310821533203, Training Accuracy: 0.45098039215686275, Validation Loss: 7.099868297576904, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 741/10000, Training Loss: 17.7214412689209, Training Accuracy: 0.5906862745098039, Validation Loss: 18.26624870300293, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 742/10000, Training Loss: 15.237059593200684, Training Accuracy: 0.571078431372549, Validation Loss: 17.047964096069336, Validation Accuracy: 0.25\n",
      "Epoch 743/10000, Training Loss: 23.798215866088867, Training Accuracy: 0.5563725490196079, Validation Loss: 7.48776388168335, Validation Accuracy: 0.5\n",
      "Epoch 744/10000, Training Loss: 37.36425018310547, Training Accuracy: 0.571078431372549, Validation Loss: 7.627922534942627, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 745/10000, Training Loss: 22.073320388793945, Training Accuracy: 0.5392156862745098, Validation Loss: 8.31985855102539, Validation Accuracy: 0.5\n",
      "Epoch 746/10000, Training Loss: 32.92559051513672, Training Accuracy: 0.49019607843137253, Validation Loss: 1.765659213066101, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 747/10000, Training Loss: 34.39323043823242, Training Accuracy: 0.49264705882352944, Validation Loss: 27.981338500976562, Validation Accuracy: 0.75\n",
      "Epoch 748/10000, Training Loss: 18.478315353393555, Training Accuracy: 0.5367647058823529, Validation Loss: 87.69246673583984, Validation Accuracy: 0.5\n",
      "Epoch 749/10000, Training Loss: 22.493940353393555, Training Accuracy: 0.5588235294117647, Validation Loss: 24.333784103393555, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 750/10000, Training Loss: 24.681283950805664, Training Accuracy: 0.5661764705882353, Validation Loss: 77.55875396728516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 751/10000, Training Loss: 29.007707595825195, Training Accuracy: 0.5367647058823529, Validation Loss: 59.46224594116211, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 752/10000, Training Loss: 15.774306297302246, Training Accuracy: 0.6151960784313726, Validation Loss: 5.547332286834717, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 753/10000, Training Loss: 14.502259254455566, Training Accuracy: 0.5563725490196079, Validation Loss: 33.36775207519531, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 754/10000, Training Loss: 12.767394065856934, Training Accuracy: 0.5269607843137255, Validation Loss: 15.878604888916016, Validation Accuracy: 0.5\n",
      "Epoch 755/10000, Training Loss: 17.672842025756836, Training Accuracy: 0.5735294117647058, Validation Loss: 16.125093460083008, Validation Accuracy: 0.5\n",
      "Epoch 756/10000, Training Loss: 25.047988891601562, Training Accuracy: 0.5465686274509803, Validation Loss: 14.80686092376709, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 757/10000, Training Loss: 23.983736038208008, Training Accuracy: 0.5514705882352942, Validation Loss: 33.941566467285156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 758/10000, Training Loss: 42.15618133544922, Training Accuracy: 0.5441176470588235, Validation Loss: 5.681360244750977, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 759/10000, Training Loss: 15.704977989196777, Training Accuracy: 0.4583333333333333, Validation Loss: 7.724945068359375, Validation Accuracy: 0.5\n",
      "Epoch 760/10000, Training Loss: 19.15823745727539, Training Accuracy: 0.5612745098039216, Validation Loss: 5.081372261047363, Validation Accuracy: 0.75\n",
      "Epoch 761/10000, Training Loss: 20.91574478149414, Training Accuracy: 0.5563725490196079, Validation Loss: 12.532086372375488, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 762/10000, Training Loss: 26.615997314453125, Training Accuracy: 0.5833333333333334, Validation Loss: 58.36497116088867, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 763/10000, Training Loss: 34.746803283691406, Training Accuracy: 0.48284313725490197, Validation Loss: 16.325544357299805, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 764/10000, Training Loss: 27.097787857055664, Training Accuracy: 0.5490196078431373, Validation Loss: 6.311391830444336, Validation Accuracy: 0.25\n",
      "Epoch 765/10000, Training Loss: 21.119340896606445, Training Accuracy: 0.5392156862745098, Validation Loss: 103.5615234375, Validation Accuracy: 0.5\n",
      "Epoch 766/10000, Training Loss: 33.237918853759766, Training Accuracy: 0.6078431372549019, Validation Loss: 35.87358856201172, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 767/10000, Training Loss: 21.57697296142578, Training Accuracy: 0.6004901960784313, Validation Loss: 35.336544036865234, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 768/10000, Training Loss: 23.210599899291992, Training Accuracy: 0.5196078431372549, Validation Loss: 8.781221389770508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 769/10000, Training Loss: 18.56818389892578, Training Accuracy: 0.5122549019607843, Validation Loss: 44.49659729003906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 770/10000, Training Loss: 62.69654846191406, Training Accuracy: 0.5245098039215687, Validation Loss: 36.09807586669922, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 771/10000, Training Loss: 14.52651596069336, Training Accuracy: 0.5563725490196079, Validation Loss: 76.02722930908203, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 772/10000, Training Loss: 39.645931243896484, Training Accuracy: 0.5906862745098039, Validation Loss: 24.994863510131836, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 773/10000, Training Loss: 23.30994415283203, Training Accuracy: 0.5171568627450981, Validation Loss: 162.082763671875, Validation Accuracy: 0.25\n",
      "Epoch 774/10000, Training Loss: 27.367782592773438, Training Accuracy: 0.46568627450980393, Validation Loss: 39.1106071472168, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 775/10000, Training Loss: 10.131182670593262, Training Accuracy: 0.5857843137254902, Validation Loss: 13.060908317565918, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 776/10000, Training Loss: 28.15342140197754, Training Accuracy: 0.5416666666666666, Validation Loss: 22.176725387573242, Validation Accuracy: 0.25\n",
      "Epoch 777/10000, Training Loss: 24.27910804748535, Training Accuracy: 0.5563725490196079, Validation Loss: 79.42736053466797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 778/10000, Training Loss: 24.241792678833008, Training Accuracy: 0.5735294117647058, Validation Loss: 143.8544158935547, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 779/10000, Training Loss: 55.06026077270508, Training Accuracy: 0.5490196078431373, Validation Loss: 40.74497604370117, Validation Accuracy: 0.5\n",
      "Epoch 780/10000, Training Loss: 20.71640396118164, Training Accuracy: 0.5171568627450981, Validation Loss: 29.758071899414062, Validation Accuracy: 0.5\n",
      "Epoch 781/10000, Training Loss: 15.20737361907959, Training Accuracy: 0.5857843137254902, Validation Loss: 9.960286140441895, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 782/10000, Training Loss: 34.77606964111328, Training Accuracy: 0.571078431372549, Validation Loss: 14.44073486328125, Validation Accuracy: 0.5\n",
      "Epoch 783/10000, Training Loss: 13.531484603881836, Training Accuracy: 0.5441176470588235, Validation Loss: 5.521608352661133, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 784/10000, Training Loss: 27.60231590270996, Training Accuracy: 0.5, Validation Loss: 28.2921199798584, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 785/10000, Training Loss: 29.79018783569336, Training Accuracy: 0.5784313725490197, Validation Loss: 75.47843170166016, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 786/10000, Training Loss: 17.34169578552246, Training Accuracy: 0.5343137254901961, Validation Loss: 5.625796794891357, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 787/10000, Training Loss: 11.482999801635742, Training Accuracy: 0.5808823529411765, Validation Loss: 47.14621353149414, Validation Accuracy: 0.5\n",
      "Epoch 788/10000, Training Loss: 17.499160766601562, Training Accuracy: 0.5318627450980392, Validation Loss: 61.64353942871094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 789/10000, Training Loss: 17.039655685424805, Training Accuracy: 0.6225490196078431, Validation Loss: 35.213592529296875, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 790/10000, Training Loss: 12.959979057312012, Training Accuracy: 0.5514705882352942, Validation Loss: 1.479383945465088, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 791/10000, Training Loss: 34.74009704589844, Training Accuracy: 0.5171568627450981, Validation Loss: 44.84296798706055, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 792/10000, Training Loss: 32.869083404541016, Training Accuracy: 0.5490196078431373, Validation Loss: 3.8276984691619873, Validation Accuracy: 0.5\n",
      "Epoch 793/10000, Training Loss: 20.53080940246582, Training Accuracy: 0.5735294117647058, Validation Loss: 8.551833152770996, Validation Accuracy: 0.25\n",
      "Epoch 794/10000, Training Loss: 14.76453685760498, Training Accuracy: 0.571078431372549, Validation Loss: 25.586212158203125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 795/10000, Training Loss: 15.9469633102417, Training Accuracy: 0.5661764705882353, Validation Loss: 24.21734046936035, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 796/10000, Training Loss: 13.994359970092773, Training Accuracy: 0.5122549019607843, Validation Loss: 4.482407093048096, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 797/10000, Training Loss: 12.048393249511719, Training Accuracy: 0.5343137254901961, Validation Loss: 17.586347579956055, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 798/10000, Training Loss: 23.707950592041016, Training Accuracy: 0.5465686274509803, Validation Loss: 7.746666431427002, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 799/10000, Training Loss: 20.980453491210938, Training Accuracy: 0.5343137254901961, Validation Loss: 1.9583320617675781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 800/10000, Training Loss: 23.22787857055664, Training Accuracy: 0.6200980392156863, Validation Loss: 12.396759033203125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 801/10000, Training Loss: 24.918895721435547, Training Accuracy: 0.5686274509803921, Validation Loss: 9.600491523742676, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 802/10000, Training Loss: 19.121782302856445, Training Accuracy: 0.5367647058823529, Validation Loss: 7.305016994476318, Validation Accuracy: 0.5\n",
      "Epoch 803/10000, Training Loss: 11.553335189819336, Training Accuracy: 0.5171568627450981, Validation Loss: 9.7749662399292, Validation Accuracy: 0.5\n",
      "Epoch 804/10000, Training Loss: 26.578710556030273, Training Accuracy: 0.5, Validation Loss: 31.214996337890625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 805/10000, Training Loss: 22.271896362304688, Training Accuracy: 0.5514705882352942, Validation Loss: 8.650623321533203, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 806/10000, Training Loss: 9.70459270477295, Training Accuracy: 0.5465686274509803, Validation Loss: 23.037757873535156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 807/10000, Training Loss: 24.351797103881836, Training Accuracy: 0.48284313725490197, Validation Loss: 6.779214859008789, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 808/10000, Training Loss: 10.068156242370605, Training Accuracy: 0.4877450980392157, Validation Loss: 6.935771465301514, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 809/10000, Training Loss: 33.51847457885742, Training Accuracy: 0.5269607843137255, Validation Loss: 3.381240129470825, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 810/10000, Training Loss: 20.238998413085938, Training Accuracy: 0.5024509803921569, Validation Loss: 19.975534439086914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 811/10000, Training Loss: 27.345287322998047, Training Accuracy: 0.5563725490196079, Validation Loss: 50.83244323730469, Validation Accuracy: 0.5\n",
      "Epoch 812/10000, Training Loss: 13.190865516662598, Training Accuracy: 0.5465686274509803, Validation Loss: 50.57466506958008, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 813/10000, Training Loss: 14.606376647949219, Training Accuracy: 0.5367647058823529, Validation Loss: 33.495330810546875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 814/10000, Training Loss: 17.50918960571289, Training Accuracy: 0.5171568627450981, Validation Loss: 11.814929008483887, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 815/10000, Training Loss: 28.807641983032227, Training Accuracy: 0.5171568627450981, Validation Loss: 17.279577255249023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 816/10000, Training Loss: 11.103111267089844, Training Accuracy: 0.5686274509803921, Validation Loss: 17.722381591796875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 817/10000, Training Loss: 19.165485382080078, Training Accuracy: 0.5588235294117647, Validation Loss: 22.220186233520508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 818/10000, Training Loss: 31.418249130249023, Training Accuracy: 0.48284313725490197, Validation Loss: 0.9247474074363708, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 819/10000, Training Loss: 11.139487266540527, Training Accuracy: 0.5612745098039216, Validation Loss: 5.646884918212891, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 820/10000, Training Loss: 25.730180740356445, Training Accuracy: 0.5, Validation Loss: 17.789445877075195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 821/10000, Training Loss: 17.254236221313477, Training Accuracy: 0.5563725490196079, Validation Loss: 20.154783248901367, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 822/10000, Training Loss: 32.8855094909668, Training Accuracy: 0.5367647058823529, Validation Loss: 67.63973236083984, Validation Accuracy: 0.5\n",
      "Epoch 823/10000, Training Loss: 41.532432556152344, Training Accuracy: 0.5416666666666666, Validation Loss: 6.345525741577148, Validation Accuracy: 0.5\n",
      "Epoch 824/10000, Training Loss: 47.61359405517578, Training Accuracy: 0.5049019607843137, Validation Loss: 44.055912017822266, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 825/10000, Training Loss: 10.553067207336426, Training Accuracy: 0.5147058823529411, Validation Loss: 17.736736297607422, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 826/10000, Training Loss: 35.12297821044922, Training Accuracy: 0.6127450980392157, Validation Loss: 60.63999557495117, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 827/10000, Training Loss: 23.635692596435547, Training Accuracy: 0.5784313725490197, Validation Loss: 23.823755264282227, Validation Accuracy: 0.5\n",
      "Epoch 828/10000, Training Loss: 17.856969833374023, Training Accuracy: 0.5343137254901961, Validation Loss: 24.90702247619629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 829/10000, Training Loss: 19.340911865234375, Training Accuracy: 0.5392156862745098, Validation Loss: 11.23249340057373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 830/10000, Training Loss: 22.66896629333496, Training Accuracy: 0.5294117647058824, Validation Loss: 5.17257022857666, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 831/10000, Training Loss: 11.748295783996582, Training Accuracy: 0.553921568627451, Validation Loss: 2.8674118518829346, Validation Accuracy: 0.25\n",
      "Epoch 832/10000, Training Loss: 18.922292709350586, Training Accuracy: 0.5637254901960784, Validation Loss: 0.34181538224220276, Validation Accuracy: 0.75\n",
      "Epoch 833/10000, Training Loss: 13.744519233703613, Training Accuracy: 0.5343137254901961, Validation Loss: 6.662220001220703, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 834/10000, Training Loss: 25.20475959777832, Training Accuracy: 0.5490196078431373, Validation Loss: 45.76932144165039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 835/10000, Training Loss: 14.227897644042969, Training Accuracy: 0.5367647058823529, Validation Loss: 16.03557777404785, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 836/10000, Training Loss: 27.3599910736084, Training Accuracy: 0.5514705882352942, Validation Loss: 17.24797248840332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 837/10000, Training Loss: 22.04787826538086, Training Accuracy: 0.571078431372549, Validation Loss: 20.919153213500977, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 838/10000, Training Loss: 20.9980525970459, Training Accuracy: 0.5294117647058824, Validation Loss: 38.3047981262207, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 839/10000, Training Loss: 20.5877628326416, Training Accuracy: 0.5441176470588235, Validation Loss: 32.25870132446289, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 840/10000, Training Loss: 32.211326599121094, Training Accuracy: 0.5490196078431373, Validation Loss: 11.584869384765625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 841/10000, Training Loss: 11.429787635803223, Training Accuracy: 0.5318627450980392, Validation Loss: 1.3220810890197754, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 842/10000, Training Loss: 18.643619537353516, Training Accuracy: 0.5416666666666666, Validation Loss: 8.472084045410156, Validation Accuracy: 0.25\n",
      "Epoch 843/10000, Training Loss: 12.183991432189941, Training Accuracy: 0.5661764705882353, Validation Loss: 29.608980178833008, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 844/10000, Training Loss: 7.327337741851807, Training Accuracy: 0.5147058823529411, Validation Loss: 45.78758239746094, Validation Accuracy: 0.5\n",
      "Epoch 845/10000, Training Loss: 10.329401016235352, Training Accuracy: 0.5980392156862745, Validation Loss: 19.50467872619629, Validation Accuracy: 0.25\n",
      "Epoch 846/10000, Training Loss: 12.862866401672363, Training Accuracy: 0.5269607843137255, Validation Loss: 2.7520599365234375, Validation Accuracy: 0.5\n",
      "Epoch 847/10000, Training Loss: 14.407915115356445, Training Accuracy: 0.5563725490196079, Validation Loss: 12.853079795837402, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 848/10000, Training Loss: 32.53786087036133, Training Accuracy: 0.6151960784313726, Validation Loss: 6.523448467254639, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 849/10000, Training Loss: 14.705915451049805, Training Accuracy: 0.5098039215686274, Validation Loss: 30.670333862304688, Validation Accuracy: 0.25\n",
      "Epoch 850/10000, Training Loss: 28.99711799621582, Training Accuracy: 0.5098039215686274, Validation Loss: 9.625266075134277, Validation Accuracy: 0.5\n",
      "Epoch 851/10000, Training Loss: 50.15469741821289, Training Accuracy: 0.5563725490196079, Validation Loss: 316.6350402832031, Validation Accuracy: 0.5\n",
      "Epoch 852/10000, Training Loss: 17.286449432373047, Training Accuracy: 0.5465686274509803, Validation Loss: 42.31686019897461, Validation Accuracy: 0.25\n",
      "Epoch 853/10000, Training Loss: 24.745874404907227, Training Accuracy: 0.5171568627450981, Validation Loss: 3.2593061923980713, Validation Accuracy: 0.5\n",
      "Epoch 854/10000, Training Loss: 7.231367111206055, Training Accuracy: 0.5955882352941176, Validation Loss: 6.30210542678833, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 855/10000, Training Loss: 16.431764602661133, Training Accuracy: 0.5024509803921569, Validation Loss: 14.939360618591309, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 856/10000, Training Loss: 18.79160499572754, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9881508946418762, Validation Accuracy: 0.5\n",
      "Epoch 857/10000, Training Loss: 27.365283966064453, Training Accuracy: 0.553921568627451, Validation Loss: 18.33259391784668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 858/10000, Training Loss: 17.328468322753906, Training Accuracy: 0.5980392156862745, Validation Loss: 29.947851181030273, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 859/10000, Training Loss: 15.274762153625488, Training Accuracy: 0.5735294117647058, Validation Loss: 23.467458724975586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 860/10000, Training Loss: 6.71686315536499, Training Accuracy: 0.5171568627450981, Validation Loss: 1.309334635734558, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 861/10000, Training Loss: 19.33432960510254, Training Accuracy: 0.5686274509803921, Validation Loss: 16.866796493530273, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 862/10000, Training Loss: 26.81354522705078, Training Accuracy: 0.5024509803921569, Validation Loss: 19.35051918029785, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 863/10000, Training Loss: 18.824790954589844, Training Accuracy: 0.5220588235294118, Validation Loss: 10.346390724182129, Validation Accuracy: 0.25\n",
      "Epoch 864/10000, Training Loss: 8.695504188537598, Training Accuracy: 0.5514705882352942, Validation Loss: 3.6879196166992188, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 865/10000, Training Loss: 33.11281204223633, Training Accuracy: 0.5171568627450981, Validation Loss: 21.477760314941406, Validation Accuracy: 0.5\n",
      "Epoch 866/10000, Training Loss: 37.16474914550781, Training Accuracy: 0.5098039215686274, Validation Loss: 58.80998229980469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 867/10000, Training Loss: 25.88266944885254, Training Accuracy: 0.5220588235294118, Validation Loss: 4.482920169830322, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 868/10000, Training Loss: 14.745270729064941, Training Accuracy: 0.5196078431372549, Validation Loss: 19.855579376220703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 869/10000, Training Loss: 11.233304023742676, Training Accuracy: 0.5588235294117647, Validation Loss: 15.198765754699707, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 870/10000, Training Loss: 18.45707130432129, Training Accuracy: 0.6102941176470589, Validation Loss: 20.625207901000977, Validation Accuracy: 0.5\n",
      "Epoch 871/10000, Training Loss: 22.061901092529297, Training Accuracy: 0.553921568627451, Validation Loss: 15.638530731201172, Validation Accuracy: 0.5\n",
      "Epoch 872/10000, Training Loss: 23.00908088684082, Training Accuracy: 0.5171568627450981, Validation Loss: 61.11181640625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 873/10000, Training Loss: 25.78137969970703, Training Accuracy: 0.5465686274509803, Validation Loss: 8.679903984069824, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 874/10000, Training Loss: 26.229320526123047, Training Accuracy: 0.5122549019607843, Validation Loss: 13.486297607421875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 875/10000, Training Loss: 23.78110694885254, Training Accuracy: 0.5441176470588235, Validation Loss: 8.853531837463379, Validation Accuracy: 0.5\n",
      "Epoch 876/10000, Training Loss: 12.986215591430664, Training Accuracy: 0.5441176470588235, Validation Loss: 10.630210876464844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 877/10000, Training Loss: 48.867820739746094, Training Accuracy: 0.48284313725490197, Validation Loss: 36.06852722167969, Validation Accuracy: 0.5\n",
      "Epoch 878/10000, Training Loss: 20.0185489654541, Training Accuracy: 0.571078431372549, Validation Loss: 40.720211029052734, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 879/10000, Training Loss: 21.12313461303711, Training Accuracy: 0.5637254901960784, Validation Loss: 14.676800727844238, Validation Accuracy: 0.5\n",
      "Epoch 880/10000, Training Loss: 13.173347473144531, Training Accuracy: 0.5073529411764706, Validation Loss: 0.40366363525390625, Validation Accuracy: 0.75\n",
      "Epoch 881/10000, Training Loss: 9.751887321472168, Training Accuracy: 0.5490196078431373, Validation Loss: 7.629337310791016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 882/10000, Training Loss: 17.673202514648438, Training Accuracy: 0.48284313725490197, Validation Loss: 23.111268997192383, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 883/10000, Training Loss: 13.186029434204102, Training Accuracy: 0.5122549019607843, Validation Loss: 2.7845773696899414, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 884/10000, Training Loss: 30.04563331604004, Training Accuracy: 0.49264705882352944, Validation Loss: 10.657630920410156, Validation Accuracy: 0.5\n",
      "Epoch 885/10000, Training Loss: 26.754772186279297, Training Accuracy: 0.6004901960784313, Validation Loss: 2.8774406909942627, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 886/10000, Training Loss: 21.8138427734375, Training Accuracy: 0.49264705882352944, Validation Loss: 38.771053314208984, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 887/10000, Training Loss: 11.28901481628418, Training Accuracy: 0.5882352941176471, Validation Loss: 8.791010856628418, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 888/10000, Training Loss: 29.414140701293945, Training Accuracy: 0.5318627450980392, Validation Loss: 11.002888679504395, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 889/10000, Training Loss: 31.134002685546875, Training Accuracy: 0.5612745098039216, Validation Loss: 43.7545166015625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 890/10000, Training Loss: 12.189021110534668, Training Accuracy: 0.5661764705882353, Validation Loss: 7.4396748542785645, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 891/10000, Training Loss: 19.175756454467773, Training Accuracy: 0.5122549019607843, Validation Loss: 30.742599487304688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 892/10000, Training Loss: 14.505522727966309, Training Accuracy: 0.5465686274509803, Validation Loss: 38.49311447143555, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 893/10000, Training Loss: 14.659917831420898, Training Accuracy: 0.5980392156862745, Validation Loss: 41.65193557739258, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 894/10000, Training Loss: 21.62196922302246, Training Accuracy: 0.5171568627450981, Validation Loss: 29.29288673400879, Validation Accuracy: 0.5\n",
      "Epoch 895/10000, Training Loss: 14.516464233398438, Training Accuracy: 0.4950980392156863, Validation Loss: 24.567886352539062, Validation Accuracy: 0.5\n",
      "Epoch 896/10000, Training Loss: 18.939355850219727, Training Accuracy: 0.5122549019607843, Validation Loss: 19.502599716186523, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 897/10000, Training Loss: 11.49580192565918, Training Accuracy: 0.5073529411764706, Validation Loss: 2.260394334793091, Validation Accuracy: 0.5\n",
      "Epoch 898/10000, Training Loss: 15.639546394348145, Training Accuracy: 0.5294117647058824, Validation Loss: 2.408536672592163, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 899/10000, Training Loss: 11.123149871826172, Training Accuracy: 0.5171568627450981, Validation Loss: 15.702422142028809, Validation Accuracy: 0.75\n",
      "Epoch 900/10000, Training Loss: 12.418279647827148, Training Accuracy: 0.46568627450980393, Validation Loss: 11.473542213439941, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 901/10000, Training Loss: 23.380176544189453, Training Accuracy: 0.6029411764705882, Validation Loss: 23.75389289855957, Validation Accuracy: 0.5\n",
      "Epoch 902/10000, Training Loss: 45.23861312866211, Training Accuracy: 0.5122549019607843, Validation Loss: 133.69273376464844, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 903/10000, Training Loss: 16.347509384155273, Training Accuracy: 0.49264705882352944, Validation Loss: 8.415136337280273, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 904/10000, Training Loss: 33.40670394897461, Training Accuracy: 0.5318627450980392, Validation Loss: 13.307411193847656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 905/10000, Training Loss: 22.303436279296875, Training Accuracy: 0.5098039215686274, Validation Loss: 52.9374885559082, Validation Accuracy: 0.5\n",
      "Epoch 906/10000, Training Loss: 13.12451171875, Training Accuracy: 0.6151960784313726, Validation Loss: 52.5250129699707, Validation Accuracy: 0.5\n",
      "Epoch 907/10000, Training Loss: 21.965465545654297, Training Accuracy: 0.5612745098039216, Validation Loss: 38.02470016479492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 908/10000, Training Loss: 8.714106559753418, Training Accuracy: 0.5882352941176471, Validation Loss: 15.22745132446289, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 909/10000, Training Loss: 24.642711639404297, Training Accuracy: 0.5661764705882353, Validation Loss: 27.566164016723633, Validation Accuracy: 0.25\n",
      "Epoch 910/10000, Training Loss: 18.271997451782227, Training Accuracy: 0.5245098039215687, Validation Loss: 15.724295616149902, Validation Accuracy: 0.75\n",
      "Epoch 911/10000, Training Loss: 7.682521343231201, Training Accuracy: 0.5808823529411765, Validation Loss: 6.270406246185303, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 912/10000, Training Loss: 15.676589012145996, Training Accuracy: 0.571078431372549, Validation Loss: 9.198582649230957, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 913/10000, Training Loss: 17.0897274017334, Training Accuracy: 0.553921568627451, Validation Loss: 20.774755477905273, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 914/10000, Training Loss: 61.17718505859375, Training Accuracy: 0.47549019607843135, Validation Loss: 56.88014602661133, Validation Accuracy: 0.75\n",
      "Epoch 915/10000, Training Loss: 9.225691795349121, Training Accuracy: 0.5098039215686274, Validation Loss: 7.871360778808594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 916/10000, Training Loss: 21.24996566772461, Training Accuracy: 0.5465686274509803, Validation Loss: 5.789742946624756, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 917/10000, Training Loss: 7.56132698059082, Training Accuracy: 0.5269607843137255, Validation Loss: 10.418334007263184, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 918/10000, Training Loss: 22.727142333984375, Training Accuracy: 0.5220588235294118, Validation Loss: 2.0469064712524414, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 919/10000, Training Loss: 14.770988464355469, Training Accuracy: 0.5637254901960784, Validation Loss: 18.03148651123047, Validation Accuracy: 0.5\n",
      "Epoch 920/10000, Training Loss: 14.624332427978516, Training Accuracy: 0.5073529411764706, Validation Loss: 58.285587310791016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 921/10000, Training Loss: 21.18899154663086, Training Accuracy: 0.5955882352941176, Validation Loss: 17.800430297851562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 922/10000, Training Loss: 8.201102256774902, Training Accuracy: 0.5980392156862745, Validation Loss: 19.557113647460938, Validation Accuracy: 0.5\n",
      "Epoch 923/10000, Training Loss: 19.090490341186523, Training Accuracy: 0.5318627450980392, Validation Loss: 27.040254592895508, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 924/10000, Training Loss: 13.449621200561523, Training Accuracy: 0.5612745098039216, Validation Loss: 16.43697166442871, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 925/10000, Training Loss: 13.518632888793945, Training Accuracy: 0.6299019607843137, Validation Loss: 3.008315086364746, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 926/10000, Training Loss: 20.63937759399414, Training Accuracy: 0.571078431372549, Validation Loss: 13.513229370117188, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 927/10000, Training Loss: 12.865835189819336, Training Accuracy: 0.553921568627451, Validation Loss: 19.51506233215332, Validation Accuracy: 0.5\n",
      "Epoch 928/10000, Training Loss: 22.83203125, Training Accuracy: 0.5269607843137255, Validation Loss: 14.156519889831543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 929/10000, Training Loss: 16.232969284057617, Training Accuracy: 0.5245098039215687, Validation Loss: 9.139020919799805, Validation Accuracy: 0.5\n",
      "Epoch 930/10000, Training Loss: 20.135217666625977, Training Accuracy: 0.5588235294117647, Validation Loss: 6.160652160644531, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 931/10000, Training Loss: 24.072710037231445, Training Accuracy: 0.4877450980392157, Validation Loss: 13.683135986328125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 932/10000, Training Loss: 14.434195518493652, Training Accuracy: 0.5196078431372549, Validation Loss: 39.875587463378906, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 933/10000, Training Loss: 9.646234512329102, Training Accuracy: 0.5588235294117647, Validation Loss: 14.071521759033203, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 934/10000, Training Loss: 13.765238761901855, Training Accuracy: 0.5735294117647058, Validation Loss: 27.004928588867188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 935/10000, Training Loss: 17.49385643005371, Training Accuracy: 0.5441176470588235, Validation Loss: 11.609020233154297, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 936/10000, Training Loss: 9.05208969116211, Training Accuracy: 0.5318627450980392, Validation Loss: 0.6413053870201111, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 937/10000, Training Loss: 8.800613403320312, Training Accuracy: 0.5931372549019608, Validation Loss: 19.845441818237305, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 938/10000, Training Loss: 23.38688087463379, Training Accuracy: 0.5220588235294118, Validation Loss: 32.68222427368164, Validation Accuracy: 0.5\n",
      "Epoch 939/10000, Training Loss: 22.802282333374023, Training Accuracy: 0.5196078431372549, Validation Loss: 8.350509643554688, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 940/10000, Training Loss: 15.655786514282227, Training Accuracy: 0.5612745098039216, Validation Loss: 78.72310638427734, Validation Accuracy: 0.25\n",
      "Epoch 941/10000, Training Loss: 26.512866973876953, Training Accuracy: 0.4803921568627451, Validation Loss: 54.6430549621582, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 942/10000, Training Loss: 18.85318946838379, Training Accuracy: 0.5171568627450981, Validation Loss: 18.52873992919922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 943/10000, Training Loss: 14.542054176330566, Training Accuracy: 0.5661764705882353, Validation Loss: 22.769075393676758, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 944/10000, Training Loss: 19.2947940826416, Training Accuracy: 0.5465686274509803, Validation Loss: 41.93983459472656, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 945/10000, Training Loss: 25.526979446411133, Training Accuracy: 0.553921568627451, Validation Loss: 32.20975112915039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 946/10000, Training Loss: 21.35683822631836, Training Accuracy: 0.5514705882352942, Validation Loss: 45.47633743286133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 947/10000, Training Loss: 13.633862495422363, Training Accuracy: 0.5465686274509803, Validation Loss: 26.49488639831543, Validation Accuracy: 0.5\n",
      "Epoch 948/10000, Training Loss: 16.203086853027344, Training Accuracy: 0.5, Validation Loss: 3.1643857955932617, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 949/10000, Training Loss: 14.206032752990723, Training Accuracy: 0.6029411764705882, Validation Loss: 30.98889923095703, Validation Accuracy: 0.5\n",
      "Epoch 950/10000, Training Loss: 29.276479721069336, Training Accuracy: 0.5392156862745098, Validation Loss: 52.027923583984375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 951/10000, Training Loss: 5.452752113342285, Training Accuracy: 0.5343137254901961, Validation Loss: 1.947985053062439, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 952/10000, Training Loss: 28.996545791625977, Training Accuracy: 0.5147058823529411, Validation Loss: 2.2320072650909424, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 953/10000, Training Loss: 13.260111808776855, Training Accuracy: 0.5367647058823529, Validation Loss: 39.0227165222168, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 954/10000, Training Loss: 9.396828651428223, Training Accuracy: 0.5490196078431373, Validation Loss: 14.544929504394531, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 955/10000, Training Loss: 27.394325256347656, Training Accuracy: 0.5343137254901961, Validation Loss: 65.33428955078125, Validation Accuracy: 0.5\n",
      "Epoch 956/10000, Training Loss: 9.864907264709473, Training Accuracy: 0.5784313725490197, Validation Loss: 8.479634284973145, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 957/10000, Training Loss: 34.48933029174805, Training Accuracy: 0.48284313725490197, Validation Loss: 17.64628028869629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 958/10000, Training Loss: 17.532901763916016, Training Accuracy: 0.5367647058823529, Validation Loss: 5.174412250518799, Validation Accuracy: 0.75\n",
      "Epoch 959/10000, Training Loss: 40.66425704956055, Training Accuracy: 0.571078431372549, Validation Loss: 31.10907745361328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 960/10000, Training Loss: 21.631715774536133, Training Accuracy: 0.5637254901960784, Validation Loss: 41.14822006225586, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 961/10000, Training Loss: 12.34998893737793, Training Accuracy: 0.5980392156862745, Validation Loss: 157.6490936279297, Validation Accuracy: 0.5\n",
      "Epoch 962/10000, Training Loss: 11.848976135253906, Training Accuracy: 0.5441176470588235, Validation Loss: 7.836644649505615, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 963/10000, Training Loss: 23.38410186767578, Training Accuracy: 0.5098039215686274, Validation Loss: 233.88287353515625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 964/10000, Training Loss: 16.866180419921875, Training Accuracy: 0.5245098039215687, Validation Loss: 9.184128761291504, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 965/10000, Training Loss: 22.035022735595703, Training Accuracy: 0.5, Validation Loss: 19.674312591552734, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 966/10000, Training Loss: 18.044416427612305, Training Accuracy: 0.5465686274509803, Validation Loss: 15.770096778869629, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 967/10000, Training Loss: 15.200944900512695, Training Accuracy: 0.5563725490196079, Validation Loss: 10.395190238952637, Validation Accuracy: 0.75\n",
      "Epoch 968/10000, Training Loss: 19.320234298706055, Training Accuracy: 0.5245098039215687, Validation Loss: 13.642212867736816, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 969/10000, Training Loss: 15.175942420959473, Training Accuracy: 0.5955882352941176, Validation Loss: 11.5250883102417, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 970/10000, Training Loss: 14.216569900512695, Training Accuracy: 0.571078431372549, Validation Loss: 10.605141639709473, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 971/10000, Training Loss: 19.65133285522461, Training Accuracy: 0.5661764705882353, Validation Loss: 48.32625198364258, Validation Accuracy: 0.25\n",
      "Epoch 972/10000, Training Loss: 10.341364860534668, Training Accuracy: 0.6004901960784313, Validation Loss: 12.036349296569824, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 973/10000, Training Loss: 15.809247970581055, Training Accuracy: 0.4877450980392157, Validation Loss: 37.45400619506836, Validation Accuracy: 0.5\n",
      "Epoch 974/10000, Training Loss: 28.134185791015625, Training Accuracy: 0.5367647058823529, Validation Loss: 23.61100196838379, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 975/10000, Training Loss: 20.41853904724121, Training Accuracy: 0.5612745098039216, Validation Loss: 50.45036697387695, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 976/10000, Training Loss: 17.409807205200195, Training Accuracy: 0.5220588235294118, Validation Loss: 10.750422477722168, Validation Accuracy: 0.5\n",
      "Epoch 977/10000, Training Loss: 14.448716163635254, Training Accuracy: 0.4803921568627451, Validation Loss: 10.623083114624023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 978/10000, Training Loss: 23.455427169799805, Training Accuracy: 0.5416666666666666, Validation Loss: 31.187667846679688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 979/10000, Training Loss: 10.119996070861816, Training Accuracy: 0.4681372549019608, Validation Loss: 1.3521136045455933, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 980/10000, Training Loss: 19.04391098022461, Training Accuracy: 0.571078431372549, Validation Loss: 9.018655776977539, Validation Accuracy: 0.25\n",
      "Epoch 981/10000, Training Loss: 33.90177917480469, Training Accuracy: 0.5049019607843137, Validation Loss: 22.880577087402344, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 982/10000, Training Loss: 22.94833755493164, Training Accuracy: 0.5147058823529411, Validation Loss: 35.00626754760742, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 983/10000, Training Loss: 42.08587646484375, Training Accuracy: 0.5318627450980392, Validation Loss: 20.474212646484375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 984/10000, Training Loss: 17.81973648071289, Training Accuracy: 0.5833333333333334, Validation Loss: 4.431201934814453, Validation Accuracy: 0.75\n",
      "Epoch 985/10000, Training Loss: 36.822879791259766, Training Accuracy: 0.5196078431372549, Validation Loss: 48.08628845214844, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 986/10000, Training Loss: 28.432050704956055, Training Accuracy: 0.4852941176470588, Validation Loss: 70.58296966552734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 987/10000, Training Loss: 8.971697807312012, Training Accuracy: 0.5441176470588235, Validation Loss: 7.851815700531006, Validation Accuracy: 0.5\n",
      "Epoch 988/10000, Training Loss: 10.973824501037598, Training Accuracy: 0.6078431372549019, Validation Loss: 37.335201263427734, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 989/10000, Training Loss: 10.468424797058105, Training Accuracy: 0.5294117647058824, Validation Loss: 7.08554220199585, Validation Accuracy: 0.5\n",
      "Epoch 990/10000, Training Loss: 24.16287612915039, Training Accuracy: 0.5318627450980392, Validation Loss: 11.599746704101562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 991/10000, Training Loss: 12.587546348571777, Training Accuracy: 0.5759803921568627, Validation Loss: 14.12594223022461, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 992/10000, Training Loss: 17.26264190673828, Training Accuracy: 0.5441176470588235, Validation Loss: 11.733840942382812, Validation Accuracy: 0.5\n",
      "Epoch 993/10000, Training Loss: 11.982178688049316, Training Accuracy: 0.5735294117647058, Validation Loss: 11.17581844329834, Validation Accuracy: 0.75\n",
      "Epoch 994/10000, Training Loss: 14.7838773727417, Training Accuracy: 0.5906862745098039, Validation Loss: 16.83113670349121, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 995/10000, Training Loss: 14.494050025939941, Training Accuracy: 0.5465686274509803, Validation Loss: 14.27301025390625, Validation Accuracy: 0.5\n",
      "Epoch 996/10000, Training Loss: 25.410472869873047, Training Accuracy: 0.5490196078431373, Validation Loss: 43.96895217895508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 997/10000, Training Loss: 7.246765613555908, Training Accuracy: 0.5343137254901961, Validation Loss: 1.5200763940811157, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 998/10000, Training Loss: 10.083657264709473, Training Accuracy: 0.6078431372549019, Validation Loss: 16.401147842407227, Validation Accuracy: 0.5\n",
      "Epoch 999/10000, Training Loss: 8.055824279785156, Training Accuracy: 0.5612745098039216, Validation Loss: 3.532886505126953, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1000/10000, Training Loss: 16.046947479248047, Training Accuracy: 0.48284313725490197, Validation Loss: 2.0046284198760986, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1001/10000, Training Loss: 18.532129287719727, Training Accuracy: 0.5686274509803921, Validation Loss: 28.662399291992188, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1002/10000, Training Loss: 10.599124908447266, Training Accuracy: 0.6151960784313726, Validation Loss: 7.0347747802734375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1003/10000, Training Loss: 19.63347816467285, Training Accuracy: 0.5343137254901961, Validation Loss: 15.310713768005371, Validation Accuracy: 0.5\n",
      "Epoch 1004/10000, Training Loss: 22.409772872924805, Training Accuracy: 0.4877450980392157, Validation Loss: 3.2993876934051514, Validation Accuracy: 0.5\n",
      "Epoch 1005/10000, Training Loss: 19.677387237548828, Training Accuracy: 0.5392156862745098, Validation Loss: 9.485873222351074, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1006/10000, Training Loss: 11.010836601257324, Training Accuracy: 0.5024509803921569, Validation Loss: 9.709431648254395, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1007/10000, Training Loss: 22.891599655151367, Training Accuracy: 0.5294117647058824, Validation Loss: 8.335603713989258, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1008/10000, Training Loss: 9.764369010925293, Training Accuracy: 0.5759803921568627, Validation Loss: 17.266769409179688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1009/10000, Training Loss: 15.17595100402832, Training Accuracy: 0.4950980392156863, Validation Loss: 71.0408706665039, Validation Accuracy: 0.25\n",
      "Epoch 1010/10000, Training Loss: 5.102237701416016, Training Accuracy: 0.5073529411764706, Validation Loss: 5.473913669586182, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1011/10000, Training Loss: 9.802409172058105, Training Accuracy: 0.6053921568627451, Validation Loss: 16.340389251708984, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1012/10000, Training Loss: 11.382606506347656, Training Accuracy: 0.5784313725490197, Validation Loss: 21.500703811645508, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1013/10000, Training Loss: 25.861982345581055, Training Accuracy: 0.4852941176470588, Validation Loss: 34.956199645996094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1014/10000, Training Loss: 25.33451271057129, Training Accuracy: 0.5318627450980392, Validation Loss: 36.664581298828125, Validation Accuracy: 0.25\n",
      "Epoch 1015/10000, Training Loss: 7.176496505737305, Training Accuracy: 0.5857843137254902, Validation Loss: 5.563041687011719, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1016/10000, Training Loss: 13.468720436096191, Training Accuracy: 0.5465686274509803, Validation Loss: 23.353506088256836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1017/10000, Training Loss: 11.474173545837402, Training Accuracy: 0.4485294117647059, Validation Loss: 5.8056159019470215, Validation Accuracy: 0.25\n",
      "Epoch 1018/10000, Training Loss: 17.868663787841797, Training Accuracy: 0.5686274509803921, Validation Loss: 4.8849053382873535, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1019/10000, Training Loss: 25.864717483520508, Training Accuracy: 0.6004901960784313, Validation Loss: 21.580286026000977, Validation Accuracy: 0.5\n",
      "Epoch 1020/10000, Training Loss: 4.569132328033447, Training Accuracy: 0.571078431372549, Validation Loss: 9.174302101135254, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1021/10000, Training Loss: 16.230222702026367, Training Accuracy: 0.553921568627451, Validation Loss: 23.725446701049805, Validation Accuracy: 0.25\n",
      "Epoch 1022/10000, Training Loss: 10.622764587402344, Training Accuracy: 0.5392156862745098, Validation Loss: 3.598520517349243, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1023/10000, Training Loss: 21.915727615356445, Training Accuracy: 0.5490196078431373, Validation Loss: 6.2762451171875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1024/10000, Training Loss: 10.320232391357422, Training Accuracy: 0.5490196078431373, Validation Loss: 16.82317543029785, Validation Accuracy: 0.5\n",
      "Epoch 1025/10000, Training Loss: 12.946799278259277, Training Accuracy: 0.571078431372549, Validation Loss: 36.69093704223633, Validation Accuracy: 0.5\n",
      "Epoch 1026/10000, Training Loss: 13.591035842895508, Training Accuracy: 0.5220588235294118, Validation Loss: 26.441612243652344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1027/10000, Training Loss: 11.66555404663086, Training Accuracy: 0.6102941176470589, Validation Loss: 14.893406867980957, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1028/10000, Training Loss: 10.9074068069458, Training Accuracy: 0.5784313725490197, Validation Loss: 3.35473895072937, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1029/10000, Training Loss: 17.404144287109375, Training Accuracy: 0.5441176470588235, Validation Loss: 30.778274536132812, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1030/10000, Training Loss: 11.331257820129395, Training Accuracy: 0.5392156862745098, Validation Loss: 3.87176513671875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1031/10000, Training Loss: 16.029356002807617, Training Accuracy: 0.5147058823529411, Validation Loss: 12.348201751708984, Validation Accuracy: 0.75\n",
      "Epoch 1032/10000, Training Loss: 15.61440658569336, Training Accuracy: 0.5416666666666666, Validation Loss: 19.689407348632812, Validation Accuracy: 0.5\n",
      "Epoch 1033/10000, Training Loss: 13.258779525756836, Training Accuracy: 0.5759803921568627, Validation Loss: 1.9922709465026855, Validation Accuracy: 0.5\n",
      "Epoch 1034/10000, Training Loss: 21.299819946289062, Training Accuracy: 0.5416666666666666, Validation Loss: 47.226070404052734, Validation Accuracy: 0.5\n",
      "Epoch 1035/10000, Training Loss: 10.016517639160156, Training Accuracy: 0.5441176470588235, Validation Loss: 15.668819427490234, Validation Accuracy: 0.75\n",
      "Epoch 1036/10000, Training Loss: 16.67594337463379, Training Accuracy: 0.5294117647058824, Validation Loss: 16.53373908996582, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1037/10000, Training Loss: 15.713103294372559, Training Accuracy: 0.5514705882352942, Validation Loss: 17.477670669555664, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1038/10000, Training Loss: 13.549599647521973, Training Accuracy: 0.5637254901960784, Validation Loss: 12.2633695602417, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1039/10000, Training Loss: 26.246423721313477, Training Accuracy: 0.5196078431372549, Validation Loss: 3.4044992923736572, Validation Accuracy: 0.75\n",
      "Epoch 1040/10000, Training Loss: 18.66335678100586, Training Accuracy: 0.5049019607843137, Validation Loss: 19.226716995239258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1041/10000, Training Loss: 9.79845905303955, Training Accuracy: 0.6446078431372549, Validation Loss: 48.929378509521484, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1042/10000, Training Loss: 12.708584785461426, Training Accuracy: 0.5465686274509803, Validation Loss: 4.367336273193359, Validation Accuracy: 0.5\n",
      "Epoch 1043/10000, Training Loss: 16.618667602539062, Training Accuracy: 0.5808823529411765, Validation Loss: 24.78277587890625, Validation Accuracy: 0.5\n",
      "Epoch 1044/10000, Training Loss: 7.652153968811035, Training Accuracy: 0.5759803921568627, Validation Loss: 4.10922908782959, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1045/10000, Training Loss: 20.47408103942871, Training Accuracy: 0.5980392156862745, Validation Loss: 36.02538299560547, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1046/10000, Training Loss: 17.11264419555664, Training Accuracy: 0.6299019607843137, Validation Loss: 77.74366760253906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1047/10000, Training Loss: 11.699942588806152, Training Accuracy: 0.5441176470588235, Validation Loss: 10.752800941467285, Validation Accuracy: 0.5\n",
      "Epoch 1048/10000, Training Loss: 15.688789367675781, Training Accuracy: 0.5759803921568627, Validation Loss: 5.659677505493164, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1049/10000, Training Loss: 25.757644653320312, Training Accuracy: 0.5735294117647058, Validation Loss: 51.07765579223633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1050/10000, Training Loss: 21.725934982299805, Training Accuracy: 0.5049019607843137, Validation Loss: 10.559417724609375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1051/10000, Training Loss: 13.633047103881836, Training Accuracy: 0.553921568627451, Validation Loss: 25.302675247192383, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1052/10000, Training Loss: 13.263680458068848, Training Accuracy: 0.5833333333333334, Validation Loss: 7.256533145904541, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1053/10000, Training Loss: 9.737980842590332, Training Accuracy: 0.6102941176470589, Validation Loss: 15.469649314880371, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1054/10000, Training Loss: 22.75675392150879, Training Accuracy: 0.4338235294117647, Validation Loss: 12.951998710632324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1055/10000, Training Loss: 14.013300895690918, Training Accuracy: 0.5196078431372549, Validation Loss: 32.91120910644531, Validation Accuracy: 0.25\n",
      "Epoch 1056/10000, Training Loss: 21.061891555786133, Training Accuracy: 0.5367647058823529, Validation Loss: 6.209959506988525, Validation Accuracy: 0.75\n",
      "Epoch 1057/10000, Training Loss: 21.21234893798828, Training Accuracy: 0.5465686274509803, Validation Loss: 15.073040008544922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1058/10000, Training Loss: 11.979693412780762, Training Accuracy: 0.5, Validation Loss: 1.5395649671554565, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1059/10000, Training Loss: 10.733559608459473, Training Accuracy: 0.6102941176470589, Validation Loss: 25.241609573364258, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1060/10000, Training Loss: 17.600099563598633, Training Accuracy: 0.5514705882352942, Validation Loss: 51.21260452270508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1061/10000, Training Loss: 13.198884963989258, Training Accuracy: 0.5441176470588235, Validation Loss: 39.46515655517578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1062/10000, Training Loss: 13.427495002746582, Training Accuracy: 0.5122549019607843, Validation Loss: 6.235523223876953, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1063/10000, Training Loss: 26.928163528442383, Training Accuracy: 0.5416666666666666, Validation Loss: 55.17304992675781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1064/10000, Training Loss: 12.618167877197266, Training Accuracy: 0.4803921568627451, Validation Loss: 11.651679039001465, Validation Accuracy: 0.25\n",
      "Epoch 1065/10000, Training Loss: 20.185258865356445, Training Accuracy: 0.5857843137254902, Validation Loss: 15.002453804016113, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1066/10000, Training Loss: 11.494608879089355, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7049164772033691, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1067/10000, Training Loss: 15.581318855285645, Training Accuracy: 0.5735294117647058, Validation Loss: 25.3172550201416, Validation Accuracy: 0.5\n",
      "Epoch 1068/10000, Training Loss: 9.209322929382324, Training Accuracy: 0.5759803921568627, Validation Loss: 14.7954740524292, Validation Accuracy: 0.5\n",
      "Epoch 1069/10000, Training Loss: 21.324565887451172, Training Accuracy: 0.5220588235294118, Validation Loss: 24.031843185424805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1070/10000, Training Loss: 19.299232482910156, Training Accuracy: 0.5049019607843137, Validation Loss: 13.417815208435059, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1071/10000, Training Loss: 24.604705810546875, Training Accuracy: 0.5318627450980392, Validation Loss: 53.37275695800781, Validation Accuracy: 0.0\n",
      "Epoch 1072/10000, Training Loss: 11.84780502319336, Training Accuracy: 0.5, Validation Loss: 18.170883178710938, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1073/10000, Training Loss: 9.05147647857666, Training Accuracy: 0.6029411764705882, Validation Loss: 6.892796039581299, Validation Accuracy: 0.5\n",
      "Epoch 1074/10000, Training Loss: 21.505849838256836, Training Accuracy: 0.571078431372549, Validation Loss: 17.919950485229492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1075/10000, Training Loss: 22.38252067565918, Training Accuracy: 0.4852941176470588, Validation Loss: 4.996846675872803, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1076/10000, Training Loss: 8.168641090393066, Training Accuracy: 0.571078431372549, Validation Loss: 14.513739585876465, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1077/10000, Training Loss: 13.40352725982666, Training Accuracy: 0.4950980392156863, Validation Loss: 3.00942063331604, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1078/10000, Training Loss: 14.13329792022705, Training Accuracy: 0.5514705882352942, Validation Loss: 57.51441955566406, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1079/10000, Training Loss: 22.666885375976562, Training Accuracy: 0.5833333333333334, Validation Loss: 99.03621673583984, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1080/10000, Training Loss: 7.077737331390381, Training Accuracy: 0.5098039215686274, Validation Loss: 8.131951332092285, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1081/10000, Training Loss: 21.445924758911133, Training Accuracy: 0.5637254901960784, Validation Loss: 11.541430473327637, Validation Accuracy: 0.5\n",
      "Epoch 1082/10000, Training Loss: 6.70110559463501, Training Accuracy: 0.5833333333333334, Validation Loss: 4.654876232147217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1083/10000, Training Loss: 19.315624237060547, Training Accuracy: 0.5612745098039216, Validation Loss: 24.12883186340332, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1084/10000, Training Loss: 11.255853652954102, Training Accuracy: 0.5441176470588235, Validation Loss: 4.537481784820557, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1085/10000, Training Loss: 20.32489776611328, Training Accuracy: 0.5514705882352942, Validation Loss: 47.29338455200195, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1086/10000, Training Loss: 21.090831756591797, Training Accuracy: 0.5637254901960784, Validation Loss: 3.843372106552124, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1087/10000, Training Loss: 14.409477233886719, Training Accuracy: 0.5318627450980392, Validation Loss: 6.590638637542725, Validation Accuracy: 0.5\n",
      "Epoch 1088/10000, Training Loss: 31.5989933013916, Training Accuracy: 0.5441176470588235, Validation Loss: 27.155532836914062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1089/10000, Training Loss: 15.039968490600586, Training Accuracy: 0.5122549019607843, Validation Loss: 9.031851768493652, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1090/10000, Training Loss: 13.306940078735352, Training Accuracy: 0.5318627450980392, Validation Loss: 14.16508960723877, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1091/10000, Training Loss: 17.180604934692383, Training Accuracy: 0.5857843137254902, Validation Loss: 47.038700103759766, Validation Accuracy: 0.5\n",
      "Epoch 1092/10000, Training Loss: 17.4384822845459, Training Accuracy: 0.5882352941176471, Validation Loss: 51.43717956542969, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1093/10000, Training Loss: 25.606060028076172, Training Accuracy: 0.5931372549019608, Validation Loss: 8.546706199645996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1094/10000, Training Loss: 25.390914916992188, Training Accuracy: 0.5147058823529411, Validation Loss: 22.958688735961914, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1095/10000, Training Loss: 13.158332824707031, Training Accuracy: 0.571078431372549, Validation Loss: 5.408172607421875, Validation Accuracy: 0.5\n",
      "Epoch 1096/10000, Training Loss: 15.401094436645508, Training Accuracy: 0.5808823529411765, Validation Loss: 13.19321060180664, Validation Accuracy: 0.75\n",
      "Epoch 1097/10000, Training Loss: 19.14263916015625, Training Accuracy: 0.5122549019607843, Validation Loss: 11.442843437194824, Validation Accuracy: 0.5\n",
      "Epoch 1098/10000, Training Loss: 12.544301986694336, Training Accuracy: 0.5833333333333334, Validation Loss: 12.21810245513916, Validation Accuracy: 0.25\n",
      "Epoch 1099/10000, Training Loss: 9.746782302856445, Training Accuracy: 0.5465686274509803, Validation Loss: 22.50160789489746, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1100/10000, Training Loss: 10.632121086120605, Training Accuracy: 0.6029411764705882, Validation Loss: 4.504177570343018, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1101/10000, Training Loss: 20.255199432373047, Training Accuracy: 0.5637254901960784, Validation Loss: 37.47068405151367, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1102/10000, Training Loss: 14.473332405090332, Training Accuracy: 0.5343137254901961, Validation Loss: 23.075210571289062, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1103/10000, Training Loss: 14.104219436645508, Training Accuracy: 0.5147058823529411, Validation Loss: 7.046747207641602, Validation Accuracy: 0.5\n",
      "Epoch 1104/10000, Training Loss: 40.709468841552734, Training Accuracy: 0.5049019607843137, Validation Loss: 39.57204818725586, Validation Accuracy: 0.5\n",
      "Epoch 1105/10000, Training Loss: 11.654940605163574, Training Accuracy: 0.5882352941176471, Validation Loss: 16.824831008911133, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1106/10000, Training Loss: 10.397212028503418, Training Accuracy: 0.5563725490196079, Validation Loss: 0.6616373658180237, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1107/10000, Training Loss: 24.68412208557129, Training Accuracy: 0.5294117647058824, Validation Loss: 23.938814163208008, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1108/10000, Training Loss: 21.223100662231445, Training Accuracy: 0.5147058823529411, Validation Loss: 8.517720222473145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1109/10000, Training Loss: 7.963266372680664, Training Accuracy: 0.5588235294117647, Validation Loss: 6.418386459350586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1110/10000, Training Loss: 23.79116439819336, Training Accuracy: 0.5318627450980392, Validation Loss: 3.6255428791046143, Validation Accuracy: 0.5\n",
      "Epoch 1111/10000, Training Loss: 9.839670181274414, Training Accuracy: 0.5931372549019608, Validation Loss: 16.61746597290039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1112/10000, Training Loss: 15.564702033996582, Training Accuracy: 0.5784313725490197, Validation Loss: 26.042617797851562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1113/10000, Training Loss: 11.946039199829102, Training Accuracy: 0.5514705882352942, Validation Loss: 3.6159279346466064, Validation Accuracy: 0.75\n",
      "Epoch 1114/10000, Training Loss: 14.071415901184082, Training Accuracy: 0.6078431372549019, Validation Loss: 5.909712314605713, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1115/10000, Training Loss: 15.652822494506836, Training Accuracy: 0.5833333333333334, Validation Loss: 31.034652709960938, Validation Accuracy: 0.25\n",
      "Epoch 1116/10000, Training Loss: 26.10480308532715, Training Accuracy: 0.5441176470588235, Validation Loss: 64.81017303466797, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1117/10000, Training Loss: 19.91013526916504, Training Accuracy: 0.5367647058823529, Validation Loss: 67.05387115478516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1118/10000, Training Loss: 11.918706893920898, Training Accuracy: 0.5073529411764706, Validation Loss: 5.9752726554870605, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1119/10000, Training Loss: 16.638059616088867, Training Accuracy: 0.5735294117647058, Validation Loss: 69.77529907226562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1120/10000, Training Loss: 8.814108848571777, Training Accuracy: 0.5563725490196079, Validation Loss: 7.051577091217041, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1121/10000, Training Loss: 10.520846366882324, Training Accuracy: 0.5514705882352942, Validation Loss: 15.813380241394043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1122/10000, Training Loss: 14.264845848083496, Training Accuracy: 0.5637254901960784, Validation Loss: 29.75345802307129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1123/10000, Training Loss: 17.070241928100586, Training Accuracy: 0.5906862745098039, Validation Loss: 1.5721330642700195, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1124/10000, Training Loss: 13.08961009979248, Training Accuracy: 0.4877450980392157, Validation Loss: 29.195329666137695, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1125/10000, Training Loss: 20.639019012451172, Training Accuracy: 0.5588235294117647, Validation Loss: 95.3472671508789, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1126/10000, Training Loss: 11.361708641052246, Training Accuracy: 0.553921568627451, Validation Loss: 7.888690948486328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1127/10000, Training Loss: 19.29914665222168, Training Accuracy: 0.5833333333333334, Validation Loss: 21.58043098449707, Validation Accuracy: 0.5\n",
      "Epoch 1128/10000, Training Loss: 13.93189525604248, Training Accuracy: 0.5343137254901961, Validation Loss: 40.20442581176758, Validation Accuracy: 0.5\n",
      "Epoch 1129/10000, Training Loss: 27.86665916442871, Training Accuracy: 0.5269607843137255, Validation Loss: 16.071378707885742, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1130/10000, Training Loss: 7.747371673583984, Training Accuracy: 0.553921568627451, Validation Loss: 10.30562973022461, Validation Accuracy: 0.5\n",
      "Epoch 1131/10000, Training Loss: 16.473485946655273, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8779745101928711, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1132/10000, Training Loss: 7.948580265045166, Training Accuracy: 0.5196078431372549, Validation Loss: 6.2747626304626465, Validation Accuracy: 0.5\n",
      "Epoch 1133/10000, Training Loss: 8.859472274780273, Training Accuracy: 0.5686274509803921, Validation Loss: 5.776059627532959, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1134/10000, Training Loss: 12.063212394714355, Training Accuracy: 0.5833333333333334, Validation Loss: 40.83816909790039, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1135/10000, Training Loss: 6.873081684112549, Training Accuracy: 0.5808823529411765, Validation Loss: 8.163286209106445, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1136/10000, Training Loss: 17.694089889526367, Training Accuracy: 0.5661764705882353, Validation Loss: 65.78324890136719, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1137/10000, Training Loss: 13.992905616760254, Training Accuracy: 0.5857843137254902, Validation Loss: 20.382471084594727, Validation Accuracy: 0.5\n",
      "Epoch 1138/10000, Training Loss: 18.99729347229004, Training Accuracy: 0.5833333333333334, Validation Loss: 186.5407257080078, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1139/10000, Training Loss: 10.231689453125, Training Accuracy: 0.6029411764705882, Validation Loss: 6.042314529418945, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1140/10000, Training Loss: 6.390768527984619, Training Accuracy: 0.6102941176470589, Validation Loss: 8.35651683807373, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1141/10000, Training Loss: 10.042245864868164, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9091551303863525, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1142/10000, Training Loss: 17.519027709960938, Training Accuracy: 0.5416666666666666, Validation Loss: 8.674919128417969, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1143/10000, Training Loss: 20.90439224243164, Training Accuracy: 0.5171568627450981, Validation Loss: 32.007816314697266, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1144/10000, Training Loss: 22.517860412597656, Training Accuracy: 0.47794117647058826, Validation Loss: 9.459545135498047, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1145/10000, Training Loss: 11.960914611816406, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8719028830528259, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1146/10000, Training Loss: 22.232872009277344, Training Accuracy: 0.5906862745098039, Validation Loss: 4.427781105041504, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1147/10000, Training Loss: 25.973257064819336, Training Accuracy: 0.5245098039215687, Validation Loss: 13.665209770202637, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1148/10000, Training Loss: 11.24229621887207, Training Accuracy: 0.5637254901960784, Validation Loss: 24.962156295776367, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1149/10000, Training Loss: 22.73105812072754, Training Accuracy: 0.6225490196078431, Validation Loss: 10.66688060760498, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1150/10000, Training Loss: 23.536548614501953, Training Accuracy: 0.5196078431372549, Validation Loss: 24.194419860839844, Validation Accuracy: 0.5\n",
      "Epoch 1151/10000, Training Loss: 8.600646018981934, Training Accuracy: 0.5808823529411765, Validation Loss: 5.463283538818359, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1152/10000, Training Loss: 11.408915519714355, Training Accuracy: 0.5931372549019608, Validation Loss: 39.48569869995117, Validation Accuracy: 0.25\n",
      "Epoch 1153/10000, Training Loss: 14.683795928955078, Training Accuracy: 0.5269607843137255, Validation Loss: 6.082544326782227, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1154/10000, Training Loss: 9.232809066772461, Training Accuracy: 0.5465686274509803, Validation Loss: 28.182411193847656, Validation Accuracy: 0.25\n",
      "Epoch 1155/10000, Training Loss: 19.08527374267578, Training Accuracy: 0.5098039215686274, Validation Loss: 12.277745246887207, Validation Accuracy: 0.25\n",
      "Epoch 1156/10000, Training Loss: 17.869037628173828, Training Accuracy: 0.5147058823529411, Validation Loss: 3.807323694229126, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1157/10000, Training Loss: 11.389959335327148, Training Accuracy: 0.5343137254901961, Validation Loss: 14.00900936126709, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1158/10000, Training Loss: 15.033429145812988, Training Accuracy: 0.5245098039215687, Validation Loss: 7.875524044036865, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1159/10000, Training Loss: 31.799718856811523, Training Accuracy: 0.5686274509803921, Validation Loss: 21.83190155029297, Validation Accuracy: 0.25\n",
      "Epoch 1160/10000, Training Loss: 13.162697792053223, Training Accuracy: 0.5171568627450981, Validation Loss: 35.1303825378418, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1161/10000, Training Loss: 19.951414108276367, Training Accuracy: 0.5588235294117647, Validation Loss: 11.396659851074219, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1162/10000, Training Loss: 14.653263092041016, Training Accuracy: 0.5343137254901961, Validation Loss: 7.851687908172607, Validation Accuracy: 0.5\n",
      "Epoch 1163/10000, Training Loss: 11.97656536102295, Training Accuracy: 0.5735294117647058, Validation Loss: 10.557870864868164, Validation Accuracy: 0.5\n",
      "Epoch 1164/10000, Training Loss: 6.567193031311035, Training Accuracy: 0.6053921568627451, Validation Loss: 5.979190826416016, Validation Accuracy: 0.5\n",
      "Epoch 1165/10000, Training Loss: 16.85575294494629, Training Accuracy: 0.5563725490196079, Validation Loss: 34.6049919128418, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1166/10000, Training Loss: 12.615874290466309, Training Accuracy: 0.5294117647058824, Validation Loss: 13.927186012268066, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1167/10000, Training Loss: 16.364288330078125, Training Accuracy: 0.6102941176470589, Validation Loss: 2.9187326431274414, Validation Accuracy: 0.75\n",
      "Epoch 1168/10000, Training Loss: 9.734509468078613, Training Accuracy: 0.5735294117647058, Validation Loss: 26.452669143676758, Validation Accuracy: 0.25\n",
      "Epoch 1169/10000, Training Loss: 13.800211906433105, Training Accuracy: 0.5637254901960784, Validation Loss: 22.805330276489258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1170/10000, Training Loss: 7.455062389373779, Training Accuracy: 0.49019607843137253, Validation Loss: 9.273216247558594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1171/10000, Training Loss: 14.328225135803223, Training Accuracy: 0.5490196078431373, Validation Loss: 16.295839309692383, Validation Accuracy: 0.5\n",
      "Epoch 1172/10000, Training Loss: 8.622725486755371, Training Accuracy: 0.5759803921568627, Validation Loss: 11.320732116699219, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1173/10000, Training Loss: 12.240450859069824, Training Accuracy: 0.5686274509803921, Validation Loss: 20.35413360595703, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1174/10000, Training Loss: 8.826641082763672, Training Accuracy: 0.5563725490196079, Validation Loss: 24.002962112426758, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1175/10000, Training Loss: 10.154239654541016, Training Accuracy: 0.553921568627451, Validation Loss: 12.146689414978027, Validation Accuracy: 0.5\n",
      "Epoch 1176/10000, Training Loss: 10.535494804382324, Training Accuracy: 0.5735294117647058, Validation Loss: 16.829282760620117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1177/10000, Training Loss: 21.11941909790039, Training Accuracy: 0.5661764705882353, Validation Loss: 29.573705673217773, Validation Accuracy: 0.5\n",
      "Epoch 1178/10000, Training Loss: 11.089336395263672, Training Accuracy: 0.5416666666666666, Validation Loss: 7.36789083480835, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1179/10000, Training Loss: 17.658714294433594, Training Accuracy: 0.5147058823529411, Validation Loss: 42.177860260009766, Validation Accuracy: 0.5\n",
      "Epoch 1180/10000, Training Loss: 16.690263748168945, Training Accuracy: 0.5098039215686274, Validation Loss: 10.028250694274902, Validation Accuracy: 0.25\n",
      "Epoch 1181/10000, Training Loss: 11.272708892822266, Training Accuracy: 0.5269607843137255, Validation Loss: 14.501019477844238, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1182/10000, Training Loss: 18.44985580444336, Training Accuracy: 0.5588235294117647, Validation Loss: 9.289692878723145, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1183/10000, Training Loss: 14.39999771118164, Training Accuracy: 0.6102941176470589, Validation Loss: 4.981802463531494, Validation Accuracy: 0.5\n",
      "Epoch 1184/10000, Training Loss: 9.319622993469238, Training Accuracy: 0.5465686274509803, Validation Loss: 5.878557205200195, Validation Accuracy: 0.75\n",
      "Epoch 1185/10000, Training Loss: 11.667121887207031, Training Accuracy: 0.5955882352941176, Validation Loss: 9.775301933288574, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1186/10000, Training Loss: 8.326987266540527, Training Accuracy: 0.5906862745098039, Validation Loss: 38.09170913696289, Validation Accuracy: 0.25\n",
      "Epoch 1187/10000, Training Loss: 13.00146484375, Training Accuracy: 0.5147058823529411, Validation Loss: 7.829624652862549, Validation Accuracy: 0.25\n",
      "Epoch 1188/10000, Training Loss: 8.431219100952148, Training Accuracy: 0.5465686274509803, Validation Loss: 4.101602077484131, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1189/10000, Training Loss: 12.455561637878418, Training Accuracy: 0.5882352941176471, Validation Loss: 4.011963844299316, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1190/10000, Training Loss: 41.414512634277344, Training Accuracy: 0.5980392156862745, Validation Loss: 36.331199645996094, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1191/10000, Training Loss: 8.39362621307373, Training Accuracy: 0.5637254901960784, Validation Loss: 2.9051265716552734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1192/10000, Training Loss: 17.41188621520996, Training Accuracy: 0.5392156862745098, Validation Loss: 12.349922180175781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1193/10000, Training Loss: 7.322344779968262, Training Accuracy: 0.5759803921568627, Validation Loss: 8.111783027648926, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1194/10000, Training Loss: 15.361181259155273, Training Accuracy: 0.5269607843137255, Validation Loss: 7.213795185089111, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1195/10000, Training Loss: 9.879552841186523, Training Accuracy: 0.5833333333333334, Validation Loss: 8.850825309753418, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1196/10000, Training Loss: 14.351561546325684, Training Accuracy: 0.5612745098039216, Validation Loss: 6.472294330596924, Validation Accuracy: 0.5\n",
      "Epoch 1197/10000, Training Loss: 24.7486515045166, Training Accuracy: 0.5147058823529411, Validation Loss: 25.862464904785156, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1198/10000, Training Loss: 11.624680519104004, Training Accuracy: 0.6078431372549019, Validation Loss: 41.051658630371094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1199/10000, Training Loss: 17.694637298583984, Training Accuracy: 0.5784313725490197, Validation Loss: 33.78984451293945, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1200/10000, Training Loss: 20.486343383789062, Training Accuracy: 0.6151960784313726, Validation Loss: 5.129983901977539, Validation Accuracy: 0.5\n",
      "Epoch 1201/10000, Training Loss: 13.776684761047363, Training Accuracy: 0.49019607843137253, Validation Loss: 8.961007118225098, Validation Accuracy: 0.25\n",
      "Epoch 1202/10000, Training Loss: 11.286638259887695, Training Accuracy: 0.5294117647058824, Validation Loss: 12.031546592712402, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1203/10000, Training Loss: 7.399616241455078, Training Accuracy: 0.625, Validation Loss: 16.21629524230957, Validation Accuracy: 0.5\n",
      "Epoch 1204/10000, Training Loss: 8.347886085510254, Training Accuracy: 0.6004901960784313, Validation Loss: 2.7673330307006836, Validation Accuracy: 0.5\n",
      "Epoch 1205/10000, Training Loss: 14.716416358947754, Training Accuracy: 0.4632352941176471, Validation Loss: 24.03843879699707, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1206/10000, Training Loss: 6.709342956542969, Training Accuracy: 0.5759803921568627, Validation Loss: 8.67622184753418, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1207/10000, Training Loss: 13.716754913330078, Training Accuracy: 0.5392156862745098, Validation Loss: 44.53034591674805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1208/10000, Training Loss: 11.493873596191406, Training Accuracy: 0.5367647058823529, Validation Loss: 17.52164649963379, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1209/10000, Training Loss: 8.121760368347168, Training Accuracy: 0.5, Validation Loss: 6.065820217132568, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1210/10000, Training Loss: 12.373653411865234, Training Accuracy: 0.4730392156862745, Validation Loss: 6.052671909332275, Validation Accuracy: 0.5\n",
      "Epoch 1211/10000, Training Loss: 9.341024398803711, Training Accuracy: 0.5514705882352942, Validation Loss: 25.352880477905273, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1212/10000, Training Loss: 13.632538795471191, Training Accuracy: 0.5784313725490197, Validation Loss: 2.4982974529266357, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1213/10000, Training Loss: 17.724191665649414, Training Accuracy: 0.5637254901960784, Validation Loss: 11.158392906188965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1214/10000, Training Loss: 22.86617660522461, Training Accuracy: 0.4583333333333333, Validation Loss: 25.044328689575195, Validation Accuracy: 0.25\n",
      "Epoch 1215/10000, Training Loss: 11.838225364685059, Training Accuracy: 0.5588235294117647, Validation Loss: 9.314248085021973, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1216/10000, Training Loss: 21.105234146118164, Training Accuracy: 0.49754901960784315, Validation Loss: 12.017261505126953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1217/10000, Training Loss: 11.81478214263916, Training Accuracy: 0.553921568627451, Validation Loss: 9.912846565246582, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1218/10000, Training Loss: 12.072700500488281, Training Accuracy: 0.5661764705882353, Validation Loss: 14.813103675842285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1219/10000, Training Loss: 10.24758243560791, Training Accuracy: 0.5686274509803921, Validation Loss: 14.088458061218262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1220/10000, Training Loss: 11.02987003326416, Training Accuracy: 0.5490196078431373, Validation Loss: 14.664179801940918, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1221/10000, Training Loss: 15.042819023132324, Training Accuracy: 0.5612745098039216, Validation Loss: 5.7698974609375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1222/10000, Training Loss: 11.405488014221191, Training Accuracy: 0.5661764705882353, Validation Loss: 14.009720802307129, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1223/10000, Training Loss: 13.354248046875, Training Accuracy: 0.5514705882352942, Validation Loss: 9.963857650756836, Validation Accuracy: 0.5\n",
      "Epoch 1224/10000, Training Loss: 11.410400390625, Training Accuracy: 0.49754901960784315, Validation Loss: 31.832204818725586, Validation Accuracy: 0.5\n",
      "Epoch 1225/10000, Training Loss: 12.645151138305664, Training Accuracy: 0.5196078431372549, Validation Loss: 8.114638328552246, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1226/10000, Training Loss: 25.243595123291016, Training Accuracy: 0.5980392156862745, Validation Loss: 13.258994102478027, Validation Accuracy: 0.5\n",
      "Epoch 1227/10000, Training Loss: 29.30620574951172, Training Accuracy: 0.5416666666666666, Validation Loss: 20.247779846191406, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1228/10000, Training Loss: 8.106306076049805, Training Accuracy: 0.48284313725490197, Validation Loss: 41.1517448425293, Validation Accuracy: 0.5\n",
      "Epoch 1229/10000, Training Loss: 9.47993278503418, Training Accuracy: 0.5465686274509803, Validation Loss: 10.033873558044434, Validation Accuracy: 0.5\n",
      "Epoch 1230/10000, Training Loss: 9.537797927856445, Training Accuracy: 0.5294117647058824, Validation Loss: 3.049381971359253, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1231/10000, Training Loss: 22.65131950378418, Training Accuracy: 0.49754901960784315, Validation Loss: 8.387838363647461, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1232/10000, Training Loss: 16.795637130737305, Training Accuracy: 0.5563725490196079, Validation Loss: 13.017562866210938, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1233/10000, Training Loss: 15.93066120147705, Training Accuracy: 0.4877450980392157, Validation Loss: 18.885835647583008, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1234/10000, Training Loss: 7.704753875732422, Training Accuracy: 0.6029411764705882, Validation Loss: 2.003643751144409, Validation Accuracy: 0.5\n",
      "Epoch 1235/10000, Training Loss: 7.762194633483887, Training Accuracy: 0.5269607843137255, Validation Loss: 14.112663269042969, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1236/10000, Training Loss: 9.59504222869873, Training Accuracy: 0.5588235294117647, Validation Loss: 3.329429864883423, Validation Accuracy: 0.75\n",
      "Epoch 1237/10000, Training Loss: 14.341111183166504, Training Accuracy: 0.5857843137254902, Validation Loss: 17.42643165588379, Validation Accuracy: 0.25\n",
      "Epoch 1238/10000, Training Loss: 26.94907569885254, Training Accuracy: 0.5171568627450981, Validation Loss: 79.91944885253906, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1239/10000, Training Loss: 12.59316635131836, Training Accuracy: 0.5416666666666666, Validation Loss: 66.34839630126953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1240/10000, Training Loss: 6.666575908660889, Training Accuracy: 0.6200980392156863, Validation Loss: 3.373271942138672, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1241/10000, Training Loss: 10.835103034973145, Training Accuracy: 0.5588235294117647, Validation Loss: 5.979325771331787, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1242/10000, Training Loss: 16.073835372924805, Training Accuracy: 0.5245098039215687, Validation Loss: 20.675228118896484, Validation Accuracy: 0.25\n",
      "Epoch 1243/10000, Training Loss: 21.822509765625, Training Accuracy: 0.5416666666666666, Validation Loss: 21.567235946655273, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1244/10000, Training Loss: 19.013118743896484, Training Accuracy: 0.5343137254901961, Validation Loss: 15.065208435058594, Validation Accuracy: 0.25\n",
      "Epoch 1245/10000, Training Loss: 24.33195686340332, Training Accuracy: 0.5, Validation Loss: 19.526472091674805, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1246/10000, Training Loss: 14.625611305236816, Training Accuracy: 0.49019607843137253, Validation Loss: 20.83648109436035, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1247/10000, Training Loss: 12.174592018127441, Training Accuracy: 0.5784313725490197, Validation Loss: 8.80066967010498, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1248/10000, Training Loss: 10.989152908325195, Training Accuracy: 0.5441176470588235, Validation Loss: 33.41398239135742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1249/10000, Training Loss: 15.604857444763184, Training Accuracy: 0.5980392156862745, Validation Loss: 23.382017135620117, Validation Accuracy: 0.5\n",
      "Epoch 1250/10000, Training Loss: 10.323256492614746, Training Accuracy: 0.5, Validation Loss: 8.808021545410156, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1251/10000, Training Loss: 8.90198802947998, Training Accuracy: 0.5612745098039216, Validation Loss: 18.18396759033203, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1252/10000, Training Loss: 10.815422058105469, Training Accuracy: 0.5955882352941176, Validation Loss: 37.35756301879883, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1253/10000, Training Loss: 20.69681167602539, Training Accuracy: 0.5612745098039216, Validation Loss: 15.7258939743042, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1254/10000, Training Loss: 10.335914611816406, Training Accuracy: 0.5955882352941176, Validation Loss: 13.138274192810059, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1255/10000, Training Loss: 9.350232124328613, Training Accuracy: 0.553921568627451, Validation Loss: 10.648165702819824, Validation Accuracy: 0.5\n",
      "Epoch 1256/10000, Training Loss: 21.154834747314453, Training Accuracy: 0.6372549019607843, Validation Loss: 40.06611251831055, Validation Accuracy: 0.5\n",
      "Epoch 1257/10000, Training Loss: 17.782270431518555, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7785045504570007, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1258/10000, Training Loss: 9.269644737243652, Training Accuracy: 0.5490196078431373, Validation Loss: 14.00125503540039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1259/10000, Training Loss: 13.230265617370605, Training Accuracy: 0.5931372549019608, Validation Loss: 65.0415267944336, Validation Accuracy: 0.5\n",
      "Epoch 1260/10000, Training Loss: 6.487181186676025, Training Accuracy: 0.5735294117647058, Validation Loss: 19.307588577270508, Validation Accuracy: 0.5\n",
      "Epoch 1261/10000, Training Loss: 17.327409744262695, Training Accuracy: 0.6421568627450981, Validation Loss: 27.197105407714844, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1262/10000, Training Loss: 23.078584671020508, Training Accuracy: 0.4485294117647059, Validation Loss: 14.210357666015625, Validation Accuracy: 0.5\n",
      "Epoch 1263/10000, Training Loss: 11.094491004943848, Training Accuracy: 0.6127450980392157, Validation Loss: 31.655221939086914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1264/10000, Training Loss: 11.925326347351074, Training Accuracy: 0.6519607843137255, Validation Loss: 4.952628135681152, Validation Accuracy: 0.5\n",
      "Epoch 1265/10000, Training Loss: 8.336431503295898, Training Accuracy: 0.49019607843137253, Validation Loss: 10.243542671203613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1266/10000, Training Loss: 11.413662910461426, Training Accuracy: 0.5196078431372549, Validation Loss: 6.172544956207275, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1267/10000, Training Loss: 16.55716896057129, Training Accuracy: 0.5661764705882353, Validation Loss: 2.6975295543670654, Validation Accuracy: 0.75\n",
      "Epoch 1268/10000, Training Loss: 12.636460304260254, Training Accuracy: 0.5343137254901961, Validation Loss: 5.186511039733887, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1269/10000, Training Loss: 8.044637680053711, Training Accuracy: 0.5392156862745098, Validation Loss: 6.716161251068115, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1270/10000, Training Loss: 10.03591251373291, Training Accuracy: 0.5171568627450981, Validation Loss: 10.796279907226562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1271/10000, Training Loss: 12.344518661499023, Training Accuracy: 0.5441176470588235, Validation Loss: 14.624545097351074, Validation Accuracy: 0.5\n",
      "Epoch 1272/10000, Training Loss: 12.255064964294434, Training Accuracy: 0.47058823529411764, Validation Loss: 8.970703125, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1273/10000, Training Loss: 11.100685119628906, Training Accuracy: 0.5269607843137255, Validation Loss: 12.743633270263672, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1274/10000, Training Loss: 16.006114959716797, Training Accuracy: 0.5612745098039216, Validation Loss: 11.743134498596191, Validation Accuracy: 0.5\n",
      "Epoch 1275/10000, Training Loss: 21.77911949157715, Training Accuracy: 0.553921568627451, Validation Loss: 35.794403076171875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1276/10000, Training Loss: 8.78669261932373, Training Accuracy: 0.5563725490196079, Validation Loss: 3.909764528274536, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1277/10000, Training Loss: 17.948400497436523, Training Accuracy: 0.5563725490196079, Validation Loss: 22.594863891601562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1278/10000, Training Loss: 13.675579071044922, Training Accuracy: 0.5735294117647058, Validation Loss: 12.53246021270752, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1279/10000, Training Loss: 16.512537002563477, Training Accuracy: 0.5073529411764706, Validation Loss: 3.6831271648406982, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1280/10000, Training Loss: 17.668943405151367, Training Accuracy: 0.49264705882352944, Validation Loss: 10.261716842651367, Validation Accuracy: 0.5\n",
      "Epoch 1281/10000, Training Loss: 11.430481910705566, Training Accuracy: 0.5269607843137255, Validation Loss: 2.7015483379364014, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1282/10000, Training Loss: 10.185890197753906, Training Accuracy: 0.6078431372549019, Validation Loss: 14.486376762390137, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1283/10000, Training Loss: 17.89652442932129, Training Accuracy: 0.5563725490196079, Validation Loss: 44.891998291015625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1284/10000, Training Loss: 21.958515167236328, Training Accuracy: 0.5392156862745098, Validation Loss: 13.680153846740723, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1285/10000, Training Loss: 17.11539077758789, Training Accuracy: 0.5220588235294118, Validation Loss: 25.843780517578125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1286/10000, Training Loss: 17.820594787597656, Training Accuracy: 0.5465686274509803, Validation Loss: 23.898399353027344, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1287/10000, Training Loss: 23.275659561157227, Training Accuracy: 0.5367647058823529, Validation Loss: 6.095545291900635, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1288/10000, Training Loss: 9.041430473327637, Training Accuracy: 0.5073529411764706, Validation Loss: 29.686269760131836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1289/10000, Training Loss: 9.597227096557617, Training Accuracy: 0.5759803921568627, Validation Loss: 5.964216709136963, Validation Accuracy: 0.5\n",
      "Epoch 1290/10000, Training Loss: 13.881025314331055, Training Accuracy: 0.5612745098039216, Validation Loss: 10.549891471862793, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1291/10000, Training Loss: 16.973255157470703, Training Accuracy: 0.5318627450980392, Validation Loss: 34.33617401123047, Validation Accuracy: 0.5\n",
      "Epoch 1292/10000, Training Loss: 9.742565155029297, Training Accuracy: 0.5759803921568627, Validation Loss: 22.230066299438477, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1293/10000, Training Loss: 24.04062843322754, Training Accuracy: 0.6127450980392157, Validation Loss: 207.3361053466797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1294/10000, Training Loss: 12.004463195800781, Training Accuracy: 0.5416666666666666, Validation Loss: 11.030938148498535, Validation Accuracy: 0.75\n",
      "Epoch 1295/10000, Training Loss: 9.083885192871094, Training Accuracy: 0.5980392156862745, Validation Loss: 4.344233989715576, Validation Accuracy: 0.5\n",
      "Epoch 1296/10000, Training Loss: 6.888702869415283, Training Accuracy: 0.5759803921568627, Validation Loss: 8.355096817016602, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1297/10000, Training Loss: 13.56843376159668, Training Accuracy: 0.5465686274509803, Validation Loss: 35.19573974609375, Validation Accuracy: 0.5\n",
      "Epoch 1298/10000, Training Loss: 6.141489505767822, Training Accuracy: 0.5808823529411765, Validation Loss: 10.55931282043457, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1299/10000, Training Loss: 19.00986671447754, Training Accuracy: 0.49754901960784315, Validation Loss: 31.52176856994629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1300/10000, Training Loss: 9.658291816711426, Training Accuracy: 0.553921568627451, Validation Loss: 13.293848991394043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1301/10000, Training Loss: 6.638216018676758, Training Accuracy: 0.5588235294117647, Validation Loss: 6.515679836273193, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1302/10000, Training Loss: 9.290613174438477, Training Accuracy: 0.5367647058823529, Validation Loss: 10.83409595489502, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1303/10000, Training Loss: 13.542828559875488, Training Accuracy: 0.47549019607843135, Validation Loss: 23.87819480895996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1304/10000, Training Loss: 7.5948486328125, Training Accuracy: 0.571078431372549, Validation Loss: 10.636932373046875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1305/10000, Training Loss: 11.405584335327148, Training Accuracy: 0.5980392156862745, Validation Loss: 12.72900676727295, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1306/10000, Training Loss: 17.224950790405273, Training Accuracy: 0.5147058823529411, Validation Loss: 12.512557983398438, Validation Accuracy: 0.5\n",
      "Epoch 1307/10000, Training Loss: 9.94453239440918, Training Accuracy: 0.5661764705882353, Validation Loss: 28.072389602661133, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1308/10000, Training Loss: 6.235053539276123, Training Accuracy: 0.5269607843137255, Validation Loss: 13.47303295135498, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1309/10000, Training Loss: 8.575460433959961, Training Accuracy: 0.5833333333333334, Validation Loss: 8.08941650390625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1310/10000, Training Loss: 18.323549270629883, Training Accuracy: 0.5441176470588235, Validation Loss: 6.494276523590088, Validation Accuracy: 0.25\n",
      "Epoch 1311/10000, Training Loss: 18.132719039916992, Training Accuracy: 0.4803921568627451, Validation Loss: 25.945829391479492, Validation Accuracy: 0.5\n",
      "Epoch 1312/10000, Training Loss: 6.350578784942627, Training Accuracy: 0.5833333333333334, Validation Loss: 2.180666446685791, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1313/10000, Training Loss: 23.333786010742188, Training Accuracy: 0.5612745098039216, Validation Loss: 26.540468215942383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1314/10000, Training Loss: 11.15886116027832, Training Accuracy: 0.5563725490196079, Validation Loss: 16.756628036499023, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1315/10000, Training Loss: 12.37677001953125, Training Accuracy: 0.5294117647058824, Validation Loss: 5.156949520111084, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1316/10000, Training Loss: 10.721272468566895, Training Accuracy: 0.5343137254901961, Validation Loss: 27.33538055419922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1317/10000, Training Loss: 10.786624908447266, Training Accuracy: 0.5465686274509803, Validation Loss: 9.183484077453613, Validation Accuracy: 0.5\n",
      "Epoch 1318/10000, Training Loss: 18.52375030517578, Training Accuracy: 0.5367647058823529, Validation Loss: 21.76788902282715, Validation Accuracy: 0.5\n",
      "Epoch 1319/10000, Training Loss: 8.027149200439453, Training Accuracy: 0.5563725490196079, Validation Loss: 10.624903678894043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1320/10000, Training Loss: 19.345327377319336, Training Accuracy: 0.5416666666666666, Validation Loss: 18.768680572509766, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1321/10000, Training Loss: 17.230607986450195, Training Accuracy: 0.5612745098039216, Validation Loss: 15.318377494812012, Validation Accuracy: 0.5\n",
      "Epoch 1322/10000, Training Loss: 7.817210674285889, Training Accuracy: 0.5367647058823529, Validation Loss: 12.861577033996582, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1323/10000, Training Loss: 13.957505226135254, Training Accuracy: 0.5147058823529411, Validation Loss: 6.408864498138428, Validation Accuracy: 0.5\n",
      "Epoch 1324/10000, Training Loss: 17.054351806640625, Training Accuracy: 0.5514705882352942, Validation Loss: 43.359832763671875, Validation Accuracy: 0.5\n",
      "Epoch 1325/10000, Training Loss: 25.36466407775879, Training Accuracy: 0.5931372549019608, Validation Loss: 19.923982620239258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1326/10000, Training Loss: 10.429766654968262, Training Accuracy: 0.6127450980392157, Validation Loss: 8.927276611328125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1327/10000, Training Loss: 13.829623222351074, Training Accuracy: 0.5490196078431373, Validation Loss: 12.320916175842285, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1328/10000, Training Loss: 10.987619400024414, Training Accuracy: 0.5098039215686274, Validation Loss: 7.350430965423584, Validation Accuracy: 0.5\n",
      "Epoch 1329/10000, Training Loss: 11.630095481872559, Training Accuracy: 0.5465686274509803, Validation Loss: 17.118547439575195, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1330/10000, Training Loss: 15.47400188446045, Training Accuracy: 0.5196078431372549, Validation Loss: 16.471723556518555, Validation Accuracy: 0.5\n",
      "Epoch 1331/10000, Training Loss: 15.477816581726074, Training Accuracy: 0.49264705882352944, Validation Loss: 15.754844665527344, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1332/10000, Training Loss: 10.661026000976562, Training Accuracy: 0.571078431372549, Validation Loss: 13.935142517089844, Validation Accuracy: 0.5\n",
      "Epoch 1333/10000, Training Loss: 17.386720657348633, Training Accuracy: 0.5784313725490197, Validation Loss: 11.383171081542969, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1334/10000, Training Loss: 11.045991897583008, Training Accuracy: 0.5416666666666666, Validation Loss: 11.516491889953613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1335/10000, Training Loss: 9.00741958618164, Training Accuracy: 0.5784313725490197, Validation Loss: 14.072054862976074, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1336/10000, Training Loss: 13.499155044555664, Training Accuracy: 0.5833333333333334, Validation Loss: 17.349021911621094, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1337/10000, Training Loss: 13.084534645080566, Training Accuracy: 0.5441176470588235, Validation Loss: 5.938384532928467, Validation Accuracy: 0.5\n",
      "Epoch 1338/10000, Training Loss: 8.068049430847168, Training Accuracy: 0.5441176470588235, Validation Loss: 4.936764717102051, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1339/10000, Training Loss: 15.997812271118164, Training Accuracy: 0.5931372549019608, Validation Loss: 36.38821792602539, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1340/10000, Training Loss: 27.695228576660156, Training Accuracy: 0.5465686274509803, Validation Loss: 10.858360290527344, Validation Accuracy: 0.5\n",
      "Epoch 1341/10000, Training Loss: 8.156577110290527, Training Accuracy: 0.5612745098039216, Validation Loss: 11.542494773864746, Validation Accuracy: 0.5\n",
      "Epoch 1342/10000, Training Loss: 21.44912338256836, Training Accuracy: 0.5392156862745098, Validation Loss: 10.823729515075684, Validation Accuracy: 0.25\n",
      "Epoch 1343/10000, Training Loss: 11.207358360290527, Training Accuracy: 0.5220588235294118, Validation Loss: 25.72185707092285, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1344/10000, Training Loss: 12.208442687988281, Training Accuracy: 0.5269607843137255, Validation Loss: 26.91571617126465, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1345/10000, Training Loss: 10.600624084472656, Training Accuracy: 0.5514705882352942, Validation Loss: 15.355533599853516, Validation Accuracy: 0.5\n",
      "Epoch 1346/10000, Training Loss: 7.848714351654053, Training Accuracy: 0.5784313725490197, Validation Loss: 10.78375244140625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1347/10000, Training Loss: 8.639915466308594, Training Accuracy: 0.5612745098039216, Validation Loss: 5.079512596130371, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1348/10000, Training Loss: 12.632614135742188, Training Accuracy: 0.4852941176470588, Validation Loss: 18.163074493408203, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1349/10000, Training Loss: 10.234097480773926, Training Accuracy: 0.5514705882352942, Validation Loss: 8.538959503173828, Validation Accuracy: 0.5\n",
      "Epoch 1350/10000, Training Loss: 7.158891201019287, Training Accuracy: 0.5465686274509803, Validation Loss: 1.6239081621170044, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1351/10000, Training Loss: 12.465202331542969, Training Accuracy: 0.5367647058823529, Validation Loss: 31.841279983520508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1352/10000, Training Loss: 9.805303573608398, Training Accuracy: 0.5318627450980392, Validation Loss: 4.296560287475586, Validation Accuracy: 0.5\n",
      "Epoch 1353/10000, Training Loss: 14.028775215148926, Training Accuracy: 0.5465686274509803, Validation Loss: 33.19783401489258, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1354/10000, Training Loss: 16.0440616607666, Training Accuracy: 0.5245098039215687, Validation Loss: 16.290672302246094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1355/10000, Training Loss: 13.020024299621582, Training Accuracy: 0.5955882352941176, Validation Loss: 29.395944595336914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1356/10000, Training Loss: 37.20676040649414, Training Accuracy: 0.4803921568627451, Validation Loss: 52.0341682434082, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1357/10000, Training Loss: 9.83802318572998, Training Accuracy: 0.5245098039215687, Validation Loss: 9.97287654876709, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1358/10000, Training Loss: 11.84660530090332, Training Accuracy: 0.5416666666666666, Validation Loss: 10.784037590026855, Validation Accuracy: 0.5\n",
      "Epoch 1359/10000, Training Loss: 12.10986042022705, Training Accuracy: 0.5049019607843137, Validation Loss: 41.85593795776367, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1360/10000, Training Loss: 11.558273315429688, Training Accuracy: 0.4877450980392157, Validation Loss: 30.322423934936523, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1361/10000, Training Loss: 13.3366060256958, Training Accuracy: 0.5392156862745098, Validation Loss: 8.714119911193848, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1362/10000, Training Loss: 7.515021800994873, Training Accuracy: 0.5759803921568627, Validation Loss: 4.042879581451416, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1363/10000, Training Loss: 10.580975532531738, Training Accuracy: 0.6053921568627451, Validation Loss: 7.257937908172607, Validation Accuracy: 0.75\n",
      "Epoch 1364/10000, Training Loss: 30.979351043701172, Training Accuracy: 0.5392156862745098, Validation Loss: 33.61668014526367, Validation Accuracy: 0.25\n",
      "Epoch 1365/10000, Training Loss: 18.656042098999023, Training Accuracy: 0.5563725490196079, Validation Loss: 19.95268440246582, Validation Accuracy: 0.5\n",
      "Epoch 1366/10000, Training Loss: 14.601591110229492, Training Accuracy: 0.5073529411764706, Validation Loss: 15.817097663879395, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1367/10000, Training Loss: 9.596153259277344, Training Accuracy: 0.4950980392156863, Validation Loss: 7.405168533325195, Validation Accuracy: 0.5\n",
      "Epoch 1368/10000, Training Loss: 14.898710250854492, Training Accuracy: 0.5441176470588235, Validation Loss: 37.38002014160156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1369/10000, Training Loss: 10.954750061035156, Training Accuracy: 0.5931372549019608, Validation Loss: 10.31430721282959, Validation Accuracy: 0.5\n",
      "Epoch 1370/10000, Training Loss: 12.335022926330566, Training Accuracy: 0.6127450980392157, Validation Loss: 5.197339057922363, Validation Accuracy: 0.75\n",
      "Epoch 1371/10000, Training Loss: 13.182796478271484, Training Accuracy: 0.5784313725490197, Validation Loss: 22.351930618286133, Validation Accuracy: 0.25\n",
      "Epoch 1372/10000, Training Loss: 14.591748237609863, Training Accuracy: 0.5269607843137255, Validation Loss: 8.35573673248291, Validation Accuracy: 0.75\n",
      "Epoch 1373/10000, Training Loss: 16.846982955932617, Training Accuracy: 0.5588235294117647, Validation Loss: 12.10473346710205, Validation Accuracy: 0.25\n",
      "Epoch 1374/10000, Training Loss: 11.961552619934082, Training Accuracy: 0.5098039215686274, Validation Loss: 6.423330307006836, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1375/10000, Training Loss: 11.841081619262695, Training Accuracy: 0.5343137254901961, Validation Loss: 15.3826265335083, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1376/10000, Training Loss: 19.76029396057129, Training Accuracy: 0.5490196078431373, Validation Loss: 15.03382396697998, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1377/10000, Training Loss: 9.07381820678711, Training Accuracy: 0.5196078431372549, Validation Loss: 11.804306983947754, Validation Accuracy: 0.5\n",
      "Epoch 1378/10000, Training Loss: 10.827073097229004, Training Accuracy: 0.6151960784313726, Validation Loss: 8.822646141052246, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1379/10000, Training Loss: 11.033658027648926, Training Accuracy: 0.5343137254901961, Validation Loss: 25.70924949645996, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1380/10000, Training Loss: 14.892290115356445, Training Accuracy: 0.5441176470588235, Validation Loss: 10.49596881866455, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1381/10000, Training Loss: 13.22260570526123, Training Accuracy: 0.6004901960784313, Validation Loss: 19.52997589111328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1382/10000, Training Loss: 8.641522407531738, Training Accuracy: 0.5196078431372549, Validation Loss: 4.27479887008667, Validation Accuracy: 0.5\n",
      "Epoch 1383/10000, Training Loss: 7.17409610748291, Training Accuracy: 0.5759803921568627, Validation Loss: 21.20854377746582, Validation Accuracy: 0.5\n",
      "Epoch 1384/10000, Training Loss: 5.224156379699707, Training Accuracy: 0.6078431372549019, Validation Loss: 3.7838802337646484, Validation Accuracy: 0.5\n",
      "Epoch 1385/10000, Training Loss: 6.640737056732178, Training Accuracy: 0.5955882352941176, Validation Loss: 28.88947105407715, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1386/10000, Training Loss: 11.877411842346191, Training Accuracy: 0.5759803921568627, Validation Loss: 15.370654106140137, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1387/10000, Training Loss: 13.18288803100586, Training Accuracy: 0.5367647058823529, Validation Loss: 16.745359420776367, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1388/10000, Training Loss: 11.399127960205078, Training Accuracy: 0.5049019607843137, Validation Loss: 1.633083701133728, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1389/10000, Training Loss: 9.764789581298828, Training Accuracy: 0.5735294117647058, Validation Loss: 14.6830472946167, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1390/10000, Training Loss: 8.278924942016602, Training Accuracy: 0.5980392156862745, Validation Loss: 7.962438106536865, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1391/10000, Training Loss: 7.277091979980469, Training Accuracy: 0.5563725490196079, Validation Loss: 18.9805965423584, Validation Accuracy: 0.25\n",
      "Epoch 1392/10000, Training Loss: 8.20510482788086, Training Accuracy: 0.5416666666666666, Validation Loss: 3.3278884887695312, Validation Accuracy: 0.75\n",
      "Epoch 1393/10000, Training Loss: 12.352404594421387, Training Accuracy: 0.5220588235294118, Validation Loss: 27.87108612060547, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1394/10000, Training Loss: 15.804072380065918, Training Accuracy: 0.5857843137254902, Validation Loss: 26.603281021118164, Validation Accuracy: 0.5\n",
      "Epoch 1395/10000, Training Loss: 10.587162017822266, Training Accuracy: 0.571078431372549, Validation Loss: 25.560884475708008, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1396/10000, Training Loss: 11.72960090637207, Training Accuracy: 0.5367647058823529, Validation Loss: 19.31342124938965, Validation Accuracy: 0.5\n",
      "Epoch 1397/10000, Training Loss: 20.592906951904297, Training Accuracy: 0.5612745098039216, Validation Loss: 5.882405757904053, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1398/10000, Training Loss: 6.536048889160156, Training Accuracy: 0.5955882352941176, Validation Loss: 11.201458930969238, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1399/10000, Training Loss: 12.143234252929688, Training Accuracy: 0.5441176470588235, Validation Loss: 16.460308074951172, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1400/10000, Training Loss: 7.727242946624756, Training Accuracy: 0.5882352941176471, Validation Loss: 25.866851806640625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1401/10000, Training Loss: 9.0094575881958, Training Accuracy: 0.5073529411764706, Validation Loss: 52.1153678894043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1402/10000, Training Loss: 16.2633113861084, Training Accuracy: 0.5955882352941176, Validation Loss: 24.98110008239746, Validation Accuracy: 0.5\n",
      "Epoch 1403/10000, Training Loss: 6.91398286819458, Training Accuracy: 0.553921568627451, Validation Loss: 6.354547500610352, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1404/10000, Training Loss: 19.1707706451416, Training Accuracy: 0.5294117647058824, Validation Loss: 2.6263771057128906, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1405/10000, Training Loss: 10.85450553894043, Training Accuracy: 0.6029411764705882, Validation Loss: 22.5882625579834, Validation Accuracy: 0.5\n",
      "Epoch 1406/10000, Training Loss: 13.25920581817627, Training Accuracy: 0.5759803921568627, Validation Loss: 14.242804527282715, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1407/10000, Training Loss: 11.071633338928223, Training Accuracy: 0.5637254901960784, Validation Loss: 78.26793670654297, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1408/10000, Training Loss: 18.238534927368164, Training Accuracy: 0.5931372549019608, Validation Loss: 77.3385009765625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1409/10000, Training Loss: 9.77126407623291, Training Accuracy: 0.5, Validation Loss: 17.673917770385742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1410/10000, Training Loss: 5.987588405609131, Training Accuracy: 0.5759803921568627, Validation Loss: 0.2506731450557709, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 1411/10000, Training Loss: 10.01643180847168, Training Accuracy: 0.48284313725490197, Validation Loss: 11.652787208557129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1412/10000, Training Loss: 13.937365531921387, Training Accuracy: 0.6151960784313726, Validation Loss: 15.069535255432129, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1413/10000, Training Loss: 9.538727760314941, Training Accuracy: 0.5441176470588235, Validation Loss: 17.804590225219727, Validation Accuracy: 0.5\n",
      "Epoch 1414/10000, Training Loss: 23.01193618774414, Training Accuracy: 0.6470588235294118, Validation Loss: 34.78341293334961, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1415/10000, Training Loss: 15.64314079284668, Training Accuracy: 0.5122549019607843, Validation Loss: 25.674890518188477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1416/10000, Training Loss: 12.499369621276855, Training Accuracy: 0.5612745098039216, Validation Loss: 10.680732727050781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1417/10000, Training Loss: 14.33368968963623, Training Accuracy: 0.6004901960784313, Validation Loss: 19.262529373168945, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1418/10000, Training Loss: 6.56557559967041, Training Accuracy: 0.5661764705882353, Validation Loss: 7.370002746582031, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1419/10000, Training Loss: 4.940300464630127, Training Accuracy: 0.5784313725490197, Validation Loss: 4.660894393920898, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1420/10000, Training Loss: 19.224441528320312, Training Accuracy: 0.5147058823529411, Validation Loss: 15.7050199508667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1421/10000, Training Loss: 20.26894187927246, Training Accuracy: 0.5073529411764706, Validation Loss: 17.238588333129883, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1422/10000, Training Loss: 11.131078720092773, Training Accuracy: 0.571078431372549, Validation Loss: 18.731815338134766, Validation Accuracy: 0.5\n",
      "Epoch 1423/10000, Training Loss: 5.517954349517822, Training Accuracy: 0.48284313725490197, Validation Loss: 4.516907691955566, Validation Accuracy: 0.5\n",
      "Epoch 1424/10000, Training Loss: 15.226550102233887, Training Accuracy: 0.5661764705882353, Validation Loss: 17.402780532836914, Validation Accuracy: 0.5\n",
      "Epoch 1425/10000, Training Loss: 27.974477767944336, Training Accuracy: 0.5906862745098039, Validation Loss: 17.041902542114258, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1426/10000, Training Loss: 9.160343170166016, Training Accuracy: 0.6053921568627451, Validation Loss: 14.552641868591309, Validation Accuracy: 0.5\n",
      "Epoch 1427/10000, Training Loss: 6.819138050079346, Training Accuracy: 0.571078431372549, Validation Loss: 3.9863898754119873, Validation Accuracy: 0.5\n",
      "Epoch 1428/10000, Training Loss: 10.163469314575195, Training Accuracy: 0.5931372549019608, Validation Loss: 14.434085845947266, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1429/10000, Training Loss: 13.010408401489258, Training Accuracy: 0.5465686274509803, Validation Loss: 49.48196792602539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1430/10000, Training Loss: 18.862417221069336, Training Accuracy: 0.5147058823529411, Validation Loss: 64.70063781738281, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1431/10000, Training Loss: 10.499887466430664, Training Accuracy: 0.5784313725490197, Validation Loss: 9.522652626037598, Validation Accuracy: 0.5\n",
      "Epoch 1432/10000, Training Loss: 6.836293697357178, Training Accuracy: 0.553921568627451, Validation Loss: 8.515578269958496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1433/10000, Training Loss: 16.003408432006836, Training Accuracy: 0.5122549019607843, Validation Loss: 7.82876443862915, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1434/10000, Training Loss: 8.053412437438965, Training Accuracy: 0.6495098039215687, Validation Loss: 55.53886413574219, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1435/10000, Training Loss: 10.483670234680176, Training Accuracy: 0.5612745098039216, Validation Loss: 13.605202674865723, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1436/10000, Training Loss: 12.398902893066406, Training Accuracy: 0.5931372549019608, Validation Loss: 10.93945598602295, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1437/10000, Training Loss: 10.426170349121094, Training Accuracy: 0.5784313725490197, Validation Loss: 10.712496757507324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1438/10000, Training Loss: 15.66308307647705, Training Accuracy: 0.4877450980392157, Validation Loss: 18.030771255493164, Validation Accuracy: 0.25\n",
      "Epoch 1439/10000, Training Loss: 7.688911437988281, Training Accuracy: 0.5588235294117647, Validation Loss: 25.82132911682129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1440/10000, Training Loss: 10.343167304992676, Training Accuracy: 0.5514705882352942, Validation Loss: 9.139229774475098, Validation Accuracy: 0.75\n",
      "Epoch 1441/10000, Training Loss: 8.817727088928223, Training Accuracy: 0.553921568627451, Validation Loss: 10.618302345275879, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1442/10000, Training Loss: 11.045297622680664, Training Accuracy: 0.49754901960784315, Validation Loss: 33.51533889770508, Validation Accuracy: 0.25\n",
      "Epoch 1443/10000, Training Loss: 12.145288467407227, Training Accuracy: 0.5392156862745098, Validation Loss: 8.541768074035645, Validation Accuracy: 0.5\n",
      "Epoch 1444/10000, Training Loss: 14.264841079711914, Training Accuracy: 0.5196078431372549, Validation Loss: 11.1122407913208, Validation Accuracy: 0.5\n",
      "Epoch 1445/10000, Training Loss: 30.64237403869629, Training Accuracy: 0.5392156862745098, Validation Loss: 15.263930320739746, Validation Accuracy: 0.25\n",
      "Epoch 1446/10000, Training Loss: 21.336219787597656, Training Accuracy: 0.553921568627451, Validation Loss: 8.968348503112793, Validation Accuracy: 0.25\n",
      "Epoch 1447/10000, Training Loss: 11.600510597229004, Training Accuracy: 0.5318627450980392, Validation Loss: 21.317893981933594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1448/10000, Training Loss: 9.704998970031738, Training Accuracy: 0.5367647058823529, Validation Loss: 10.937690734863281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1449/10000, Training Loss: 12.741196632385254, Training Accuracy: 0.5661764705882353, Validation Loss: 9.921034812927246, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1450/10000, Training Loss: 10.013989448547363, Training Accuracy: 0.5857843137254902, Validation Loss: 10.262767791748047, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1451/10000, Training Loss: 12.337126731872559, Training Accuracy: 0.5392156862745098, Validation Loss: 4.692983627319336, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1452/10000, Training Loss: 11.46626091003418, Training Accuracy: 0.5759803921568627, Validation Loss: 9.546981811523438, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1453/10000, Training Loss: 7.483112335205078, Training Accuracy: 0.5759803921568627, Validation Loss: 7.979343891143799, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1454/10000, Training Loss: 6.888436794281006, Training Accuracy: 0.5735294117647058, Validation Loss: 20.729745864868164, Validation Accuracy: 0.5\n",
      "Epoch 1455/10000, Training Loss: 14.920348167419434, Training Accuracy: 0.553921568627451, Validation Loss: 45.07265090942383, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1456/10000, Training Loss: 9.46822738647461, Training Accuracy: 0.5392156862745098, Validation Loss: 13.223121643066406, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1457/10000, Training Loss: 8.27432918548584, Training Accuracy: 0.5514705882352942, Validation Loss: 3.4246346950531006, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1458/10000, Training Loss: 7.014371395111084, Training Accuracy: 0.5367647058823529, Validation Loss: 5.5321502685546875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1459/10000, Training Loss: 7.411738872528076, Training Accuracy: 0.6004901960784313, Validation Loss: 15.24559497833252, Validation Accuracy: 0.25\n",
      "Epoch 1460/10000, Training Loss: 11.83199405670166, Training Accuracy: 0.5955882352941176, Validation Loss: 7.072710037231445, Validation Accuracy: 0.5\n",
      "Epoch 1461/10000, Training Loss: 9.435545921325684, Training Accuracy: 0.6176470588235294, Validation Loss: 7.185371398925781, Validation Accuracy: 0.5\n",
      "Epoch 1462/10000, Training Loss: 9.98161792755127, Training Accuracy: 0.5490196078431373, Validation Loss: 33.156925201416016, Validation Accuracy: 0.75\n",
      "Epoch 1463/10000, Training Loss: 7.882408618927002, Training Accuracy: 0.5098039215686274, Validation Loss: 12.423895835876465, Validation Accuracy: 0.5\n",
      "Epoch 1464/10000, Training Loss: 7.325907230377197, Training Accuracy: 0.571078431372549, Validation Loss: 18.245206832885742, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1465/10000, Training Loss: 10.086701393127441, Training Accuracy: 0.5294117647058824, Validation Loss: 21.882558822631836, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1466/10000, Training Loss: 10.665627479553223, Training Accuracy: 0.6127450980392157, Validation Loss: 18.442487716674805, Validation Accuracy: 0.5\n",
      "Epoch 1467/10000, Training Loss: 7.641608715057373, Training Accuracy: 0.6053921568627451, Validation Loss: 38.41265106201172, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1468/10000, Training Loss: 9.402851104736328, Training Accuracy: 0.5049019607843137, Validation Loss: 16.184656143188477, Validation Accuracy: 0.5\n",
      "Epoch 1469/10000, Training Loss: 9.99307918548584, Training Accuracy: 0.5857843137254902, Validation Loss: 11.907248497009277, Validation Accuracy: 0.25\n",
      "Epoch 1470/10000, Training Loss: 12.447050094604492, Training Accuracy: 0.5612745098039216, Validation Loss: 20.963632583618164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1471/10000, Training Loss: 7.832743167877197, Training Accuracy: 0.5318627450980392, Validation Loss: 14.764901161193848, Validation Accuracy: 0.5\n",
      "Epoch 1472/10000, Training Loss: 10.031557083129883, Training Accuracy: 0.5490196078431373, Validation Loss: 10.87209701538086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1473/10000, Training Loss: 16.123456954956055, Training Accuracy: 0.5367647058823529, Validation Loss: 41.623374938964844, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1474/10000, Training Loss: 4.89492654800415, Training Accuracy: 0.5784313725490197, Validation Loss: 22.63568115234375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1475/10000, Training Loss: 11.128470420837402, Training Accuracy: 0.5318627450980392, Validation Loss: 5.937650203704834, Validation Accuracy: 0.5\n",
      "Epoch 1476/10000, Training Loss: 9.824501991271973, Training Accuracy: 0.5416666666666666, Validation Loss: 8.869847297668457, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1477/10000, Training Loss: 9.368799209594727, Training Accuracy: 0.5612745098039216, Validation Loss: 1.2362781763076782, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 1478/10000, Training Loss: 9.404494285583496, Training Accuracy: 0.5784313725490197, Validation Loss: 11.915786743164062, Validation Accuracy: 0.5\n",
      "Epoch 1479/10000, Training Loss: 14.196980476379395, Training Accuracy: 0.5122549019607843, Validation Loss: 13.375866889953613, Validation Accuracy: 0.5\n",
      "Epoch 1480/10000, Training Loss: 11.377113342285156, Training Accuracy: 0.6102941176470589, Validation Loss: 15.057934761047363, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1481/10000, Training Loss: 11.44218921661377, Training Accuracy: 0.5490196078431373, Validation Loss: 10.919156074523926, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1482/10000, Training Loss: 12.318217277526855, Training Accuracy: 0.5294117647058824, Validation Loss: 14.94036865234375, Validation Accuracy: 0.5\n",
      "Epoch 1483/10000, Training Loss: 8.501517295837402, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7385739684104919, Validation Accuracy: 0.75\n",
      "Epoch 1484/10000, Training Loss: 8.734782218933105, Training Accuracy: 0.5367647058823529, Validation Loss: 11.130378723144531, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1485/10000, Training Loss: 6.846956253051758, Training Accuracy: 0.571078431372549, Validation Loss: 14.030326843261719, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1486/10000, Training Loss: 11.474407196044922, Training Accuracy: 0.5857843137254902, Validation Loss: 3.3737123012542725, Validation Accuracy: 0.75\n",
      "Epoch 1487/10000, Training Loss: 10.937997817993164, Training Accuracy: 0.6299019607843137, Validation Loss: 50.097198486328125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1488/10000, Training Loss: 6.450909614562988, Training Accuracy: 0.6004901960784313, Validation Loss: 20.57475471496582, Validation Accuracy: 0.25\n",
      "Epoch 1489/10000, Training Loss: 8.93675708770752, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0877763032913208, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1490/10000, Training Loss: 13.274625778198242, Training Accuracy: 0.6078431372549019, Validation Loss: 18.854272842407227, Validation Accuracy: 0.5\n",
      "Epoch 1491/10000, Training Loss: 11.397644996643066, Training Accuracy: 0.5784313725490197, Validation Loss: 12.226387023925781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1492/10000, Training Loss: 10.543822288513184, Training Accuracy: 0.6053921568627451, Validation Loss: 29.87196922302246, Validation Accuracy: 0.5\n",
      "Epoch 1493/10000, Training Loss: 9.180681228637695, Training Accuracy: 0.5196078431372549, Validation Loss: 24.38893699645996, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1494/10000, Training Loss: 16.406755447387695, Training Accuracy: 0.5906862745098039, Validation Loss: 12.05530071258545, Validation Accuracy: 0.5\n",
      "Epoch 1495/10000, Training Loss: 7.29198694229126, Training Accuracy: 0.4950980392156863, Validation Loss: 9.277238845825195, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1496/10000, Training Loss: 9.198365211486816, Training Accuracy: 0.5220588235294118, Validation Loss: 13.332768440246582, Validation Accuracy: 0.75\n",
      "Epoch 1497/10000, Training Loss: 10.560528755187988, Training Accuracy: 0.5416666666666666, Validation Loss: 3.4296562671661377, Validation Accuracy: 0.5\n",
      "Epoch 1498/10000, Training Loss: 5.633687496185303, Training Accuracy: 0.5147058823529411, Validation Loss: 4.906968593597412, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1499/10000, Training Loss: 16.59889793395996, Training Accuracy: 0.6029411764705882, Validation Loss: 30.48419952392578, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1500/10000, Training Loss: 17.168197631835938, Training Accuracy: 0.6102941176470589, Validation Loss: 97.98904418945312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1501/10000, Training Loss: 6.357046127319336, Training Accuracy: 0.6151960784313726, Validation Loss: 7.59965181350708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1502/10000, Training Loss: 8.967415809631348, Training Accuracy: 0.6078431372549019, Validation Loss: 11.240023612976074, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1503/10000, Training Loss: 8.478558540344238, Training Accuracy: 0.5367647058823529, Validation Loss: 15.187076568603516, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1504/10000, Training Loss: 9.189312934875488, Training Accuracy: 0.5514705882352942, Validation Loss: 4.609620571136475, Validation Accuracy: 0.5\n",
      "Epoch 1505/10000, Training Loss: 8.962985038757324, Training Accuracy: 0.5, Validation Loss: 8.605672836303711, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1506/10000, Training Loss: 11.945608139038086, Training Accuracy: 0.6053921568627451, Validation Loss: 13.556522369384766, Validation Accuracy: 0.25\n",
      "Epoch 1507/10000, Training Loss: 5.51694393157959, Training Accuracy: 0.6053921568627451, Validation Loss: 9.634293556213379, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1508/10000, Training Loss: 11.420705795288086, Training Accuracy: 0.5490196078431373, Validation Loss: 9.585615158081055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1509/10000, Training Loss: 8.876304626464844, Training Accuracy: 0.5661764705882353, Validation Loss: 8.01897144317627, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1510/10000, Training Loss: 16.527502059936523, Training Accuracy: 0.5686274509803921, Validation Loss: 25.2484188079834, Validation Accuracy: 0.5\n",
      "Epoch 1511/10000, Training Loss: 11.843005180358887, Training Accuracy: 0.5857843137254902, Validation Loss: 10.11252212524414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1512/10000, Training Loss: 8.46479320526123, Training Accuracy: 0.5857843137254902, Validation Loss: 5.593743801116943, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1513/10000, Training Loss: 7.856076717376709, Training Accuracy: 0.46568627450980393, Validation Loss: 6.238332271575928, Validation Accuracy: 0.5\n",
      "Epoch 1514/10000, Training Loss: 12.790142059326172, Training Accuracy: 0.5367647058823529, Validation Loss: 6.697809219360352, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1515/10000, Training Loss: 9.133930206298828, Training Accuracy: 0.5759803921568627, Validation Loss: 13.458847045898438, Validation Accuracy: 0.5\n",
      "Epoch 1516/10000, Training Loss: 7.750180721282959, Training Accuracy: 0.6323529411764706, Validation Loss: 13.685465812683105, Validation Accuracy: 0.25\n",
      "Epoch 1517/10000, Training Loss: 9.19278335571289, Training Accuracy: 0.5392156862745098, Validation Loss: 4.701500415802002, Validation Accuracy: 0.5\n",
      "Epoch 1518/10000, Training Loss: 10.235088348388672, Training Accuracy: 0.5318627450980392, Validation Loss: 2.656019926071167, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1519/10000, Training Loss: 12.521127700805664, Training Accuracy: 0.5416666666666666, Validation Loss: 10.28284740447998, Validation Accuracy: 0.5\n",
      "Epoch 1520/10000, Training Loss: 16.467479705810547, Training Accuracy: 0.5563725490196079, Validation Loss: 17.919031143188477, Validation Accuracy: 0.5\n",
      "Epoch 1521/10000, Training Loss: 4.077525615692139, Training Accuracy: 0.6421568627450981, Validation Loss: 12.180312156677246, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1522/10000, Training Loss: 5.510275840759277, Training Accuracy: 0.5833333333333334, Validation Loss: 17.417585372924805, Validation Accuracy: 0.5\n",
      "Epoch 1523/10000, Training Loss: 7.13895320892334, Training Accuracy: 0.5686274509803921, Validation Loss: 22.783456802368164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1524/10000, Training Loss: 19.378307342529297, Training Accuracy: 0.6004901960784313, Validation Loss: 28.432565689086914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1525/10000, Training Loss: 7.416459560394287, Training Accuracy: 0.6029411764705882, Validation Loss: 16.91135597229004, Validation Accuracy: 0.5\n",
      "Epoch 1526/10000, Training Loss: 13.1246976852417, Training Accuracy: 0.5588235294117647, Validation Loss: 6.764228343963623, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1527/10000, Training Loss: 10.249732971191406, Training Accuracy: 0.5857843137254902, Validation Loss: 30.047332763671875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1528/10000, Training Loss: 17.895122528076172, Training Accuracy: 0.49019607843137253, Validation Loss: 5.0605788230896, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1529/10000, Training Loss: 12.134686470031738, Training Accuracy: 0.5735294117647058, Validation Loss: 6.894171237945557, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1530/10000, Training Loss: 18.287097930908203, Training Accuracy: 0.5294117647058824, Validation Loss: 51.61006546020508, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1531/10000, Training Loss: 5.934424877166748, Training Accuracy: 0.5098039215686274, Validation Loss: 7.899205684661865, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1532/10000, Training Loss: 9.254311561584473, Training Accuracy: 0.5441176470588235, Validation Loss: 29.59290313720703, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1533/10000, Training Loss: 9.911706924438477, Training Accuracy: 0.6127450980392157, Validation Loss: 14.963438987731934, Validation Accuracy: 0.25\n",
      "Epoch 1534/10000, Training Loss: 5.690174579620361, Training Accuracy: 0.625, Validation Loss: 4.234854221343994, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1535/10000, Training Loss: 10.83422565460205, Training Accuracy: 0.5931372549019608, Validation Loss: 27.827939987182617, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1536/10000, Training Loss: 6.944542407989502, Training Accuracy: 0.5833333333333334, Validation Loss: 18.88177490234375, Validation Accuracy: 0.25\n",
      "Epoch 1537/10000, Training Loss: 5.641111850738525, Training Accuracy: 0.6127450980392157, Validation Loss: 20.55630111694336, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1538/10000, Training Loss: 11.345622062683105, Training Accuracy: 0.5441176470588235, Validation Loss: 15.644810676574707, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1539/10000, Training Loss: 7.937530040740967, Training Accuracy: 0.5465686274509803, Validation Loss: 5.887042999267578, Validation Accuracy: 0.5\n",
      "Epoch 1540/10000, Training Loss: 12.715726852416992, Training Accuracy: 0.5392156862745098, Validation Loss: 18.37368392944336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1541/10000, Training Loss: 6.669583797454834, Training Accuracy: 0.5294117647058824, Validation Loss: 5.841630935668945, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1542/10000, Training Loss: 12.910710334777832, Training Accuracy: 0.5784313725490197, Validation Loss: 19.469425201416016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1543/10000, Training Loss: 11.523995399475098, Training Accuracy: 0.5147058823529411, Validation Loss: 11.752999305725098, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1544/10000, Training Loss: 12.732938766479492, Training Accuracy: 0.553921568627451, Validation Loss: 13.230494499206543, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1545/10000, Training Loss: 7.974143028259277, Training Accuracy: 0.5612745098039216, Validation Loss: 4.648000240325928, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1546/10000, Training Loss: 6.33107852935791, Training Accuracy: 0.5514705882352942, Validation Loss: 2.735442876815796, Validation Accuracy: 0.5\n",
      "Epoch 1547/10000, Training Loss: 15.249977111816406, Training Accuracy: 0.5098039215686274, Validation Loss: 20.212228775024414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1548/10000, Training Loss: 15.208181381225586, Training Accuracy: 0.553921568627451, Validation Loss: 10.09964370727539, Validation Accuracy: 0.75\n",
      "Epoch 1549/10000, Training Loss: 7.944880485534668, Training Accuracy: 0.5049019607843137, Validation Loss: 32.3734245300293, Validation Accuracy: 0.5\n",
      "Epoch 1550/10000, Training Loss: 11.570406913757324, Training Accuracy: 0.5441176470588235, Validation Loss: 9.276887893676758, Validation Accuracy: 0.5\n",
      "Epoch 1551/10000, Training Loss: 6.829082012176514, Training Accuracy: 0.571078431372549, Validation Loss: 13.7924165725708, Validation Accuracy: 0.5\n",
      "Epoch 1552/10000, Training Loss: 10.394368171691895, Training Accuracy: 0.5367647058823529, Validation Loss: 7.550518035888672, Validation Accuracy: 0.25\n",
      "Epoch 1553/10000, Training Loss: 9.697561264038086, Training Accuracy: 0.5686274509803921, Validation Loss: 6.205316066741943, Validation Accuracy: 0.5\n",
      "Epoch 1554/10000, Training Loss: 8.621383666992188, Training Accuracy: 0.5563725490196079, Validation Loss: 6.944555759429932, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1555/10000, Training Loss: 10.904145240783691, Training Accuracy: 0.5122549019607843, Validation Loss: 14.989021301269531, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1556/10000, Training Loss: 5.834220886230469, Training Accuracy: 0.5416666666666666, Validation Loss: 2.3231096267700195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1557/10000, Training Loss: 5.773129463195801, Training Accuracy: 0.5588235294117647, Validation Loss: 8.379104614257812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1558/10000, Training Loss: 9.292601585388184, Training Accuracy: 0.5122549019607843, Validation Loss: 15.270146369934082, Validation Accuracy: 0.5\n",
      "Epoch 1559/10000, Training Loss: 8.505571365356445, Training Accuracy: 0.5637254901960784, Validation Loss: 8.982895851135254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1560/10000, Training Loss: 11.271493911743164, Training Accuracy: 0.4803921568627451, Validation Loss: 4.433484077453613, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1561/10000, Training Loss: 7.208175182342529, Training Accuracy: 0.5196078431372549, Validation Loss: 4.842174530029297, Validation Accuracy: 0.5\n",
      "Epoch 1562/10000, Training Loss: 8.999204635620117, Training Accuracy: 0.5857843137254902, Validation Loss: 26.342079162597656, Validation Accuracy: 0.25\n",
      "Epoch 1563/10000, Training Loss: 8.176615715026855, Training Accuracy: 0.571078431372549, Validation Loss: 2.0458078384399414, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1564/10000, Training Loss: 11.406401634216309, Training Accuracy: 0.5490196078431373, Validation Loss: 14.58243179321289, Validation Accuracy: 0.5\n",
      "Epoch 1565/10000, Training Loss: 14.3075590133667, Training Accuracy: 0.5857843137254902, Validation Loss: 10.700263977050781, Validation Accuracy: 0.5\n",
      "Epoch 1566/10000, Training Loss: 3.8139328956604004, Training Accuracy: 0.5882352941176471, Validation Loss: 9.58332347869873, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1567/10000, Training Loss: 7.760098934173584, Training Accuracy: 0.5318627450980392, Validation Loss: 3.3441972732543945, Validation Accuracy: 0.5\n",
      "Epoch 1568/10000, Training Loss: 10.568503379821777, Training Accuracy: 0.5612745098039216, Validation Loss: 11.752955436706543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1569/10000, Training Loss: 6.49777364730835, Training Accuracy: 0.5661764705882353, Validation Loss: 5.596506595611572, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1570/10000, Training Loss: 10.354318618774414, Training Accuracy: 0.5367647058823529, Validation Loss: 8.214167594909668, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1571/10000, Training Loss: 7.970876216888428, Training Accuracy: 0.5367647058823529, Validation Loss: 19.489473342895508, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1572/10000, Training Loss: 14.148727416992188, Training Accuracy: 0.5392156862745098, Validation Loss: 16.832231521606445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1573/10000, Training Loss: 5.279963970184326, Training Accuracy: 0.6053921568627451, Validation Loss: 10.872715950012207, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1574/10000, Training Loss: 13.404570579528809, Training Accuracy: 0.5661764705882353, Validation Loss: 11.263786315917969, Validation Accuracy: 0.5\n",
      "Epoch 1575/10000, Training Loss: 8.190953254699707, Training Accuracy: 0.5735294117647058, Validation Loss: 17.619123458862305, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1576/10000, Training Loss: 8.43746280670166, Training Accuracy: 0.5882352941176471, Validation Loss: 7.157716751098633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1577/10000, Training Loss: 6.915043354034424, Training Accuracy: 0.5049019607843137, Validation Loss: 17.449491500854492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1578/10000, Training Loss: 6.952455520629883, Training Accuracy: 0.5588235294117647, Validation Loss: 2.4016523361206055, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1579/10000, Training Loss: 11.975176811218262, Training Accuracy: 0.49264705882352944, Validation Loss: 5.884631633758545, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1580/10000, Training Loss: 10.285738945007324, Training Accuracy: 0.5637254901960784, Validation Loss: 26.79259490966797, Validation Accuracy: 0.5\n",
      "Epoch 1581/10000, Training Loss: 6.2028489112854, Training Accuracy: 0.5490196078431373, Validation Loss: 10.38280200958252, Validation Accuracy: 0.75\n",
      "Epoch 1582/10000, Training Loss: 8.601865768432617, Training Accuracy: 0.5563725490196079, Validation Loss: 12.451480865478516, Validation Accuracy: 0.5\n",
      "Epoch 1583/10000, Training Loss: 7.221144199371338, Training Accuracy: 0.5245098039215687, Validation Loss: 3.2384424209594727, Validation Accuracy: 0.5\n",
      "Epoch 1584/10000, Training Loss: 9.667945861816406, Training Accuracy: 0.5661764705882353, Validation Loss: 17.816274642944336, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1585/10000, Training Loss: 8.27684497833252, Training Accuracy: 0.5392156862745098, Validation Loss: 1.8188319206237793, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1586/10000, Training Loss: 8.75762939453125, Training Accuracy: 0.5245098039215687, Validation Loss: 24.081199645996094, Validation Accuracy: 0.5\n",
      "Epoch 1587/10000, Training Loss: 12.573256492614746, Training Accuracy: 0.5955882352941176, Validation Loss: 6.81547212600708, Validation Accuracy: 0.5\n",
      "Epoch 1588/10000, Training Loss: 6.258002281188965, Training Accuracy: 0.5784313725490197, Validation Loss: 2.6480157375335693, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1589/10000, Training Loss: 12.271090507507324, Training Accuracy: 0.571078431372549, Validation Loss: 2.527967691421509, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1590/10000, Training Loss: 6.130207538604736, Training Accuracy: 0.5465686274509803, Validation Loss: 28.780311584472656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1591/10000, Training Loss: 4.02899694442749, Training Accuracy: 0.5392156862745098, Validation Loss: 0.4412671625614166, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1592/10000, Training Loss: 5.829154014587402, Training Accuracy: 0.5269607843137255, Validation Loss: 2.801194190979004, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1593/10000, Training Loss: 15.510505676269531, Training Accuracy: 0.5465686274509803, Validation Loss: 29.118019104003906, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 1594/10000, Training Loss: 14.726975440979004, Training Accuracy: 0.5588235294117647, Validation Loss: 6.960184574127197, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1595/10000, Training Loss: 8.687064170837402, Training Accuracy: 0.6372549019607843, Validation Loss: 6.776165008544922, Validation Accuracy: 0.5\n",
      "Epoch 1596/10000, Training Loss: 6.833314895629883, Training Accuracy: 0.571078431372549, Validation Loss: 5.598760604858398, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1597/10000, Training Loss: 11.480501174926758, Training Accuracy: 0.5318627450980392, Validation Loss: 13.634474754333496, Validation Accuracy: 0.5\n",
      "Epoch 1598/10000, Training Loss: 6.479311466217041, Training Accuracy: 0.5392156862745098, Validation Loss: 4.570934772491455, Validation Accuracy: 0.5\n",
      "Epoch 1599/10000, Training Loss: 10.239449501037598, Training Accuracy: 0.5759803921568627, Validation Loss: 17.426013946533203, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1600/10000, Training Loss: 5.255129814147949, Training Accuracy: 0.6102941176470589, Validation Loss: 6.04443883895874, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1601/10000, Training Loss: 15.86767864227295, Training Accuracy: 0.553921568627451, Validation Loss: 9.688602447509766, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1602/10000, Training Loss: 8.71519947052002, Training Accuracy: 0.5245098039215687, Validation Loss: 18.85530662536621, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1603/10000, Training Loss: 6.163931369781494, Training Accuracy: 0.5686274509803921, Validation Loss: 8.991283416748047, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1604/10000, Training Loss: 5.186873435974121, Training Accuracy: 0.5882352941176471, Validation Loss: 3.6035404205322266, Validation Accuracy: 0.75\n",
      "Epoch 1605/10000, Training Loss: 10.454816818237305, Training Accuracy: 0.5098039215686274, Validation Loss: 17.54100227355957, Validation Accuracy: 0.5\n",
      "Epoch 1606/10000, Training Loss: 10.096908569335938, Training Accuracy: 0.6151960784313726, Validation Loss: 6.583672046661377, Validation Accuracy: 0.5\n",
      "Epoch 1607/10000, Training Loss: 11.250665664672852, Training Accuracy: 0.6372549019607843, Validation Loss: 3.061518669128418, Validation Accuracy: 0.5\n",
      "Epoch 1608/10000, Training Loss: 12.261445045471191, Training Accuracy: 0.5294117647058824, Validation Loss: 14.06979751586914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1609/10000, Training Loss: 7.932969093322754, Training Accuracy: 0.6053921568627451, Validation Loss: 3.601533889770508, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 1610/10000, Training Loss: 13.830329895019531, Training Accuracy: 0.553921568627451, Validation Loss: 9.997694969177246, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1611/10000, Training Loss: 8.27309799194336, Training Accuracy: 0.571078431372549, Validation Loss: 5.766152858734131, Validation Accuracy: 0.5\n",
      "Epoch 1612/10000, Training Loss: 10.347519874572754, Training Accuracy: 0.5367647058823529, Validation Loss: 29.005109786987305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1613/10000, Training Loss: 11.637511253356934, Training Accuracy: 0.5416666666666666, Validation Loss: 21.060426712036133, Validation Accuracy: 0.25\n",
      "Epoch 1614/10000, Training Loss: 7.497617244720459, Training Accuracy: 0.6102941176470589, Validation Loss: 4.593237400054932, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1615/10000, Training Loss: 11.236102104187012, Training Accuracy: 0.49264705882352944, Validation Loss: 10.88000774383545, Validation Accuracy: 0.5\n",
      "Epoch 1616/10000, Training Loss: 14.0765962600708, Training Accuracy: 0.5784313725490197, Validation Loss: 7.258856296539307, Validation Accuracy: 0.5\n",
      "Epoch 1617/10000, Training Loss: 6.18236780166626, Training Accuracy: 0.5416666666666666, Validation Loss: 5.536266803741455, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1618/10000, Training Loss: 15.138128280639648, Training Accuracy: 0.5122549019607843, Validation Loss: 8.40868854522705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1619/10000, Training Loss: 5.899234771728516, Training Accuracy: 0.5343137254901961, Validation Loss: 23.178680419921875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1620/10000, Training Loss: 10.673467636108398, Training Accuracy: 0.5563725490196079, Validation Loss: 3.1799957752227783, Validation Accuracy: 0.5\n",
      "Epoch 1621/10000, Training Loss: 11.86473274230957, Training Accuracy: 0.5196078431372549, Validation Loss: 44.516292572021484, Validation Accuracy: 0.5\n",
      "Epoch 1622/10000, Training Loss: 9.61677360534668, Training Accuracy: 0.5612745098039216, Validation Loss: 10.302383422851562, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1623/10000, Training Loss: 16.156753540039062, Training Accuracy: 0.5808823529411765, Validation Loss: 58.56344223022461, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1624/10000, Training Loss: 10.856233596801758, Training Accuracy: 0.5955882352941176, Validation Loss: 29.668237686157227, Validation Accuracy: 0.25\n",
      "Epoch 1625/10000, Training Loss: 11.517963409423828, Training Accuracy: 0.6127450980392157, Validation Loss: 68.98224639892578, Validation Accuracy: 0.5\n",
      "Epoch 1626/10000, Training Loss: 8.760032653808594, Training Accuracy: 0.571078431372549, Validation Loss: 15.487650871276855, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1627/10000, Training Loss: 10.45584487915039, Training Accuracy: 0.5490196078431373, Validation Loss: 24.839818954467773, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1628/10000, Training Loss: 6.538905620574951, Training Accuracy: 0.6348039215686274, Validation Loss: 4.892517566680908, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1629/10000, Training Loss: 16.87567710876465, Training Accuracy: 0.5343137254901961, Validation Loss: 16.93553352355957, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1630/10000, Training Loss: 5.715946197509766, Training Accuracy: 0.5882352941176471, Validation Loss: 3.7463009357452393, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1631/10000, Training Loss: 12.746031761169434, Training Accuracy: 0.5563725490196079, Validation Loss: 18.48753547668457, Validation Accuracy: 0.75\n",
      "Epoch 1632/10000, Training Loss: 11.300956726074219, Training Accuracy: 0.5588235294117647, Validation Loss: 11.164305686950684, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1633/10000, Training Loss: 15.001801490783691, Training Accuracy: 0.5245098039215687, Validation Loss: 32.155818939208984, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1634/10000, Training Loss: 17.640514373779297, Training Accuracy: 0.5367647058823529, Validation Loss: 47.4907341003418, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1635/10000, Training Loss: 19.572601318359375, Training Accuracy: 0.46078431372549017, Validation Loss: 15.571537971496582, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1636/10000, Training Loss: 5.437751293182373, Training Accuracy: 0.5588235294117647, Validation Loss: 5.764652252197266, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1637/10000, Training Loss: 12.29330825805664, Training Accuracy: 0.5245098039215687, Validation Loss: 11.630125999450684, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1638/10000, Training Loss: 15.329021453857422, Training Accuracy: 0.6029411764705882, Validation Loss: 14.469101905822754, Validation Accuracy: 0.75\n",
      "Epoch 1639/10000, Training Loss: 6.957627773284912, Training Accuracy: 0.5661764705882353, Validation Loss: 9.560860633850098, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1640/10000, Training Loss: 9.065635681152344, Training Accuracy: 0.5784313725490197, Validation Loss: 19.001184463500977, Validation Accuracy: 0.5\n",
      "Epoch 1641/10000, Training Loss: 5.026759624481201, Training Accuracy: 0.5318627450980392, Validation Loss: 5.506349563598633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1642/10000, Training Loss: 9.682887077331543, Training Accuracy: 0.6029411764705882, Validation Loss: 12.609027862548828, Validation Accuracy: 0.5\n",
      "Epoch 1643/10000, Training Loss: 7.294669151306152, Training Accuracy: 0.5588235294117647, Validation Loss: 15.237103462219238, Validation Accuracy: 0.5\n",
      "Epoch 1644/10000, Training Loss: 9.092035293579102, Training Accuracy: 0.571078431372549, Validation Loss: 6.496985912322998, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1645/10000, Training Loss: 10.1278715133667, Training Accuracy: 0.5588235294117647, Validation Loss: 56.19401550292969, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1646/10000, Training Loss: 11.14523696899414, Training Accuracy: 0.5882352941176471, Validation Loss: 6.638216495513916, Validation Accuracy: 0.5\n",
      "Epoch 1647/10000, Training Loss: 6.970705509185791, Training Accuracy: 0.5759803921568627, Validation Loss: 5.118771553039551, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1648/10000, Training Loss: 9.195869445800781, Training Accuracy: 0.5857843137254902, Validation Loss: 32.21225357055664, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1649/10000, Training Loss: 10.063639640808105, Training Accuracy: 0.5612745098039216, Validation Loss: 9.776945114135742, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1650/10000, Training Loss: 14.214101791381836, Training Accuracy: 0.5686274509803921, Validation Loss: 13.40251636505127, Validation Accuracy: 0.25\n",
      "Epoch 1651/10000, Training Loss: 9.068621635437012, Training Accuracy: 0.5098039215686274, Validation Loss: 16.43828773498535, Validation Accuracy: 0.5\n",
      "Epoch 1652/10000, Training Loss: 17.92971420288086, Training Accuracy: 0.5514705882352942, Validation Loss: 52.39338684082031, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1653/10000, Training Loss: 12.664929389953613, Training Accuracy: 0.5759803921568627, Validation Loss: 15.855414390563965, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1654/10000, Training Loss: 9.169429779052734, Training Accuracy: 0.571078431372549, Validation Loss: 18.897287368774414, Validation Accuracy: 0.25\n",
      "Epoch 1655/10000, Training Loss: 7.702113628387451, Training Accuracy: 0.5588235294117647, Validation Loss: 10.842758178710938, Validation Accuracy: 0.25\n",
      "Epoch 1656/10000, Training Loss: 6.941116809844971, Training Accuracy: 0.5367647058823529, Validation Loss: 2.8556747436523438, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1657/10000, Training Loss: 4.885647773742676, Training Accuracy: 0.5441176470588235, Validation Loss: 14.988322257995605, Validation Accuracy: 0.25\n",
      "Epoch 1658/10000, Training Loss: 7.017207145690918, Training Accuracy: 0.5661764705882353, Validation Loss: 6.3338470458984375, Validation Accuracy: 0.5\n",
      "Epoch 1659/10000, Training Loss: 12.299263000488281, Training Accuracy: 0.5220588235294118, Validation Loss: 5.2792134284973145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1660/10000, Training Loss: 7.006396293640137, Training Accuracy: 0.5735294117647058, Validation Loss: 6.426711559295654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1661/10000, Training Loss: 7.015457630157471, Training Accuracy: 0.5490196078431373, Validation Loss: 15.508593559265137, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1662/10000, Training Loss: 7.210367679595947, Training Accuracy: 0.5098039215686274, Validation Loss: 0.6978839039802551, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1663/10000, Training Loss: 6.649691104888916, Training Accuracy: 0.5661764705882353, Validation Loss: 2.220754623413086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1664/10000, Training Loss: 10.936426162719727, Training Accuracy: 0.5686274509803921, Validation Loss: 14.800299644470215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1665/10000, Training Loss: 7.435871124267578, Training Accuracy: 0.5833333333333334, Validation Loss: 12.396034240722656, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1666/10000, Training Loss: 10.171954154968262, Training Accuracy: 0.5465686274509803, Validation Loss: 5.1435041427612305, Validation Accuracy: 0.75\n",
      "Epoch 1667/10000, Training Loss: 11.182595252990723, Training Accuracy: 0.5784313725490197, Validation Loss: 18.930408477783203, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1668/10000, Training Loss: 5.68474817276001, Training Accuracy: 0.5833333333333334, Validation Loss: 17.667598724365234, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1669/10000, Training Loss: 10.13875961303711, Training Accuracy: 0.5465686274509803, Validation Loss: 8.354872703552246, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1670/10000, Training Loss: 9.705041885375977, Training Accuracy: 0.4803921568627451, Validation Loss: 7.8231072425842285, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1671/10000, Training Loss: 9.139578819274902, Training Accuracy: 0.5686274509803921, Validation Loss: 16.00855827331543, Validation Accuracy: 0.5\n",
      "Epoch 1672/10000, Training Loss: 11.343978881835938, Training Accuracy: 0.5147058823529411, Validation Loss: 3.575108766555786, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1673/10000, Training Loss: 7.289186477661133, Training Accuracy: 0.5441176470588235, Validation Loss: 1.432511329650879, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1674/10000, Training Loss: 11.496024131774902, Training Accuracy: 0.5563725490196079, Validation Loss: 19.422399520874023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1675/10000, Training Loss: 6.802631378173828, Training Accuracy: 0.6102941176470589, Validation Loss: 16.835006713867188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1676/10000, Training Loss: 12.17399787902832, Training Accuracy: 0.5196078431372549, Validation Loss: 20.1115665435791, Validation Accuracy: 0.25\n",
      "Epoch 1677/10000, Training Loss: 10.591272354125977, Training Accuracy: 0.5808823529411765, Validation Loss: 46.30621337890625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1678/10000, Training Loss: 8.93149185180664, Training Accuracy: 0.5759803921568627, Validation Loss: 17.466638565063477, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1679/10000, Training Loss: 5.126272678375244, Training Accuracy: 0.571078431372549, Validation Loss: 8.395037651062012, Validation Accuracy: 0.5\n",
      "Epoch 1680/10000, Training Loss: 10.179956436157227, Training Accuracy: 0.5931372549019608, Validation Loss: 11.008007049560547, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1681/10000, Training Loss: 9.683548927307129, Training Accuracy: 0.5514705882352942, Validation Loss: 14.925763130187988, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1682/10000, Training Loss: 7.224388122558594, Training Accuracy: 0.625, Validation Loss: 4.726247310638428, Validation Accuracy: 0.5\n",
      "Epoch 1683/10000, Training Loss: 9.335618019104004, Training Accuracy: 0.5808823529411765, Validation Loss: 15.127742767333984, Validation Accuracy: 0.5\n",
      "Epoch 1684/10000, Training Loss: 6.831021308898926, Training Accuracy: 0.5857843137254902, Validation Loss: 17.708406448364258, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1685/10000, Training Loss: 6.503638744354248, Training Accuracy: 0.5490196078431373, Validation Loss: 17.274396896362305, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1686/10000, Training Loss: 8.043449401855469, Training Accuracy: 0.5955882352941176, Validation Loss: 12.693397521972656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1687/10000, Training Loss: 9.22320556640625, Training Accuracy: 0.5465686274509803, Validation Loss: 11.830470085144043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1688/10000, Training Loss: 12.037834167480469, Training Accuracy: 0.625, Validation Loss: 15.653491020202637, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1689/10000, Training Loss: 8.977765083312988, Training Accuracy: 0.5441176470588235, Validation Loss: 16.646507263183594, Validation Accuracy: 0.5\n",
      "Epoch 1690/10000, Training Loss: 9.554984092712402, Training Accuracy: 0.5367647058823529, Validation Loss: 15.150489807128906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1691/10000, Training Loss: 11.89388656616211, Training Accuracy: 0.5294117647058824, Validation Loss: 6.927810192108154, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1692/10000, Training Loss: 8.434300422668457, Training Accuracy: 0.5147058823529411, Validation Loss: 4.934255123138428, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1693/10000, Training Loss: 12.582891464233398, Training Accuracy: 0.5465686274509803, Validation Loss: 51.80842971801758, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1694/10000, Training Loss: 7.666444301605225, Training Accuracy: 0.5098039215686274, Validation Loss: 8.854186058044434, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1695/10000, Training Loss: 17.62496566772461, Training Accuracy: 0.5318627450980392, Validation Loss: 31.839019775390625, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1696/10000, Training Loss: 8.88341999053955, Training Accuracy: 0.5318627450980392, Validation Loss: 6.671213626861572, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1697/10000, Training Loss: 10.559863090515137, Training Accuracy: 0.5931372549019608, Validation Loss: 13.441619873046875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1698/10000, Training Loss: 7.644832134246826, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0884078741073608, Validation Accuracy: 0.75\n",
      "Epoch 1699/10000, Training Loss: 9.90072250366211, Training Accuracy: 0.5759803921568627, Validation Loss: 5.572425842285156, Validation Accuracy: 0.5\n",
      "Epoch 1700/10000, Training Loss: 6.105311870574951, Training Accuracy: 0.5294117647058824, Validation Loss: 7.707313537597656, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1701/10000, Training Loss: 6.102139472961426, Training Accuracy: 0.5416666666666666, Validation Loss: 5.135381698608398, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1702/10000, Training Loss: 5.314347743988037, Training Accuracy: 0.5343137254901961, Validation Loss: 6.090768814086914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1703/10000, Training Loss: 9.20716381072998, Training Accuracy: 0.44607843137254904, Validation Loss: 18.58689308166504, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1704/10000, Training Loss: 7.473050117492676, Training Accuracy: 0.5637254901960784, Validation Loss: 4.673408508300781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1705/10000, Training Loss: 13.043776512145996, Training Accuracy: 0.4803921568627451, Validation Loss: 7.164234161376953, Validation Accuracy: 0.75\n",
      "Epoch 1706/10000, Training Loss: 6.762636661529541, Training Accuracy: 0.5490196078431373, Validation Loss: 20.101348876953125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1707/10000, Training Loss: 13.286974906921387, Training Accuracy: 0.553921568627451, Validation Loss: 9.567481994628906, Validation Accuracy: 0.5\n",
      "Epoch 1708/10000, Training Loss: 9.16430377960205, Training Accuracy: 0.5269607843137255, Validation Loss: 17.221446990966797, Validation Accuracy: 0.5\n",
      "Epoch 1709/10000, Training Loss: 7.869239330291748, Training Accuracy: 0.553921568627451, Validation Loss: 29.39433479309082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1710/10000, Training Loss: 9.406526565551758, Training Accuracy: 0.6372549019607843, Validation Loss: 33.448631286621094, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1711/10000, Training Loss: 10.566498756408691, Training Accuracy: 0.5196078431372549, Validation Loss: 16.466047286987305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1712/10000, Training Loss: 8.354265213012695, Training Accuracy: 0.5686274509803921, Validation Loss: 18.51569175720215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1713/10000, Training Loss: 9.601716041564941, Training Accuracy: 0.5661764705882353, Validation Loss: 3.160557746887207, Validation Accuracy: 0.5\n",
      "Epoch 1714/10000, Training Loss: 9.650598526000977, Training Accuracy: 0.5098039215686274, Validation Loss: 2.0955231189727783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1715/10000, Training Loss: 9.394386291503906, Training Accuracy: 0.5049019607843137, Validation Loss: 16.482168197631836, Validation Accuracy: 0.25\n",
      "Epoch 1716/10000, Training Loss: 8.158809661865234, Training Accuracy: 0.5563725490196079, Validation Loss: 21.309947967529297, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1717/10000, Training Loss: 6.919260025024414, Training Accuracy: 0.5563725490196079, Validation Loss: 6.940443515777588, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1718/10000, Training Loss: 5.640382289886475, Training Accuracy: 0.5416666666666666, Validation Loss: 3.405390501022339, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1719/10000, Training Loss: 9.390158653259277, Training Accuracy: 0.5098039215686274, Validation Loss: 18.800565719604492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1720/10000, Training Loss: 7.587104797363281, Training Accuracy: 0.5686274509803921, Validation Loss: 12.85628604888916, Validation Accuracy: 0.5\n",
      "Epoch 1721/10000, Training Loss: 11.403192520141602, Training Accuracy: 0.5392156862745098, Validation Loss: 13.35335922241211, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1722/10000, Training Loss: 11.688772201538086, Training Accuracy: 0.5612745098039216, Validation Loss: 13.525202751159668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1723/10000, Training Loss: 6.690004348754883, Training Accuracy: 0.5955882352941176, Validation Loss: 7.366318225860596, Validation Accuracy: 0.5\n",
      "Epoch 1724/10000, Training Loss: 10.282020568847656, Training Accuracy: 0.5147058823529411, Validation Loss: 6.032703876495361, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1725/10000, Training Loss: 8.566511154174805, Training Accuracy: 0.553921568627451, Validation Loss: 18.313365936279297, Validation Accuracy: 0.25\n",
      "Epoch 1726/10000, Training Loss: 15.32260799407959, Training Accuracy: 0.5098039215686274, Validation Loss: 8.196393966674805, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1727/10000, Training Loss: 5.494626045227051, Training Accuracy: 0.5735294117647058, Validation Loss: 8.381674766540527, Validation Accuracy: 0.5\n",
      "Epoch 1728/10000, Training Loss: 6.488337993621826, Training Accuracy: 0.6029411764705882, Validation Loss: 4.674230098724365, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1729/10000, Training Loss: 11.541496276855469, Training Accuracy: 0.6397058823529411, Validation Loss: 13.877071380615234, Validation Accuracy: 0.5\n",
      "Epoch 1730/10000, Training Loss: 9.1782865524292, Training Accuracy: 0.5147058823529411, Validation Loss: 21.092790603637695, Validation Accuracy: 0.5\n",
      "Epoch 1731/10000, Training Loss: 6.641591548919678, Training Accuracy: 0.5588235294117647, Validation Loss: 5.566066265106201, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1732/10000, Training Loss: 6.465080738067627, Training Accuracy: 0.5490196078431373, Validation Loss: 6.649604797363281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1733/10000, Training Loss: 10.557064056396484, Training Accuracy: 0.6200980392156863, Validation Loss: 47.85536575317383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1734/10000, Training Loss: 7.561934947967529, Training Accuracy: 0.5588235294117647, Validation Loss: 7.7562255859375, Validation Accuracy: 0.5\n",
      "Epoch 1735/10000, Training Loss: 6.236454010009766, Training Accuracy: 0.5392156862745098, Validation Loss: 5.984586238861084, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1736/10000, Training Loss: 10.587889671325684, Training Accuracy: 0.5122549019607843, Validation Loss: 14.32784366607666, Validation Accuracy: 0.5\n",
      "Epoch 1737/10000, Training Loss: 10.477924346923828, Training Accuracy: 0.6151960784313726, Validation Loss: 2.186687469482422, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1738/10000, Training Loss: 9.815754890441895, Training Accuracy: 0.5098039215686274, Validation Loss: 8.13647174835205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1739/10000, Training Loss: 9.071823120117188, Training Accuracy: 0.5931372549019608, Validation Loss: 11.587066650390625, Validation Accuracy: 0.5\n",
      "Epoch 1740/10000, Training Loss: 11.696911811828613, Training Accuracy: 0.5686274509803921, Validation Loss: 16.632373809814453, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1741/10000, Training Loss: 8.23326301574707, Training Accuracy: 0.5686274509803921, Validation Loss: 4.382554054260254, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1742/10000, Training Loss: 4.941619396209717, Training Accuracy: 0.6004901960784313, Validation Loss: 6.106190204620361, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1743/10000, Training Loss: 7.534862995147705, Training Accuracy: 0.5759803921568627, Validation Loss: 8.448807716369629, Validation Accuracy: 0.25\n",
      "Epoch 1744/10000, Training Loss: 8.885815620422363, Training Accuracy: 0.5514705882352942, Validation Loss: 6.081597805023193, Validation Accuracy: 0.5\n",
      "Epoch 1745/10000, Training Loss: 9.43105697631836, Training Accuracy: 0.5833333333333334, Validation Loss: 72.8050765991211, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1746/10000, Training Loss: 23.99304962158203, Training Accuracy: 0.5147058823529411, Validation Loss: 36.18741226196289, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1747/10000, Training Loss: 10.768362045288086, Training Accuracy: 0.4730392156862745, Validation Loss: 3.0517656803131104, Validation Accuracy: 0.75\n",
      "Epoch 1748/10000, Training Loss: 8.000991821289062, Training Accuracy: 0.5294117647058824, Validation Loss: 4.783684253692627, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1749/10000, Training Loss: 11.337233543395996, Training Accuracy: 0.5343137254901961, Validation Loss: 11.32970905303955, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1750/10000, Training Loss: 6.816823959350586, Training Accuracy: 0.6029411764705882, Validation Loss: 14.96514892578125, Validation Accuracy: 0.5\n",
      "Epoch 1751/10000, Training Loss: 10.058266639709473, Training Accuracy: 0.5637254901960784, Validation Loss: 3.1904563903808594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1752/10000, Training Loss: 7.452846527099609, Training Accuracy: 0.5906862745098039, Validation Loss: 5.635957717895508, Validation Accuracy: 0.5\n",
      "Epoch 1753/10000, Training Loss: 9.21278190612793, Training Accuracy: 0.5073529411764706, Validation Loss: 14.373238563537598, Validation Accuracy: 0.25\n",
      "Epoch 1754/10000, Training Loss: 10.406503677368164, Training Accuracy: 0.5661764705882353, Validation Loss: 10.31371784210205, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1755/10000, Training Loss: 6.821317195892334, Training Accuracy: 0.5759803921568627, Validation Loss: 4.630252361297607, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1756/10000, Training Loss: 10.220246315002441, Training Accuracy: 0.4583333333333333, Validation Loss: 4.9516472816467285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1757/10000, Training Loss: 7.091219425201416, Training Accuracy: 0.6029411764705882, Validation Loss: 7.641748905181885, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1758/10000, Training Loss: 5.032325744628906, Training Accuracy: 0.5563725490196079, Validation Loss: 2.4582815170288086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1759/10000, Training Loss: 9.580743789672852, Training Accuracy: 0.5294117647058824, Validation Loss: 50.776859283447266, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1760/10000, Training Loss: 7.733821392059326, Training Accuracy: 0.571078431372549, Validation Loss: 2.1970436573028564, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1761/10000, Training Loss: 6.819867134094238, Training Accuracy: 0.5220588235294118, Validation Loss: 8.517382621765137, Validation Accuracy: 0.5\n",
      "Epoch 1762/10000, Training Loss: 7.014496326446533, Training Accuracy: 0.5857843137254902, Validation Loss: 20.567665100097656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1763/10000, Training Loss: 6.487245082855225, Training Accuracy: 0.5073529411764706, Validation Loss: 6.409755706787109, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1764/10000, Training Loss: 6.724347114562988, Training Accuracy: 0.6225490196078431, Validation Loss: 17.98032569885254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1765/10000, Training Loss: 6.183717250823975, Training Accuracy: 0.6078431372549019, Validation Loss: 5.784355640411377, Validation Accuracy: 0.5\n",
      "Epoch 1766/10000, Training Loss: 5.756993293762207, Training Accuracy: 0.5857843137254902, Validation Loss: 9.297707557678223, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1767/10000, Training Loss: 12.00417709350586, Training Accuracy: 0.5441176470588235, Validation Loss: 8.723644256591797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1768/10000, Training Loss: 9.080443382263184, Training Accuracy: 0.4803921568627451, Validation Loss: 14.966584205627441, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1769/10000, Training Loss: 8.354925155639648, Training Accuracy: 0.5245098039215687, Validation Loss: 18.6348934173584, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1770/10000, Training Loss: 6.887510776519775, Training Accuracy: 0.5514705882352942, Validation Loss: 9.608382225036621, Validation Accuracy: 0.5\n",
      "Epoch 1771/10000, Training Loss: 8.781229972839355, Training Accuracy: 0.5980392156862745, Validation Loss: 15.541398048400879, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1772/10000, Training Loss: 12.475699424743652, Training Accuracy: 0.5171568627450981, Validation Loss: 7.527794361114502, Validation Accuracy: 0.75\n",
      "Epoch 1773/10000, Training Loss: 6.777737617492676, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6021220088005066, Validation Accuracy: 0.75\n",
      "Epoch 1774/10000, Training Loss: 10.06611442565918, Training Accuracy: 0.5906862745098039, Validation Loss: 20.5661678314209, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1775/10000, Training Loss: 5.508973598480225, Training Accuracy: 0.5514705882352942, Validation Loss: 4.467635631561279, Validation Accuracy: 0.25\n",
      "Epoch 1776/10000, Training Loss: 18.082136154174805, Training Accuracy: 0.5490196078431373, Validation Loss: 19.248632431030273, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1777/10000, Training Loss: 11.635161399841309, Training Accuracy: 0.5490196078431373, Validation Loss: 8.816530227661133, Validation Accuracy: 0.5\n",
      "Epoch 1778/10000, Training Loss: 5.283497333526611, Training Accuracy: 0.5980392156862745, Validation Loss: 6.676101207733154, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1779/10000, Training Loss: 7.435391426086426, Training Accuracy: 0.5661764705882353, Validation Loss: 6.925619125366211, Validation Accuracy: 0.5\n",
      "Epoch 1780/10000, Training Loss: 7.036437511444092, Training Accuracy: 0.5245098039215687, Validation Loss: 21.990442276000977, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1781/10000, Training Loss: 5.959345817565918, Training Accuracy: 0.5269607843137255, Validation Loss: 3.4514427185058594, Validation Accuracy: 0.75\n",
      "Epoch 1782/10000, Training Loss: 5.885011196136475, Training Accuracy: 0.6078431372549019, Validation Loss: 3.373847007751465, Validation Accuracy: 0.5\n",
      "Epoch 1783/10000, Training Loss: 5.108420372009277, Training Accuracy: 0.5735294117647058, Validation Loss: 3.7886972427368164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1784/10000, Training Loss: 11.430465698242188, Training Accuracy: 0.5906862745098039, Validation Loss: 6.126088619232178, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1785/10000, Training Loss: 5.292994976043701, Training Accuracy: 0.5343137254901961, Validation Loss: 16.249467849731445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1786/10000, Training Loss: 8.078767776489258, Training Accuracy: 0.5122549019607843, Validation Loss: 9.939727783203125, Validation Accuracy: 0.5\n",
      "Epoch 1787/10000, Training Loss: 6.187465667724609, Training Accuracy: 0.5196078431372549, Validation Loss: 2.921802520751953, Validation Accuracy: 0.5\n",
      "Epoch 1788/10000, Training Loss: 6.967980861663818, Training Accuracy: 0.5784313725490197, Validation Loss: 17.761058807373047, Validation Accuracy: 0.5\n",
      "Epoch 1789/10000, Training Loss: 7.687793254852295, Training Accuracy: 0.553921568627451, Validation Loss: 2.6804845333099365, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1790/10000, Training Loss: 10.31995677947998, Training Accuracy: 0.5661764705882353, Validation Loss: 9.23291301727295, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1791/10000, Training Loss: 7.883403778076172, Training Accuracy: 0.5612745098039216, Validation Loss: 9.886112213134766, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1792/10000, Training Loss: 5.547238349914551, Training Accuracy: 0.5049019607843137, Validation Loss: 6.808994770050049, Validation Accuracy: 0.5\n",
      "Epoch 1793/10000, Training Loss: 6.901419639587402, Training Accuracy: 0.553921568627451, Validation Loss: 5.375566482543945, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1794/10000, Training Loss: 6.607923984527588, Training Accuracy: 0.5367647058823529, Validation Loss: 15.900782585144043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1795/10000, Training Loss: 12.890756607055664, Training Accuracy: 0.5318627450980392, Validation Loss: 7.598618030548096, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1796/10000, Training Loss: 8.95669174194336, Training Accuracy: 0.6004901960784313, Validation Loss: 12.02502155303955, Validation Accuracy: 0.5\n",
      "Epoch 1797/10000, Training Loss: 4.498705863952637, Training Accuracy: 0.5882352941176471, Validation Loss: 6.726291179656982, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1798/10000, Training Loss: 6.040225982666016, Training Accuracy: 0.5318627450980392, Validation Loss: 17.670686721801758, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1799/10000, Training Loss: 6.625978946685791, Training Accuracy: 0.5808823529411765, Validation Loss: 14.232921600341797, Validation Accuracy: 0.25\n",
      "Epoch 1800/10000, Training Loss: 23.682205200195312, Training Accuracy: 0.5784313725490197, Validation Loss: 8.010239601135254, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1801/10000, Training Loss: 13.001221656799316, Training Accuracy: 0.49754901960784315, Validation Loss: 13.094765663146973, Validation Accuracy: 0.25\n",
      "Epoch 1802/10000, Training Loss: 5.764942169189453, Training Accuracy: 0.5784313725490197, Validation Loss: 15.36327838897705, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1803/10000, Training Loss: 10.161337852478027, Training Accuracy: 0.5490196078431373, Validation Loss: 12.170268058776855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1804/10000, Training Loss: 8.993805885314941, Training Accuracy: 0.5686274509803921, Validation Loss: 5.770334243774414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1805/10000, Training Loss: 7.115774154663086, Training Accuracy: 0.5563725490196079, Validation Loss: 5.695213317871094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1806/10000, Training Loss: 5.899025917053223, Training Accuracy: 0.5171568627450981, Validation Loss: 2.6628589630126953, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1807/10000, Training Loss: 8.463360786437988, Training Accuracy: 0.6127450980392157, Validation Loss: 7.657199859619141, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1808/10000, Training Loss: 6.728889465332031, Training Accuracy: 0.5563725490196079, Validation Loss: 3.1397573947906494, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1809/10000, Training Loss: 6.743283748626709, Training Accuracy: 0.5049019607843137, Validation Loss: 3.3029396533966064, Validation Accuracy: 0.5\n",
      "Epoch 1810/10000, Training Loss: 9.176551818847656, Training Accuracy: 0.5416666666666666, Validation Loss: 5.091695308685303, Validation Accuracy: 0.5\n",
      "Epoch 1811/10000, Training Loss: 8.809720993041992, Training Accuracy: 0.5588235294117647, Validation Loss: 12.301021575927734, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1812/10000, Training Loss: 13.477949142456055, Training Accuracy: 0.5, Validation Loss: 10.380791664123535, Validation Accuracy: 0.5\n",
      "Epoch 1813/10000, Training Loss: 9.362401008605957, Training Accuracy: 0.5318627450980392, Validation Loss: 6.340012073516846, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1814/10000, Training Loss: 8.896600723266602, Training Accuracy: 0.5, Validation Loss: 37.917701721191406, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1815/10000, Training Loss: 8.80565357208252, Training Accuracy: 0.6053921568627451, Validation Loss: 7.698110103607178, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1816/10000, Training Loss: 6.714234828948975, Training Accuracy: 0.5416666666666666, Validation Loss: 5.101711273193359, Validation Accuracy: 0.5\n",
      "Epoch 1817/10000, Training Loss: 6.35983943939209, Training Accuracy: 0.5612745098039216, Validation Loss: 6.706521987915039, Validation Accuracy: 0.75\n",
      "Epoch 1818/10000, Training Loss: 10.655129432678223, Training Accuracy: 0.5612745098039216, Validation Loss: 8.923835754394531, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1819/10000, Training Loss: 5.934591770172119, Training Accuracy: 0.5563725490196079, Validation Loss: 7.419479846954346, Validation Accuracy: 0.5\n",
      "Epoch 1820/10000, Training Loss: 9.418643951416016, Training Accuracy: 0.5612745098039216, Validation Loss: 22.211057662963867, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1821/10000, Training Loss: 10.132277488708496, Training Accuracy: 0.5416666666666666, Validation Loss: 9.730015754699707, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1822/10000, Training Loss: 10.958527565002441, Training Accuracy: 0.5784313725490197, Validation Loss: 20.214914321899414, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1823/10000, Training Loss: 11.226064682006836, Training Accuracy: 0.6323529411764706, Validation Loss: 15.798965454101562, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1824/10000, Training Loss: 7.337590217590332, Training Accuracy: 0.5759803921568627, Validation Loss: 16.19371223449707, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1825/10000, Training Loss: 4.383674621582031, Training Accuracy: 0.553921568627451, Validation Loss: 1.9449890851974487, Validation Accuracy: 0.75\n",
      "Epoch 1826/10000, Training Loss: 6.880702018737793, Training Accuracy: 0.5465686274509803, Validation Loss: 2.8923819065093994, Validation Accuracy: 0.5\n",
      "Epoch 1827/10000, Training Loss: 7.618697643280029, Training Accuracy: 0.5588235294117647, Validation Loss: 13.073745727539062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1828/10000, Training Loss: 4.5409836769104, Training Accuracy: 0.6348039215686274, Validation Loss: 6.3529052734375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1829/10000, Training Loss: 10.871378898620605, Training Accuracy: 0.49264705882352944, Validation Loss: 18.00031089782715, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1830/10000, Training Loss: 9.914549827575684, Training Accuracy: 0.5661764705882353, Validation Loss: 8.430620193481445, Validation Accuracy: 0.5\n",
      "Epoch 1831/10000, Training Loss: 7.033298969268799, Training Accuracy: 0.5465686274509803, Validation Loss: 60.41202926635742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1832/10000, Training Loss: 5.302107334136963, Training Accuracy: 0.5049019607843137, Validation Loss: 1.658077359199524, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1833/10000, Training Loss: 8.796944618225098, Training Accuracy: 0.5612745098039216, Validation Loss: 14.632251739501953, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1834/10000, Training Loss: 5.462086200714111, Training Accuracy: 0.6029411764705882, Validation Loss: 15.672943115234375, Validation Accuracy: 0.25\n",
      "Epoch 1835/10000, Training Loss: 8.152549743652344, Training Accuracy: 0.6200980392156863, Validation Loss: 20.07115364074707, Validation Accuracy: 0.5\n",
      "Epoch 1836/10000, Training Loss: 6.518604278564453, Training Accuracy: 0.5808823529411765, Validation Loss: 4.352814674377441, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1837/10000, Training Loss: 8.246603965759277, Training Accuracy: 0.5049019607843137, Validation Loss: 7.083253383636475, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1838/10000, Training Loss: 7.672745227813721, Training Accuracy: 0.5661764705882353, Validation Loss: 40.56753921508789, Validation Accuracy: 0.25\n",
      "Epoch 1839/10000, Training Loss: 6.941536903381348, Training Accuracy: 0.5906862745098039, Validation Loss: 6.751044750213623, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1840/10000, Training Loss: 10.964326858520508, Training Accuracy: 0.5784313725490197, Validation Loss: 12.51115894317627, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1841/10000, Training Loss: 8.386457443237305, Training Accuracy: 0.5465686274509803, Validation Loss: 6.898099899291992, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1842/10000, Training Loss: 6.288837432861328, Training Accuracy: 0.5833333333333334, Validation Loss: 7.262735366821289, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1843/10000, Training Loss: 12.569486618041992, Training Accuracy: 0.5367647058823529, Validation Loss: 25.46125602722168, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1844/10000, Training Loss: 6.49171257019043, Training Accuracy: 0.6004901960784313, Validation Loss: 4.368520736694336, Validation Accuracy: 0.75\n",
      "Epoch 1845/10000, Training Loss: 10.663061141967773, Training Accuracy: 0.5343137254901961, Validation Loss: 16.78986167907715, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1846/10000, Training Loss: 11.438841819763184, Training Accuracy: 0.5465686274509803, Validation Loss: 12.025592803955078, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1847/10000, Training Loss: 12.744791984558105, Training Accuracy: 0.5171568627450981, Validation Loss: 1.1733750104904175, Validation Accuracy: 0.75\n",
      "Epoch 1848/10000, Training Loss: 4.694994926452637, Training Accuracy: 0.5563725490196079, Validation Loss: 10.775364875793457, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1849/10000, Training Loss: 9.407140731811523, Training Accuracy: 0.6004901960784313, Validation Loss: 2.7231638431549072, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1850/10000, Training Loss: 9.475449562072754, Training Accuracy: 0.5098039215686274, Validation Loss: 16.76036262512207, Validation Accuracy: 0.25\n",
      "Epoch 1851/10000, Training Loss: 6.174515247344971, Training Accuracy: 0.5196078431372549, Validation Loss: 3.884181022644043, Validation Accuracy: 0.75\n",
      "Epoch 1852/10000, Training Loss: 6.430360794067383, Training Accuracy: 0.5269607843137255, Validation Loss: 1.764548659324646, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1853/10000, Training Loss: 5.055128574371338, Training Accuracy: 0.5661764705882353, Validation Loss: 10.237526893615723, Validation Accuracy: 0.25\n",
      "Epoch 1854/10000, Training Loss: 5.445857048034668, Training Accuracy: 0.6151960784313726, Validation Loss: 3.6974258422851562, Validation Accuracy: 0.75\n",
      "Epoch 1855/10000, Training Loss: 11.704245567321777, Training Accuracy: 0.5416666666666666, Validation Loss: 7.62595796585083, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1856/10000, Training Loss: 14.37703800201416, Training Accuracy: 0.5465686274509803, Validation Loss: 5.670829772949219, Validation Accuracy: 0.75\n",
      "Epoch 1857/10000, Training Loss: 9.565433502197266, Training Accuracy: 0.4852941176470588, Validation Loss: 4.121658802032471, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1858/10000, Training Loss: 10.333474159240723, Training Accuracy: 0.5784313725490197, Validation Loss: 15.087837219238281, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1859/10000, Training Loss: 9.162859916687012, Training Accuracy: 0.5612745098039216, Validation Loss: 9.105284690856934, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1860/10000, Training Loss: 12.01203727722168, Training Accuracy: 0.571078431372549, Validation Loss: 46.10599899291992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1861/10000, Training Loss: 12.767452239990234, Training Accuracy: 0.5294117647058824, Validation Loss: 2.386383533477783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1862/10000, Training Loss: 18.864994049072266, Training Accuracy: 0.6274509803921569, Validation Loss: 307.5380554199219, Validation Accuracy: 0.25\n",
      "Epoch 1863/10000, Training Loss: 12.93607234954834, Training Accuracy: 0.6004901960784313, Validation Loss: 27.51889991760254, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1864/10000, Training Loss: 5.211650371551514, Training Accuracy: 0.6151960784313726, Validation Loss: 19.0450382232666, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1865/10000, Training Loss: 7.03278923034668, Training Accuracy: 0.6102941176470589, Validation Loss: 19.332015991210938, Validation Accuracy: 0.5\n",
      "Epoch 1866/10000, Training Loss: 8.950257301330566, Training Accuracy: 0.5367647058823529, Validation Loss: 10.005707740783691, Validation Accuracy: 0.75\n",
      "Epoch 1867/10000, Training Loss: 11.62905216217041, Training Accuracy: 0.5441176470588235, Validation Loss: 26.52873992919922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1868/10000, Training Loss: 5.725358486175537, Training Accuracy: 0.5343137254901961, Validation Loss: 1.75611412525177, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1869/10000, Training Loss: 10.839105606079102, Training Accuracy: 0.5196078431372549, Validation Loss: 4.781957149505615, Validation Accuracy: 0.5\n",
      "Epoch 1870/10000, Training Loss: 9.29487133026123, Training Accuracy: 0.5661764705882353, Validation Loss: 5.4764404296875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1871/10000, Training Loss: 8.616608619689941, Training Accuracy: 0.5906862745098039, Validation Loss: 11.803314208984375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1872/10000, Training Loss: 7.206153869628906, Training Accuracy: 0.553921568627451, Validation Loss: 11.15445327758789, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1873/10000, Training Loss: 7.045830726623535, Training Accuracy: 0.5612745098039216, Validation Loss: 4.116480350494385, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1874/10000, Training Loss: 11.134849548339844, Training Accuracy: 0.5514705882352942, Validation Loss: 5.327800750732422, Validation Accuracy: 0.75\n",
      "Epoch 1875/10000, Training Loss: 6.611480712890625, Training Accuracy: 0.5661764705882353, Validation Loss: 12.869036674499512, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1876/10000, Training Loss: 7.175766468048096, Training Accuracy: 0.5857843137254902, Validation Loss: 4.203159809112549, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1877/10000, Training Loss: 7.857838153839111, Training Accuracy: 0.5612745098039216, Validation Loss: 14.26737117767334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1878/10000, Training Loss: 6.194839954376221, Training Accuracy: 0.5073529411764706, Validation Loss: 7.739027500152588, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1879/10000, Training Loss: 7.233251094818115, Training Accuracy: 0.5196078431372549, Validation Loss: 2.578258752822876, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1880/10000, Training Loss: 9.19040584564209, Training Accuracy: 0.5784313725490197, Validation Loss: 15.87088680267334, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1881/10000, Training Loss: 15.6364107131958, Training Accuracy: 0.4950980392156863, Validation Loss: 1.5079799890518188, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1882/10000, Training Loss: 13.97443962097168, Training Accuracy: 0.5637254901960784, Validation Loss: 12.081787109375, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1883/10000, Training Loss: 7.312497138977051, Training Accuracy: 0.5269607843137255, Validation Loss: 11.308194160461426, Validation Accuracy: 0.5\n",
      "Epoch 1884/10000, Training Loss: 8.62475872039795, Training Accuracy: 0.5367647058823529, Validation Loss: 15.726571083068848, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1885/10000, Training Loss: 7.154759883880615, Training Accuracy: 0.5955882352941176, Validation Loss: 2.94281005859375, Validation Accuracy: 0.75\n",
      "Epoch 1886/10000, Training Loss: 7.78953742980957, Training Accuracy: 0.5294117647058824, Validation Loss: 11.278647422790527, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1887/10000, Training Loss: 7.273061275482178, Training Accuracy: 0.5637254901960784, Validation Loss: 11.350716590881348, Validation Accuracy: 0.5\n",
      "Epoch 1888/10000, Training Loss: 8.644280433654785, Training Accuracy: 0.5563725490196079, Validation Loss: 23.480432510375977, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1889/10000, Training Loss: 9.594884872436523, Training Accuracy: 0.5514705882352942, Validation Loss: 0.4693562090396881, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1890/10000, Training Loss: 4.373950958251953, Training Accuracy: 0.5784313725490197, Validation Loss: 2.681384801864624, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1891/10000, Training Loss: 5.377284049987793, Training Accuracy: 0.553921568627451, Validation Loss: 5.210072994232178, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1892/10000, Training Loss: 9.088967323303223, Training Accuracy: 0.5196078431372549, Validation Loss: 2.406916618347168, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1893/10000, Training Loss: 7.600378513336182, Training Accuracy: 0.6225490196078431, Validation Loss: 9.992533683776855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1894/10000, Training Loss: 6.275214195251465, Training Accuracy: 0.5318627450980392, Validation Loss: 24.103271484375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1895/10000, Training Loss: 8.366965293884277, Training Accuracy: 0.5343137254901961, Validation Loss: 11.607975006103516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1896/10000, Training Loss: 8.160922050476074, Training Accuracy: 0.5269607843137255, Validation Loss: 15.434886932373047, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1897/10000, Training Loss: 8.525291442871094, Training Accuracy: 0.5955882352941176, Validation Loss: 18.483755111694336, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1898/10000, Training Loss: 7.564481258392334, Training Accuracy: 0.5882352941176471, Validation Loss: 27.880279541015625, Validation Accuracy: 0.25\n",
      "Epoch 1899/10000, Training Loss: 20.598133087158203, Training Accuracy: 0.5147058823529411, Validation Loss: 34.609283447265625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1900/10000, Training Loss: 5.849268436431885, Training Accuracy: 0.5686274509803921, Validation Loss: 8.4916410446167, Validation Accuracy: 0.25\n",
      "Epoch 1901/10000, Training Loss: 6.850560665130615, Training Accuracy: 0.6053921568627451, Validation Loss: 6.243692398071289, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1902/10000, Training Loss: 5.839621067047119, Training Accuracy: 0.5906862745098039, Validation Loss: 24.08855438232422, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1903/10000, Training Loss: 7.408864974975586, Training Accuracy: 0.4803921568627451, Validation Loss: 7.680971145629883, Validation Accuracy: 0.25\n",
      "Epoch 1904/10000, Training Loss: 6.025398254394531, Training Accuracy: 0.5857843137254902, Validation Loss: 7.498671054840088, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1905/10000, Training Loss: 6.582035541534424, Training Accuracy: 0.5637254901960784, Validation Loss: 9.037674903869629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1906/10000, Training Loss: 7.963531494140625, Training Accuracy: 0.5196078431372549, Validation Loss: 9.278315544128418, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1907/10000, Training Loss: 7.353348255157471, Training Accuracy: 0.5808823529411765, Validation Loss: 16.12208366394043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1908/10000, Training Loss: 6.223085880279541, Training Accuracy: 0.6127450980392157, Validation Loss: 13.981669425964355, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1909/10000, Training Loss: 5.526571750640869, Training Accuracy: 0.6004901960784313, Validation Loss: 9.163707733154297, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1910/10000, Training Loss: 6.824375629425049, Training Accuracy: 0.5906862745098039, Validation Loss: 1.2729655504226685, Validation Accuracy: 0.75\n",
      "Epoch 1911/10000, Training Loss: 7.004886627197266, Training Accuracy: 0.5514705882352942, Validation Loss: 6.281438827514648, Validation Accuracy: 0.25\n",
      "Epoch 1912/10000, Training Loss: 6.477577209472656, Training Accuracy: 0.5318627450980392, Validation Loss: 6.724642276763916, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1913/10000, Training Loss: 8.096277236938477, Training Accuracy: 0.5465686274509803, Validation Loss: 9.968733787536621, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1914/10000, Training Loss: 5.69764518737793, Training Accuracy: 0.5269607843137255, Validation Loss: 10.778708457946777, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1915/10000, Training Loss: 6.362834453582764, Training Accuracy: 0.5637254901960784, Validation Loss: 13.619460105895996, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1916/10000, Training Loss: 6.019737243652344, Training Accuracy: 0.5294117647058824, Validation Loss: 8.991646766662598, Validation Accuracy: 0.25\n",
      "Epoch 1917/10000, Training Loss: 11.242986679077148, Training Accuracy: 0.6151960784313726, Validation Loss: 14.837689399719238, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1918/10000, Training Loss: 9.03235149383545, Training Accuracy: 0.6029411764705882, Validation Loss: 9.298417091369629, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1919/10000, Training Loss: 6.745458126068115, Training Accuracy: 0.5637254901960784, Validation Loss: 5.402130126953125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1920/10000, Training Loss: 5.871912479400635, Training Accuracy: 0.5661764705882353, Validation Loss: 3.2279016971588135, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1921/10000, Training Loss: 6.282851696014404, Training Accuracy: 0.5661764705882353, Validation Loss: 11.9014310836792, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1922/10000, Training Loss: 7.875398635864258, Training Accuracy: 0.47794117647058826, Validation Loss: 6.861292362213135, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1923/10000, Training Loss: 7.43974494934082, Training Accuracy: 0.5759803921568627, Validation Loss: 8.228336334228516, Validation Accuracy: 0.25\n",
      "Epoch 1924/10000, Training Loss: 5.075307846069336, Training Accuracy: 0.5392156862745098, Validation Loss: 6.114687442779541, Validation Accuracy: 0.5\n",
      "Epoch 1925/10000, Training Loss: 6.328587055206299, Training Accuracy: 0.5465686274509803, Validation Loss: 13.973713874816895, Validation Accuracy: 0.25\n",
      "Epoch 1926/10000, Training Loss: 5.360870361328125, Training Accuracy: 0.5343137254901961, Validation Loss: 8.532061576843262, Validation Accuracy: 0.25\n",
      "Epoch 1927/10000, Training Loss: 14.3136625289917, Training Accuracy: 0.553921568627451, Validation Loss: 3.8554649353027344, Validation Accuracy: 0.5\n",
      "Epoch 1928/10000, Training Loss: 7.006546974182129, Training Accuracy: 0.5833333333333334, Validation Loss: 6.926502704620361, Validation Accuracy: 0.5\n",
      "Epoch 1929/10000, Training Loss: 8.320393562316895, Training Accuracy: 0.5196078431372549, Validation Loss: 8.012506484985352, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1930/10000, Training Loss: 5.716256141662598, Training Accuracy: 0.5294117647058824, Validation Loss: 7.88162088394165, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1931/10000, Training Loss: 9.869908332824707, Training Accuracy: 0.5490196078431373, Validation Loss: 3.482020139694214, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1932/10000, Training Loss: 9.165584564208984, Training Accuracy: 0.5735294117647058, Validation Loss: 8.378230094909668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1933/10000, Training Loss: 4.624176502227783, Training Accuracy: 0.5416666666666666, Validation Loss: 4.085967540740967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1934/10000, Training Loss: 9.626887321472168, Training Accuracy: 0.5931372549019608, Validation Loss: 30.79129981994629, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1935/10000, Training Loss: 8.593459129333496, Training Accuracy: 0.5367647058823529, Validation Loss: 22.254547119140625, Validation Accuracy: 0.5\n",
      "Epoch 1936/10000, Training Loss: 12.247057914733887, Training Accuracy: 0.5416666666666666, Validation Loss: 47.33979415893555, Validation Accuracy: 0.25\n",
      "Epoch 1937/10000, Training Loss: 6.186524868011475, Training Accuracy: 0.5588235294117647, Validation Loss: 12.815353393554688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1938/10000, Training Loss: 6.714211463928223, Training Accuracy: 0.5196078431372549, Validation Loss: 7.2543110847473145, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1939/10000, Training Loss: 7.161924839019775, Training Accuracy: 0.4852941176470588, Validation Loss: 18.845651626586914, Validation Accuracy: 0.5\n",
      "Epoch 1940/10000, Training Loss: 7.84964656829834, Training Accuracy: 0.5343137254901961, Validation Loss: 8.977875709533691, Validation Accuracy: 0.5\n",
      "Epoch 1941/10000, Training Loss: 3.9583959579467773, Training Accuracy: 0.5980392156862745, Validation Loss: 12.649212837219238, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1942/10000, Training Loss: 5.939884185791016, Training Accuracy: 0.553921568627451, Validation Loss: 11.4634370803833, Validation Accuracy: 0.5\n",
      "Epoch 1943/10000, Training Loss: 7.661099433898926, Training Accuracy: 0.5196078431372549, Validation Loss: 8.391945838928223, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1944/10000, Training Loss: 10.848030090332031, Training Accuracy: 0.5269607843137255, Validation Loss: 12.14408016204834, Validation Accuracy: 0.5\n",
      "Epoch 1945/10000, Training Loss: 6.441558361053467, Training Accuracy: 0.5882352941176471, Validation Loss: 6.458332061767578, Validation Accuracy: 0.5\n",
      "Epoch 1946/10000, Training Loss: 14.40900993347168, Training Accuracy: 0.5686274509803921, Validation Loss: 17.459453582763672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1947/10000, Training Loss: 8.864069938659668, Training Accuracy: 0.5490196078431373, Validation Loss: 8.496081352233887, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1948/10000, Training Loss: 5.917586803436279, Training Accuracy: 0.571078431372549, Validation Loss: 2.471712350845337, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1949/10000, Training Loss: 7.43317174911499, Training Accuracy: 0.5612745098039216, Validation Loss: 9.988627433776855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1950/10000, Training Loss: 7.515911102294922, Training Accuracy: 0.5416666666666666, Validation Loss: 6.760564804077148, Validation Accuracy: 0.5\n",
      "Epoch 1951/10000, Training Loss: 7.582767486572266, Training Accuracy: 0.5686274509803921, Validation Loss: 12.783524513244629, Validation Accuracy: 0.5\n",
      "Epoch 1952/10000, Training Loss: 6.442314147949219, Training Accuracy: 0.5612745098039216, Validation Loss: 4.539890289306641, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1953/10000, Training Loss: 8.409451484680176, Training Accuracy: 0.6053921568627451, Validation Loss: 11.17761516571045, Validation Accuracy: 0.5\n",
      "Epoch 1954/10000, Training Loss: 8.836893081665039, Training Accuracy: 0.5833333333333334, Validation Loss: 9.331387519836426, Validation Accuracy: 0.5\n",
      "Epoch 1955/10000, Training Loss: 7.459087371826172, Training Accuracy: 0.5392156862745098, Validation Loss: 8.798609733581543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1956/10000, Training Loss: 5.132067680358887, Training Accuracy: 0.5931372549019608, Validation Loss: 9.958569526672363, Validation Accuracy: 0.5\n",
      "Epoch 1957/10000, Training Loss: 8.37258529663086, Training Accuracy: 0.5367647058823529, Validation Loss: 6.336053848266602, Validation Accuracy: 0.75\n",
      "Epoch 1958/10000, Training Loss: 5.669429779052734, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1930526494979858, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1959/10000, Training Loss: 6.915633678436279, Training Accuracy: 0.5171568627450981, Validation Loss: 10.742805480957031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1960/10000, Training Loss: 6.67100715637207, Training Accuracy: 0.5465686274509803, Validation Loss: 2.357785224914551, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1961/10000, Training Loss: 10.82526969909668, Training Accuracy: 0.5931372549019608, Validation Loss: 19.62189483642578, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1962/10000, Training Loss: 8.888629913330078, Training Accuracy: 0.5318627450980392, Validation Loss: 4.7310614585876465, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1963/10000, Training Loss: 7.548664093017578, Training Accuracy: 0.5833333333333334, Validation Loss: 2.871238946914673, Validation Accuracy: 0.75\n",
      "Epoch 1964/10000, Training Loss: 4.726588249206543, Training Accuracy: 0.5612745098039216, Validation Loss: 6.742729187011719, Validation Accuracy: 0.5\n",
      "Epoch 1965/10000, Training Loss: 9.318245887756348, Training Accuracy: 0.5318627450980392, Validation Loss: 4.062573432922363, Validation Accuracy: 0.5\n",
      "Epoch 1966/10000, Training Loss: 8.369756698608398, Training Accuracy: 0.5392156862745098, Validation Loss: 1.7212109565734863, Validation Accuracy: 0.75\n",
      "Epoch 1967/10000, Training Loss: 9.19983196258545, Training Accuracy: 0.4583333333333333, Validation Loss: 10.712574005126953, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1968/10000, Training Loss: 6.887123107910156, Training Accuracy: 0.5931372549019608, Validation Loss: 13.26002025604248, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1969/10000, Training Loss: 8.099963188171387, Training Accuracy: 0.5588235294117647, Validation Loss: 5.64477014541626, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1970/10000, Training Loss: 5.240960597991943, Training Accuracy: 0.6127450980392157, Validation Loss: 15.572388648986816, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 1971/10000, Training Loss: 9.727261543273926, Training Accuracy: 0.5465686274509803, Validation Loss: 5.2510223388671875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1972/10000, Training Loss: 5.826516628265381, Training Accuracy: 0.5735294117647058, Validation Loss: 7.526559352874756, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1973/10000, Training Loss: 7.266032695770264, Training Accuracy: 0.5612745098039216, Validation Loss: 9.105088233947754, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1974/10000, Training Loss: 5.975745677947998, Training Accuracy: 0.5686274509803921, Validation Loss: 10.725712776184082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1975/10000, Training Loss: 6.536538600921631, Training Accuracy: 0.5122549019607843, Validation Loss: 7.393102169036865, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1976/10000, Training Loss: 6.757977485656738, Training Accuracy: 0.5416666666666666, Validation Loss: 4.022655487060547, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1977/10000, Training Loss: 9.711211204528809, Training Accuracy: 0.5294117647058824, Validation Loss: 4.466456413269043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1978/10000, Training Loss: 4.560515880584717, Training Accuracy: 0.625, Validation Loss: 7.160801410675049, Validation Accuracy: 0.5\n",
      "Epoch 1979/10000, Training Loss: 5.385859966278076, Training Accuracy: 0.6004901960784313, Validation Loss: 11.266142845153809, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1980/10000, Training Loss: 5.628502368927002, Training Accuracy: 0.5882352941176471, Validation Loss: 2.658986806869507, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1981/10000, Training Loss: 8.302241325378418, Training Accuracy: 0.6274509803921569, Validation Loss: 51.573246002197266, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1982/10000, Training Loss: 11.185453414916992, Training Accuracy: 0.5147058823529411, Validation Loss: 14.17824649810791, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1983/10000, Training Loss: 8.288786888122559, Training Accuracy: 0.6176470588235294, Validation Loss: 1.198377013206482, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1984/10000, Training Loss: 4.975971221923828, Training Accuracy: 0.4803921568627451, Validation Loss: 4.615917205810547, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1985/10000, Training Loss: 9.274349212646484, Training Accuracy: 0.5857843137254902, Validation Loss: 5.176599979400635, Validation Accuracy: 0.5\n",
      "Epoch 1986/10000, Training Loss: 5.261866569519043, Training Accuracy: 0.5465686274509803, Validation Loss: 3.396479845046997, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1987/10000, Training Loss: 8.544424057006836, Training Accuracy: 0.5637254901960784, Validation Loss: 20.999536514282227, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1988/10000, Training Loss: 6.048475742340088, Training Accuracy: 0.6078431372549019, Validation Loss: 24.52393913269043, Validation Accuracy: 0.5\n",
      "Epoch 1989/10000, Training Loss: 11.908918380737305, Training Accuracy: 0.5686274509803921, Validation Loss: 8.335184097290039, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1990/10000, Training Loss: 4.145693778991699, Training Accuracy: 0.5661764705882353, Validation Loss: 4.297366619110107, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 1991/10000, Training Loss: 3.6903438568115234, Training Accuracy: 0.6029411764705882, Validation Loss: 10.868491172790527, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1992/10000, Training Loss: 7.131746292114258, Training Accuracy: 0.5269607843137255, Validation Loss: 3.193939447402954, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1993/10000, Training Loss: 6.062061309814453, Training Accuracy: 0.5465686274509803, Validation Loss: 7.5756916999816895, Validation Accuracy: 0.5\n",
      "Epoch 1994/10000, Training Loss: 6.326833248138428, Training Accuracy: 0.5563725490196079, Validation Loss: 1.9315487146377563, Validation Accuracy: 0.75\n",
      "Epoch 1995/10000, Training Loss: 12.838072776794434, Training Accuracy: 0.5588235294117647, Validation Loss: 3.8933029174804688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 1996/10000, Training Loss: 6.823871612548828, Training Accuracy: 0.553921568627451, Validation Loss: 10.772099494934082, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 1997/10000, Training Loss: 3.959923267364502, Training Accuracy: 0.5784313725490197, Validation Loss: 6.286777973175049, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 1998/10000, Training Loss: 7.968459606170654, Training Accuracy: 0.5465686274509803, Validation Loss: 4.470897197723389, Validation Accuracy: 0.5\n",
      "Epoch 1999/10000, Training Loss: 6.934873580932617, Training Accuracy: 0.553921568627451, Validation Loss: 7.549270153045654, Validation Accuracy: 0.25\n",
      "Epoch 2000/10000, Training Loss: 6.803852081298828, Training Accuracy: 0.571078431372549, Validation Loss: 198.0701446533203, Validation Accuracy: 0.5\n",
      "Epoch 2001/10000, Training Loss: 6.038955211639404, Training Accuracy: 0.5416666666666666, Validation Loss: 3.2717950344085693, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2002/10000, Training Loss: 11.35049057006836, Training Accuracy: 0.49754901960784315, Validation Loss: 8.150971412658691, Validation Accuracy: 0.5\n",
      "Epoch 2003/10000, Training Loss: 9.033774375915527, Training Accuracy: 0.5318627450980392, Validation Loss: 5.903810501098633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2004/10000, Training Loss: 8.545637130737305, Training Accuracy: 0.5882352941176471, Validation Loss: 15.402560234069824, Validation Accuracy: 0.5\n",
      "Epoch 2005/10000, Training Loss: 6.386964797973633, Training Accuracy: 0.5759803921568627, Validation Loss: 3.899348258972168, Validation Accuracy: 0.5\n",
      "Epoch 2006/10000, Training Loss: 6.213910102844238, Training Accuracy: 0.5588235294117647, Validation Loss: 8.948378562927246, Validation Accuracy: 0.5\n",
      "Epoch 2007/10000, Training Loss: 3.4918155670166016, Training Accuracy: 0.5465686274509803, Validation Loss: 6.019311904907227, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2008/10000, Training Loss: 6.823077201843262, Training Accuracy: 0.5906862745098039, Validation Loss: 18.16533088684082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2009/10000, Training Loss: 5.989987373352051, Training Accuracy: 0.5833333333333334, Validation Loss: 3.3141534328460693, Validation Accuracy: 0.5\n",
      "Epoch 2010/10000, Training Loss: 8.158513069152832, Training Accuracy: 0.5122549019607843, Validation Loss: 11.573482513427734, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2011/10000, Training Loss: 6.137979984283447, Training Accuracy: 0.6176470588235294, Validation Loss: 6.355895519256592, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2012/10000, Training Loss: 5.400918960571289, Training Accuracy: 0.5392156862745098, Validation Loss: 5.2983012199401855, Validation Accuracy: 0.5\n",
      "Epoch 2013/10000, Training Loss: 11.053555488586426, Training Accuracy: 0.5759803921568627, Validation Loss: 15.30298900604248, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2014/10000, Training Loss: 4.427011489868164, Training Accuracy: 0.5686274509803921, Validation Loss: 2.8714511394500732, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2015/10000, Training Loss: 5.937350273132324, Training Accuracy: 0.5367647058823529, Validation Loss: 11.468998908996582, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2016/10000, Training Loss: 8.645159721374512, Training Accuracy: 0.6078431372549019, Validation Loss: 10.203401565551758, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2017/10000, Training Loss: 8.538973808288574, Training Accuracy: 0.5441176470588235, Validation Loss: 15.759488105773926, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2018/10000, Training Loss: 6.813520431518555, Training Accuracy: 0.5416666666666666, Validation Loss: 3.960012435913086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2019/10000, Training Loss: 4.683752536773682, Training Accuracy: 0.5857843137254902, Validation Loss: 3.7116620540618896, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2020/10000, Training Loss: 7.922786712646484, Training Accuracy: 0.5612745098039216, Validation Loss: 7.856199741363525, Validation Accuracy: 0.5\n",
      "Epoch 2021/10000, Training Loss: 7.578323841094971, Training Accuracy: 0.6029411764705882, Validation Loss: 7.746037006378174, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2022/10000, Training Loss: 6.980856418609619, Training Accuracy: 0.5392156862745098, Validation Loss: 11.533392906188965, Validation Accuracy: 0.25\n",
      "Epoch 2023/10000, Training Loss: 4.323677062988281, Training Accuracy: 0.6078431372549019, Validation Loss: 13.159758567810059, Validation Accuracy: 0.5\n",
      "Epoch 2024/10000, Training Loss: 9.905841827392578, Training Accuracy: 0.5661764705882353, Validation Loss: 12.118597984313965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2025/10000, Training Loss: 5.731919288635254, Training Accuracy: 0.5563725490196079, Validation Loss: 6.247503757476807, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2026/10000, Training Loss: 6.314259052276611, Training Accuracy: 0.5245098039215687, Validation Loss: 12.154350280761719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2027/10000, Training Loss: 12.796979904174805, Training Accuracy: 0.5, Validation Loss: 26.32663917541504, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2028/10000, Training Loss: 4.7371978759765625, Training Accuracy: 0.5588235294117647, Validation Loss: 6.124377727508545, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2029/10000, Training Loss: 12.99915885925293, Training Accuracy: 0.5318627450980392, Validation Loss: 23.6427001953125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2030/10000, Training Loss: 8.54929256439209, Training Accuracy: 0.5196078431372549, Validation Loss: 4.178346633911133, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2031/10000, Training Loss: 5.786921501159668, Training Accuracy: 0.5343137254901961, Validation Loss: 6.7238922119140625, Validation Accuracy: 0.5\n",
      "Epoch 2032/10000, Training Loss: 5.69908332824707, Training Accuracy: 0.5808823529411765, Validation Loss: 17.710371017456055, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2033/10000, Training Loss: 7.108029365539551, Training Accuracy: 0.5857843137254902, Validation Loss: 8.540084838867188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2034/10000, Training Loss: 7.855934143066406, Training Accuracy: 0.5661764705882353, Validation Loss: 6.905493259429932, Validation Accuracy: 0.5\n",
      "Epoch 2035/10000, Training Loss: 2.9166789054870605, Training Accuracy: 0.6421568627450981, Validation Loss: 3.4800243377685547, Validation Accuracy: 0.5\n",
      "Epoch 2036/10000, Training Loss: 7.360353946685791, Training Accuracy: 0.5343137254901961, Validation Loss: 8.036089897155762, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2037/10000, Training Loss: 8.866267204284668, Training Accuracy: 0.5612745098039216, Validation Loss: 7.5513014793396, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2038/10000, Training Loss: 5.507712364196777, Training Accuracy: 0.5196078431372549, Validation Loss: 2.847426176071167, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2039/10000, Training Loss: 5.285009860992432, Training Accuracy: 0.6004901960784313, Validation Loss: 4.607059955596924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2040/10000, Training Loss: 6.57045316696167, Training Accuracy: 0.5392156862745098, Validation Loss: 27.0674991607666, Validation Accuracy: 0.75\n",
      "Epoch 2041/10000, Training Loss: 8.569145202636719, Training Accuracy: 0.5588235294117647, Validation Loss: 8.571799278259277, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2042/10000, Training Loss: 4.283331394195557, Training Accuracy: 0.553921568627451, Validation Loss: 3.8210859298706055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2043/10000, Training Loss: 4.664453983306885, Training Accuracy: 0.5171568627450981, Validation Loss: 4.44241189956665, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2044/10000, Training Loss: 10.603328704833984, Training Accuracy: 0.625, Validation Loss: 16.47633171081543, Validation Accuracy: 0.5\n",
      "Epoch 2045/10000, Training Loss: 7.321683883666992, Training Accuracy: 0.5171568627450981, Validation Loss: 4.133790493011475, Validation Accuracy: 0.5\n",
      "Epoch 2046/10000, Training Loss: 8.562627792358398, Training Accuracy: 0.5196078431372549, Validation Loss: 7.325431823730469, Validation Accuracy: 0.5\n",
      "Epoch 2047/10000, Training Loss: 8.299015045166016, Training Accuracy: 0.5416666666666666, Validation Loss: 12.097432136535645, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2048/10000, Training Loss: 5.511474132537842, Training Accuracy: 0.5049019607843137, Validation Loss: 8.025733947753906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2049/10000, Training Loss: 5.26235294342041, Training Accuracy: 0.5833333333333334, Validation Loss: 10.507247924804688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2050/10000, Training Loss: 5.715202808380127, Training Accuracy: 0.6127450980392157, Validation Loss: 3.2392473220825195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2051/10000, Training Loss: 6.793689250946045, Training Accuracy: 0.5661764705882353, Validation Loss: 10.813433647155762, Validation Accuracy: 0.5\n",
      "Epoch 2052/10000, Training Loss: 5.228909492492676, Training Accuracy: 0.625, Validation Loss: 6.636538028717041, Validation Accuracy: 0.5\n",
      "Epoch 2053/10000, Training Loss: 6.369179725646973, Training Accuracy: 0.4803921568627451, Validation Loss: 16.95405387878418, Validation Accuracy: 0.25\n",
      "Epoch 2054/10000, Training Loss: 4.856947898864746, Training Accuracy: 0.5661764705882353, Validation Loss: 7.284085750579834, Validation Accuracy: 0.5\n",
      "Epoch 2055/10000, Training Loss: 4.948575973510742, Training Accuracy: 0.5318627450980392, Validation Loss: 7.433875560760498, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2056/10000, Training Loss: 4.505843162536621, Training Accuracy: 0.5686274509803921, Validation Loss: 5.559689044952393, Validation Accuracy: 0.25\n",
      "Epoch 2057/10000, Training Loss: 8.567933082580566, Training Accuracy: 0.5024509803921569, Validation Loss: 3.631382942199707, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2058/10000, Training Loss: 7.052800178527832, Training Accuracy: 0.5416666666666666, Validation Loss: 2.2753231525421143, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2059/10000, Training Loss: 6.593757629394531, Training Accuracy: 0.553921568627451, Validation Loss: 13.082222938537598, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2060/10000, Training Loss: 5.477606773376465, Training Accuracy: 0.4950980392156863, Validation Loss: 6.905785083770752, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2061/10000, Training Loss: 4.235081195831299, Training Accuracy: 0.5637254901960784, Validation Loss: 8.271398544311523, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2062/10000, Training Loss: 8.224701881408691, Training Accuracy: 0.5882352941176471, Validation Loss: 21.58228874206543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2063/10000, Training Loss: 5.310604095458984, Training Accuracy: 0.5098039215686274, Validation Loss: 8.840043067932129, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2064/10000, Training Loss: 5.303487300872803, Training Accuracy: 0.5269607843137255, Validation Loss: 4.093811511993408, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2065/10000, Training Loss: 6.040855407714844, Training Accuracy: 0.5441176470588235, Validation Loss: 4.009133815765381, Validation Accuracy: 0.75\n",
      "Epoch 2066/10000, Training Loss: 5.888789653778076, Training Accuracy: 0.5049019607843137, Validation Loss: 1.7733217477798462, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2067/10000, Training Loss: 4.391662120819092, Training Accuracy: 0.5294117647058824, Validation Loss: 3.325670003890991, Validation Accuracy: 0.5\n",
      "Epoch 2068/10000, Training Loss: 9.738232612609863, Training Accuracy: 0.5906862745098039, Validation Loss: 50.041229248046875, Validation Accuracy: 0.25\n",
      "Epoch 2069/10000, Training Loss: 11.603721618652344, Training Accuracy: 0.553921568627451, Validation Loss: 9.150747299194336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2070/10000, Training Loss: 5.321579933166504, Training Accuracy: 0.5857843137254902, Validation Loss: 9.597979545593262, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2071/10000, Training Loss: 5.291907787322998, Training Accuracy: 0.5759803921568627, Validation Loss: 10.511666297912598, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2072/10000, Training Loss: 9.534212112426758, Training Accuracy: 0.6127450980392157, Validation Loss: 16.737749099731445, Validation Accuracy: 0.25\n",
      "Epoch 2073/10000, Training Loss: 7.060318470001221, Training Accuracy: 0.6274509803921569, Validation Loss: 11.265654563903809, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2074/10000, Training Loss: 10.110098838806152, Training Accuracy: 0.5735294117647058, Validation Loss: 15.036406517028809, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2075/10000, Training Loss: 4.843316555023193, Training Accuracy: 0.5735294117647058, Validation Loss: 7.628404140472412, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2076/10000, Training Loss: 8.71410846710205, Training Accuracy: 0.5588235294117647, Validation Loss: 3.917030096054077, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2077/10000, Training Loss: 4.92835807800293, Training Accuracy: 0.5220588235294118, Validation Loss: 8.213191032409668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2078/10000, Training Loss: 5.527626991271973, Training Accuracy: 0.5735294117647058, Validation Loss: 4.006541728973389, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2079/10000, Training Loss: 3.651912212371826, Training Accuracy: 0.5563725490196079, Validation Loss: 2.835423707962036, Validation Accuracy: 0.25\n",
      "Epoch 2080/10000, Training Loss: 4.070171356201172, Training Accuracy: 0.5294117647058824, Validation Loss: 2.4554812908172607, Validation Accuracy: 0.75\n",
      "Epoch 2081/10000, Training Loss: 8.450523376464844, Training Accuracy: 0.5784313725490197, Validation Loss: 24.94989776611328, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2082/10000, Training Loss: 4.890364170074463, Training Accuracy: 0.571078431372549, Validation Loss: 14.033247947692871, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2083/10000, Training Loss: 7.156390190124512, Training Accuracy: 0.5784313725490197, Validation Loss: 13.032488822937012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2084/10000, Training Loss: 7.457297325134277, Training Accuracy: 0.5882352941176471, Validation Loss: 7.6563944816589355, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2085/10000, Training Loss: 10.107049942016602, Training Accuracy: 0.5514705882352942, Validation Loss: 38.110740661621094, Validation Accuracy: 0.5\n",
      "Epoch 2086/10000, Training Loss: 4.404043197631836, Training Accuracy: 0.5563725490196079, Validation Loss: 5.101613998413086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2087/10000, Training Loss: 4.245922088623047, Training Accuracy: 0.6274509803921569, Validation Loss: 4.457149505615234, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2088/10000, Training Loss: 10.62265396118164, Training Accuracy: 0.5588235294117647, Validation Loss: 21.2947940826416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2089/10000, Training Loss: 5.842494487762451, Training Accuracy: 0.5294117647058824, Validation Loss: 4.985692024230957, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2090/10000, Training Loss: 3.3414525985717773, Training Accuracy: 0.553921568627451, Validation Loss: 1.4539761543273926, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2091/10000, Training Loss: 4.634240627288818, Training Accuracy: 0.5637254901960784, Validation Loss: 5.956145763397217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2092/10000, Training Loss: 4.639668941497803, Training Accuracy: 0.5882352941176471, Validation Loss: 1.8246288299560547, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2093/10000, Training Loss: 6.760422229766846, Training Accuracy: 0.6127450980392157, Validation Loss: 12.193699836730957, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2094/10000, Training Loss: 5.595981597900391, Training Accuracy: 0.5147058823529411, Validation Loss: 16.5231876373291, Validation Accuracy: 0.5\n",
      "Epoch 2095/10000, Training Loss: 10.703384399414062, Training Accuracy: 0.553921568627451, Validation Loss: 25.038055419921875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2096/10000, Training Loss: 7.294933319091797, Training Accuracy: 0.5882352941176471, Validation Loss: 3.0418453216552734, Validation Accuracy: 0.5\n",
      "Epoch 2097/10000, Training Loss: 5.323974132537842, Training Accuracy: 0.5686274509803921, Validation Loss: 4.210049152374268, Validation Accuracy: 0.5\n",
      "Epoch 2098/10000, Training Loss: 6.501108646392822, Training Accuracy: 0.49754901960784315, Validation Loss: 9.059109687805176, Validation Accuracy: 0.25\n",
      "Epoch 2099/10000, Training Loss: 5.515970230102539, Training Accuracy: 0.6299019607843137, Validation Loss: 16.0262393951416, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2100/10000, Training Loss: 6.408111095428467, Training Accuracy: 0.5098039215686274, Validation Loss: 6.144225597381592, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2101/10000, Training Loss: 6.403738021850586, Training Accuracy: 0.5220588235294118, Validation Loss: 6.918949127197266, Validation Accuracy: 0.25\n",
      "Epoch 2102/10000, Training Loss: 5.558668613433838, Training Accuracy: 0.5588235294117647, Validation Loss: 3.1912295818328857, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2103/10000, Training Loss: 6.995865821838379, Training Accuracy: 0.5392156862745098, Validation Loss: 8.04514217376709, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2104/10000, Training Loss: 4.731792449951172, Training Accuracy: 0.5465686274509803, Validation Loss: 3.908447027206421, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2105/10000, Training Loss: 8.821151733398438, Training Accuracy: 0.5343137254901961, Validation Loss: 9.707758903503418, Validation Accuracy: 0.75\n",
      "Epoch 2106/10000, Training Loss: 3.7144808769226074, Training Accuracy: 0.6200980392156863, Validation Loss: 6.093102931976318, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2107/10000, Training Loss: 6.293808937072754, Training Accuracy: 0.5147058823529411, Validation Loss: 9.502076148986816, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2108/10000, Training Loss: 7.774477481842041, Training Accuracy: 0.5686274509803921, Validation Loss: 2.2145609855651855, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2109/10000, Training Loss: 6.224397659301758, Training Accuracy: 0.5833333333333334, Validation Loss: 6.928552150726318, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2110/10000, Training Loss: 5.697009563446045, Training Accuracy: 0.6127450980392157, Validation Loss: 1.4791940450668335, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2111/10000, Training Loss: 6.442617893218994, Training Accuracy: 0.5367647058823529, Validation Loss: 10.930636405944824, Validation Accuracy: 0.5\n",
      "Epoch 2112/10000, Training Loss: 5.238324165344238, Training Accuracy: 0.5735294117647058, Validation Loss: 2.3167715072631836, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2113/10000, Training Loss: 6.033855438232422, Training Accuracy: 0.5612745098039216, Validation Loss: 10.072806358337402, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2114/10000, Training Loss: 8.481425285339355, Training Accuracy: 0.5759803921568627, Validation Loss: 8.760016441345215, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2115/10000, Training Loss: 4.589540004730225, Training Accuracy: 0.5784313725490197, Validation Loss: 3.639478921890259, Validation Accuracy: 0.5\n",
      "Epoch 2116/10000, Training Loss: 6.020736217498779, Training Accuracy: 0.5514705882352942, Validation Loss: 3.7165310382843018, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2117/10000, Training Loss: 6.987892150878906, Training Accuracy: 0.5490196078431373, Validation Loss: 8.25904369354248, Validation Accuracy: 0.5\n",
      "Epoch 2118/10000, Training Loss: 7.813371181488037, Training Accuracy: 0.5294117647058824, Validation Loss: 5.44700813293457, Validation Accuracy: 0.5\n",
      "Epoch 2119/10000, Training Loss: 8.624954223632812, Training Accuracy: 0.5686274509803921, Validation Loss: 17.71439552307129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2120/10000, Training Loss: 6.382530689239502, Training Accuracy: 0.5196078431372549, Validation Loss: 19.339536666870117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2121/10000, Training Loss: 7.756369590759277, Training Accuracy: 0.4852941176470588, Validation Loss: 2.992999792098999, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2122/10000, Training Loss: 4.363651752471924, Training Accuracy: 0.6176470588235294, Validation Loss: 7.133923053741455, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2123/10000, Training Loss: 7.604238510131836, Training Accuracy: 0.5441176470588235, Validation Loss: 7.973080158233643, Validation Accuracy: 0.5\n",
      "Epoch 2124/10000, Training Loss: 10.217093467712402, Training Accuracy: 0.5367647058823529, Validation Loss: 5.01548433303833, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2125/10000, Training Loss: 5.279422760009766, Training Accuracy: 0.5784313725490197, Validation Loss: 5.4821391105651855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2126/10000, Training Loss: 5.014227867126465, Training Accuracy: 0.6078431372549019, Validation Loss: 1.290923833847046, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2127/10000, Training Loss: 7.111182689666748, Training Accuracy: 0.5514705882352942, Validation Loss: 3.062584638595581, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2128/10000, Training Loss: 5.848835468292236, Training Accuracy: 0.6078431372549019, Validation Loss: 8.177794456481934, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2129/10000, Training Loss: 3.2549774646759033, Training Accuracy: 0.5563725490196079, Validation Loss: 3.2878010272979736, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2130/10000, Training Loss: 10.322101593017578, Training Accuracy: 0.5294117647058824, Validation Loss: 19.900636672973633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2131/10000, Training Loss: 2.793091058731079, Training Accuracy: 0.6323529411764706, Validation Loss: 4.389175891876221, Validation Accuracy: 0.25\n",
      "Epoch 2132/10000, Training Loss: 4.383433818817139, Training Accuracy: 0.5122549019607843, Validation Loss: 7.761448383331299, Validation Accuracy: 0.25\n",
      "Epoch 2133/10000, Training Loss: 7.148388385772705, Training Accuracy: 0.571078431372549, Validation Loss: 6.3534417152404785, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2134/10000, Training Loss: 4.871805191040039, Training Accuracy: 0.6053921568627451, Validation Loss: 9.066217422485352, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2135/10000, Training Loss: 7.365451812744141, Training Accuracy: 0.5686274509803921, Validation Loss: 10.083970069885254, Validation Accuracy: 0.5\n",
      "Epoch 2136/10000, Training Loss: 7.167433738708496, Training Accuracy: 0.45098039215686275, Validation Loss: 4.020806789398193, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2137/10000, Training Loss: 5.368474006652832, Training Accuracy: 0.6225490196078431, Validation Loss: 12.65992259979248, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2138/10000, Training Loss: 8.194879531860352, Training Accuracy: 0.5122549019607843, Validation Loss: 9.864880561828613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2139/10000, Training Loss: 5.726937294006348, Training Accuracy: 0.5122549019607843, Validation Loss: 10.132015228271484, Validation Accuracy: 0.5\n",
      "Epoch 2140/10000, Training Loss: 4.035093784332275, Training Accuracy: 0.5808823529411765, Validation Loss: 3.1336240768432617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2141/10000, Training Loss: 10.68678092956543, Training Accuracy: 0.5784313725490197, Validation Loss: 8.129559516906738, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2142/10000, Training Loss: 6.936549663543701, Training Accuracy: 0.553921568627451, Validation Loss: 6.761795520782471, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2143/10000, Training Loss: 9.039344787597656, Training Accuracy: 0.4730392156862745, Validation Loss: 3.2232139110565186, Validation Accuracy: 0.5\n",
      "Epoch 2144/10000, Training Loss: 6.558621883392334, Training Accuracy: 0.5196078431372549, Validation Loss: 10.39955997467041, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2145/10000, Training Loss: 8.052766799926758, Training Accuracy: 0.5441176470588235, Validation Loss: 10.860583305358887, Validation Accuracy: 0.5\n",
      "Epoch 2146/10000, Training Loss: 8.271683692932129, Training Accuracy: 0.5245098039215687, Validation Loss: 17.383413314819336, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2147/10000, Training Loss: 6.281160831451416, Training Accuracy: 0.4803921568627451, Validation Loss: 4.811007976531982, Validation Accuracy: 0.25\n",
      "Epoch 2148/10000, Training Loss: 6.476214408874512, Training Accuracy: 0.5490196078431373, Validation Loss: 13.810455322265625, Validation Accuracy: 0.5\n",
      "Epoch 2149/10000, Training Loss: 5.932032108306885, Training Accuracy: 0.5196078431372549, Validation Loss: 4.4952073097229, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2150/10000, Training Loss: 5.376612186431885, Training Accuracy: 0.6176470588235294, Validation Loss: 10.350711822509766, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 2151/10000, Training Loss: 6.484556674957275, Training Accuracy: 0.5, Validation Loss: 2.9449777603149414, Validation Accuracy: 0.75\n",
      "Epoch 2152/10000, Training Loss: 6.64962100982666, Training Accuracy: 0.5490196078431373, Validation Loss: 8.609700202941895, Validation Accuracy: 0.5\n",
      "Epoch 2153/10000, Training Loss: 5.70005464553833, Training Accuracy: 0.5612745098039216, Validation Loss: 18.82369613647461, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2154/10000, Training Loss: 7.089306831359863, Training Accuracy: 0.5588235294117647, Validation Loss: 4.281025409698486, Validation Accuracy: 0.5\n",
      "Epoch 2155/10000, Training Loss: 3.927408456802368, Training Accuracy: 0.571078431372549, Validation Loss: 5.054366111755371, Validation Accuracy: 0.5\n",
      "Epoch 2156/10000, Training Loss: 4.711271286010742, Training Accuracy: 0.6127450980392157, Validation Loss: 5.299524307250977, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2157/10000, Training Loss: 5.034319877624512, Training Accuracy: 0.6274509803921569, Validation Loss: 11.837898254394531, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2158/10000, Training Loss: 6.383591651916504, Training Accuracy: 0.5857843137254902, Validation Loss: 5.60740852355957, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2159/10000, Training Loss: 6.945505619049072, Training Accuracy: 0.5269607843137255, Validation Loss: 3.1861495971679688, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2160/10000, Training Loss: 7.134210109710693, Training Accuracy: 0.5245098039215687, Validation Loss: 9.429783821105957, Validation Accuracy: 0.5\n",
      "Epoch 2161/10000, Training Loss: 3.2713654041290283, Training Accuracy: 0.5122549019607843, Validation Loss: 2.2577524185180664, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2162/10000, Training Loss: 4.02212381362915, Training Accuracy: 0.5441176470588235, Validation Loss: 12.161109924316406, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2163/10000, Training Loss: 2.739224672317505, Training Accuracy: 0.5171568627450981, Validation Loss: 7.802648067474365, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2164/10000, Training Loss: 4.969203472137451, Training Accuracy: 0.5808823529411765, Validation Loss: 12.1279878616333, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2165/10000, Training Loss: 6.469198226928711, Training Accuracy: 0.5318627450980392, Validation Loss: 5.400407791137695, Validation Accuracy: 0.5\n",
      "Epoch 2166/10000, Training Loss: 7.068605422973633, Training Accuracy: 0.46078431372549017, Validation Loss: 9.882634162902832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2167/10000, Training Loss: 8.128701210021973, Training Accuracy: 0.49019607843137253, Validation Loss: 12.23282241821289, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2168/10000, Training Loss: 3.837580680847168, Training Accuracy: 0.5735294117647058, Validation Loss: 3.67098069190979, Validation Accuracy: 0.5\n",
      "Epoch 2169/10000, Training Loss: 6.126137733459473, Training Accuracy: 0.5490196078431373, Validation Loss: 7.36859655380249, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2170/10000, Training Loss: 5.416423797607422, Training Accuracy: 0.5980392156862745, Validation Loss: 16.80923080444336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2171/10000, Training Loss: 3.808586359024048, Training Accuracy: 0.6053921568627451, Validation Loss: 8.288832664489746, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2172/10000, Training Loss: 6.464917182922363, Training Accuracy: 0.5588235294117647, Validation Loss: 3.9424216747283936, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2173/10000, Training Loss: 7.702922821044922, Training Accuracy: 0.5833333333333334, Validation Loss: 4.4671502113342285, Validation Accuracy: 0.75\n",
      "Epoch 2174/10000, Training Loss: 7.105033874511719, Training Accuracy: 0.5098039215686274, Validation Loss: 0.47891464829444885, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 2175/10000, Training Loss: 3.3309929370880127, Training Accuracy: 0.5955882352941176, Validation Loss: 19.3134822845459, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2176/10000, Training Loss: 6.046581268310547, Training Accuracy: 0.5294117647058824, Validation Loss: 11.049860954284668, Validation Accuracy: 0.25\n",
      "Epoch 2177/10000, Training Loss: 5.589938163757324, Training Accuracy: 0.5392156862745098, Validation Loss: 5.059190273284912, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2178/10000, Training Loss: 5.003124237060547, Training Accuracy: 0.5612745098039216, Validation Loss: 5.062902927398682, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2179/10000, Training Loss: 3.84920072555542, Training Accuracy: 0.6151960784313726, Validation Loss: 11.611419677734375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2180/10000, Training Loss: 6.783555030822754, Training Accuracy: 0.5416666666666666, Validation Loss: 5.30814790725708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2181/10000, Training Loss: 7.63140869140625, Training Accuracy: 0.5882352941176471, Validation Loss: 9.688340187072754, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2182/10000, Training Loss: 5.475797653198242, Training Accuracy: 0.5, Validation Loss: 1.365195870399475, Validation Accuracy: 0.75\n",
      "Epoch 2183/10000, Training Loss: 4.666367530822754, Training Accuracy: 0.5392156862745098, Validation Loss: 6.02239990234375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2184/10000, Training Loss: 4.078686714172363, Training Accuracy: 0.5024509803921569, Validation Loss: 1.4745022058486938, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2185/10000, Training Loss: 7.281065464019775, Training Accuracy: 0.5490196078431373, Validation Loss: 4.417026042938232, Validation Accuracy: 0.5\n",
      "Epoch 2186/10000, Training Loss: 7.752460479736328, Training Accuracy: 0.5735294117647058, Validation Loss: 8.493579864501953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2187/10000, Training Loss: 5.065218448638916, Training Accuracy: 0.571078431372549, Validation Loss: 5.972541809082031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2188/10000, Training Loss: 5.27020263671875, Training Accuracy: 0.5269607843137255, Validation Loss: 5.137290000915527, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2189/10000, Training Loss: 3.354463815689087, Training Accuracy: 0.5661764705882353, Validation Loss: 2.8254806995391846, Validation Accuracy: 0.25\n",
      "Epoch 2190/10000, Training Loss: 5.605511665344238, Training Accuracy: 0.6029411764705882, Validation Loss: 4.748083591461182, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2191/10000, Training Loss: 7.00606107711792, Training Accuracy: 0.5392156862745098, Validation Loss: 8.653691291809082, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2192/10000, Training Loss: 4.538111209869385, Training Accuracy: 0.6127450980392157, Validation Loss: 3.5947647094726562, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2193/10000, Training Loss: 6.2533278465271, Training Accuracy: 0.5833333333333334, Validation Loss: 14.22731876373291, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2194/10000, Training Loss: 3.5605642795562744, Training Accuracy: 0.5857843137254902, Validation Loss: 3.0979645252227783, Validation Accuracy: 0.5\n",
      "Epoch 2195/10000, Training Loss: 8.51203727722168, Training Accuracy: 0.5245098039215687, Validation Loss: 3.898927688598633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2196/10000, Training Loss: 5.369144916534424, Training Accuracy: 0.5098039215686274, Validation Loss: 4.475562572479248, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2197/10000, Training Loss: 6.194215297698975, Training Accuracy: 0.6078431372549019, Validation Loss: 6.158751964569092, Validation Accuracy: 0.5\n",
      "Epoch 2198/10000, Training Loss: 9.57190990447998, Training Accuracy: 0.5784313725490197, Validation Loss: 4.070892333984375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2199/10000, Training Loss: 4.494882583618164, Training Accuracy: 0.5906862745098039, Validation Loss: 3.192436933517456, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2200/10000, Training Loss: 4.578784465789795, Training Accuracy: 0.5563725490196079, Validation Loss: 2.7964954376220703, Validation Accuracy: 0.75\n",
      "Epoch 2201/10000, Training Loss: 6.204785346984863, Training Accuracy: 0.5661764705882353, Validation Loss: 7.380126953125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2202/10000, Training Loss: 4.790456295013428, Training Accuracy: 0.5245098039215687, Validation Loss: 4.266144275665283, Validation Accuracy: 0.5\n",
      "Epoch 2203/10000, Training Loss: 10.337727546691895, Training Accuracy: 0.5441176470588235, Validation Loss: 16.129697799682617, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2204/10000, Training Loss: 5.61923360824585, Training Accuracy: 0.5759803921568627, Validation Loss: 5.1655497550964355, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2205/10000, Training Loss: 4.751964569091797, Training Accuracy: 0.5147058823529411, Validation Loss: 8.596726417541504, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2206/10000, Training Loss: 4.396261692047119, Training Accuracy: 0.6102941176470589, Validation Loss: 8.021194458007812, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2207/10000, Training Loss: 5.453846454620361, Training Accuracy: 0.5931372549019608, Validation Loss: 7.626424789428711, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2208/10000, Training Loss: 7.351425647735596, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9818108677864075, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2209/10000, Training Loss: 4.60781717300415, Training Accuracy: 0.5490196078431373, Validation Loss: 5.592527389526367, Validation Accuracy: 0.5\n",
      "Epoch 2210/10000, Training Loss: 5.922891139984131, Training Accuracy: 0.5661764705882353, Validation Loss: 9.053439140319824, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2211/10000, Training Loss: 6.382967472076416, Training Accuracy: 0.5, Validation Loss: 5.112614631652832, Validation Accuracy: 0.5\n",
      "Epoch 2212/10000, Training Loss: 6.096540927886963, Training Accuracy: 0.5661764705882353, Validation Loss: 10.072243690490723, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2213/10000, Training Loss: 8.588964462280273, Training Accuracy: 0.4877450980392157, Validation Loss: 11.303321838378906, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2214/10000, Training Loss: 4.8939995765686035, Training Accuracy: 0.5833333333333334, Validation Loss: 6.354763507843018, Validation Accuracy: 0.5\n",
      "Epoch 2215/10000, Training Loss: 7.481472969055176, Training Accuracy: 0.5049019607843137, Validation Loss: 2.2622766494750977, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2216/10000, Training Loss: 6.985042572021484, Training Accuracy: 0.5073529411764706, Validation Loss: 10.992912292480469, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2217/10000, Training Loss: 6.612929344177246, Training Accuracy: 0.5980392156862745, Validation Loss: 9.517109870910645, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2218/10000, Training Loss: 5.18101167678833, Training Accuracy: 0.5686274509803921, Validation Loss: 4.2456793785095215, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2219/10000, Training Loss: 6.432197570800781, Training Accuracy: 0.6029411764705882, Validation Loss: 5.857064723968506, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2220/10000, Training Loss: 5.939445495605469, Training Accuracy: 0.5906862745098039, Validation Loss: 7.792595386505127, Validation Accuracy: 0.5\n",
      "Epoch 2221/10000, Training Loss: 8.412392616271973, Training Accuracy: 0.5588235294117647, Validation Loss: 11.06592082977295, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2222/10000, Training Loss: 4.830082893371582, Training Accuracy: 0.5441176470588235, Validation Loss: 7.793918132781982, Validation Accuracy: 0.5\n",
      "Epoch 2223/10000, Training Loss: 7.664432525634766, Training Accuracy: 0.6225490196078431, Validation Loss: 17.75018310546875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2224/10000, Training Loss: 6.301225662231445, Training Accuracy: 0.6078431372549019, Validation Loss: 4.972253322601318, Validation Accuracy: 0.5\n",
      "Epoch 2225/10000, Training Loss: 4.883216381072998, Training Accuracy: 0.5147058823529411, Validation Loss: 4.123352527618408, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2226/10000, Training Loss: 6.537282466888428, Training Accuracy: 0.5441176470588235, Validation Loss: 6.524400234222412, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2227/10000, Training Loss: 4.791534900665283, Training Accuracy: 0.6029411764705882, Validation Loss: 2.823488473892212, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2228/10000, Training Loss: 6.208291053771973, Training Accuracy: 0.5343137254901961, Validation Loss: 19.9365234375, Validation Accuracy: 0.5\n",
      "Epoch 2229/10000, Training Loss: 8.303657531738281, Training Accuracy: 0.5661764705882353, Validation Loss: 6.976934909820557, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2230/10000, Training Loss: 4.032725811004639, Training Accuracy: 0.6029411764705882, Validation Loss: 4.567759990692139, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2231/10000, Training Loss: 8.791678428649902, Training Accuracy: 0.5245098039215687, Validation Loss: 7.220918655395508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2232/10000, Training Loss: 5.995184898376465, Training Accuracy: 0.5220588235294118, Validation Loss: 8.712952613830566, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2233/10000, Training Loss: 6.74646520614624, Training Accuracy: 0.5612745098039216, Validation Loss: 8.339588165283203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2234/10000, Training Loss: 4.022777557373047, Training Accuracy: 0.571078431372549, Validation Loss: 6.017299652099609, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2235/10000, Training Loss: 6.11504602432251, Training Accuracy: 0.5735294117647058, Validation Loss: 3.1666641235351562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2236/10000, Training Loss: 7.931248188018799, Training Accuracy: 0.5122549019607843, Validation Loss: 11.705330848693848, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2237/10000, Training Loss: 6.875042915344238, Training Accuracy: 0.5441176470588235, Validation Loss: 10.710097312927246, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2238/10000, Training Loss: 3.0619537830352783, Training Accuracy: 0.5416666666666666, Validation Loss: 1.1313155889511108, Validation Accuracy: 0.5\n",
      "Epoch 2239/10000, Training Loss: 4.797221660614014, Training Accuracy: 0.5955882352941176, Validation Loss: 10.666892051696777, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2240/10000, Training Loss: 12.050437927246094, Training Accuracy: 0.5367647058823529, Validation Loss: 20.863447189331055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2241/10000, Training Loss: 4.455730438232422, Training Accuracy: 0.6029411764705882, Validation Loss: 6.138538360595703, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2242/10000, Training Loss: 7.137378215789795, Training Accuracy: 0.553921568627451, Validation Loss: 1.198689341545105, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2243/10000, Training Loss: 5.660359859466553, Training Accuracy: 0.5857843137254902, Validation Loss: 6.644041538238525, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2244/10000, Training Loss: 5.653780460357666, Training Accuracy: 0.5269607843137255, Validation Loss: 1.9269682168960571, Validation Accuracy: 0.75\n",
      "Epoch 2245/10000, Training Loss: 5.079947471618652, Training Accuracy: 0.5857843137254902, Validation Loss: 5.542556285858154, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2246/10000, Training Loss: 6.429252624511719, Training Accuracy: 0.5294117647058824, Validation Loss: 5.9799017906188965, Validation Accuracy: 0.5\n",
      "Epoch 2247/10000, Training Loss: 4.210428237915039, Training Accuracy: 0.6176470588235294, Validation Loss: 7.515464782714844, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2248/10000, Training Loss: 3.3248627185821533, Training Accuracy: 0.5563725490196079, Validation Loss: 6.0327839851379395, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2249/10000, Training Loss: 3.269598960876465, Training Accuracy: 0.6200980392156863, Validation Loss: 10.982612609863281, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2250/10000, Training Loss: 7.481433391571045, Training Accuracy: 0.5784313725490197, Validation Loss: 5.0195631980896, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2251/10000, Training Loss: 5.573605537414551, Training Accuracy: 0.5661764705882353, Validation Loss: 15.098644256591797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2252/10000, Training Loss: 6.412131309509277, Training Accuracy: 0.6200980392156863, Validation Loss: 6.21050500869751, Validation Accuracy: 0.5\n",
      "Epoch 2253/10000, Training Loss: 6.043862819671631, Training Accuracy: 0.5735294117647058, Validation Loss: 10.146578788757324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2254/10000, Training Loss: 4.282742500305176, Training Accuracy: 0.5098039215686274, Validation Loss: 5.689931869506836, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2255/10000, Training Loss: 4.993173599243164, Training Accuracy: 0.5686274509803921, Validation Loss: 6.348388195037842, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2256/10000, Training Loss: 8.851991653442383, Training Accuracy: 0.5686274509803921, Validation Loss: 6.773535251617432, Validation Accuracy: 0.5\n",
      "Epoch 2257/10000, Training Loss: 4.307526111602783, Training Accuracy: 0.5441176470588235, Validation Loss: 5.88543701171875, Validation Accuracy: 0.5\n",
      "Epoch 2258/10000, Training Loss: 8.424834251403809, Training Accuracy: 0.5245098039215687, Validation Loss: 7.2224955558776855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2259/10000, Training Loss: 5.411036491394043, Training Accuracy: 0.5686274509803921, Validation Loss: 6.128111362457275, Validation Accuracy: 0.5\n",
      "Epoch 2260/10000, Training Loss: 3.4588615894317627, Training Accuracy: 0.5980392156862745, Validation Loss: 3.049089193344116, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2261/10000, Training Loss: 4.632126808166504, Training Accuracy: 0.5490196078431373, Validation Loss: 11.316596031188965, Validation Accuracy: 0.5\n",
      "Epoch 2262/10000, Training Loss: 5.397730350494385, Training Accuracy: 0.5318627450980392, Validation Loss: 3.515726089477539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2263/10000, Training Loss: 4.718916416168213, Training Accuracy: 0.5955882352941176, Validation Loss: 10.929036140441895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2264/10000, Training Loss: 3.770127058029175, Training Accuracy: 0.6323529411764706, Validation Loss: 9.757850646972656, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2265/10000, Training Loss: 4.040562629699707, Training Accuracy: 0.6666666666666666, Validation Loss: 17.248332977294922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2266/10000, Training Loss: 6.456083297729492, Training Accuracy: 0.5931372549019608, Validation Loss: 7.541049480438232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2267/10000, Training Loss: 7.67159366607666, Training Accuracy: 0.5441176470588235, Validation Loss: 2.803096055984497, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2268/10000, Training Loss: 5.914605617523193, Training Accuracy: 0.5392156862745098, Validation Loss: 13.780686378479004, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2269/10000, Training Loss: 5.150094985961914, Training Accuracy: 0.5392156862745098, Validation Loss: 6.923940658569336, Validation Accuracy: 0.25\n",
      "Epoch 2270/10000, Training Loss: 4.661431312561035, Training Accuracy: 0.5857843137254902, Validation Loss: 5.154210567474365, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2271/10000, Training Loss: 4.551816940307617, Training Accuracy: 0.5906862745098039, Validation Loss: 7.040976047515869, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2272/10000, Training Loss: 5.128232955932617, Training Accuracy: 0.5514705882352942, Validation Loss: 10.302447319030762, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2273/10000, Training Loss: 5.024463176727295, Training Accuracy: 0.571078431372549, Validation Loss: 5.621889591217041, Validation Accuracy: 0.5\n",
      "Epoch 2274/10000, Training Loss: 5.345086097717285, Training Accuracy: 0.5686274509803921, Validation Loss: 4.122596263885498, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2275/10000, Training Loss: 4.532856464385986, Training Accuracy: 0.5392156862745098, Validation Loss: 7.2549147605896, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2276/10000, Training Loss: 10.347694396972656, Training Accuracy: 0.5735294117647058, Validation Loss: 7.787080764770508, Validation Accuracy: 0.25\n",
      "Epoch 2277/10000, Training Loss: 6.381669044494629, Training Accuracy: 0.5808823529411765, Validation Loss: 12.705653190612793, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2278/10000, Training Loss: 6.889454364776611, Training Accuracy: 0.5196078431372549, Validation Loss: 6.201755523681641, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2279/10000, Training Loss: 2.5579988956451416, Training Accuracy: 0.625, Validation Loss: 4.8948073387146, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2280/10000, Training Loss: 5.169083118438721, Training Accuracy: 0.5465686274509803, Validation Loss: 5.5148186683654785, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2281/10000, Training Loss: 4.56137752532959, Training Accuracy: 0.5514705882352942, Validation Loss: 2.591670036315918, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2282/10000, Training Loss: 5.5506911277771, Training Accuracy: 0.5, Validation Loss: 8.429094314575195, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2283/10000, Training Loss: 5.638749122619629, Training Accuracy: 0.5514705882352942, Validation Loss: 13.788509368896484, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2284/10000, Training Loss: 5.229321002960205, Training Accuracy: 0.5833333333333334, Validation Loss: 9.767748832702637, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2285/10000, Training Loss: 5.0054707527160645, Training Accuracy: 0.5808823529411765, Validation Loss: 5.394571304321289, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2286/10000, Training Loss: 6.833511829376221, Training Accuracy: 0.5073529411764706, Validation Loss: 6.88724946975708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2287/10000, Training Loss: 3.435415029525757, Training Accuracy: 0.5833333333333334, Validation Loss: 4.734510898590088, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2288/10000, Training Loss: 4.666062831878662, Training Accuracy: 0.5980392156862745, Validation Loss: 7.511054992675781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2289/10000, Training Loss: 4.470506191253662, Training Accuracy: 0.5833333333333334, Validation Loss: 5.982283115386963, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2290/10000, Training Loss: 3.9767112731933594, Training Accuracy: 0.5367647058823529, Validation Loss: 1.7122540473937988, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2291/10000, Training Loss: 4.898614883422852, Training Accuracy: 0.5147058823529411, Validation Loss: 3.4023971557617188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2292/10000, Training Loss: 3.435462474822998, Training Accuracy: 0.5808823529411765, Validation Loss: 5.647382736206055, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2293/10000, Training Loss: 4.258037567138672, Training Accuracy: 0.5686274509803921, Validation Loss: 3.630082845687866, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2294/10000, Training Loss: 3.825876474380493, Training Accuracy: 0.5735294117647058, Validation Loss: 3.1507482528686523, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2295/10000, Training Loss: 4.407569408416748, Training Accuracy: 0.6078431372549019, Validation Loss: 4.773282051086426, Validation Accuracy: 0.5\n",
      "Epoch 2296/10000, Training Loss: 5.453220844268799, Training Accuracy: 0.5857843137254902, Validation Loss: 6.664580821990967, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2297/10000, Training Loss: 4.267417907714844, Training Accuracy: 0.5563725490196079, Validation Loss: 3.3248131275177, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2298/10000, Training Loss: 4.052637577056885, Training Accuracy: 0.5857843137254902, Validation Loss: 9.688984870910645, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2299/10000, Training Loss: 6.062663555145264, Training Accuracy: 0.5318627450980392, Validation Loss: 5.600345134735107, Validation Accuracy: 0.5\n",
      "Epoch 2300/10000, Training Loss: 7.728760242462158, Training Accuracy: 0.5514705882352942, Validation Loss: 1.2762577533721924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2301/10000, Training Loss: 6.078351974487305, Training Accuracy: 0.5465686274509803, Validation Loss: 5.351382732391357, Validation Accuracy: 0.5\n",
      "Epoch 2302/10000, Training Loss: 5.231314182281494, Training Accuracy: 0.5416666666666666, Validation Loss: 8.155014991760254, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2303/10000, Training Loss: 5.420435905456543, Training Accuracy: 0.5612745098039216, Validation Loss: 8.726120948791504, Validation Accuracy: 0.5\n",
      "Epoch 2304/10000, Training Loss: 7.503432750701904, Training Accuracy: 0.5147058823529411, Validation Loss: 25.42188835144043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2305/10000, Training Loss: 7.019330978393555, Training Accuracy: 0.5588235294117647, Validation Loss: 3.5196447372436523, Validation Accuracy: 0.5\n",
      "Epoch 2306/10000, Training Loss: 4.448750972747803, Training Accuracy: 0.6053921568627451, Validation Loss: 6.4413604736328125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2307/10000, Training Loss: 6.305949687957764, Training Accuracy: 0.5392156862745098, Validation Loss: 9.772266387939453, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2308/10000, Training Loss: 7.953416347503662, Training Accuracy: 0.5073529411764706, Validation Loss: 10.316641807556152, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2309/10000, Training Loss: 6.291841506958008, Training Accuracy: 0.5490196078431373, Validation Loss: 13.250689506530762, Validation Accuracy: 0.25\n",
      "Epoch 2310/10000, Training Loss: 2.7188682556152344, Training Accuracy: 0.5833333333333334, Validation Loss: 4.687608242034912, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2311/10000, Training Loss: 5.171665191650391, Training Accuracy: 0.6446078431372549, Validation Loss: 12.34793758392334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2312/10000, Training Loss: 5.162669658660889, Training Accuracy: 0.5661764705882353, Validation Loss: 7.247308254241943, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2313/10000, Training Loss: 6.770046234130859, Training Accuracy: 0.5759803921568627, Validation Loss: 3.871363639831543, Validation Accuracy: 0.75\n",
      "Epoch 2314/10000, Training Loss: 4.465999126434326, Training Accuracy: 0.5490196078431373, Validation Loss: 5.94413423538208, Validation Accuracy: 0.5\n",
      "Epoch 2315/10000, Training Loss: 8.25302791595459, Training Accuracy: 0.5392156862745098, Validation Loss: 1.770579218864441, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2316/10000, Training Loss: 5.336411476135254, Training Accuracy: 0.5661764705882353, Validation Loss: 3.049192190170288, Validation Accuracy: 0.75\n",
      "Epoch 2317/10000, Training Loss: 6.563689708709717, Training Accuracy: 0.5245098039215687, Validation Loss: 10.255358695983887, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2318/10000, Training Loss: 4.16921329498291, Training Accuracy: 0.6176470588235294, Validation Loss: 20.128087997436523, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2319/10000, Training Loss: 3.6495697498321533, Training Accuracy: 0.5661764705882353, Validation Loss: 5.525104999542236, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2320/10000, Training Loss: 5.126650810241699, Training Accuracy: 0.4632352941176471, Validation Loss: 1.6693605184555054, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2321/10000, Training Loss: 5.813332557678223, Training Accuracy: 0.5612745098039216, Validation Loss: 5.72608757019043, Validation Accuracy: 0.5\n",
      "Epoch 2322/10000, Training Loss: 6.046247959136963, Training Accuracy: 0.5661764705882353, Validation Loss: 3.9414854049682617, Validation Accuracy: 0.75\n",
      "Epoch 2323/10000, Training Loss: 4.375836372375488, Training Accuracy: 0.5220588235294118, Validation Loss: 2.0980117321014404, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2324/10000, Training Loss: 5.042995452880859, Training Accuracy: 0.5808823529411765, Validation Loss: 5.292918682098389, Validation Accuracy: 0.5\n",
      "Epoch 2325/10000, Training Loss: 5.731635570526123, Training Accuracy: 0.5980392156862745, Validation Loss: 13.82943058013916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2326/10000, Training Loss: 10.70947265625, Training Accuracy: 0.5882352941176471, Validation Loss: 5.727859973907471, Validation Accuracy: 0.75\n",
      "Epoch 2327/10000, Training Loss: 5.188479423522949, Training Accuracy: 0.6029411764705882, Validation Loss: 25.094057083129883, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2328/10000, Training Loss: 4.880406856536865, Training Accuracy: 0.49754901960784315, Validation Loss: 12.841612815856934, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2329/10000, Training Loss: 5.713446140289307, Training Accuracy: 0.4681372549019608, Validation Loss: 3.086139440536499, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2330/10000, Training Loss: 5.109984874725342, Training Accuracy: 0.5245098039215687, Validation Loss: 5.658109188079834, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2331/10000, Training Loss: 5.641922473907471, Training Accuracy: 0.5857843137254902, Validation Loss: 2.417937994003296, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2332/10000, Training Loss: 5.014881134033203, Training Accuracy: 0.5392156862745098, Validation Loss: 5.4294915199279785, Validation Accuracy: 0.25\n",
      "Epoch 2333/10000, Training Loss: 6.018436908721924, Training Accuracy: 0.5661764705882353, Validation Loss: 2.7504098415374756, Validation Accuracy: 0.5\n",
      "Epoch 2334/10000, Training Loss: 17.142719268798828, Training Accuracy: 0.5416666666666666, Validation Loss: 33.592403411865234, Validation Accuracy: 0.25\n",
      "Epoch 2335/10000, Training Loss: 5.465663433074951, Training Accuracy: 0.5196078431372549, Validation Loss: 4.52459716796875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2336/10000, Training Loss: 4.520540237426758, Training Accuracy: 0.5906862745098039, Validation Loss: 11.101737976074219, Validation Accuracy: 0.25\n",
      "Epoch 2337/10000, Training Loss: 4.531770706176758, Training Accuracy: 0.571078431372549, Validation Loss: 3.4785754680633545, Validation Accuracy: 0.5\n",
      "Epoch 2338/10000, Training Loss: 7.591393947601318, Training Accuracy: 0.5220588235294118, Validation Loss: 17.78082847595215, Validation Accuracy: 0.25\n",
      "Epoch 2339/10000, Training Loss: 4.603176116943359, Training Accuracy: 0.5196078431372549, Validation Loss: 4.9166741371154785, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2340/10000, Training Loss: 8.315085411071777, Training Accuracy: 0.5661764705882353, Validation Loss: 5.074833393096924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2341/10000, Training Loss: 4.898426532745361, Training Accuracy: 0.5098039215686274, Validation Loss: 6.904752254486084, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2342/10000, Training Loss: 3.507852554321289, Training Accuracy: 0.5661764705882353, Validation Loss: 3.5481045246124268, Validation Accuracy: 0.25\n",
      "Epoch 2343/10000, Training Loss: 4.935774803161621, Training Accuracy: 0.5514705882352942, Validation Loss: 4.806407928466797, Validation Accuracy: 0.5\n",
      "Epoch 2344/10000, Training Loss: 3.264923095703125, Training Accuracy: 0.5465686274509803, Validation Loss: 5.474911212921143, Validation Accuracy: 0.5\n",
      "Epoch 2345/10000, Training Loss: 3.1051621437072754, Training Accuracy: 0.5980392156862745, Validation Loss: 4.574609279632568, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2346/10000, Training Loss: 3.774772882461548, Training Accuracy: 0.6593137254901961, Validation Loss: 15.56295108795166, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2347/10000, Training Loss: 4.483575820922852, Training Accuracy: 0.5318627450980392, Validation Loss: 2.807101249694824, Validation Accuracy: 0.5\n",
      "Epoch 2348/10000, Training Loss: 3.3574702739715576, Training Accuracy: 0.6102941176470589, Validation Loss: 4.933974742889404, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2349/10000, Training Loss: 4.634878158569336, Training Accuracy: 0.49264705882352944, Validation Loss: 4.076444149017334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2350/10000, Training Loss: 5.772561550140381, Training Accuracy: 0.5024509803921569, Validation Loss: 4.3014397621154785, Validation Accuracy: 0.75\n",
      "Epoch 2351/10000, Training Loss: 4.746278285980225, Training Accuracy: 0.6274509803921569, Validation Loss: 3.6021039485931396, Validation Accuracy: 0.75\n",
      "Epoch 2352/10000, Training Loss: 5.122731685638428, Training Accuracy: 0.47058823529411764, Validation Loss: 4.486660003662109, Validation Accuracy: 0.5\n",
      "Epoch 2353/10000, Training Loss: 7.992541790008545, Training Accuracy: 0.5490196078431373, Validation Loss: 27.046369552612305, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2354/10000, Training Loss: 5.950849533081055, Training Accuracy: 0.5980392156862745, Validation Loss: 17.95115852355957, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2355/10000, Training Loss: 4.793604373931885, Training Accuracy: 0.5563725490196079, Validation Loss: 3.4436473846435547, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2356/10000, Training Loss: 4.592532634735107, Training Accuracy: 0.49754901960784315, Validation Loss: 7.104034423828125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2357/10000, Training Loss: 3.2927844524383545, Training Accuracy: 0.6299019607843137, Validation Loss: 11.79476547241211, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2358/10000, Training Loss: 5.764870643615723, Training Accuracy: 0.5661764705882353, Validation Loss: 15.752495765686035, Validation Accuracy: 0.5\n",
      "Epoch 2359/10000, Training Loss: 4.787407875061035, Training Accuracy: 0.5857843137254902, Validation Loss: 14.051742553710938, Validation Accuracy: 0.5\n",
      "Epoch 2360/10000, Training Loss: 4.695545673370361, Training Accuracy: 0.5147058823529411, Validation Loss: 9.330195426940918, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2361/10000, Training Loss: 5.252335071563721, Training Accuracy: 0.5735294117647058, Validation Loss: 4.732962608337402, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2362/10000, Training Loss: 4.817617416381836, Training Accuracy: 0.5563725490196079, Validation Loss: 2.0734174251556396, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2363/10000, Training Loss: 3.388523578643799, Training Accuracy: 0.5563725490196079, Validation Loss: 10.125073432922363, Validation Accuracy: 0.25\n",
      "Epoch 2364/10000, Training Loss: 4.70023250579834, Training Accuracy: 0.5661764705882353, Validation Loss: 6.556934356689453, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2365/10000, Training Loss: 5.941861152648926, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3685487508773804, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2366/10000, Training Loss: 4.288345813751221, Training Accuracy: 0.5784313725490197, Validation Loss: 10.151266098022461, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2367/10000, Training Loss: 3.249629259109497, Training Accuracy: 0.5955882352941176, Validation Loss: 12.883407592773438, Validation Accuracy: 0.25\n",
      "Epoch 2368/10000, Training Loss: 4.577271938323975, Training Accuracy: 0.5563725490196079, Validation Loss: 8.316424369812012, Validation Accuracy: 0.5\n",
      "Epoch 2369/10000, Training Loss: 4.69364070892334, Training Accuracy: 0.6053921568627451, Validation Loss: 14.325698852539062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2370/10000, Training Loss: 4.076571464538574, Training Accuracy: 0.5857843137254902, Validation Loss: 5.5317230224609375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2371/10000, Training Loss: 4.896669387817383, Training Accuracy: 0.5, Validation Loss: 5.154507160186768, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2372/10000, Training Loss: 6.971302032470703, Training Accuracy: 0.5367647058823529, Validation Loss: 9.751941680908203, Validation Accuracy: 0.5\n",
      "Epoch 2373/10000, Training Loss: 5.393634796142578, Training Accuracy: 0.5490196078431373, Validation Loss: 5.120199680328369, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2374/10000, Training Loss: 8.859797477722168, Training Accuracy: 0.5416666666666666, Validation Loss: 4.17976188659668, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2375/10000, Training Loss: 8.063669204711914, Training Accuracy: 0.5416666666666666, Validation Loss: 10.963837623596191, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2376/10000, Training Loss: 7.009644985198975, Training Accuracy: 0.5759803921568627, Validation Loss: 2.4582464694976807, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2377/10000, Training Loss: 3.79292631149292, Training Accuracy: 0.5441176470588235, Validation Loss: 13.023871421813965, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2378/10000, Training Loss: 6.339584827423096, Training Accuracy: 0.5171568627450981, Validation Loss: 9.00840950012207, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2379/10000, Training Loss: 5.828030586242676, Training Accuracy: 0.5294117647058824, Validation Loss: 3.4842395782470703, Validation Accuracy: 0.5\n",
      "Epoch 2380/10000, Training Loss: 4.401863098144531, Training Accuracy: 0.4950980392156863, Validation Loss: 6.535974502563477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2381/10000, Training Loss: 7.192734241485596, Training Accuracy: 0.5563725490196079, Validation Loss: 5.868020534515381, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2382/10000, Training Loss: 3.718287706375122, Training Accuracy: 0.6225490196078431, Validation Loss: 7.953350067138672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2383/10000, Training Loss: 4.180944442749023, Training Accuracy: 0.5294117647058824, Validation Loss: 4.386903285980225, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2384/10000, Training Loss: 4.743720531463623, Training Accuracy: 0.5882352941176471, Validation Loss: 6.309246063232422, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2385/10000, Training Loss: 4.161122798919678, Training Accuracy: 0.5245098039215687, Validation Loss: 8.167668342590332, Validation Accuracy: 0.5\n",
      "Epoch 2386/10000, Training Loss: 4.533468723297119, Training Accuracy: 0.5588235294117647, Validation Loss: 9.328513145446777, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2387/10000, Training Loss: 4.965869903564453, Training Accuracy: 0.5784313725490197, Validation Loss: 7.82011604309082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2388/10000, Training Loss: 4.982837200164795, Training Accuracy: 0.5735294117647058, Validation Loss: 3.9517288208007812, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2389/10000, Training Loss: 5.193140506744385, Training Accuracy: 0.5882352941176471, Validation Loss: 10.764416694641113, Validation Accuracy: 0.25\n",
      "Epoch 2390/10000, Training Loss: 5.900069713592529, Training Accuracy: 0.5171568627450981, Validation Loss: 5.408231258392334, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2391/10000, Training Loss: 5.009850978851318, Training Accuracy: 0.49754901960784315, Validation Loss: 2.7916202545166016, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2392/10000, Training Loss: 5.167705059051514, Training Accuracy: 0.5686274509803921, Validation Loss: 6.281406402587891, Validation Accuracy: 0.25\n",
      "Epoch 2393/10000, Training Loss: 8.003117561340332, Training Accuracy: 0.49019607843137253, Validation Loss: 8.153046607971191, Validation Accuracy: 0.25\n",
      "Epoch 2394/10000, Training Loss: 5.451603889465332, Training Accuracy: 0.5759803921568627, Validation Loss: 8.751423835754395, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2395/10000, Training Loss: 3.999459743499756, Training Accuracy: 0.571078431372549, Validation Loss: 3.8516690731048584, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2396/10000, Training Loss: 3.475864887237549, Training Accuracy: 0.5759803921568627, Validation Loss: 6.237734317779541, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2397/10000, Training Loss: 7.494196891784668, Training Accuracy: 0.5612745098039216, Validation Loss: 7.599834442138672, Validation Accuracy: 0.5\n",
      "Epoch 2398/10000, Training Loss: 5.18648099899292, Training Accuracy: 0.6004901960784313, Validation Loss: 4.5963873863220215, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2399/10000, Training Loss: 4.32313346862793, Training Accuracy: 0.5833333333333334, Validation Loss: 3.202723264694214, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2400/10000, Training Loss: 4.754931449890137, Training Accuracy: 0.5735294117647058, Validation Loss: 2.1679160594940186, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2401/10000, Training Loss: 4.231317043304443, Training Accuracy: 0.5980392156862745, Validation Loss: 0.695706307888031, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2402/10000, Training Loss: 5.993060111999512, Training Accuracy: 0.6053921568627451, Validation Loss: 12.273273468017578, Validation Accuracy: 0.5\n",
      "Epoch 2403/10000, Training Loss: 4.711927890777588, Training Accuracy: 0.5220588235294118, Validation Loss: 1.7871249914169312, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2404/10000, Training Loss: 5.041292190551758, Training Accuracy: 0.5318627450980392, Validation Loss: 2.8325207233428955, Validation Accuracy: 0.5\n",
      "Epoch 2405/10000, Training Loss: 6.208694934844971, Training Accuracy: 0.6127450980392157, Validation Loss: 15.539965629577637, Validation Accuracy: 0.25\n",
      "Epoch 2406/10000, Training Loss: 6.154728412628174, Training Accuracy: 0.5318627450980392, Validation Loss: 6.267947673797607, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2407/10000, Training Loss: 4.827880382537842, Training Accuracy: 0.5514705882352942, Validation Loss: 4.584854602813721, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2408/10000, Training Loss: 4.72671365737915, Training Accuracy: 0.5563725490196079, Validation Loss: 7.112860202789307, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2409/10000, Training Loss: 6.088860034942627, Training Accuracy: 0.5147058823529411, Validation Loss: 4.337993144989014, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2410/10000, Training Loss: 6.078886032104492, Training Accuracy: 0.5955882352941176, Validation Loss: 8.460214614868164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2411/10000, Training Loss: 7.590240001678467, Training Accuracy: 0.6078431372549019, Validation Loss: 11.978175163269043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2412/10000, Training Loss: 5.194060802459717, Training Accuracy: 0.6004901960784313, Validation Loss: 4.895003795623779, Validation Accuracy: 0.25\n",
      "Epoch 2413/10000, Training Loss: 6.248124599456787, Training Accuracy: 0.5196078431372549, Validation Loss: 3.8094642162323, Validation Accuracy: 0.5\n",
      "Epoch 2414/10000, Training Loss: 3.6824607849121094, Training Accuracy: 0.6519607843137255, Validation Loss: 6.93437385559082, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2415/10000, Training Loss: 4.664846420288086, Training Accuracy: 0.4950980392156863, Validation Loss: 4.61946964263916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2416/10000, Training Loss: 5.404638767242432, Training Accuracy: 0.5588235294117647, Validation Loss: 1.8419065475463867, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2417/10000, Training Loss: 5.164543628692627, Training Accuracy: 0.5784313725490197, Validation Loss: 14.409416198730469, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2418/10000, Training Loss: 7.178534507751465, Training Accuracy: 0.5171568627450981, Validation Loss: 2.1259398460388184, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2419/10000, Training Loss: 6.22996187210083, Training Accuracy: 0.49754901960784315, Validation Loss: 12.883574485778809, Validation Accuracy: 0.25\n",
      "Epoch 2420/10000, Training Loss: 4.499064922332764, Training Accuracy: 0.5514705882352942, Validation Loss: 2.745023727416992, Validation Accuracy: 0.5\n",
      "Epoch 2421/10000, Training Loss: 3.298957347869873, Training Accuracy: 0.5367647058823529, Validation Loss: 6.040010929107666, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2422/10000, Training Loss: 4.853767395019531, Training Accuracy: 0.5318627450980392, Validation Loss: 7.686122894287109, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2423/10000, Training Loss: 4.622546195983887, Training Accuracy: 0.6544117647058824, Validation Loss: 8.186129570007324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2424/10000, Training Loss: 4.554250717163086, Training Accuracy: 0.6004901960784313, Validation Loss: 7.246952056884766, Validation Accuracy: 0.5\n",
      "Epoch 2425/10000, Training Loss: 4.648687839508057, Training Accuracy: 0.5392156862745098, Validation Loss: 7.50083589553833, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2426/10000, Training Loss: 3.1112000942230225, Training Accuracy: 0.6274509803921569, Validation Loss: 8.318984985351562, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2427/10000, Training Loss: 8.77370548248291, Training Accuracy: 0.5049019607843137, Validation Loss: 4.4380292892456055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2428/10000, Training Loss: 6.690229415893555, Training Accuracy: 0.5196078431372549, Validation Loss: 4.166794300079346, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2429/10000, Training Loss: 6.848875045776367, Training Accuracy: 0.5514705882352942, Validation Loss: 10.453629493713379, Validation Accuracy: 0.5\n",
      "Epoch 2430/10000, Training Loss: 7.926079273223877, Training Accuracy: 0.6519607843137255, Validation Loss: 12.627652168273926, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2431/10000, Training Loss: 3.625959873199463, Training Accuracy: 0.5759803921568627, Validation Loss: 0.5612850785255432, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2432/10000, Training Loss: 4.436262130737305, Training Accuracy: 0.5955882352941176, Validation Loss: 3.3257639408111572, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2433/10000, Training Loss: 10.796298027038574, Training Accuracy: 0.5098039215686274, Validation Loss: 9.253605842590332, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2434/10000, Training Loss: 5.171072483062744, Training Accuracy: 0.6127450980392157, Validation Loss: 6.8256988525390625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2435/10000, Training Loss: 4.174459934234619, Training Accuracy: 0.5245098039215687, Validation Loss: 4.538862228393555, Validation Accuracy: 0.5\n",
      "Epoch 2436/10000, Training Loss: 5.486800193786621, Training Accuracy: 0.5563725490196079, Validation Loss: 12.236536979675293, Validation Accuracy: 0.5\n",
      "Epoch 2437/10000, Training Loss: 4.687591075897217, Training Accuracy: 0.5098039215686274, Validation Loss: 1.9827680587768555, Validation Accuracy: 0.5\n",
      "Epoch 2438/10000, Training Loss: 3.937126398086548, Training Accuracy: 0.5980392156862745, Validation Loss: 3.9270026683807373, Validation Accuracy: 0.5\n",
      "Epoch 2439/10000, Training Loss: 4.627549648284912, Training Accuracy: 0.5759803921568627, Validation Loss: 13.089397430419922, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2440/10000, Training Loss: 3.9949657917022705, Training Accuracy: 0.5955882352941176, Validation Loss: 2.998987913131714, Validation Accuracy: 0.5\n",
      "Epoch 2441/10000, Training Loss: 6.595395088195801, Training Accuracy: 0.5955882352941176, Validation Loss: 4.640178680419922, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2442/10000, Training Loss: 3.699265956878662, Training Accuracy: 0.5686274509803921, Validation Loss: 3.9229812622070312, Validation Accuracy: 0.5\n",
      "Epoch 2443/10000, Training Loss: 3.3121471405029297, Training Accuracy: 0.6127450980392157, Validation Loss: 2.0118658542633057, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2444/10000, Training Loss: 4.112931728363037, Training Accuracy: 0.5759803921568627, Validation Loss: 10.693299293518066, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2445/10000, Training Loss: 3.8825016021728516, Training Accuracy: 0.5661764705882353, Validation Loss: 6.430534839630127, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2446/10000, Training Loss: 3.7887489795684814, Training Accuracy: 0.5612745098039216, Validation Loss: 4.174006462097168, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2447/10000, Training Loss: 5.597603797912598, Training Accuracy: 0.5931372549019608, Validation Loss: 8.921820640563965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2448/10000, Training Loss: 5.3337082862854, Training Accuracy: 0.5343137254901961, Validation Loss: 7.254120349884033, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2449/10000, Training Loss: 5.100203990936279, Training Accuracy: 0.5098039215686274, Validation Loss: 6.581113815307617, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2450/10000, Training Loss: 8.27233600616455, Training Accuracy: 0.5465686274509803, Validation Loss: 13.423918724060059, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2451/10000, Training Loss: 5.566280364990234, Training Accuracy: 0.625, Validation Loss: 12.523863792419434, Validation Accuracy: 0.25\n",
      "Epoch 2452/10000, Training Loss: 9.088212966918945, Training Accuracy: 0.5269607843137255, Validation Loss: 7.464593410491943, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2453/10000, Training Loss: 3.495981216430664, Training Accuracy: 0.5612745098039216, Validation Loss: 3.0392634868621826, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2454/10000, Training Loss: 4.751761436462402, Training Accuracy: 0.5686274509803921, Validation Loss: 3.371567487716675, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2455/10000, Training Loss: 6.746771335601807, Training Accuracy: 0.49754901960784315, Validation Loss: 3.3108789920806885, Validation Accuracy: 0.5\n",
      "Epoch 2456/10000, Training Loss: 5.361842632293701, Training Accuracy: 0.5588235294117647, Validation Loss: 3.6427271366119385, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2457/10000, Training Loss: 5.049066066741943, Training Accuracy: 0.5882352941176471, Validation Loss: 10.916221618652344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2458/10000, Training Loss: 6.022068977355957, Training Accuracy: 0.553921568627451, Validation Loss: 12.443062782287598, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2459/10000, Training Loss: 6.205082416534424, Training Accuracy: 0.5637254901960784, Validation Loss: 15.298937797546387, Validation Accuracy: 0.25\n",
      "Epoch 2460/10000, Training Loss: 5.02870512008667, Training Accuracy: 0.5122549019607843, Validation Loss: 7.875669479370117, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2461/10000, Training Loss: 5.212088584899902, Training Accuracy: 0.5857843137254902, Validation Loss: 10.81002140045166, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2462/10000, Training Loss: 4.297694683074951, Training Accuracy: 0.5857843137254902, Validation Loss: 3.2197437286376953, Validation Accuracy: 0.5\n",
      "Epoch 2463/10000, Training Loss: 5.104872703552246, Training Accuracy: 0.5686274509803921, Validation Loss: 7.345138072967529, Validation Accuracy: 0.25\n",
      "Epoch 2464/10000, Training Loss: 5.92594051361084, Training Accuracy: 0.5980392156862745, Validation Loss: 10.895953178405762, Validation Accuracy: 0.25\n",
      "Epoch 2465/10000, Training Loss: 3.1604816913604736, Training Accuracy: 0.5318627450980392, Validation Loss: 1.5391896963119507, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2466/10000, Training Loss: 6.147373676300049, Training Accuracy: 0.4950980392156863, Validation Loss: 8.77276611328125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2467/10000, Training Loss: 8.319544792175293, Training Accuracy: 0.5784313725490197, Validation Loss: 2.134279251098633, Validation Accuracy: 0.75\n",
      "Epoch 2468/10000, Training Loss: 3.8987224102020264, Training Accuracy: 0.5661764705882353, Validation Loss: 4.901492118835449, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2469/10000, Training Loss: 3.8514249324798584, Training Accuracy: 0.5612745098039216, Validation Loss: 3.549384832382202, Validation Accuracy: 0.5\n",
      "Epoch 2470/10000, Training Loss: 5.03700065612793, Training Accuracy: 0.5367647058823529, Validation Loss: 6.770191192626953, Validation Accuracy: 0.5\n",
      "Epoch 2471/10000, Training Loss: 3.3684258460998535, Training Accuracy: 0.5980392156862745, Validation Loss: 3.854060411453247, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2472/10000, Training Loss: 4.833521366119385, Training Accuracy: 0.5416666666666666, Validation Loss: 16.960397720336914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2473/10000, Training Loss: 4.073527812957764, Training Accuracy: 0.5857843137254902, Validation Loss: 4.102232456207275, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2474/10000, Training Loss: 8.263944625854492, Training Accuracy: 0.5171568627450981, Validation Loss: 5.768385410308838, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2475/10000, Training Loss: 5.483309268951416, Training Accuracy: 0.5490196078431373, Validation Loss: 19.081857681274414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2476/10000, Training Loss: 5.263601779937744, Training Accuracy: 0.571078431372549, Validation Loss: 4.813429832458496, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2477/10000, Training Loss: 6.699219226837158, Training Accuracy: 0.5808823529411765, Validation Loss: 6.153295993804932, Validation Accuracy: 0.5\n",
      "Epoch 2478/10000, Training Loss: 4.697206497192383, Training Accuracy: 0.5098039215686274, Validation Loss: 0.9911110997200012, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2479/10000, Training Loss: 5.053914546966553, Training Accuracy: 0.5563725490196079, Validation Loss: 3.0289652347564697, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2480/10000, Training Loss: 5.636382579803467, Training Accuracy: 0.5073529411764706, Validation Loss: 5.4733428955078125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2481/10000, Training Loss: 4.382326602935791, Training Accuracy: 0.5563725490196079, Validation Loss: 4.675164222717285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2482/10000, Training Loss: 4.313292026519775, Training Accuracy: 0.5416666666666666, Validation Loss: 4.786580562591553, Validation Accuracy: 0.75\n",
      "Epoch 2483/10000, Training Loss: 4.387557029724121, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9555547833442688, Validation Accuracy: 0.75\n",
      "Epoch 2484/10000, Training Loss: 7.613778114318848, Training Accuracy: 0.5882352941176471, Validation Loss: 12.551547050476074, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2485/10000, Training Loss: 5.58619499206543, Training Accuracy: 0.5588235294117647, Validation Loss: 3.2763803005218506, Validation Accuracy: 0.5\n",
      "Epoch 2486/10000, Training Loss: 6.515116214752197, Training Accuracy: 0.5465686274509803, Validation Loss: 11.242137908935547, Validation Accuracy: 0.5\n",
      "Epoch 2487/10000, Training Loss: 4.853527545928955, Training Accuracy: 0.5906862745098039, Validation Loss: 7.356903076171875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2488/10000, Training Loss: 5.175017833709717, Training Accuracy: 0.5416666666666666, Validation Loss: 1.9244874715805054, Validation Accuracy: 0.5\n",
      "Epoch 2489/10000, Training Loss: 3.935718059539795, Training Accuracy: 0.5906862745098039, Validation Loss: 10.725987434387207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2490/10000, Training Loss: 7.644256114959717, Training Accuracy: 0.5, Validation Loss: 7.147603988647461, Validation Accuracy: 0.5\n",
      "Epoch 2491/10000, Training Loss: 4.328545570373535, Training Accuracy: 0.6078431372549019, Validation Loss: 8.1600980758667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2492/10000, Training Loss: 4.722909450531006, Training Accuracy: 0.553921568627451, Validation Loss: 5.906276226043701, Validation Accuracy: 0.5\n",
      "Epoch 2493/10000, Training Loss: 7.027756214141846, Training Accuracy: 0.5514705882352942, Validation Loss: 2.1600141525268555, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2494/10000, Training Loss: 3.8994386196136475, Training Accuracy: 0.6078431372549019, Validation Loss: 1.7595702409744263, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2495/10000, Training Loss: 4.54950475692749, Training Accuracy: 0.5735294117647058, Validation Loss: 3.970994710922241, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2496/10000, Training Loss: 4.392640113830566, Training Accuracy: 0.5686274509803921, Validation Loss: 4.84684419631958, Validation Accuracy: 0.5\n",
      "Epoch 2497/10000, Training Loss: 3.4415204524993896, Training Accuracy: 0.5588235294117647, Validation Loss: 4.580082893371582, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2498/10000, Training Loss: 5.725034236907959, Training Accuracy: 0.5588235294117647, Validation Loss: 4.071462154388428, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2499/10000, Training Loss: 3.3955070972442627, Training Accuracy: 0.5661764705882353, Validation Loss: 3.0240633487701416, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2500/10000, Training Loss: 5.698895454406738, Training Accuracy: 0.6127450980392157, Validation Loss: 1.5980339050292969, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2501/10000, Training Loss: 5.007981777191162, Training Accuracy: 0.5882352941176471, Validation Loss: 6.8619914054870605, Validation Accuracy: 0.5\n",
      "Epoch 2502/10000, Training Loss: 4.27760124206543, Training Accuracy: 0.5147058823529411, Validation Loss: 2.1058828830718994, Validation Accuracy: 0.5\n",
      "Epoch 2503/10000, Training Loss: 3.642505645751953, Training Accuracy: 0.6053921568627451, Validation Loss: 3.6831624507904053, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2504/10000, Training Loss: 3.6216955184936523, Training Accuracy: 0.625, Validation Loss: 2.0696558952331543, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2505/10000, Training Loss: 5.285362243652344, Training Accuracy: 0.5490196078431373, Validation Loss: 15.245770454406738, Validation Accuracy: 0.25\n",
      "Epoch 2506/10000, Training Loss: 4.735925197601318, Training Accuracy: 0.5514705882352942, Validation Loss: 5.429399013519287, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2507/10000, Training Loss: 5.200327396392822, Training Accuracy: 0.5833333333333334, Validation Loss: 6.880058288574219, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2508/10000, Training Loss: 5.759481906890869, Training Accuracy: 0.571078431372549, Validation Loss: 12.200435638427734, Validation Accuracy: 0.25\n",
      "Epoch 2509/10000, Training Loss: 5.371649265289307, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1936426162719727, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2510/10000, Training Loss: 4.527753829956055, Training Accuracy: 0.6029411764705882, Validation Loss: 5.4720282554626465, Validation Accuracy: 0.75\n",
      "Epoch 2511/10000, Training Loss: 4.075195789337158, Training Accuracy: 0.5588235294117647, Validation Loss: 6.02006196975708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2512/10000, Training Loss: 2.933485746383667, Training Accuracy: 0.5833333333333334, Validation Loss: 2.8043339252471924, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2513/10000, Training Loss: 5.603290557861328, Training Accuracy: 0.5392156862745098, Validation Loss: 11.376851081848145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2514/10000, Training Loss: 4.699290752410889, Training Accuracy: 0.5049019607843137, Validation Loss: 2.055392026901245, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2515/10000, Training Loss: 5.256195545196533, Training Accuracy: 0.5343137254901961, Validation Loss: 10.41297435760498, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2516/10000, Training Loss: 11.981866836547852, Training Accuracy: 0.571078431372549, Validation Loss: 15.571614265441895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2517/10000, Training Loss: 3.69931960105896, Training Accuracy: 0.5024509803921569, Validation Loss: 3.7779786586761475, Validation Accuracy: 0.5\n",
      "Epoch 2518/10000, Training Loss: 3.798344373703003, Training Accuracy: 0.5392156862745098, Validation Loss: 7.790531158447266, Validation Accuracy: 0.5\n",
      "Epoch 2519/10000, Training Loss: 3.9212005138397217, Training Accuracy: 0.5857843137254902, Validation Loss: 5.644371509552002, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2520/10000, Training Loss: 3.523348331451416, Training Accuracy: 0.5661764705882353, Validation Loss: 8.11536693572998, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2521/10000, Training Loss: 6.486488342285156, Training Accuracy: 0.5245098039215687, Validation Loss: 5.220798969268799, Validation Accuracy: 0.5\n",
      "Epoch 2522/10000, Training Loss: 4.596046447753906, Training Accuracy: 0.5441176470588235, Validation Loss: 6.151257038116455, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2523/10000, Training Loss: 8.164543151855469, Training Accuracy: 0.5784313725490197, Validation Loss: 4.568671703338623, Validation Accuracy: 0.5\n",
      "Epoch 2524/10000, Training Loss: 4.73190975189209, Training Accuracy: 0.5147058823529411, Validation Loss: 5.620981216430664, Validation Accuracy: 0.5\n",
      "Epoch 2525/10000, Training Loss: 5.786051273345947, Training Accuracy: 0.5465686274509803, Validation Loss: 4.259582996368408, Validation Accuracy: 0.75\n",
      "Epoch 2526/10000, Training Loss: 4.271504878997803, Training Accuracy: 0.5906862745098039, Validation Loss: 7.969900131225586, Validation Accuracy: 0.5\n",
      "Epoch 2527/10000, Training Loss: 7.76162052154541, Training Accuracy: 0.5637254901960784, Validation Loss: 3.7857513427734375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2528/10000, Training Loss: 3.229869842529297, Training Accuracy: 0.5294117647058824, Validation Loss: 2.098503828048706, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2529/10000, Training Loss: 3.575827121734619, Training Accuracy: 0.5955882352941176, Validation Loss: 8.695622444152832, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2530/10000, Training Loss: 2.9699037075042725, Training Accuracy: 0.6299019607843137, Validation Loss: 8.740656852722168, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2531/10000, Training Loss: 6.899388790130615, Training Accuracy: 0.5735294117647058, Validation Loss: 10.443954467773438, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2532/10000, Training Loss: 2.7670326232910156, Training Accuracy: 0.571078431372549, Validation Loss: 1.5881832838058472, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2533/10000, Training Loss: 3.689021110534668, Training Accuracy: 0.553921568627451, Validation Loss: 8.925642967224121, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2534/10000, Training Loss: 5.451336860656738, Training Accuracy: 0.5637254901960784, Validation Loss: 7.092315673828125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2535/10000, Training Loss: 4.878744125366211, Training Accuracy: 0.5808823529411765, Validation Loss: 1.347935676574707, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2536/10000, Training Loss: 3.8715500831604004, Training Accuracy: 0.5612745098039216, Validation Loss: 3.3859519958496094, Validation Accuracy: 0.5\n",
      "Epoch 2537/10000, Training Loss: 6.129806041717529, Training Accuracy: 0.5441176470588235, Validation Loss: 6.027536869049072, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2538/10000, Training Loss: 5.703405857086182, Training Accuracy: 0.5343137254901961, Validation Loss: 2.0139667987823486, Validation Accuracy: 0.5\n",
      "Epoch 2539/10000, Training Loss: 3.6099109649658203, Training Accuracy: 0.5661764705882353, Validation Loss: 5.1290130615234375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2540/10000, Training Loss: 3.58441162109375, Training Accuracy: 0.5588235294117647, Validation Loss: 3.8498733043670654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2541/10000, Training Loss: 4.184292793273926, Training Accuracy: 0.5416666666666666, Validation Loss: 12.392401695251465, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2542/10000, Training Loss: 2.883474588394165, Training Accuracy: 0.5392156862745098, Validation Loss: 3.101973533630371, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2543/10000, Training Loss: 3.317145347595215, Training Accuracy: 0.5514705882352942, Validation Loss: 5.760486125946045, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2544/10000, Training Loss: 5.542530059814453, Training Accuracy: 0.5588235294117647, Validation Loss: 7.8501434326171875, Validation Accuracy: 0.25\n",
      "Epoch 2545/10000, Training Loss: 7.486098766326904, Training Accuracy: 0.5098039215686274, Validation Loss: 2.264930248260498, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2546/10000, Training Loss: 5.251336574554443, Training Accuracy: 0.5588235294117647, Validation Loss: 8.35484790802002, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2547/10000, Training Loss: 3.3974196910858154, Training Accuracy: 0.625, Validation Loss: 2.7382850646972656, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2548/10000, Training Loss: 4.787225246429443, Training Accuracy: 0.5392156862745098, Validation Loss: 3.253228187561035, Validation Accuracy: 0.5\n",
      "Epoch 2549/10000, Training Loss: 4.299510955810547, Training Accuracy: 0.6299019607843137, Validation Loss: 5.990994930267334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2550/10000, Training Loss: 5.32546329498291, Training Accuracy: 0.5147058823529411, Validation Loss: 5.515162944793701, Validation Accuracy: 0.5\n",
      "Epoch 2551/10000, Training Loss: 4.485064506530762, Training Accuracy: 0.6053921568627451, Validation Loss: 8.552783012390137, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2552/10000, Training Loss: 5.219581127166748, Training Accuracy: 0.5049019607843137, Validation Loss: 8.919724464416504, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2553/10000, Training Loss: 5.069821357727051, Training Accuracy: 0.5563725490196079, Validation Loss: 3.4823808670043945, Validation Accuracy: 0.5\n",
      "Epoch 2554/10000, Training Loss: 6.368351936340332, Training Accuracy: 0.5122549019607843, Validation Loss: 9.419032096862793, Validation Accuracy: 0.5\n",
      "Epoch 2555/10000, Training Loss: 4.535696983337402, Training Accuracy: 0.6029411764705882, Validation Loss: 5.173172473907471, Validation Accuracy: 0.5\n",
      "Epoch 2556/10000, Training Loss: 4.501055717468262, Training Accuracy: 0.49019607843137253, Validation Loss: 7.634620666503906, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2557/10000, Training Loss: 5.247003078460693, Training Accuracy: 0.5441176470588235, Validation Loss: 11.37628173828125, Validation Accuracy: 0.5\n",
      "Epoch 2558/10000, Training Loss: 3.268657684326172, Training Accuracy: 0.5661764705882353, Validation Loss: 2.3319146633148193, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2559/10000, Training Loss: 3.1618030071258545, Training Accuracy: 0.5637254901960784, Validation Loss: 4.741639137268066, Validation Accuracy: 0.25\n",
      "Epoch 2560/10000, Training Loss: 5.193437576293945, Training Accuracy: 0.5784313725490197, Validation Loss: 3.86114764213562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2561/10000, Training Loss: 5.127459526062012, Training Accuracy: 0.5392156862745098, Validation Loss: 2.1540043354034424, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2562/10000, Training Loss: 4.386127471923828, Training Accuracy: 0.6053921568627451, Validation Loss: 4.859461307525635, Validation Accuracy: 0.5\n",
      "Epoch 2563/10000, Training Loss: 4.423117160797119, Training Accuracy: 0.5392156862745098, Validation Loss: 4.530044078826904, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2564/10000, Training Loss: 4.473371982574463, Training Accuracy: 0.5294117647058824, Validation Loss: 1.7398914098739624, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2565/10000, Training Loss: 4.952213287353516, Training Accuracy: 0.5588235294117647, Validation Loss: 5.430013656616211, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2566/10000, Training Loss: 3.8005101680755615, Training Accuracy: 0.5490196078431373, Validation Loss: 2.5846521854400635, Validation Accuracy: 0.75\n",
      "Epoch 2567/10000, Training Loss: 4.758238792419434, Training Accuracy: 0.5367647058823529, Validation Loss: 4.410670280456543, Validation Accuracy: 0.5\n",
      "Epoch 2568/10000, Training Loss: 3.6443824768066406, Training Accuracy: 0.5906862745098039, Validation Loss: 3.7673871517181396, Validation Accuracy: 0.5\n",
      "Epoch 2569/10000, Training Loss: 3.828172206878662, Training Accuracy: 0.5808823529411765, Validation Loss: 5.849564075469971, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2570/10000, Training Loss: 4.325409889221191, Training Accuracy: 0.5759803921568627, Validation Loss: 2.9443016052246094, Validation Accuracy: 0.5\n",
      "Epoch 2571/10000, Training Loss: 5.293984413146973, Training Accuracy: 0.5588235294117647, Validation Loss: 21.934898376464844, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2572/10000, Training Loss: 6.102681636810303, Training Accuracy: 0.5612745098039216, Validation Loss: 4.693896293640137, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2573/10000, Training Loss: 4.355885028839111, Training Accuracy: 0.5563725490196079, Validation Loss: 3.789449691772461, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2574/10000, Training Loss: 5.659733772277832, Training Accuracy: 0.5514705882352942, Validation Loss: 4.121963977813721, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2575/10000, Training Loss: 3.617623805999756, Training Accuracy: 0.6053921568627451, Validation Loss: 6.757927417755127, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2576/10000, Training Loss: 4.261754035949707, Training Accuracy: 0.5269607843137255, Validation Loss: 1.2432852983474731, Validation Accuracy: 0.5\n",
      "Epoch 2577/10000, Training Loss: 5.690424919128418, Training Accuracy: 0.553921568627451, Validation Loss: 1.8727840185165405, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 2578/10000, Training Loss: 4.508553504943848, Training Accuracy: 0.571078431372549, Validation Loss: 12.68636417388916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2579/10000, Training Loss: 5.515555381774902, Training Accuracy: 0.6078431372549019, Validation Loss: 2.0166311264038086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2580/10000, Training Loss: 5.207159519195557, Training Accuracy: 0.5220588235294118, Validation Loss: 4.685157299041748, Validation Accuracy: 0.75\n",
      "Epoch 2581/10000, Training Loss: 5.186135768890381, Training Accuracy: 0.5906862745098039, Validation Loss: 6.516056537628174, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2582/10000, Training Loss: 5.162689208984375, Training Accuracy: 0.5318627450980392, Validation Loss: 3.4921722412109375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2583/10000, Training Loss: 5.568120002746582, Training Accuracy: 0.553921568627451, Validation Loss: 8.805414199829102, Validation Accuracy: 0.25\n",
      "Epoch 2584/10000, Training Loss: 3.843071699142456, Training Accuracy: 0.5857843137254902, Validation Loss: 6.390482425689697, Validation Accuracy: 0.5\n",
      "Epoch 2585/10000, Training Loss: 4.800726890563965, Training Accuracy: 0.5955882352941176, Validation Loss: 2.041274309158325, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2586/10000, Training Loss: 3.8087663650512695, Training Accuracy: 0.5392156862745098, Validation Loss: 1.4988099336624146, Validation Accuracy: 0.75\n",
      "Epoch 2587/10000, Training Loss: 5.066826343536377, Training Accuracy: 0.5147058823529411, Validation Loss: 7.936408996582031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2588/10000, Training Loss: 7.350411891937256, Training Accuracy: 0.49019607843137253, Validation Loss: 10.176135063171387, Validation Accuracy: 0.5\n",
      "Epoch 2589/10000, Training Loss: 4.586391925811768, Training Accuracy: 0.5833333333333334, Validation Loss: 7.646165370941162, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2590/10000, Training Loss: 3.785039186477661, Training Accuracy: 0.5245098039215687, Validation Loss: 5.158988952636719, Validation Accuracy: 0.25\n",
      "Epoch 2591/10000, Training Loss: 5.390540599822998, Training Accuracy: 0.5269607843137255, Validation Loss: 2.3280885219573975, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2592/10000, Training Loss: 3.87501859664917, Training Accuracy: 0.5588235294117647, Validation Loss: 4.096695899963379, Validation Accuracy: 0.5\n",
      "Epoch 2593/10000, Training Loss: 5.475596904754639, Training Accuracy: 0.5906862745098039, Validation Loss: 15.96507740020752, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2594/10000, Training Loss: 3.361255407333374, Training Accuracy: 0.5514705882352942, Validation Loss: 3.3487980365753174, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2595/10000, Training Loss: 3.5413620471954346, Training Accuracy: 0.5833333333333334, Validation Loss: 2.4836628437042236, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2596/10000, Training Loss: 4.160917282104492, Training Accuracy: 0.6200980392156863, Validation Loss: 6.789310455322266, Validation Accuracy: 0.5\n",
      "Epoch 2597/10000, Training Loss: 5.993433475494385, Training Accuracy: 0.5759803921568627, Validation Loss: 10.146798133850098, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2598/10000, Training Loss: 4.059919834136963, Training Accuracy: 0.6151960784313726, Validation Loss: 2.632161855697632, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2599/10000, Training Loss: 3.990778684616089, Training Accuracy: 0.5612745098039216, Validation Loss: 2.3648908138275146, Validation Accuracy: 0.75\n",
      "Epoch 2600/10000, Training Loss: 4.441145420074463, Training Accuracy: 0.5196078431372549, Validation Loss: 6.6340789794921875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2601/10000, Training Loss: 3.779393196105957, Training Accuracy: 0.5514705882352942, Validation Loss: 1.648183822631836, Validation Accuracy: 0.5\n",
      "Epoch 2602/10000, Training Loss: 3.526883363723755, Training Accuracy: 0.5024509803921569, Validation Loss: 1.8722347021102905, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2603/10000, Training Loss: 4.103002548217773, Training Accuracy: 0.5441176470588235, Validation Loss: 3.3216421604156494, Validation Accuracy: 0.5\n",
      "Epoch 2604/10000, Training Loss: 5.052216053009033, Training Accuracy: 0.5759803921568627, Validation Loss: 5.613772869110107, Validation Accuracy: 0.25\n",
      "Epoch 2605/10000, Training Loss: 3.34601092338562, Training Accuracy: 0.5784313725490197, Validation Loss: 7.992677688598633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2606/10000, Training Loss: 3.6108264923095703, Training Accuracy: 0.5367647058823529, Validation Loss: 31.4512939453125, Validation Accuracy: 0.5\n",
      "Epoch 2607/10000, Training Loss: 2.7250428199768066, Training Accuracy: 0.5514705882352942, Validation Loss: 1.9242295026779175, Validation Accuracy: 0.75\n",
      "Epoch 2608/10000, Training Loss: 4.14015007019043, Training Accuracy: 0.5245098039215687, Validation Loss: 8.453081130981445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2609/10000, Training Loss: 4.0419721603393555, Training Accuracy: 0.4950980392156863, Validation Loss: 2.990401268005371, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2610/10000, Training Loss: 4.407904624938965, Training Accuracy: 0.5024509803921569, Validation Loss: 7.153868198394775, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2611/10000, Training Loss: 2.9268105030059814, Training Accuracy: 0.5980392156862745, Validation Loss: 7.1338677406311035, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2612/10000, Training Loss: 4.199862480163574, Training Accuracy: 0.5882352941176471, Validation Loss: 1.393153190612793, Validation Accuracy: 0.5\n",
      "Epoch 2613/10000, Training Loss: 4.199383735656738, Training Accuracy: 0.5563725490196079, Validation Loss: 10.205231666564941, Validation Accuracy: 0.5\n",
      "Epoch 2614/10000, Training Loss: 5.015398025512695, Training Accuracy: 0.5122549019607843, Validation Loss: 4.018260478973389, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2615/10000, Training Loss: 3.5622849464416504, Training Accuracy: 0.5759803921568627, Validation Loss: 5.233772277832031, Validation Accuracy: 0.5\n",
      "Epoch 2616/10000, Training Loss: 4.048994064331055, Training Accuracy: 0.6200980392156863, Validation Loss: 10.083490371704102, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2617/10000, Training Loss: 4.368553161621094, Training Accuracy: 0.5955882352941176, Validation Loss: 7.049041748046875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2618/10000, Training Loss: 4.352030277252197, Training Accuracy: 0.5637254901960784, Validation Loss: 3.5227749347686768, Validation Accuracy: 0.5\n",
      "Epoch 2619/10000, Training Loss: 3.541741132736206, Training Accuracy: 0.571078431372549, Validation Loss: 0.7924048900604248, Validation Accuracy: 0.75\n",
      "Epoch 2620/10000, Training Loss: 5.475231647491455, Training Accuracy: 0.5857843137254902, Validation Loss: 14.981414794921875, Validation Accuracy: 0.25\n",
      "Epoch 2621/10000, Training Loss: 3.6736950874328613, Training Accuracy: 0.5220588235294118, Validation Loss: 2.4404079914093018, Validation Accuracy: 0.5\n",
      "Epoch 2622/10000, Training Loss: 4.5161452293396, Training Accuracy: 0.5955882352941176, Validation Loss: 13.335185050964355, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2623/10000, Training Loss: 3.362617254257202, Training Accuracy: 0.5857843137254902, Validation Loss: 7.9944915771484375, Validation Accuracy: 0.5\n",
      "Epoch 2624/10000, Training Loss: 6.636312007904053, Training Accuracy: 0.5882352941176471, Validation Loss: 13.268940925598145, Validation Accuracy: 0.5\n",
      "Epoch 2625/10000, Training Loss: 4.551772594451904, Training Accuracy: 0.5490196078431373, Validation Loss: 10.339056968688965, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2626/10000, Training Loss: 3.809434175491333, Training Accuracy: 0.5122549019607843, Validation Loss: 3.935857057571411, Validation Accuracy: 0.75\n",
      "Epoch 2627/10000, Training Loss: 3.897179126739502, Training Accuracy: 0.5906862745098039, Validation Loss: 6.16974401473999, Validation Accuracy: 0.5\n",
      "Epoch 2628/10000, Training Loss: 4.112013339996338, Training Accuracy: 0.6078431372549019, Validation Loss: 4.5726318359375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2629/10000, Training Loss: 5.998651027679443, Training Accuracy: 0.5465686274509803, Validation Loss: 12.179230690002441, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2630/10000, Training Loss: 4.705961227416992, Training Accuracy: 0.6078431372549019, Validation Loss: 3.2245237827301025, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2631/10000, Training Loss: 5.280604362487793, Training Accuracy: 0.5392156862745098, Validation Loss: 5.351712703704834, Validation Accuracy: 0.75\n",
      "Epoch 2632/10000, Training Loss: 5.221056938171387, Training Accuracy: 0.5220588235294118, Validation Loss: 5.2414398193359375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2633/10000, Training Loss: 5.847207069396973, Training Accuracy: 0.5220588235294118, Validation Loss: 8.678218841552734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2634/10000, Training Loss: 6.081850051879883, Training Accuracy: 0.4583333333333333, Validation Loss: 4.203932762145996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2635/10000, Training Loss: 5.798996925354004, Training Accuracy: 0.4950980392156863, Validation Loss: 7.6781535148620605, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2636/10000, Training Loss: 3.623150110244751, Training Accuracy: 0.5343137254901961, Validation Loss: 2.685574769973755, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2637/10000, Training Loss: 6.237384796142578, Training Accuracy: 0.5367647058823529, Validation Loss: 8.83108139038086, Validation Accuracy: 0.25\n",
      "Epoch 2638/10000, Training Loss: 4.093836307525635, Training Accuracy: 0.5882352941176471, Validation Loss: 4.000314235687256, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2639/10000, Training Loss: 3.1123454570770264, Training Accuracy: 0.5931372549019608, Validation Loss: 3.546170949935913, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2640/10000, Training Loss: 2.7906830310821533, Training Accuracy: 0.5416666666666666, Validation Loss: 4.684756278991699, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2641/10000, Training Loss: 3.1845600605010986, Training Accuracy: 0.5759803921568627, Validation Loss: 5.065907955169678, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2642/10000, Training Loss: 5.332190990447998, Training Accuracy: 0.5318627450980392, Validation Loss: 9.550766944885254, Validation Accuracy: 0.25\n",
      "Epoch 2643/10000, Training Loss: 3.105595350265503, Training Accuracy: 0.5784313725490197, Validation Loss: 9.592219352722168, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2644/10000, Training Loss: 2.3024299144744873, Training Accuracy: 0.5318627450980392, Validation Loss: 6.125766754150391, Validation Accuracy: 0.25\n",
      "Epoch 2645/10000, Training Loss: 3.2886061668395996, Training Accuracy: 0.6299019607843137, Validation Loss: 0.452404648065567, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2646/10000, Training Loss: 2.9452388286590576, Training Accuracy: 0.6127450980392157, Validation Loss: 15.281463623046875, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2647/10000, Training Loss: 4.208106994628906, Training Accuracy: 0.5612745098039216, Validation Loss: 5.835011959075928, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2648/10000, Training Loss: 4.149493217468262, Training Accuracy: 0.553921568627451, Validation Loss: 12.034184455871582, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2649/10000, Training Loss: 4.993646144866943, Training Accuracy: 0.5122549019607843, Validation Loss: 3.507779836654663, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2650/10000, Training Loss: 2.9232890605926514, Training Accuracy: 0.6029411764705882, Validation Loss: 3.3397958278656006, Validation Accuracy: 0.5\n",
      "Epoch 2651/10000, Training Loss: 6.969590663909912, Training Accuracy: 0.5392156862745098, Validation Loss: 5.520046234130859, Validation Accuracy: 0.25\n",
      "Epoch 2652/10000, Training Loss: 3.4851181507110596, Training Accuracy: 0.5, Validation Loss: 3.1874005794525146, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2653/10000, Training Loss: 3.0905511379241943, Training Accuracy: 0.5588235294117647, Validation Loss: 3.5300705432891846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2654/10000, Training Loss: 5.909732818603516, Training Accuracy: 0.5833333333333334, Validation Loss: 3.8371477127075195, Validation Accuracy: 0.5\n",
      "Epoch 2655/10000, Training Loss: 3.54073166847229, Training Accuracy: 0.6348039215686274, Validation Loss: 5.173518657684326, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2656/10000, Training Loss: 4.802606105804443, Training Accuracy: 0.5857843137254902, Validation Loss: 6.943880558013916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2657/10000, Training Loss: 10.719584465026855, Training Accuracy: 0.5808823529411765, Validation Loss: 5.749509811401367, Validation Accuracy: 0.25\n",
      "Epoch 2658/10000, Training Loss: 4.460256099700928, Training Accuracy: 0.5612745098039216, Validation Loss: 12.117171287536621, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2659/10000, Training Loss: 4.505343914031982, Training Accuracy: 0.5808823529411765, Validation Loss: 2.6888935565948486, Validation Accuracy: 0.75\n",
      "Epoch 2660/10000, Training Loss: 3.523797035217285, Training Accuracy: 0.6421568627450981, Validation Loss: 6.1954803466796875, Validation Accuracy: 0.25\n",
      "Epoch 2661/10000, Training Loss: 4.281505584716797, Training Accuracy: 0.5857843137254902, Validation Loss: 1.8808536529541016, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 2662/10000, Training Loss: 6.776029586791992, Training Accuracy: 0.5563725490196079, Validation Loss: 19.355775833129883, Validation Accuracy: 0.5\n",
      "Epoch 2663/10000, Training Loss: 4.226062297821045, Training Accuracy: 0.6200980392156863, Validation Loss: 3.9862470626831055, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2664/10000, Training Loss: 3.741201877593994, Training Accuracy: 0.5563725490196079, Validation Loss: 4.859141826629639, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2665/10000, Training Loss: 4.069403648376465, Training Accuracy: 0.5245098039215687, Validation Loss: 8.244776725769043, Validation Accuracy: 0.5\n",
      "Epoch 2666/10000, Training Loss: 4.577347278594971, Training Accuracy: 0.5122549019607843, Validation Loss: 10.061415672302246, Validation Accuracy: 0.25\n",
      "Epoch 2667/10000, Training Loss: 3.2956793308258057, Training Accuracy: 0.5196078431372549, Validation Loss: 3.499582052230835, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2668/10000, Training Loss: 6.852379322052002, Training Accuracy: 0.5073529411764706, Validation Loss: 6.916347503662109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2669/10000, Training Loss: 3.633591651916504, Training Accuracy: 0.5171568627450981, Validation Loss: 4.984126091003418, Validation Accuracy: 0.25\n",
      "Epoch 2670/10000, Training Loss: 6.271488666534424, Training Accuracy: 0.5367647058823529, Validation Loss: 9.95201587677002, Validation Accuracy: 0.5\n",
      "Epoch 2671/10000, Training Loss: 5.993338108062744, Training Accuracy: 0.6740196078431373, Validation Loss: 8.490387916564941, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2672/10000, Training Loss: 4.38734245300293, Training Accuracy: 0.5049019607843137, Validation Loss: 4.765221118927002, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2673/10000, Training Loss: 3.293813943862915, Training Accuracy: 0.5686274509803921, Validation Loss: 3.9185705184936523, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2674/10000, Training Loss: 5.888071060180664, Training Accuracy: 0.5, Validation Loss: 4.635721206665039, Validation Accuracy: 0.5\n",
      "Epoch 2675/10000, Training Loss: 4.017596244812012, Training Accuracy: 0.6078431372549019, Validation Loss: 3.086322546005249, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2676/10000, Training Loss: 4.713545799255371, Training Accuracy: 0.5171568627450981, Validation Loss: 9.389897346496582, Validation Accuracy: 0.0\n",
      "Epoch 2677/10000, Training Loss: 5.2493896484375, Training Accuracy: 0.5073529411764706, Validation Loss: 6.449591159820557, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2678/10000, Training Loss: 4.9759321212768555, Training Accuracy: 0.5931372549019608, Validation Loss: 11.911206245422363, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2679/10000, Training Loss: 4.452639579772949, Training Accuracy: 0.5882352941176471, Validation Loss: 13.387595176696777, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2680/10000, Training Loss: 4.047457218170166, Training Accuracy: 0.5049019607843137, Validation Loss: 7.6002326011657715, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2681/10000, Training Loss: 3.349405527114868, Training Accuracy: 0.5931372549019608, Validation Loss: 7.068210601806641, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2682/10000, Training Loss: 5.869778633117676, Training Accuracy: 0.5906862745098039, Validation Loss: 7.861978530883789, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2683/10000, Training Loss: 3.6944217681884766, Training Accuracy: 0.5563725490196079, Validation Loss: 8.168230056762695, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2684/10000, Training Loss: 5.092580795288086, Training Accuracy: 0.5637254901960784, Validation Loss: 3.1824865341186523, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2685/10000, Training Loss: 4.134884834289551, Training Accuracy: 0.5857843137254902, Validation Loss: 5.497032165527344, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2686/10000, Training Loss: 4.976716995239258, Training Accuracy: 0.5220588235294118, Validation Loss: 2.2639381885528564, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2687/10000, Training Loss: 3.410655975341797, Training Accuracy: 0.5759803921568627, Validation Loss: 5.392299175262451, Validation Accuracy: 0.5\n",
      "Epoch 2688/10000, Training Loss: 3.9338412284851074, Training Accuracy: 0.5955882352941176, Validation Loss: 2.1070268154144287, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2689/10000, Training Loss: 5.319066047668457, Training Accuracy: 0.5465686274509803, Validation Loss: 4.652548313140869, Validation Accuracy: 0.5\n",
      "Epoch 2690/10000, Training Loss: 3.087265729904175, Training Accuracy: 0.5661764705882353, Validation Loss: 3.95755934715271, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2691/10000, Training Loss: 4.067759037017822, Training Accuracy: 0.5318627450980392, Validation Loss: 1.99061918258667, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2692/10000, Training Loss: 3.760141372680664, Training Accuracy: 0.6372549019607843, Validation Loss: 6.882749080657959, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2693/10000, Training Loss: 5.358266353607178, Training Accuracy: 0.5343137254901961, Validation Loss: 7.03997802734375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2694/10000, Training Loss: 3.0972490310668945, Training Accuracy: 0.5392156862745098, Validation Loss: 1.3231021165847778, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2695/10000, Training Loss: 6.226605415344238, Training Accuracy: 0.5514705882352942, Validation Loss: 10.818241119384766, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2696/10000, Training Loss: 2.728145122528076, Training Accuracy: 0.6053921568627451, Validation Loss: 7.08994722366333, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2697/10000, Training Loss: 2.9814491271972656, Training Accuracy: 0.5563725490196079, Validation Loss: 1.8366327285766602, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2698/10000, Training Loss: 3.3452141284942627, Training Accuracy: 0.5784313725490197, Validation Loss: 3.7030179500579834, Validation Accuracy: 0.75\n",
      "Epoch 2699/10000, Training Loss: 3.9135186672210693, Training Accuracy: 0.6102941176470589, Validation Loss: 15.033954620361328, Validation Accuracy: 0.5\n",
      "Epoch 2700/10000, Training Loss: 3.8366641998291016, Training Accuracy: 0.6274509803921569, Validation Loss: 10.383541107177734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2701/10000, Training Loss: 4.210740566253662, Training Accuracy: 0.47794117647058826, Validation Loss: 1.3175078630447388, Validation Accuracy: 0.5\n",
      "Epoch 2702/10000, Training Loss: 4.52331018447876, Training Accuracy: 0.6421568627450981, Validation Loss: 3.959951162338257, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2703/10000, Training Loss: 3.898344039916992, Training Accuracy: 0.5955882352941176, Validation Loss: 4.726728439331055, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2704/10000, Training Loss: 4.996449947357178, Training Accuracy: 0.5735294117647058, Validation Loss: 12.177212715148926, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2705/10000, Training Loss: 6.983585357666016, Training Accuracy: 0.5318627450980392, Validation Loss: 8.006455421447754, Validation Accuracy: 0.5\n",
      "Epoch 2706/10000, Training Loss: 4.505308628082275, Training Accuracy: 0.5759803921568627, Validation Loss: 13.13436222076416, Validation Accuracy: 0.5\n",
      "Epoch 2707/10000, Training Loss: 3.576119899749756, Training Accuracy: 0.6176470588235294, Validation Loss: 7.151092529296875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2708/10000, Training Loss: 4.384514808654785, Training Accuracy: 0.5759803921568627, Validation Loss: 4.272647380828857, Validation Accuracy: 0.5\n",
      "Epoch 2709/10000, Training Loss: 4.166566371917725, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9778473377227783, Validation Accuracy: 0.5\n",
      "Epoch 2710/10000, Training Loss: 3.228178024291992, Training Accuracy: 0.5882352941176471, Validation Loss: 5.300618648529053, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2711/10000, Training Loss: 4.197877883911133, Training Accuracy: 0.5637254901960784, Validation Loss: 4.580961227416992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2712/10000, Training Loss: 4.469353675842285, Training Accuracy: 0.4852941176470588, Validation Loss: 6.149999141693115, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2713/10000, Training Loss: 5.539263725280762, Training Accuracy: 0.5416666666666666, Validation Loss: 4.828817367553711, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2714/10000, Training Loss: 6.192594051361084, Training Accuracy: 0.5392156862745098, Validation Loss: 2.3302340507507324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2715/10000, Training Loss: 4.785277366638184, Training Accuracy: 0.5073529411764706, Validation Loss: 5.995008945465088, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2716/10000, Training Loss: 3.636270046234131, Training Accuracy: 0.5588235294117647, Validation Loss: 3.934455156326294, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2717/10000, Training Loss: 2.279076099395752, Training Accuracy: 0.571078431372549, Validation Loss: 3.7455949783325195, Validation Accuracy: 0.5\n",
      "Epoch 2718/10000, Training Loss: 3.926084518432617, Training Accuracy: 0.5661764705882353, Validation Loss: 4.798919677734375, Validation Accuracy: 0.75\n",
      "Epoch 2719/10000, Training Loss: 5.071299076080322, Training Accuracy: 0.5465686274509803, Validation Loss: 2.1344306468963623, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2720/10000, Training Loss: 6.796905040740967, Training Accuracy: 0.5759803921568627, Validation Loss: 8.137140274047852, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2721/10000, Training Loss: 4.117459774017334, Training Accuracy: 0.6225490196078431, Validation Loss: 4.7350382804870605, Validation Accuracy: 0.5\n",
      "Epoch 2722/10000, Training Loss: 4.70746374130249, Training Accuracy: 0.5735294117647058, Validation Loss: 2.923302412033081, Validation Accuracy: 0.5\n",
      "Epoch 2723/10000, Training Loss: 5.193511486053467, Training Accuracy: 0.4632352941176471, Validation Loss: 2.891162633895874, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2724/10000, Training Loss: 3.833890199661255, Training Accuracy: 0.5735294117647058, Validation Loss: 14.537429809570312, Validation Accuracy: 0.25\n",
      "Epoch 2725/10000, Training Loss: 2.9356820583343506, Training Accuracy: 0.571078431372549, Validation Loss: 1.8223352432250977, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2726/10000, Training Loss: 3.5314033031463623, Training Accuracy: 0.5514705882352942, Validation Loss: 4.381866931915283, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2727/10000, Training Loss: 4.121726989746094, Training Accuracy: 0.5269607843137255, Validation Loss: 5.8005290031433105, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2728/10000, Training Loss: 4.175079822540283, Training Accuracy: 0.5588235294117647, Validation Loss: 10.90318775177002, Validation Accuracy: 0.25\n",
      "Epoch 2729/10000, Training Loss: 3.9772164821624756, Training Accuracy: 0.6348039215686274, Validation Loss: 13.083329200744629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2730/10000, Training Loss: 4.7919158935546875, Training Accuracy: 0.5906862745098039, Validation Loss: 3.151543617248535, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2731/10000, Training Loss: 5.269715785980225, Training Accuracy: 0.5931372549019608, Validation Loss: 11.034061431884766, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2732/10000, Training Loss: 2.734790086746216, Training Accuracy: 0.5661764705882353, Validation Loss: 4.834207534790039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2733/10000, Training Loss: 2.9693520069122314, Training Accuracy: 0.5661764705882353, Validation Loss: 5.8174147605896, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2734/10000, Training Loss: 4.996197700500488, Training Accuracy: 0.47794117647058826, Validation Loss: 4.935068607330322, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2735/10000, Training Loss: 3.7566447257995605, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3932963609695435, Validation Accuracy: 0.75\n",
      "Epoch 2736/10000, Training Loss: 4.120202541351318, Training Accuracy: 0.5882352941176471, Validation Loss: 4.044897079467773, Validation Accuracy: 0.5\n",
      "Epoch 2737/10000, Training Loss: 3.1980390548706055, Training Accuracy: 0.5465686274509803, Validation Loss: 5.957892894744873, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2738/10000, Training Loss: 3.486696720123291, Training Accuracy: 0.6348039215686274, Validation Loss: 4.9942545890808105, Validation Accuracy: 0.25\n",
      "Epoch 2739/10000, Training Loss: 4.380515098571777, Training Accuracy: 0.5098039215686274, Validation Loss: 5.162657260894775, Validation Accuracy: 0.5\n",
      "Epoch 2740/10000, Training Loss: 3.5789289474487305, Training Accuracy: 0.5416666666666666, Validation Loss: 6.179943561553955, Validation Accuracy: 0.5\n",
      "Epoch 2741/10000, Training Loss: 4.076365947723389, Training Accuracy: 0.571078431372549, Validation Loss: 3.292762041091919, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2742/10000, Training Loss: 3.9088103771209717, Training Accuracy: 0.5245098039215687, Validation Loss: 6.779333114624023, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2743/10000, Training Loss: 4.660380840301514, Training Accuracy: 0.5514705882352942, Validation Loss: 6.723593235015869, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2744/10000, Training Loss: 4.168675422668457, Training Accuracy: 0.5980392156862745, Validation Loss: 7.041036128997803, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2745/10000, Training Loss: 3.554567813873291, Training Accuracy: 0.571078431372549, Validation Loss: 2.0879666805267334, Validation Accuracy: 0.75\n",
      "Epoch 2746/10000, Training Loss: 4.97830867767334, Training Accuracy: 0.5735294117647058, Validation Loss: 7.411135196685791, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2747/10000, Training Loss: 4.030818939208984, Training Accuracy: 0.5318627450980392, Validation Loss: 3.143810987472534, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2748/10000, Training Loss: 3.709765911102295, Training Accuracy: 0.5784313725490197, Validation Loss: 4.926173686981201, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2749/10000, Training Loss: 4.413041114807129, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8372185230255127, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2750/10000, Training Loss: 7.353446960449219, Training Accuracy: 0.5441176470588235, Validation Loss: 4.326547622680664, Validation Accuracy: 0.5\n",
      "Epoch 2751/10000, Training Loss: 2.7428362369537354, Training Accuracy: 0.5367647058823529, Validation Loss: 7.7699713706970215, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2752/10000, Training Loss: 4.211890697479248, Training Accuracy: 0.5245098039215687, Validation Loss: 8.340895652770996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2753/10000, Training Loss: 3.519336462020874, Training Accuracy: 0.6397058823529411, Validation Loss: 3.827491044998169, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2754/10000, Training Loss: 5.288649082183838, Training Accuracy: 0.5245098039215687, Validation Loss: 6.069572925567627, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2755/10000, Training Loss: 4.714212417602539, Training Accuracy: 0.5588235294117647, Validation Loss: 5.885770797729492, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2756/10000, Training Loss: 3.800870895385742, Training Accuracy: 0.5441176470588235, Validation Loss: 7.564797878265381, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2757/10000, Training Loss: 3.335179090499878, Training Accuracy: 0.5808823529411765, Validation Loss: 7.193527698516846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2758/10000, Training Loss: 2.8113133907318115, Training Accuracy: 0.5196078431372549, Validation Loss: 1.5492061376571655, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2759/10000, Training Loss: 3.280475616455078, Training Accuracy: 0.5563725490196079, Validation Loss: 2.643803834915161, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2760/10000, Training Loss: 3.3264708518981934, Training Accuracy: 0.5465686274509803, Validation Loss: 8.394501686096191, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2761/10000, Training Loss: 5.48678731918335, Training Accuracy: 0.6004901960784313, Validation Loss: 7.371445178985596, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2762/10000, Training Loss: 5.956281661987305, Training Accuracy: 0.5735294117647058, Validation Loss: 9.72545051574707, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2763/10000, Training Loss: 3.3768465518951416, Training Accuracy: 0.5857843137254902, Validation Loss: 1.9924439191818237, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2764/10000, Training Loss: 3.949906349182129, Training Accuracy: 0.47794117647058826, Validation Loss: 8.067453384399414, Validation Accuracy: 0.25\n",
      "Epoch 2765/10000, Training Loss: 6.22698450088501, Training Accuracy: 0.5441176470588235, Validation Loss: 4.893577575683594, Validation Accuracy: 0.5\n",
      "Epoch 2766/10000, Training Loss: 2.9295525550842285, Training Accuracy: 0.571078431372549, Validation Loss: 2.2927017211914062, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2767/10000, Training Loss: 2.9576005935668945, Training Accuracy: 0.5955882352941176, Validation Loss: 4.835190296173096, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2768/10000, Training Loss: 3.9460082054138184, Training Accuracy: 0.5318627450980392, Validation Loss: 4.242741107940674, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2769/10000, Training Loss: 3.6035406589508057, Training Accuracy: 0.5220588235294118, Validation Loss: 0.4455256462097168, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2770/10000, Training Loss: 2.9596004486083984, Training Accuracy: 0.6029411764705882, Validation Loss: 6.71159553527832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2771/10000, Training Loss: 3.395834445953369, Training Accuracy: 0.6053921568627451, Validation Loss: 3.9022216796875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2772/10000, Training Loss: 4.710664749145508, Training Accuracy: 0.6004901960784313, Validation Loss: 8.717442512512207, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2773/10000, Training Loss: 3.192598581314087, Training Accuracy: 0.5171568627450981, Validation Loss: 2.1054046154022217, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2774/10000, Training Loss: 4.002516269683838, Training Accuracy: 0.6102941176470589, Validation Loss: 4.734853267669678, Validation Accuracy: 0.5\n",
      "Epoch 2775/10000, Training Loss: 2.662989377975464, Training Accuracy: 0.6004901960784313, Validation Loss: 3.899329423904419, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2776/10000, Training Loss: 4.583382606506348, Training Accuracy: 0.5392156862745098, Validation Loss: 3.442066192626953, Validation Accuracy: 0.5\n",
      "Epoch 2777/10000, Training Loss: 4.084476947784424, Training Accuracy: 0.5122549019607843, Validation Loss: 3.595317840576172, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2778/10000, Training Loss: 4.484762668609619, Training Accuracy: 0.5465686274509803, Validation Loss: 5.275772571563721, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2779/10000, Training Loss: 3.801889419555664, Training Accuracy: 0.5294117647058824, Validation Loss: 2.8876876831054688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2780/10000, Training Loss: 3.8492510318756104, Training Accuracy: 0.49754901960784315, Validation Loss: 2.8935019969940186, Validation Accuracy: 0.5\n",
      "Epoch 2781/10000, Training Loss: 3.2155675888061523, Training Accuracy: 0.5024509803921569, Validation Loss: 2.5352866649627686, Validation Accuracy: 0.5\n",
      "Epoch 2782/10000, Training Loss: 3.1195898056030273, Training Accuracy: 0.6274509803921569, Validation Loss: 6.8047194480896, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2783/10000, Training Loss: 4.037510871887207, Training Accuracy: 0.5735294117647058, Validation Loss: 2.7995941638946533, Validation Accuracy: 0.5\n",
      "Epoch 2784/10000, Training Loss: 5.186540603637695, Training Accuracy: 0.5392156862745098, Validation Loss: 14.935367584228516, Validation Accuracy: 0.25\n",
      "Epoch 2785/10000, Training Loss: 3.268829345703125, Training Accuracy: 0.5637254901960784, Validation Loss: 7.754293441772461, Validation Accuracy: 0.25\n",
      "Epoch 2786/10000, Training Loss: 3.3434059619903564, Training Accuracy: 0.5980392156862745, Validation Loss: 4.076318264007568, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2787/10000, Training Loss: 4.524855136871338, Training Accuracy: 0.4632352941176471, Validation Loss: 6.785526275634766, Validation Accuracy: 0.5\n",
      "Epoch 2788/10000, Training Loss: 3.889127731323242, Training Accuracy: 0.5637254901960784, Validation Loss: 6.922515392303467, Validation Accuracy: 0.25\n",
      "Epoch 2789/10000, Training Loss: 3.04434871673584, Training Accuracy: 0.5441176470588235, Validation Loss: 1.5011225938796997, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2790/10000, Training Loss: 5.960730075836182, Training Accuracy: 0.5318627450980392, Validation Loss: 11.72891616821289, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2791/10000, Training Loss: 3.7842912673950195, Training Accuracy: 0.6323529411764706, Validation Loss: 6.900966644287109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2792/10000, Training Loss: 4.267978668212891, Training Accuracy: 0.5220588235294118, Validation Loss: 6.034482955932617, Validation Accuracy: 0.25\n",
      "Epoch 2793/10000, Training Loss: 3.503653049468994, Training Accuracy: 0.5318627450980392, Validation Loss: 8.645861625671387, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2794/10000, Training Loss: 4.629090785980225, Training Accuracy: 0.5637254901960784, Validation Loss: 7.035442352294922, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2795/10000, Training Loss: 3.776169776916504, Training Accuracy: 0.5098039215686274, Validation Loss: 8.122629165649414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2796/10000, Training Loss: 4.790447235107422, Training Accuracy: 0.5073529411764706, Validation Loss: 5.69338846206665, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2797/10000, Training Loss: 3.061368703842163, Training Accuracy: 0.5931372549019608, Validation Loss: 5.734552383422852, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2798/10000, Training Loss: 3.048053026199341, Training Accuracy: 0.5906862745098039, Validation Loss: 3.1179704666137695, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2799/10000, Training Loss: 3.7579472064971924, Training Accuracy: 0.553921568627451, Validation Loss: 1.9441460371017456, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2800/10000, Training Loss: 4.757091045379639, Training Accuracy: 0.571078431372549, Validation Loss: 8.945597648620605, Validation Accuracy: 0.5\n",
      "Epoch 2801/10000, Training Loss: 4.7450151443481445, Training Accuracy: 0.6102941176470589, Validation Loss: 20.65091896057129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2802/10000, Training Loss: 2.7709434032440186, Training Accuracy: 0.5759803921568627, Validation Loss: 9.045586585998535, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2803/10000, Training Loss: 2.647165060043335, Training Accuracy: 0.5759803921568627, Validation Loss: 3.087161064147949, Validation Accuracy: 0.25\n",
      "Epoch 2804/10000, Training Loss: 2.75689959526062, Training Accuracy: 0.5441176470588235, Validation Loss: 2.9182546138763428, Validation Accuracy: 0.5\n",
      "Epoch 2805/10000, Training Loss: 3.1728899478912354, Training Accuracy: 0.5220588235294118, Validation Loss: 3.631561517715454, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2806/10000, Training Loss: 2.256183624267578, Training Accuracy: 0.625, Validation Loss: 6.137228012084961, Validation Accuracy: 0.5\n",
      "Epoch 2807/10000, Training Loss: 6.809236526489258, Training Accuracy: 0.5122549019607843, Validation Loss: 10.6639404296875, Validation Accuracy: 0.25\n",
      "Epoch 2808/10000, Training Loss: 3.602855920791626, Training Accuracy: 0.5147058823529411, Validation Loss: 2.3450047969818115, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2809/10000, Training Loss: 3.6100924015045166, Training Accuracy: 0.5465686274509803, Validation Loss: 7.885740280151367, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2810/10000, Training Loss: 3.6929569244384766, Training Accuracy: 0.5906862745098039, Validation Loss: 3.21651554107666, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2811/10000, Training Loss: 3.9924659729003906, Training Accuracy: 0.5196078431372549, Validation Loss: 4.048309803009033, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2812/10000, Training Loss: 3.296989679336548, Training Accuracy: 0.5392156862745098, Validation Loss: 8.401688575744629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2813/10000, Training Loss: 4.258700370788574, Training Accuracy: 0.5367647058823529, Validation Loss: 9.92174243927002, Validation Accuracy: 0.25\n",
      "Epoch 2814/10000, Training Loss: 4.248412132263184, Training Accuracy: 0.5612745098039216, Validation Loss: 4.2661356925964355, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2815/10000, Training Loss: 2.986142873764038, Training Accuracy: 0.5637254901960784, Validation Loss: 6.783278942108154, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2816/10000, Training Loss: 5.102367877960205, Training Accuracy: 0.5612745098039216, Validation Loss: 17.841453552246094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2817/10000, Training Loss: 3.8443408012390137, Training Accuracy: 0.5661764705882353, Validation Loss: 2.761180877685547, Validation Accuracy: 0.75\n",
      "Epoch 2818/10000, Training Loss: 3.2569499015808105, Training Accuracy: 0.5833333333333334, Validation Loss: 3.337677001953125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2819/10000, Training Loss: 4.670816898345947, Training Accuracy: 0.6348039215686274, Validation Loss: 7.250104904174805, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2820/10000, Training Loss: 2.5271408557891846, Training Accuracy: 0.5465686274509803, Validation Loss: 3.4815587997436523, Validation Accuracy: 0.25\n",
      "Epoch 2821/10000, Training Loss: 3.4761502742767334, Training Accuracy: 0.5465686274509803, Validation Loss: 3.0465269088745117, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2822/10000, Training Loss: 2.450033664703369, Training Accuracy: 0.5857843137254902, Validation Loss: 4.746782302856445, Validation Accuracy: 0.5\n",
      "Epoch 2823/10000, Training Loss: 4.749365329742432, Training Accuracy: 0.5931372549019608, Validation Loss: 8.690275192260742, Validation Accuracy: 0.5\n",
      "Epoch 2824/10000, Training Loss: 3.070927619934082, Training Accuracy: 0.6053921568627451, Validation Loss: 6.388996601104736, Validation Accuracy: 0.5\n",
      "Epoch 2825/10000, Training Loss: 5.12434720993042, Training Accuracy: 0.5098039215686274, Validation Loss: 2.8572824001312256, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2826/10000, Training Loss: 2.7391765117645264, Training Accuracy: 0.5759803921568627, Validation Loss: 2.360842704772949, Validation Accuracy: 0.75\n",
      "Epoch 2827/10000, Training Loss: 5.706806659698486, Training Accuracy: 0.5024509803921569, Validation Loss: 3.3733012676239014, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2828/10000, Training Loss: 5.768348693847656, Training Accuracy: 0.5392156862745098, Validation Loss: 9.872109413146973, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2829/10000, Training Loss: 5.23976993560791, Training Accuracy: 0.5098039215686274, Validation Loss: 5.803040027618408, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2830/10000, Training Loss: 3.647540807723999, Training Accuracy: 0.625, Validation Loss: 8.618687629699707, Validation Accuracy: 0.25\n",
      "Epoch 2831/10000, Training Loss: 4.779472351074219, Training Accuracy: 0.5122549019607843, Validation Loss: 6.957858562469482, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2832/10000, Training Loss: 2.868070125579834, Training Accuracy: 0.5784313725490197, Validation Loss: 7.962348461151123, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2833/10000, Training Loss: 4.141711235046387, Training Accuracy: 0.5661764705882353, Validation Loss: 5.765697002410889, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2834/10000, Training Loss: 4.2025465965271, Training Accuracy: 0.571078431372549, Validation Loss: 5.976524829864502, Validation Accuracy: 0.5\n",
      "Epoch 2835/10000, Training Loss: 3.92494797706604, Training Accuracy: 0.6078431372549019, Validation Loss: 6.5892720222473145, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2836/10000, Training Loss: 3.1331958770751953, Training Accuracy: 0.625, Validation Loss: 9.637225151062012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2837/10000, Training Loss: 4.003172874450684, Training Accuracy: 0.571078431372549, Validation Loss: 2.112032651901245, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2838/10000, Training Loss: 2.2781476974487305, Training Accuracy: 0.5955882352941176, Validation Loss: 4.060180187225342, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2839/10000, Training Loss: 4.411728858947754, Training Accuracy: 0.49754901960784315, Validation Loss: 2.193277359008789, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2840/10000, Training Loss: 3.856590747833252, Training Accuracy: 0.553921568627451, Validation Loss: 6.378499984741211, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2841/10000, Training Loss: 3.6336164474487305, Training Accuracy: 0.5073529411764706, Validation Loss: 6.627172946929932, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2842/10000, Training Loss: 3.8225409984588623, Training Accuracy: 0.5808823529411765, Validation Loss: 1.9522424936294556, Validation Accuracy: 0.75\n",
      "Epoch 2843/10000, Training Loss: 3.189908742904663, Training Accuracy: 0.6078431372549019, Validation Loss: 1.615626335144043, Validation Accuracy: 0.5\n",
      "Epoch 2844/10000, Training Loss: 4.228947639465332, Training Accuracy: 0.5, Validation Loss: 5.4968390464782715, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2845/10000, Training Loss: 3.050187349319458, Training Accuracy: 0.6299019607843137, Validation Loss: 2.629396677017212, Validation Accuracy: 0.5\n",
      "Epoch 2846/10000, Training Loss: 3.278329372406006, Training Accuracy: 0.571078431372549, Validation Loss: 2.679347276687622, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2847/10000, Training Loss: 4.974807262420654, Training Accuracy: 0.5955882352941176, Validation Loss: 2.045522928237915, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2848/10000, Training Loss: 5.388007164001465, Training Accuracy: 0.5098039215686274, Validation Loss: 3.6809842586517334, Validation Accuracy: 0.5\n",
      "Epoch 2849/10000, Training Loss: 3.603297472000122, Training Accuracy: 0.5735294117647058, Validation Loss: 3.9128353595733643, Validation Accuracy: 0.5\n",
      "Epoch 2850/10000, Training Loss: 3.635300636291504, Training Accuracy: 0.5931372549019608, Validation Loss: 7.627445220947266, Validation Accuracy: 0.25\n",
      "Epoch 2851/10000, Training Loss: 4.2484130859375, Training Accuracy: 0.5980392156862745, Validation Loss: 11.553054809570312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2852/10000, Training Loss: 5.205169200897217, Training Accuracy: 0.5245098039215687, Validation Loss: 4.858521938323975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2853/10000, Training Loss: 5.630589485168457, Training Accuracy: 0.6348039215686274, Validation Loss: 5.296133518218994, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2854/10000, Training Loss: 3.838888645172119, Training Accuracy: 0.6151960784313726, Validation Loss: 7.062366962432861, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2855/10000, Training Loss: 3.402022361755371, Training Accuracy: 0.5906862745098039, Validation Loss: 5.421604156494141, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2856/10000, Training Loss: 5.694746494293213, Training Accuracy: 0.5147058823529411, Validation Loss: 7.479856491088867, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2857/10000, Training Loss: 3.5423831939697266, Training Accuracy: 0.6078431372549019, Validation Loss: 5.750150203704834, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2858/10000, Training Loss: 3.2477760314941406, Training Accuracy: 0.5637254901960784, Validation Loss: 4.998170375823975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2859/10000, Training Loss: 4.309505939483643, Training Accuracy: 0.49019607843137253, Validation Loss: 4.360971927642822, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2860/10000, Training Loss: 3.1955363750457764, Training Accuracy: 0.5686274509803921, Validation Loss: 2.5298333168029785, Validation Accuracy: 0.5\n",
      "Epoch 2861/10000, Training Loss: 3.15283465385437, Training Accuracy: 0.5857843137254902, Validation Loss: 3.9246280193328857, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2862/10000, Training Loss: 3.3076884746551514, Training Accuracy: 0.6274509803921569, Validation Loss: 2.164135694503784, Validation Accuracy: 0.75\n",
      "Epoch 2863/10000, Training Loss: 3.7960495948791504, Training Accuracy: 0.5759803921568627, Validation Loss: 9.984395027160645, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2864/10000, Training Loss: 4.323248386383057, Training Accuracy: 0.5857843137254902, Validation Loss: 3.3260326385498047, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2865/10000, Training Loss: 3.5128092765808105, Training Accuracy: 0.5931372549019608, Validation Loss: 2.0910942554473877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2866/10000, Training Loss: 2.970311164855957, Training Accuracy: 0.5367647058823529, Validation Loss: 0.9153575897216797, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2867/10000, Training Loss: 3.005793809890747, Training Accuracy: 0.6274509803921569, Validation Loss: 3.9705679416656494, Validation Accuracy: 0.5\n",
      "Epoch 2868/10000, Training Loss: 4.306028366088867, Training Accuracy: 0.5343137254901961, Validation Loss: 4.934858798980713, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2869/10000, Training Loss: 3.594067096710205, Training Accuracy: 0.5098039215686274, Validation Loss: 7.810607433319092, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2870/10000, Training Loss: 3.6617205142974854, Training Accuracy: 0.5196078431372549, Validation Loss: 3.0551297664642334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2871/10000, Training Loss: 4.0496978759765625, Training Accuracy: 0.5686274509803921, Validation Loss: 3.9853527545928955, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2872/10000, Training Loss: 4.214474678039551, Training Accuracy: 0.5269607843137255, Validation Loss: 2.61604642868042, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2873/10000, Training Loss: 2.855170965194702, Training Accuracy: 0.4803921568627451, Validation Loss: 3.279141664505005, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2874/10000, Training Loss: 3.4553635120391846, Training Accuracy: 0.5490196078431373, Validation Loss: 4.864452838897705, Validation Accuracy: 0.5\n",
      "Epoch 2875/10000, Training Loss: 4.888290882110596, Training Accuracy: 0.5269607843137255, Validation Loss: 5.952047824859619, Validation Accuracy: 0.5\n",
      "Epoch 2876/10000, Training Loss: 3.789848566055298, Training Accuracy: 0.553921568627451, Validation Loss: 4.556833744049072, Validation Accuracy: 0.5\n",
      "Epoch 2877/10000, Training Loss: 2.9110045433044434, Training Accuracy: 0.6102941176470589, Validation Loss: 3.3541152477264404, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2878/10000, Training Loss: 3.7536113262176514, Training Accuracy: 0.5612745098039216, Validation Loss: 2.923980474472046, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2879/10000, Training Loss: 2.5539324283599854, Training Accuracy: 0.5441176470588235, Validation Loss: 2.770049810409546, Validation Accuracy: 0.5\n",
      "Epoch 2880/10000, Training Loss: 3.2401835918426514, Training Accuracy: 0.5882352941176471, Validation Loss: 8.145899772644043, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2881/10000, Training Loss: 3.5844130516052246, Training Accuracy: 0.6053921568627451, Validation Loss: 5.796377182006836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2882/10000, Training Loss: 4.709238052368164, Training Accuracy: 0.5514705882352942, Validation Loss: 2.6977312564849854, Validation Accuracy: 0.5\n",
      "Epoch 2883/10000, Training Loss: 2.559624195098877, Training Accuracy: 0.5490196078431373, Validation Loss: 3.535659074783325, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2884/10000, Training Loss: 6.081117630004883, Training Accuracy: 0.4632352941176471, Validation Loss: 0.7168657183647156, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2885/10000, Training Loss: 3.435554265975952, Training Accuracy: 0.5098039215686274, Validation Loss: 4.6953206062316895, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2886/10000, Training Loss: 3.66928768157959, Training Accuracy: 0.5906862745098039, Validation Loss: 5.984241962432861, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2887/10000, Training Loss: 3.8459784984588623, Training Accuracy: 0.5612745098039216, Validation Loss: 5.020928382873535, Validation Accuracy: 0.5\n",
      "Epoch 2888/10000, Training Loss: 4.731255531311035, Training Accuracy: 0.5073529411764706, Validation Loss: 5.251622676849365, Validation Accuracy: 0.5\n",
      "Epoch 2889/10000, Training Loss: 3.495476245880127, Training Accuracy: 0.5637254901960784, Validation Loss: 2.2156665325164795, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2890/10000, Training Loss: 4.527886390686035, Training Accuracy: 0.47058823529411764, Validation Loss: 2.242684841156006, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2891/10000, Training Loss: 3.858114242553711, Training Accuracy: 0.6004901960784313, Validation Loss: 5.4845662117004395, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2892/10000, Training Loss: 4.311692237854004, Training Accuracy: 0.5612745098039216, Validation Loss: 5.740423679351807, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2893/10000, Training Loss: 3.088757276535034, Training Accuracy: 0.6078431372549019, Validation Loss: 3.7530410289764404, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2894/10000, Training Loss: 3.076312303543091, Training Accuracy: 0.5441176470588235, Validation Loss: 2.2462539672851562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2895/10000, Training Loss: 2.4514079093933105, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8724040985107422, Validation Accuracy: 0.75\n",
      "Epoch 2896/10000, Training Loss: 3.3542566299438477, Training Accuracy: 0.5514705882352942, Validation Loss: 5.666411876678467, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2897/10000, Training Loss: 3.624918222427368, Training Accuracy: 0.5245098039215687, Validation Loss: 3.621837615966797, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2898/10000, Training Loss: 2.4685659408569336, Training Accuracy: 0.6127450980392157, Validation Loss: 2.9237422943115234, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2899/10000, Training Loss: 4.614962100982666, Training Accuracy: 0.5563725490196079, Validation Loss: 4.24902868270874, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2900/10000, Training Loss: 4.649585723876953, Training Accuracy: 0.5980392156862745, Validation Loss: 8.029945373535156, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2901/10000, Training Loss: 2.6654250621795654, Training Accuracy: 0.5759803921568627, Validation Loss: 7.868492603302002, Validation Accuracy: 0.5\n",
      "Epoch 2902/10000, Training Loss: 4.375889301300049, Training Accuracy: 0.5245098039215687, Validation Loss: 13.618820190429688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2903/10000, Training Loss: 4.68273401260376, Training Accuracy: 0.5269607843137255, Validation Loss: 2.076824903488159, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2904/10000, Training Loss: 4.045012950897217, Training Accuracy: 0.5318627450980392, Validation Loss: 4.657587051391602, Validation Accuracy: 0.5\n",
      "Epoch 2905/10000, Training Loss: 4.211631774902344, Training Accuracy: 0.5367647058823529, Validation Loss: 8.737045288085938, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2906/10000, Training Loss: 2.6237828731536865, Training Accuracy: 0.5980392156862745, Validation Loss: 3.2708213329315186, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2907/10000, Training Loss: 3.580692768096924, Training Accuracy: 0.5220588235294118, Validation Loss: 4.856959819793701, Validation Accuracy: 0.5\n",
      "Epoch 2908/10000, Training Loss: 4.980785369873047, Training Accuracy: 0.5808823529411765, Validation Loss: 7.247263431549072, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2909/10000, Training Loss: 3.114863872528076, Training Accuracy: 0.5490196078431373, Validation Loss: 2.3487038612365723, Validation Accuracy: 0.5\n",
      "Epoch 2910/10000, Training Loss: 2.642463207244873, Training Accuracy: 0.5220588235294118, Validation Loss: 3.64764666557312, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2911/10000, Training Loss: 5.058857440948486, Training Accuracy: 0.5441176470588235, Validation Loss: 1.892666220664978, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2912/10000, Training Loss: 5.233157157897949, Training Accuracy: 0.553921568627451, Validation Loss: 2.707750082015991, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2913/10000, Training Loss: 3.330124616622925, Training Accuracy: 0.5612745098039216, Validation Loss: 9.34991455078125, Validation Accuracy: 0.0\n",
      "Epoch 2914/10000, Training Loss: 3.946434497833252, Training Accuracy: 0.6446078431372549, Validation Loss: 1.6627172231674194, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2915/10000, Training Loss: 3.164670944213867, Training Accuracy: 0.6372549019607843, Validation Loss: 3.594543218612671, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2916/10000, Training Loss: 2.830889940261841, Training Accuracy: 0.6127450980392157, Validation Loss: 3.6734352111816406, Validation Accuracy: 0.5\n",
      "Epoch 2917/10000, Training Loss: 4.545065879821777, Training Accuracy: 0.47549019607843135, Validation Loss: 5.257901668548584, Validation Accuracy: 0.5\n",
      "Epoch 2918/10000, Training Loss: 3.205456018447876, Training Accuracy: 0.5882352941176471, Validation Loss: 5.840321063995361, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2919/10000, Training Loss: 5.035645008087158, Training Accuracy: 0.5857843137254902, Validation Loss: 5.573329925537109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2920/10000, Training Loss: 4.910178184509277, Training Accuracy: 0.5049019607843137, Validation Loss: 5.618981838226318, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2921/10000, Training Loss: 3.496903419494629, Training Accuracy: 0.5882352941176471, Validation Loss: 10.68320369720459, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2922/10000, Training Loss: 4.67991828918457, Training Accuracy: 0.5245098039215687, Validation Loss: 9.78550910949707, Validation Accuracy: 0.5\n",
      "Epoch 2923/10000, Training Loss: 2.740135669708252, Training Accuracy: 0.5563725490196079, Validation Loss: 4.178867816925049, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2924/10000, Training Loss: 3.7032058238983154, Training Accuracy: 0.48284313725490197, Validation Loss: 5.836113452911377, Validation Accuracy: 0.5\n",
      "Epoch 2925/10000, Training Loss: 2.5028042793273926, Training Accuracy: 0.6176470588235294, Validation Loss: 3.8195505142211914, Validation Accuracy: 0.5\n",
      "Epoch 2926/10000, Training Loss: 3.2523200511932373, Training Accuracy: 0.5220588235294118, Validation Loss: 4.399745941162109, Validation Accuracy: 0.5\n",
      "Epoch 2927/10000, Training Loss: 4.125327110290527, Training Accuracy: 0.5416666666666666, Validation Loss: 3.403367042541504, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 2928/10000, Training Loss: 3.905625104904175, Training Accuracy: 0.5465686274509803, Validation Loss: 4.4706501960754395, Validation Accuracy: 0.5\n",
      "Epoch 2929/10000, Training Loss: 3.9626827239990234, Training Accuracy: 0.5759803921568627, Validation Loss: 7.105016708374023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2930/10000, Training Loss: 2.3523550033569336, Training Accuracy: 0.5637254901960784, Validation Loss: 2.7634925842285156, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2931/10000, Training Loss: 3.153893232345581, Training Accuracy: 0.5759803921568627, Validation Loss: 1.9593205451965332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2932/10000, Training Loss: 2.4002768993377686, Training Accuracy: 0.5784313725490197, Validation Loss: 3.6538307666778564, Validation Accuracy: 0.5\n",
      "Epoch 2933/10000, Training Loss: 4.498489856719971, Training Accuracy: 0.6004901960784313, Validation Loss: 7.880218982696533, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2934/10000, Training Loss: 3.6034674644470215, Training Accuracy: 0.5955882352941176, Validation Loss: 7.864118576049805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2935/10000, Training Loss: 3.8784289360046387, Training Accuracy: 0.5367647058823529, Validation Loss: 3.178654909133911, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2936/10000, Training Loss: 2.21164870262146, Training Accuracy: 0.5931372549019608, Validation Loss: 4.528475284576416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2937/10000, Training Loss: 3.910526752471924, Training Accuracy: 0.5882352941176471, Validation Loss: 5.4698100090026855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2938/10000, Training Loss: 3.1174938678741455, Training Accuracy: 0.5098039215686274, Validation Loss: 1.5992647409439087, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2939/10000, Training Loss: 4.270308971405029, Training Accuracy: 0.5465686274509803, Validation Loss: 4.04889440536499, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2940/10000, Training Loss: 2.783217430114746, Training Accuracy: 0.6813725490196079, Validation Loss: 9.897468566894531, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2941/10000, Training Loss: 4.069557189941406, Training Accuracy: 0.5220588235294118, Validation Loss: 7.213053226470947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2942/10000, Training Loss: 3.5811026096343994, Training Accuracy: 0.5588235294117647, Validation Loss: 2.72473406791687, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2943/10000, Training Loss: 3.155963182449341, Training Accuracy: 0.5833333333333334, Validation Loss: 3.9005587100982666, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2944/10000, Training Loss: 3.0469796657562256, Training Accuracy: 0.5465686274509803, Validation Loss: 5.970283508300781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2945/10000, Training Loss: 3.7715892791748047, Training Accuracy: 0.5196078431372549, Validation Loss: 6.117991924285889, Validation Accuracy: 0.5\n",
      "Epoch 2946/10000, Training Loss: 2.5283896923065186, Training Accuracy: 0.6225490196078431, Validation Loss: 1.2232683897018433, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2947/10000, Training Loss: 3.132498264312744, Training Accuracy: 0.5294117647058824, Validation Loss: 3.7294819355010986, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2948/10000, Training Loss: 3.6609368324279785, Training Accuracy: 0.5661764705882353, Validation Loss: 5.92449951171875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2949/10000, Training Loss: 2.941744089126587, Training Accuracy: 0.5637254901960784, Validation Loss: 4.709110736846924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2950/10000, Training Loss: 3.355644702911377, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6054748892784119, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 2951/10000, Training Loss: 3.1515564918518066, Training Accuracy: 0.5490196078431373, Validation Loss: 2.9151716232299805, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2952/10000, Training Loss: 2.6325652599334717, Training Accuracy: 0.5955882352941176, Validation Loss: 3.621941328048706, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2953/10000, Training Loss: 3.3959662914276123, Training Accuracy: 0.6446078431372549, Validation Loss: 2.5627403259277344, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2954/10000, Training Loss: 5.45986270904541, Training Accuracy: 0.5735294117647058, Validation Loss: 12.766387939453125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2955/10000, Training Loss: 3.1675519943237305, Training Accuracy: 0.5686274509803921, Validation Loss: 1.7606879472732544, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2956/10000, Training Loss: 3.1337857246398926, Training Accuracy: 0.5808823529411765, Validation Loss: 6.568688869476318, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2957/10000, Training Loss: 4.111399173736572, Training Accuracy: 0.5882352941176471, Validation Loss: 6.552101135253906, Validation Accuracy: 0.25\n",
      "Epoch 2958/10000, Training Loss: 4.116389751434326, Training Accuracy: 0.5294117647058824, Validation Loss: 5.771152973175049, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2959/10000, Training Loss: 3.037867546081543, Training Accuracy: 0.5269607843137255, Validation Loss: 3.537102699279785, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2960/10000, Training Loss: 3.108241081237793, Training Accuracy: 0.5098039215686274, Validation Loss: 4.074652194976807, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2961/10000, Training Loss: 3.8433496952056885, Training Accuracy: 0.5612745098039216, Validation Loss: 6.224546909332275, Validation Accuracy: 0.75\n",
      "Epoch 2962/10000, Training Loss: 3.186352014541626, Training Accuracy: 0.6568627450980392, Validation Loss: 2.1952662467956543, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2963/10000, Training Loss: 2.948215961456299, Training Accuracy: 0.4877450980392157, Validation Loss: 8.230793952941895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2964/10000, Training Loss: 3.2681100368499756, Training Accuracy: 0.6127450980392157, Validation Loss: 13.958680152893066, Validation Accuracy: 0.5\n",
      "Epoch 2965/10000, Training Loss: 3.0233542919158936, Training Accuracy: 0.6176470588235294, Validation Loss: 5.303258419036865, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2966/10000, Training Loss: 3.476824998855591, Training Accuracy: 0.5735294117647058, Validation Loss: 3.298962354660034, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2967/10000, Training Loss: 2.630685567855835, Training Accuracy: 0.6495098039215687, Validation Loss: 4.8302507400512695, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2968/10000, Training Loss: 2.840325117111206, Training Accuracy: 0.5588235294117647, Validation Loss: 2.0123941898345947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2969/10000, Training Loss: 3.9243414402008057, Training Accuracy: 0.5269607843137255, Validation Loss: 3.391472816467285, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2970/10000, Training Loss: 2.800332546234131, Training Accuracy: 0.6004901960784313, Validation Loss: 6.4715962409973145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2971/10000, Training Loss: 2.417072057723999, Training Accuracy: 0.6299019607843137, Validation Loss: 1.017811894416809, Validation Accuracy: 0.75\n",
      "Epoch 2972/10000, Training Loss: 3.1990859508514404, Training Accuracy: 0.5441176470588235, Validation Loss: 5.2528557777404785, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2973/10000, Training Loss: 4.874080657958984, Training Accuracy: 0.5490196078431373, Validation Loss: 3.122211456298828, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2974/10000, Training Loss: 4.324994087219238, Training Accuracy: 0.5416666666666666, Validation Loss: 5.196646690368652, Validation Accuracy: 0.5\n",
      "Epoch 2975/10000, Training Loss: 3.6663782596588135, Training Accuracy: 0.5882352941176471, Validation Loss: 4.657015800476074, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2976/10000, Training Loss: 2.93141770362854, Training Accuracy: 0.571078431372549, Validation Loss: 0.8760420680046082, Validation Accuracy: 0.75\n",
      "Epoch 2977/10000, Training Loss: 2.3253822326660156, Training Accuracy: 0.6470588235294118, Validation Loss: 6.1635284423828125, Validation Accuracy: 0.5\n",
      "Epoch 2978/10000, Training Loss: 3.390259027481079, Training Accuracy: 0.5588235294117647, Validation Loss: 3.30607008934021, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2979/10000, Training Loss: 2.8317861557006836, Training Accuracy: 0.6029411764705882, Validation Loss: 2.575622797012329, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2980/10000, Training Loss: 3.212709665298462, Training Accuracy: 0.5808823529411765, Validation Loss: 3.474201202392578, Validation Accuracy: 0.5\n",
      "Epoch 2981/10000, Training Loss: 2.311511516571045, Training Accuracy: 0.5686274509803921, Validation Loss: 12.391410827636719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2982/10000, Training Loss: 2.412107467651367, Training Accuracy: 0.6348039215686274, Validation Loss: 5.381140232086182, Validation Accuracy: 0.5\n",
      "Epoch 2983/10000, Training Loss: 2.17726469039917, Training Accuracy: 0.6323529411764706, Validation Loss: 6.376152515411377, Validation Accuracy: 0.25\n",
      "Epoch 2984/10000, Training Loss: 3.959110736846924, Training Accuracy: 0.44607843137254904, Validation Loss: 5.778337001800537, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2985/10000, Training Loss: 3.072227954864502, Training Accuracy: 0.5441176470588235, Validation Loss: 4.362546920776367, Validation Accuracy: 0.5\n",
      "Epoch 2986/10000, Training Loss: 3.9783568382263184, Training Accuracy: 0.6200980392156863, Validation Loss: 6.552995204925537, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2987/10000, Training Loss: 3.5241498947143555, Training Accuracy: 0.5220588235294118, Validation Loss: 4.473048686981201, Validation Accuracy: 0.5\n",
      "Epoch 2988/10000, Training Loss: 3.4148638248443604, Training Accuracy: 0.5269607843137255, Validation Loss: 4.100916385650635, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2989/10000, Training Loss: 3.074800968170166, Training Accuracy: 0.6004901960784313, Validation Loss: 7.739452838897705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2990/10000, Training Loss: 2.765042543411255, Training Accuracy: 0.6299019607843137, Validation Loss: 7.786706924438477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2991/10000, Training Loss: 3.499136209487915, Training Accuracy: 0.6176470588235294, Validation Loss: 2.804326295852661, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 2992/10000, Training Loss: 2.8069849014282227, Training Accuracy: 0.5808823529411765, Validation Loss: 0.5665367245674133, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 2993/10000, Training Loss: 2.4071030616760254, Training Accuracy: 0.5735294117647058, Validation Loss: 2.1317689418792725, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2994/10000, Training Loss: 2.6102654933929443, Training Accuracy: 0.5759803921568627, Validation Loss: 1.2728482484817505, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 2995/10000, Training Loss: 2.96917462348938, Training Accuracy: 0.5563725490196079, Validation Loss: 2.7796614170074463, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 2996/10000, Training Loss: 3.7145564556121826, Training Accuracy: 0.5343137254901961, Validation Loss: 3.7829601764678955, Validation Accuracy: 0.5\n",
      "Epoch 2997/10000, Training Loss: 2.727191686630249, Training Accuracy: 0.5392156862745098, Validation Loss: 3.9138870239257812, Validation Accuracy: 0.5\n",
      "Epoch 2998/10000, Training Loss: 2.554388999938965, Training Accuracy: 0.5343137254901961, Validation Loss: 1.838111400604248, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 2999/10000, Training Loss: 4.180002689361572, Training Accuracy: 0.5441176470588235, Validation Loss: 2.6263267993927, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3000/10000, Training Loss: 3.2171764373779297, Training Accuracy: 0.5294117647058824, Validation Loss: 3.9117469787597656, Validation Accuracy: 0.25\n",
      "Epoch 3001/10000, Training Loss: 3.9465696811676025, Training Accuracy: 0.5490196078431373, Validation Loss: 3.9145965576171875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3002/10000, Training Loss: 3.46010422706604, Training Accuracy: 0.5735294117647058, Validation Loss: 0.970813512802124, Validation Accuracy: 0.75\n",
      "Epoch 3003/10000, Training Loss: 3.413616418838501, Training Accuracy: 0.4852941176470588, Validation Loss: 4.713429927825928, Validation Accuracy: 0.5\n",
      "Epoch 3004/10000, Training Loss: 2.337926149368286, Training Accuracy: 0.5416666666666666, Validation Loss: 3.4584243297576904, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3005/10000, Training Loss: 3.1755735874176025, Training Accuracy: 0.5147058823529411, Validation Loss: 2.740800619125366, Validation Accuracy: 0.5\n",
      "Epoch 3006/10000, Training Loss: 2.5459136962890625, Training Accuracy: 0.5612745098039216, Validation Loss: 5.501903057098389, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3007/10000, Training Loss: 2.690211296081543, Training Accuracy: 0.5073529411764706, Validation Loss: 3.973127603530884, Validation Accuracy: 0.5\n",
      "Epoch 3008/10000, Training Loss: 3.014521360397339, Training Accuracy: 0.5612745098039216, Validation Loss: 6.5428924560546875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3009/10000, Training Loss: 2.790959119796753, Training Accuracy: 0.5759803921568627, Validation Loss: 1.646862506866455, Validation Accuracy: 0.5\n",
      "Epoch 3010/10000, Training Loss: 4.717321872711182, Training Accuracy: 0.5269607843137255, Validation Loss: 9.736454010009766, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3011/10000, Training Loss: 2.839442014694214, Training Accuracy: 0.5588235294117647, Validation Loss: 2.8944597244262695, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3012/10000, Training Loss: 2.980991840362549, Training Accuracy: 0.553921568627451, Validation Loss: 4.1918439865112305, Validation Accuracy: 0.25\n",
      "Epoch 3013/10000, Training Loss: 2.3188774585723877, Training Accuracy: 0.5588235294117647, Validation Loss: 3.797207832336426, Validation Accuracy: 0.5\n",
      "Epoch 3014/10000, Training Loss: 2.888143539428711, Training Accuracy: 0.6397058823529411, Validation Loss: 2.319885492324829, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3015/10000, Training Loss: 2.8517491817474365, Training Accuracy: 0.6127450980392157, Validation Loss: 2.5287389755249023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3016/10000, Training Loss: 3.241624116897583, Training Accuracy: 0.6127450980392157, Validation Loss: 12.436107635498047, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3017/10000, Training Loss: 3.521629571914673, Training Accuracy: 0.5759803921568627, Validation Loss: 4.787254333496094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3018/10000, Training Loss: 3.18269681930542, Training Accuracy: 0.5563725490196079, Validation Loss: 7.909250259399414, Validation Accuracy: 0.25\n",
      "Epoch 3019/10000, Training Loss: 3.0840885639190674, Training Accuracy: 0.5049019607843137, Validation Loss: 3.8369357585906982, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3020/10000, Training Loss: 2.406362771987915, Training Accuracy: 0.6372549019607843, Validation Loss: 5.141568660736084, Validation Accuracy: 0.25\n",
      "Epoch 3021/10000, Training Loss: 2.855719566345215, Training Accuracy: 0.6421568627450981, Validation Loss: 5.861862659454346, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3022/10000, Training Loss: 3.1906261444091797, Training Accuracy: 0.5857843137254902, Validation Loss: 1.8276313543319702, Validation Accuracy: 0.75\n",
      "Epoch 3023/10000, Training Loss: 2.9066336154937744, Training Accuracy: 0.5857843137254902, Validation Loss: 2.4884135723114014, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3024/10000, Training Loss: 2.7652618885040283, Training Accuracy: 0.5980392156862745, Validation Loss: 3.0600268840789795, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3025/10000, Training Loss: 3.7993412017822266, Training Accuracy: 0.5196078431372549, Validation Loss: 8.847012519836426, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3026/10000, Training Loss: 2.448817253112793, Training Accuracy: 0.5906862745098039, Validation Loss: 7.848785400390625, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3027/10000, Training Loss: 3.1343231201171875, Training Accuracy: 0.6568627450980392, Validation Loss: 3.0983874797821045, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3028/10000, Training Loss: 3.165456771850586, Training Accuracy: 0.5955882352941176, Validation Loss: 1.4044033288955688, Validation Accuracy: 0.5\n",
      "Epoch 3029/10000, Training Loss: 3.102069616317749, Training Accuracy: 0.5294117647058824, Validation Loss: 4.30702543258667, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3030/10000, Training Loss: 2.997706651687622, Training Accuracy: 0.5637254901960784, Validation Loss: 5.443234920501709, Validation Accuracy: 0.5\n",
      "Epoch 3031/10000, Training Loss: 2.5452351570129395, Training Accuracy: 0.5784313725490197, Validation Loss: 6.988157272338867, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3032/10000, Training Loss: 4.842899799346924, Training Accuracy: 0.5122549019607843, Validation Loss: 8.384712219238281, Validation Accuracy: 0.25\n",
      "Epoch 3033/10000, Training Loss: 2.960693359375, Training Accuracy: 0.5049019607843137, Validation Loss: 8.412732124328613, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3034/10000, Training Loss: 4.597585201263428, Training Accuracy: 0.571078431372549, Validation Loss: 10.887164115905762, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3035/10000, Training Loss: 2.9117255210876465, Training Accuracy: 0.5906862745098039, Validation Loss: 5.7907538414001465, Validation Accuracy: 0.5\n",
      "Epoch 3036/10000, Training Loss: 3.350074291229248, Training Accuracy: 0.5808823529411765, Validation Loss: 5.522902011871338, Validation Accuracy: 0.5\n",
      "Epoch 3037/10000, Training Loss: 3.8712594509124756, Training Accuracy: 0.553921568627451, Validation Loss: 5.690238952636719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3038/10000, Training Loss: 4.477132320404053, Training Accuracy: 0.5245098039215687, Validation Loss: 3.3197882175445557, Validation Accuracy: 0.5\n",
      "Epoch 3039/10000, Training Loss: 4.669677734375, Training Accuracy: 0.5857843137254902, Validation Loss: 3.6921844482421875, Validation Accuracy: 0.5\n",
      "Epoch 3040/10000, Training Loss: 2.611515522003174, Training Accuracy: 0.6225490196078431, Validation Loss: 5.739454746246338, Validation Accuracy: 0.5\n",
      "Epoch 3041/10000, Training Loss: 2.7047293186187744, Training Accuracy: 0.5637254901960784, Validation Loss: 3.6848602294921875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3042/10000, Training Loss: 3.74658203125, Training Accuracy: 0.5122549019607843, Validation Loss: 3.8327646255493164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3043/10000, Training Loss: 4.412939548492432, Training Accuracy: 0.5465686274509803, Validation Loss: 4.009915828704834, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3044/10000, Training Loss: 4.170122146606445, Training Accuracy: 0.5392156862745098, Validation Loss: 4.734213352203369, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3045/10000, Training Loss: 4.551280498504639, Training Accuracy: 0.5612745098039216, Validation Loss: 2.64290452003479, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3046/10000, Training Loss: 3.1620168685913086, Training Accuracy: 0.6151960784313726, Validation Loss: 2.592302083969116, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3047/10000, Training Loss: 3.4581689834594727, Training Accuracy: 0.5931372549019608, Validation Loss: 7.72787618637085, Validation Accuracy: 0.5\n",
      "Epoch 3048/10000, Training Loss: 2.970271587371826, Training Accuracy: 0.553921568627451, Validation Loss: 4.301614284515381, Validation Accuracy: 0.5\n",
      "Epoch 3049/10000, Training Loss: 3.382736921310425, Training Accuracy: 0.5490196078431373, Validation Loss: 5.641625881195068, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3050/10000, Training Loss: 3.883457660675049, Training Accuracy: 0.5612745098039216, Validation Loss: 4.488600254058838, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3051/10000, Training Loss: 2.8507885932922363, Training Accuracy: 0.5343137254901961, Validation Loss: 2.616129159927368, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3052/10000, Training Loss: 3.1403117179870605, Training Accuracy: 0.5612745098039216, Validation Loss: 3.858027696609497, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3053/10000, Training Loss: 2.4660418033599854, Training Accuracy: 0.5563725490196079, Validation Loss: 5.013821125030518, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3054/10000, Training Loss: 2.340932607650757, Training Accuracy: 0.625, Validation Loss: 2.6633331775665283, Validation Accuracy: 0.25\n",
      "Epoch 3055/10000, Training Loss: 3.964987277984619, Training Accuracy: 0.5637254901960784, Validation Loss: 3.414593458175659, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3056/10000, Training Loss: 3.2628448009490967, Training Accuracy: 0.6029411764705882, Validation Loss: 3.554779291152954, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3057/10000, Training Loss: 2.3414549827575684, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3566826581954956, Validation Accuracy: 0.75\n",
      "Epoch 3058/10000, Training Loss: 3.785127639770508, Training Accuracy: 0.5612745098039216, Validation Loss: 4.9757161140441895, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3059/10000, Training Loss: 3.337106227874756, Training Accuracy: 0.5808823529411765, Validation Loss: 3.8797760009765625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3060/10000, Training Loss: 5.218123912811279, Training Accuracy: 0.5122549019607843, Validation Loss: 7.161571979522705, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3061/10000, Training Loss: 3.959352970123291, Training Accuracy: 0.5980392156862745, Validation Loss: 4.905317306518555, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3062/10000, Training Loss: 1.8939882516860962, Training Accuracy: 0.6299019607843137, Validation Loss: 1.2894479036331177, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3063/10000, Training Loss: 2.939638137817383, Training Accuracy: 0.5808823529411765, Validation Loss: 2.451058864593506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3064/10000, Training Loss: 3.4975669384002686, Training Accuracy: 0.5220588235294118, Validation Loss: 3.4261131286621094, Validation Accuracy: 0.5\n",
      "Epoch 3065/10000, Training Loss: 3.093348741531372, Training Accuracy: 0.5759803921568627, Validation Loss: 3.2206428050994873, Validation Accuracy: 0.75\n",
      "Epoch 3066/10000, Training Loss: 2.4081974029541016, Training Accuracy: 0.5759803921568627, Validation Loss: 3.237833261489868, Validation Accuracy: 0.25\n",
      "Epoch 3067/10000, Training Loss: 4.467213153839111, Training Accuracy: 0.5367647058823529, Validation Loss: 5.009127140045166, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3068/10000, Training Loss: 4.075816631317139, Training Accuracy: 0.5759803921568627, Validation Loss: 1.680238127708435, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3069/10000, Training Loss: 5.276439189910889, Training Accuracy: 0.5686274509803921, Validation Loss: 7.220999240875244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3070/10000, Training Loss: 2.243788242340088, Training Accuracy: 0.6127450980392157, Validation Loss: 3.171741247177124, Validation Accuracy: 0.75\n",
      "Epoch 3071/10000, Training Loss: 2.7266671657562256, Training Accuracy: 0.6495098039215687, Validation Loss: 3.1273880004882812, Validation Accuracy: 0.5\n",
      "Epoch 3072/10000, Training Loss: 2.358896017074585, Training Accuracy: 0.5294117647058824, Validation Loss: 3.1102161407470703, Validation Accuracy: 0.5\n",
      "Epoch 3073/10000, Training Loss: 3.7145516872406006, Training Accuracy: 0.5147058823529411, Validation Loss: 5.17746114730835, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3074/10000, Training Loss: 4.045032978057861, Training Accuracy: 0.553921568627451, Validation Loss: 2.325831413269043, Validation Accuracy: 0.5\n",
      "Epoch 3075/10000, Training Loss: 4.491144180297852, Training Accuracy: 0.5784313725490197, Validation Loss: 2.8691158294677734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3076/10000, Training Loss: 3.705439805984497, Training Accuracy: 0.5245098039215687, Validation Loss: 1.3984211683273315, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3077/10000, Training Loss: 2.6574554443359375, Training Accuracy: 0.6446078431372549, Validation Loss: 2.5437753200531006, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3078/10000, Training Loss: 2.730083465576172, Training Accuracy: 0.6102941176470589, Validation Loss: 5.495429992675781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3079/10000, Training Loss: 3.919126033782959, Training Accuracy: 0.5563725490196079, Validation Loss: 5.135814189910889, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3080/10000, Training Loss: 3.275477409362793, Training Accuracy: 0.6372549019607843, Validation Loss: 7.004444599151611, Validation Accuracy: 0.5\n",
      "Epoch 3081/10000, Training Loss: 3.952939748764038, Training Accuracy: 0.4950980392156863, Validation Loss: 3.953340530395508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3082/10000, Training Loss: 4.252764701843262, Training Accuracy: 0.5122549019607843, Validation Loss: 6.712498188018799, Validation Accuracy: 0.25\n",
      "Epoch 3083/10000, Training Loss: 4.022336959838867, Training Accuracy: 0.5049019607843137, Validation Loss: 1.9561704397201538, Validation Accuracy: 0.5\n",
      "Epoch 3084/10000, Training Loss: 2.801041841506958, Training Accuracy: 0.5588235294117647, Validation Loss: 4.75193452835083, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3085/10000, Training Loss: 2.6741414070129395, Training Accuracy: 0.6029411764705882, Validation Loss: 4.291560173034668, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3086/10000, Training Loss: 2.813441038131714, Training Accuracy: 0.5465686274509803, Validation Loss: 1.5060639381408691, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3087/10000, Training Loss: 2.106356382369995, Training Accuracy: 0.5833333333333334, Validation Loss: 1.7904056310653687, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3088/10000, Training Loss: 2.808692455291748, Training Accuracy: 0.5343137254901961, Validation Loss: 1.852860927581787, Validation Accuracy: 0.5\n",
      "Epoch 3089/10000, Training Loss: 2.6117262840270996, Training Accuracy: 0.5490196078431373, Validation Loss: 2.864741563796997, Validation Accuracy: 0.25\n",
      "Epoch 3090/10000, Training Loss: 3.126246690750122, Training Accuracy: 0.5220588235294118, Validation Loss: 0.9017193913459778, Validation Accuracy: 0.75\n",
      "Epoch 3091/10000, Training Loss: 2.2371790409088135, Training Accuracy: 0.5367647058823529, Validation Loss: 3.1841747760772705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3092/10000, Training Loss: 3.569939613342285, Training Accuracy: 0.5906862745098039, Validation Loss: 3.733785629272461, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3093/10000, Training Loss: 2.7226271629333496, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0214778184890747, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3094/10000, Training Loss: 3.347390651702881, Training Accuracy: 0.571078431372549, Validation Loss: 7.36889123916626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3095/10000, Training Loss: 3.1846604347229004, Training Accuracy: 0.5833333333333334, Validation Loss: 2.2078821659088135, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3096/10000, Training Loss: 3.187826633453369, Training Accuracy: 0.5147058823529411, Validation Loss: 3.7019309997558594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3097/10000, Training Loss: 2.2212142944335938, Training Accuracy: 0.5906862745098039, Validation Loss: 2.8375651836395264, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3098/10000, Training Loss: 2.90364933013916, Training Accuracy: 0.5220588235294118, Validation Loss: 3.392934560775757, Validation Accuracy: 0.5\n",
      "Epoch 3099/10000, Training Loss: 3.6173484325408936, Training Accuracy: 0.5808823529411765, Validation Loss: 3.6592912673950195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3100/10000, Training Loss: 3.780569553375244, Training Accuracy: 0.5269607843137255, Validation Loss: 2.6924197673797607, Validation Accuracy: 0.75\n",
      "Epoch 3101/10000, Training Loss: 2.575124740600586, Training Accuracy: 0.5416666666666666, Validation Loss: 4.4670023918151855, Validation Accuracy: 0.5\n",
      "Epoch 3102/10000, Training Loss: 3.338778018951416, Training Accuracy: 0.5882352941176471, Validation Loss: 3.350083112716675, Validation Accuracy: 0.5\n",
      "Epoch 3103/10000, Training Loss: 2.5056347846984863, Training Accuracy: 0.6053921568627451, Validation Loss: 4.530893325805664, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3104/10000, Training Loss: 2.5206120014190674, Training Accuracy: 0.5588235294117647, Validation Loss: 2.427659273147583, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3105/10000, Training Loss: 3.8040595054626465, Training Accuracy: 0.5220588235294118, Validation Loss: 4.312465190887451, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3106/10000, Training Loss: 2.6812779903411865, Training Accuracy: 0.5588235294117647, Validation Loss: 2.813441038131714, Validation Accuracy: 0.75\n",
      "Epoch 3107/10000, Training Loss: 3.562063694000244, Training Accuracy: 0.5343137254901961, Validation Loss: 1.0377013683319092, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3108/10000, Training Loss: 3.0574772357940674, Training Accuracy: 0.5857843137254902, Validation Loss: 10.313895225524902, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3109/10000, Training Loss: 2.6043083667755127, Training Accuracy: 0.5833333333333334, Validation Loss: 4.876222610473633, Validation Accuracy: 0.5\n",
      "Epoch 3110/10000, Training Loss: 3.21075439453125, Training Accuracy: 0.5931372549019608, Validation Loss: 2.1123156547546387, Validation Accuracy: 0.5\n",
      "Epoch 3111/10000, Training Loss: 3.2517309188842773, Training Accuracy: 0.5980392156862745, Validation Loss: 5.816289901733398, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3112/10000, Training Loss: 2.262732982635498, Training Accuracy: 0.5906862745098039, Validation Loss: 2.1788604259490967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3113/10000, Training Loss: 3.912968158721924, Training Accuracy: 0.49019607843137253, Validation Loss: 7.57873010635376, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3114/10000, Training Loss: 3.5027971267700195, Training Accuracy: 0.5686274509803921, Validation Loss: 5.69365930557251, Validation Accuracy: 0.5\n",
      "Epoch 3115/10000, Training Loss: 2.8749613761901855, Training Accuracy: 0.5686274509803921, Validation Loss: 3.9431049823760986, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3116/10000, Training Loss: 2.647829294204712, Training Accuracy: 0.5661764705882353, Validation Loss: 5.78415060043335, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3117/10000, Training Loss: 2.6072261333465576, Training Accuracy: 0.5931372549019608, Validation Loss: 3.11942982673645, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3118/10000, Training Loss: 2.3368520736694336, Training Accuracy: 0.5857843137254902, Validation Loss: 2.448948383331299, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3119/10000, Training Loss: 2.9897241592407227, Training Accuracy: 0.6176470588235294, Validation Loss: 2.355358839035034, Validation Accuracy: 0.5\n",
      "Epoch 3120/10000, Training Loss: 2.8750174045562744, Training Accuracy: 0.5269607843137255, Validation Loss: 3.8004958629608154, Validation Accuracy: 0.5\n",
      "Epoch 3121/10000, Training Loss: 3.954732894897461, Training Accuracy: 0.4877450980392157, Validation Loss: 5.132084369659424, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3122/10000, Training Loss: 3.5229718685150146, Training Accuracy: 0.5686274509803921, Validation Loss: 12.602787017822266, Validation Accuracy: 0.5\n",
      "Epoch 3123/10000, Training Loss: 3.747392177581787, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9924077391624451, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3124/10000, Training Loss: 1.9718656539916992, Training Accuracy: 0.6053921568627451, Validation Loss: 3.261464834213257, Validation Accuracy: 0.5\n",
      "Epoch 3125/10000, Training Loss: 4.205454349517822, Training Accuracy: 0.5294117647058824, Validation Loss: 1.7857190370559692, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3126/10000, Training Loss: 2.094593048095703, Training Accuracy: 0.5857843137254902, Validation Loss: 4.711883068084717, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3127/10000, Training Loss: 3.718351364135742, Training Accuracy: 0.571078431372549, Validation Loss: 3.8864758014678955, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3128/10000, Training Loss: 2.5248966217041016, Training Accuracy: 0.5073529411764706, Validation Loss: 3.2714030742645264, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3129/10000, Training Loss: 2.984114408493042, Training Accuracy: 0.5906862745098039, Validation Loss: 3.703324317932129, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3130/10000, Training Loss: 2.478684425354004, Training Accuracy: 0.5563725490196079, Validation Loss: 3.793076753616333, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3131/10000, Training Loss: 5.289243221282959, Training Accuracy: 0.4950980392156863, Validation Loss: 2.5646181106567383, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3132/10000, Training Loss: 4.834593772888184, Training Accuracy: 0.5661764705882353, Validation Loss: 4.733892440795898, Validation Accuracy: 0.5\n",
      "Epoch 3133/10000, Training Loss: 3.14546275138855, Training Accuracy: 0.553921568627451, Validation Loss: 4.221738338470459, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3134/10000, Training Loss: 2.794837236404419, Training Accuracy: 0.5661764705882353, Validation Loss: 7.369085788726807, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3135/10000, Training Loss: 2.763429641723633, Training Accuracy: 0.553921568627451, Validation Loss: 5.326629161834717, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3136/10000, Training Loss: 2.7086782455444336, Training Accuracy: 0.5392156862745098, Validation Loss: 1.6983933448791504, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3137/10000, Training Loss: 3.505358934402466, Training Accuracy: 0.5808823529411765, Validation Loss: 2.031839609146118, Validation Accuracy: 0.5\n",
      "Epoch 3138/10000, Training Loss: 5.366588592529297, Training Accuracy: 0.5833333333333334, Validation Loss: 11.111613273620605, Validation Accuracy: 0.25\n",
      "Epoch 3139/10000, Training Loss: 2.951308488845825, Training Accuracy: 0.571078431372549, Validation Loss: 2.3955607414245605, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3140/10000, Training Loss: 2.849652051925659, Training Accuracy: 0.5490196078431373, Validation Loss: 0.8765838146209717, Validation Accuracy: 0.5\n",
      "Epoch 3141/10000, Training Loss: 3.7566120624542236, Training Accuracy: 0.5514705882352942, Validation Loss: 4.985372066497803, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3142/10000, Training Loss: 2.900423765182495, Training Accuracy: 0.6102941176470589, Validation Loss: 12.92232894897461, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3143/10000, Training Loss: 3.0509583950042725, Training Accuracy: 0.5857843137254902, Validation Loss: 5.766635417938232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3144/10000, Training Loss: 2.883157253265381, Training Accuracy: 0.5245098039215687, Validation Loss: 3.6116816997528076, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3145/10000, Training Loss: 3.747544288635254, Training Accuracy: 0.5220588235294118, Validation Loss: 5.135213851928711, Validation Accuracy: 0.25\n",
      "Epoch 3146/10000, Training Loss: 2.079866647720337, Training Accuracy: 0.5637254901960784, Validation Loss: 3.9157731533050537, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3147/10000, Training Loss: 3.713313102722168, Training Accuracy: 0.5637254901960784, Validation Loss: 5.624767303466797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3148/10000, Training Loss: 2.83646559715271, Training Accuracy: 0.5686274509803921, Validation Loss: 2.8669939041137695, Validation Accuracy: 0.5\n",
      "Epoch 3149/10000, Training Loss: 4.104989528656006, Training Accuracy: 0.5955882352941176, Validation Loss: 6.356903076171875, Validation Accuracy: 0.5\n",
      "Epoch 3150/10000, Training Loss: 2.6109585762023926, Training Accuracy: 0.5269607843137255, Validation Loss: 2.547212839126587, Validation Accuracy: 0.5\n",
      "Epoch 3151/10000, Training Loss: 2.625913619995117, Training Accuracy: 0.6176470588235294, Validation Loss: 4.07974100112915, Validation Accuracy: 0.5\n",
      "Epoch 3152/10000, Training Loss: 2.8784172534942627, Training Accuracy: 0.5784313725490197, Validation Loss: 4.576085090637207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3153/10000, Training Loss: 4.208467960357666, Training Accuracy: 0.5, Validation Loss: 2.160654067993164, Validation Accuracy: 0.5\n",
      "Epoch 3154/10000, Training Loss: 3.901677370071411, Training Accuracy: 0.5073529411764706, Validation Loss: 2.660892963409424, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3155/10000, Training Loss: 3.0085909366607666, Training Accuracy: 0.5098039215686274, Validation Loss: 0.5288134217262268, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 3156/10000, Training Loss: 3.2640392780303955, Training Accuracy: 0.6200980392156863, Validation Loss: 6.060959339141846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3157/10000, Training Loss: 2.686249017715454, Training Accuracy: 0.5931372549019608, Validation Loss: 6.990963459014893, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3158/10000, Training Loss: 2.624912738800049, Training Accuracy: 0.5318627450980392, Validation Loss: 4.189095973968506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3159/10000, Training Loss: 3.510713815689087, Training Accuracy: 0.5759803921568627, Validation Loss: 2.807847738265991, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3160/10000, Training Loss: 2.7144110202789307, Training Accuracy: 0.5465686274509803, Validation Loss: 3.0449554920196533, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3161/10000, Training Loss: 4.073276519775391, Training Accuracy: 0.48284313725490197, Validation Loss: 4.072817325592041, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3162/10000, Training Loss: 2.6185975074768066, Training Accuracy: 0.5833333333333334, Validation Loss: 5.631866931915283, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3163/10000, Training Loss: 3.3623929023742676, Training Accuracy: 0.5294117647058824, Validation Loss: 5.067703723907471, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3164/10000, Training Loss: 3.1963281631469727, Training Accuracy: 0.5465686274509803, Validation Loss: 4.6192851066589355, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3165/10000, Training Loss: 1.9390835762023926, Training Accuracy: 0.6372549019607843, Validation Loss: 3.9390580654144287, Validation Accuracy: 0.25\n",
      "Epoch 3166/10000, Training Loss: 2.75780987739563, Training Accuracy: 0.5392156862745098, Validation Loss: 3.633146286010742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3167/10000, Training Loss: 3.965924024581909, Training Accuracy: 0.5318627450980392, Validation Loss: 10.841553688049316, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3168/10000, Training Loss: 3.1273388862609863, Training Accuracy: 0.5588235294117647, Validation Loss: 2.636014699935913, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3169/10000, Training Loss: 3.9856276512145996, Training Accuracy: 0.5588235294117647, Validation Loss: 8.330517768859863, Validation Accuracy: 0.25\n",
      "Epoch 3170/10000, Training Loss: 2.96882700920105, Training Accuracy: 0.5343137254901961, Validation Loss: 2.6492927074432373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3171/10000, Training Loss: 3.699172258377075, Training Accuracy: 0.6102941176470589, Validation Loss: 6.3930439949035645, Validation Accuracy: 0.5\n",
      "Epoch 3172/10000, Training Loss: 2.0949833393096924, Training Accuracy: 0.5294117647058824, Validation Loss: 1.5755733251571655, Validation Accuracy: 0.5\n",
      "Epoch 3173/10000, Training Loss: 4.26700496673584, Training Accuracy: 0.5049019607843137, Validation Loss: 14.452984809875488, Validation Accuracy: 0.25\n",
      "Epoch 3174/10000, Training Loss: 2.778719425201416, Training Accuracy: 0.4852941176470588, Validation Loss: 1.48503577709198, Validation Accuracy: 0.5\n",
      "Epoch 3175/10000, Training Loss: 3.0390799045562744, Training Accuracy: 0.5735294117647058, Validation Loss: 4.000309467315674, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3176/10000, Training Loss: 2.8230669498443604, Training Accuracy: 0.571078431372549, Validation Loss: 4.613125801086426, Validation Accuracy: 0.25\n",
      "Epoch 3177/10000, Training Loss: 3.2546684741973877, Training Accuracy: 0.5416666666666666, Validation Loss: 2.293034315109253, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3178/10000, Training Loss: 3.3826825618743896, Training Accuracy: 0.5294117647058824, Validation Loss: 3.4770395755767822, Validation Accuracy: 0.5\n",
      "Epoch 3179/10000, Training Loss: 2.0018608570098877, Training Accuracy: 0.5392156862745098, Validation Loss: 2.698162794113159, Validation Accuracy: 0.5\n",
      "Epoch 3180/10000, Training Loss: 4.226000785827637, Training Accuracy: 0.5686274509803921, Validation Loss: 5.98449182510376, Validation Accuracy: 0.5\n",
      "Epoch 3181/10000, Training Loss: 2.3802080154418945, Training Accuracy: 0.5686274509803921, Validation Loss: 1.6719588041305542, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3182/10000, Training Loss: 2.528024673461914, Training Accuracy: 0.5931372549019608, Validation Loss: 8.404166221618652, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3183/10000, Training Loss: 3.883291482925415, Training Accuracy: 0.5098039215686274, Validation Loss: 0.3374536335468292, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 3184/10000, Training Loss: 2.2075140476226807, Training Accuracy: 0.5808823529411765, Validation Loss: 6.734660625457764, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3185/10000, Training Loss: 2.3834187984466553, Training Accuracy: 0.5367647058823529, Validation Loss: 1.0465786457061768, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3186/10000, Training Loss: 3.873487949371338, Training Accuracy: 0.5294117647058824, Validation Loss: 3.058410406112671, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3187/10000, Training Loss: 3.2654359340667725, Training Accuracy: 0.5343137254901961, Validation Loss: 5.644451141357422, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3188/10000, Training Loss: 4.139030456542969, Training Accuracy: 0.5294117647058824, Validation Loss: 7.608672618865967, Validation Accuracy: 0.5\n",
      "Epoch 3189/10000, Training Loss: 2.5864250659942627, Training Accuracy: 0.5392156862745098, Validation Loss: 3.4658918380737305, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3190/10000, Training Loss: 2.3497164249420166, Training Accuracy: 0.571078431372549, Validation Loss: 2.5985500812530518, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3191/10000, Training Loss: 2.831089496612549, Training Accuracy: 0.5661764705882353, Validation Loss: 4.536922454833984, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3192/10000, Training Loss: 2.2318778038024902, Training Accuracy: 0.5808823529411765, Validation Loss: 3.289191961288452, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3193/10000, Training Loss: 3.9251108169555664, Training Accuracy: 0.5686274509803921, Validation Loss: 8.689900398254395, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3194/10000, Training Loss: 3.639134645462036, Training Accuracy: 0.5392156862745098, Validation Loss: 4.200536251068115, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3195/10000, Training Loss: 2.8307578563690186, Training Accuracy: 0.6397058823529411, Validation Loss: 8.483772277832031, Validation Accuracy: 0.25\n",
      "Epoch 3196/10000, Training Loss: 3.4122066497802734, Training Accuracy: 0.5441176470588235, Validation Loss: 1.5855520963668823, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3197/10000, Training Loss: 2.7938969135284424, Training Accuracy: 0.5735294117647058, Validation Loss: 3.6205532550811768, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3198/10000, Training Loss: 2.149998903274536, Training Accuracy: 0.5661764705882353, Validation Loss: 1.6206369400024414, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3199/10000, Training Loss: 2.1249053478240967, Training Accuracy: 0.5931372549019608, Validation Loss: 2.585137128829956, Validation Accuracy: 0.5\n",
      "Epoch 3200/10000, Training Loss: 2.9073755741119385, Training Accuracy: 0.571078431372549, Validation Loss: 4.857635021209717, Validation Accuracy: 0.5\n",
      "Epoch 3201/10000, Training Loss: 3.233241558074951, Training Accuracy: 0.6004901960784313, Validation Loss: 3.6227476596832275, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3202/10000, Training Loss: 2.9840734004974365, Training Accuracy: 0.6102941176470589, Validation Loss: 4.022212505340576, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3203/10000, Training Loss: 2.5330259799957275, Training Accuracy: 0.5612745098039216, Validation Loss: 3.0548038482666016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3204/10000, Training Loss: 2.5550949573516846, Training Accuracy: 0.5245098039215687, Validation Loss: 4.108367443084717, Validation Accuracy: 0.5\n",
      "Epoch 3205/10000, Training Loss: 2.8604140281677246, Training Accuracy: 0.5, Validation Loss: 7.666391372680664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3206/10000, Training Loss: 2.1384551525115967, Training Accuracy: 0.5612745098039216, Validation Loss: 4.989954948425293, Validation Accuracy: 0.25\n",
      "Epoch 3207/10000, Training Loss: 4.086000442504883, Training Accuracy: 0.6299019607843137, Validation Loss: 3.5847012996673584, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3208/10000, Training Loss: 2.6840851306915283, Training Accuracy: 0.553921568627451, Validation Loss: 0.32698339223861694, Validation Accuracy: 0.75\n",
      "Epoch 3209/10000, Training Loss: 2.1211354732513428, Training Accuracy: 0.6004901960784313, Validation Loss: 5.245835781097412, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3210/10000, Training Loss: 1.8620675802230835, Training Accuracy: 0.5637254901960784, Validation Loss: 3.902982711791992, Validation Accuracy: 0.25\n",
      "Epoch 3211/10000, Training Loss: 1.8927795886993408, Training Accuracy: 0.571078431372549, Validation Loss: 2.4591588973999023, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3212/10000, Training Loss: 2.532191276550293, Training Accuracy: 0.5735294117647058, Validation Loss: 5.008820533752441, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3213/10000, Training Loss: 4.503390789031982, Training Accuracy: 0.5735294117647058, Validation Loss: 5.03729248046875, Validation Accuracy: 0.5\n",
      "Epoch 3214/10000, Training Loss: 3.318723201751709, Training Accuracy: 0.5784313725490197, Validation Loss: 4.375870227813721, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3215/10000, Training Loss: 2.155427932739258, Training Accuracy: 0.6004901960784313, Validation Loss: 2.413186550140381, Validation Accuracy: 0.5\n",
      "Epoch 3216/10000, Training Loss: 2.656994342803955, Training Accuracy: 0.5637254901960784, Validation Loss: 7.213235855102539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3217/10000, Training Loss: 2.0778427124023438, Training Accuracy: 0.5833333333333334, Validation Loss: 5.172382831573486, Validation Accuracy: 0.5\n",
      "Epoch 3218/10000, Training Loss: 2.7033445835113525, Training Accuracy: 0.5122549019607843, Validation Loss: 6.226812839508057, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3219/10000, Training Loss: 2.973036527633667, Training Accuracy: 0.5637254901960784, Validation Loss: 3.233888864517212, Validation Accuracy: 0.5\n",
      "Epoch 3220/10000, Training Loss: 3.2915070056915283, Training Accuracy: 0.4950980392156863, Validation Loss: 4.950530529022217, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3221/10000, Training Loss: 2.7759289741516113, Training Accuracy: 0.6519607843137255, Validation Loss: 6.098945617675781, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3222/10000, Training Loss: 3.392328977584839, Training Accuracy: 0.5514705882352942, Validation Loss: 3.477093458175659, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3223/10000, Training Loss: 2.2324719429016113, Training Accuracy: 0.5931372549019608, Validation Loss: 9.183457374572754, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3224/10000, Training Loss: 2.527742385864258, Training Accuracy: 0.5784313725490197, Validation Loss: 2.908522844314575, Validation Accuracy: 0.25\n",
      "Epoch 3225/10000, Training Loss: 3.3144848346710205, Training Accuracy: 0.5465686274509803, Validation Loss: 2.928860664367676, Validation Accuracy: 0.5\n",
      "Epoch 3226/10000, Training Loss: 2.3844311237335205, Training Accuracy: 0.5563725490196079, Validation Loss: 2.6006693840026855, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3227/10000, Training Loss: 3.650240659713745, Training Accuracy: 0.5049019607843137, Validation Loss: 2.597633123397827, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3228/10000, Training Loss: 2.9010443687438965, Training Accuracy: 0.5171568627450981, Validation Loss: 2.3544557094573975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3229/10000, Training Loss: 2.5450217723846436, Training Accuracy: 0.5980392156862745, Validation Loss: 2.5061140060424805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3230/10000, Training Loss: 1.858367919921875, Training Accuracy: 0.6372549019607843, Validation Loss: 1.5946019887924194, Validation Accuracy: 0.75\n",
      "Epoch 3231/10000, Training Loss: 4.621524810791016, Training Accuracy: 0.5931372549019608, Validation Loss: 4.09755277633667, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3232/10000, Training Loss: 3.906360626220703, Training Accuracy: 0.5392156862745098, Validation Loss: 3.512423515319824, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3233/10000, Training Loss: 2.2103402614593506, Training Accuracy: 0.6102941176470589, Validation Loss: 5.318645477294922, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3234/10000, Training Loss: 2.5302135944366455, Training Accuracy: 0.5171568627450981, Validation Loss: 0.7247317433357239, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3235/10000, Training Loss: 2.3669214248657227, Training Accuracy: 0.6102941176470589, Validation Loss: 4.05806303024292, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3236/10000, Training Loss: 1.94579017162323, Training Accuracy: 0.5147058823529411, Validation Loss: 3.0256588459014893, Validation Accuracy: 0.5\n",
      "Epoch 3237/10000, Training Loss: 3.084890604019165, Training Accuracy: 0.5661764705882353, Validation Loss: 8.446015357971191, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3238/10000, Training Loss: 2.7802486419677734, Training Accuracy: 0.5416666666666666, Validation Loss: 1.93270742893219, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3239/10000, Training Loss: 3.64136004447937, Training Accuracy: 0.5833333333333334, Validation Loss: 1.9481114149093628, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3240/10000, Training Loss: 3.6280033588409424, Training Accuracy: 0.553921568627451, Validation Loss: 4.527400016784668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3241/10000, Training Loss: 3.8435895442962646, Training Accuracy: 0.5931372549019608, Validation Loss: 4.497466564178467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3242/10000, Training Loss: 2.5280487537384033, Training Accuracy: 0.5808823529411765, Validation Loss: 2.970248222351074, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3243/10000, Training Loss: 3.8960704803466797, Training Accuracy: 0.6666666666666666, Validation Loss: 8.155226707458496, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3244/10000, Training Loss: 3.801119565963745, Training Accuracy: 0.571078431372549, Validation Loss: 4.115077495574951, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3245/10000, Training Loss: 2.815845489501953, Training Accuracy: 0.5294117647058824, Validation Loss: 3.8003222942352295, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3246/10000, Training Loss: 2.6814610958099365, Training Accuracy: 0.5735294117647058, Validation Loss: 4.781057357788086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3247/10000, Training Loss: 4.134258270263672, Training Accuracy: 0.5367647058823529, Validation Loss: 3.8184032440185547, Validation Accuracy: 0.5\n",
      "Epoch 3248/10000, Training Loss: 3.0736377239227295, Training Accuracy: 0.6446078431372549, Validation Loss: 1.388825535774231, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3249/10000, Training Loss: 3.0817885398864746, Training Accuracy: 0.5367647058823529, Validation Loss: 2.810837984085083, Validation Accuracy: 0.5\n",
      "Epoch 3250/10000, Training Loss: 3.366320848464966, Training Accuracy: 0.6200980392156863, Validation Loss: 1.4940524101257324, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3251/10000, Training Loss: 4.995064735412598, Training Accuracy: 0.49754901960784315, Validation Loss: 5.117798805236816, Validation Accuracy: 0.25\n",
      "Epoch 3252/10000, Training Loss: 2.507658004760742, Training Accuracy: 0.6446078431372549, Validation Loss: 3.598688840866089, Validation Accuracy: 0.5\n",
      "Epoch 3253/10000, Training Loss: 2.271388292312622, Training Accuracy: 0.5784313725490197, Validation Loss: 2.3533174991607666, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3254/10000, Training Loss: 4.892588138580322, Training Accuracy: 0.5171568627450981, Validation Loss: 5.416938781738281, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3255/10000, Training Loss: 4.292108535766602, Training Accuracy: 0.5784313725490197, Validation Loss: 10.941658020019531, Validation Accuracy: 0.25\n",
      "Epoch 3256/10000, Training Loss: 2.508831024169922, Training Accuracy: 0.6151960784313726, Validation Loss: 5.082822799682617, Validation Accuracy: 0.5\n",
      "Epoch 3257/10000, Training Loss: 3.421461582183838, Training Accuracy: 0.4877450980392157, Validation Loss: 0.8820056915283203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3258/10000, Training Loss: 3.10780930519104, Training Accuracy: 0.5955882352941176, Validation Loss: 5.506202220916748, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3259/10000, Training Loss: 2.92225980758667, Training Accuracy: 0.5098039215686274, Validation Loss: 4.6179986000061035, Validation Accuracy: 0.5\n",
      "Epoch 3260/10000, Training Loss: 3.2426958084106445, Training Accuracy: 0.5269607843137255, Validation Loss: 2.2820351123809814, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3261/10000, Training Loss: 3.1039841175079346, Training Accuracy: 0.5294117647058824, Validation Loss: 5.62066125869751, Validation Accuracy: 0.25\n",
      "Epoch 3262/10000, Training Loss: 3.1306793689727783, Training Accuracy: 0.5661764705882353, Validation Loss: 2.5752687454223633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3263/10000, Training Loss: 2.525702714920044, Training Accuracy: 0.5661764705882353, Validation Loss: 4.268550395965576, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3264/10000, Training Loss: 1.9985352754592896, Training Accuracy: 0.5563725490196079, Validation Loss: 4.6969828605651855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3265/10000, Training Loss: 3.3566346168518066, Training Accuracy: 0.5196078431372549, Validation Loss: 1.4053853750228882, Validation Accuracy: 0.5\n",
      "Epoch 3266/10000, Training Loss: 3.1291444301605225, Training Accuracy: 0.6225490196078431, Validation Loss: 4.50325345993042, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3267/10000, Training Loss: 2.833211898803711, Training Accuracy: 0.5759803921568627, Validation Loss: 3.29546856880188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3268/10000, Training Loss: 3.0195157527923584, Training Accuracy: 0.5588235294117647, Validation Loss: 9.542346000671387, Validation Accuracy: 0.25\n",
      "Epoch 3269/10000, Training Loss: 4.474597454071045, Training Accuracy: 0.5367647058823529, Validation Loss: 4.442358493804932, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3270/10000, Training Loss: 4.316044330596924, Training Accuracy: 0.5906862745098039, Validation Loss: 9.920784950256348, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3271/10000, Training Loss: 3.1385180950164795, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9447161555290222, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3272/10000, Training Loss: 2.0313076972961426, Training Accuracy: 0.6593137254901961, Validation Loss: 2.7117507457733154, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3273/10000, Training Loss: 2.003702402114868, Training Accuracy: 0.6151960784313726, Validation Loss: 6.630266189575195, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3274/10000, Training Loss: 2.786541223526001, Training Accuracy: 0.5588235294117647, Validation Loss: 2.915858030319214, Validation Accuracy: 0.5\n",
      "Epoch 3275/10000, Training Loss: 2.9707350730895996, Training Accuracy: 0.5931372549019608, Validation Loss: 4.704273223876953, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3276/10000, Training Loss: 1.6401350498199463, Training Accuracy: 0.6299019607843137, Validation Loss: 4.088183879852295, Validation Accuracy: 0.25\n",
      "Epoch 3277/10000, Training Loss: 2.652235984802246, Training Accuracy: 0.5661764705882353, Validation Loss: 1.738709568977356, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3278/10000, Training Loss: 2.521284818649292, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7109649181365967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3279/10000, Training Loss: 2.18404483795166, Training Accuracy: 0.5367647058823529, Validation Loss: 2.482545852661133, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3280/10000, Training Loss: 2.3910086154937744, Training Accuracy: 0.6151960784313726, Validation Loss: 4.0962815284729, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3281/10000, Training Loss: 3.4253411293029785, Training Accuracy: 0.571078431372549, Validation Loss: 6.155478000640869, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3282/10000, Training Loss: 1.6620655059814453, Training Accuracy: 0.625, Validation Loss: 3.4504497051239014, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3283/10000, Training Loss: 2.393594741821289, Training Accuracy: 0.5661764705882353, Validation Loss: 3.054611921310425, Validation Accuracy: 0.5\n",
      "Epoch 3284/10000, Training Loss: 3.7979581356048584, Training Accuracy: 0.5784313725490197, Validation Loss: 13.486836433410645, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3285/10000, Training Loss: 3.192251682281494, Training Accuracy: 0.5367647058823529, Validation Loss: 2.911303758621216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3286/10000, Training Loss: 1.9525963068008423, Training Accuracy: 0.5514705882352942, Validation Loss: 2.40946364402771, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3287/10000, Training Loss: 1.9684324264526367, Training Accuracy: 0.5294117647058824, Validation Loss: 2.182445764541626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3288/10000, Training Loss: 3.2941839694976807, Training Accuracy: 0.5318627450980392, Validation Loss: 5.498902797698975, Validation Accuracy: 0.5\n",
      "Epoch 3289/10000, Training Loss: 3.4456727504730225, Training Accuracy: 0.5906862745098039, Validation Loss: 5.687639236450195, Validation Accuracy: 0.5\n",
      "Epoch 3290/10000, Training Loss: 2.4270825386047363, Training Accuracy: 0.6372549019607843, Validation Loss: 4.287255764007568, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3291/10000, Training Loss: 3.0486886501312256, Training Accuracy: 0.5661764705882353, Validation Loss: 2.282200574874878, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3292/10000, Training Loss: 2.298809051513672, Training Accuracy: 0.5980392156862745, Validation Loss: 3.094486951828003, Validation Accuracy: 0.25\n",
      "Epoch 3293/10000, Training Loss: 2.3264729976654053, Training Accuracy: 0.5980392156862745, Validation Loss: 1.8993297815322876, Validation Accuracy: 0.75\n",
      "Epoch 3294/10000, Training Loss: 2.5360844135284424, Training Accuracy: 0.5416666666666666, Validation Loss: 6.256866455078125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3295/10000, Training Loss: 3.8043107986450195, Training Accuracy: 0.5392156862745098, Validation Loss: 7.448467254638672, Validation Accuracy: 0.25\n",
      "Epoch 3296/10000, Training Loss: 2.9651596546173096, Training Accuracy: 0.6225490196078431, Validation Loss: 4.442784786224365, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3297/10000, Training Loss: 3.1758432388305664, Training Accuracy: 0.571078431372549, Validation Loss: 4.263143539428711, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3298/10000, Training Loss: 2.6856985092163086, Training Accuracy: 0.6470588235294118, Validation Loss: 4.173732280731201, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3299/10000, Training Loss: 2.7335541248321533, Training Accuracy: 0.5465686274509803, Validation Loss: 4.307437419891357, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3300/10000, Training Loss: 2.9511945247650146, Training Accuracy: 0.6421568627450981, Validation Loss: 4.7847771644592285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3301/10000, Training Loss: 2.6393017768859863, Training Accuracy: 0.5318627450980392, Validation Loss: 2.816560983657837, Validation Accuracy: 0.5\n",
      "Epoch 3302/10000, Training Loss: 2.6217758655548096, Training Accuracy: 0.5073529411764706, Validation Loss: 1.7631525993347168, Validation Accuracy: 0.75\n",
      "Epoch 3303/10000, Training Loss: 3.684370517730713, Training Accuracy: 0.5122549019607843, Validation Loss: 6.272031307220459, Validation Accuracy: 0.25\n",
      "Epoch 3304/10000, Training Loss: 3.4352498054504395, Training Accuracy: 0.6102941176470589, Validation Loss: 3.0523853302001953, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3305/10000, Training Loss: 2.509580373764038, Training Accuracy: 0.5171568627450981, Validation Loss: 1.9727798700332642, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3306/10000, Training Loss: 2.7745201587677, Training Accuracy: 0.5465686274509803, Validation Loss: 3.847696542739868, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3307/10000, Training Loss: 4.418158531188965, Training Accuracy: 0.47549019607843135, Validation Loss: 5.507410049438477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3308/10000, Training Loss: 2.694985866546631, Training Accuracy: 0.6127450980392157, Validation Loss: 3.2291572093963623, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3309/10000, Training Loss: 2.20464825630188, Training Accuracy: 0.5245098039215687, Validation Loss: 4.601635456085205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3310/10000, Training Loss: 2.0307631492614746, Training Accuracy: 0.5735294117647058, Validation Loss: 1.4442816972732544, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3311/10000, Training Loss: 3.3042685985565186, Training Accuracy: 0.5245098039215687, Validation Loss: 5.823390960693359, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3312/10000, Training Loss: 2.4541268348693848, Training Accuracy: 0.5808823529411765, Validation Loss: 3.5584793090820312, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3313/10000, Training Loss: 2.8150641918182373, Training Accuracy: 0.4950980392156863, Validation Loss: 3.077894449234009, Validation Accuracy: 0.5\n",
      "Epoch 3314/10000, Training Loss: 3.8156630992889404, Training Accuracy: 0.5073529411764706, Validation Loss: 4.2854228019714355, Validation Accuracy: 0.5\n",
      "Epoch 3315/10000, Training Loss: 3.458449125289917, Training Accuracy: 0.5980392156862745, Validation Loss: 10.06501293182373, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3316/10000, Training Loss: 2.2123377323150635, Training Accuracy: 0.5637254901960784, Validation Loss: 3.477339506149292, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3317/10000, Training Loss: 3.053034782409668, Training Accuracy: 0.5367647058823529, Validation Loss: 3.28167462348938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3318/10000, Training Loss: 2.8799166679382324, Training Accuracy: 0.5416666666666666, Validation Loss: 5.47010612487793, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3319/10000, Training Loss: 2.0613601207733154, Training Accuracy: 0.5857843137254902, Validation Loss: 2.554736375808716, Validation Accuracy: 0.5\n",
      "Epoch 3320/10000, Training Loss: 4.066971302032471, Training Accuracy: 0.5808823529411765, Validation Loss: 4.007695198059082, Validation Accuracy: 0.5\n",
      "Epoch 3321/10000, Training Loss: 4.2270426750183105, Training Accuracy: 0.5637254901960784, Validation Loss: 2.9403164386749268, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3322/10000, Training Loss: 2.917997121810913, Training Accuracy: 0.5490196078431373, Validation Loss: 6.884022235870361, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3323/10000, Training Loss: 3.859403371810913, Training Accuracy: 0.5514705882352942, Validation Loss: 5.574446201324463, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3324/10000, Training Loss: 3.2153992652893066, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0681043863296509, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3325/10000, Training Loss: 3.492377281188965, Training Accuracy: 0.6053921568627451, Validation Loss: 3.2304258346557617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3326/10000, Training Loss: 1.856487512588501, Training Accuracy: 0.5416666666666666, Validation Loss: 5.862936019897461, Validation Accuracy: 0.5\n",
      "Epoch 3327/10000, Training Loss: 2.573032855987549, Training Accuracy: 0.5441176470588235, Validation Loss: 5.04146671295166, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3328/10000, Training Loss: 2.581860303878784, Training Accuracy: 0.5441176470588235, Validation Loss: 1.9561505317687988, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3329/10000, Training Loss: 3.225437641143799, Training Accuracy: 0.5882352941176471, Validation Loss: 7.412489414215088, Validation Accuracy: 0.5\n",
      "Epoch 3330/10000, Training Loss: 2.7208523750305176, Training Accuracy: 0.5882352941176471, Validation Loss: 9.64157485961914, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3331/10000, Training Loss: 3.0005180835723877, Training Accuracy: 0.553921568627451, Validation Loss: 2.060765504837036, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3332/10000, Training Loss: 3.550922393798828, Training Accuracy: 0.5612745098039216, Validation Loss: 5.17518949508667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3333/10000, Training Loss: 2.9695489406585693, Training Accuracy: 0.6127450980392157, Validation Loss: 4.586923599243164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3334/10000, Training Loss: 2.866710662841797, Training Accuracy: 0.553921568627451, Validation Loss: 2.3807356357574463, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3335/10000, Training Loss: 2.7540531158447266, Training Accuracy: 0.5318627450980392, Validation Loss: 2.754481077194214, Validation Accuracy: 0.5\n",
      "Epoch 3336/10000, Training Loss: 3.513406753540039, Training Accuracy: 0.4877450980392157, Validation Loss: 1.8264812231063843, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3337/10000, Training Loss: 2.905583143234253, Training Accuracy: 0.6151960784313726, Validation Loss: 2.4264144897460938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3338/10000, Training Loss: 3.5008325576782227, Training Accuracy: 0.5808823529411765, Validation Loss: 4.405097961425781, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3339/10000, Training Loss: 2.7067675590515137, Training Accuracy: 0.5735294117647058, Validation Loss: 2.626835823059082, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3340/10000, Training Loss: 3.7238895893096924, Training Accuracy: 0.5416666666666666, Validation Loss: 4.8922343254089355, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3341/10000, Training Loss: 2.7542850971221924, Training Accuracy: 0.5857843137254902, Validation Loss: 3.2278735637664795, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3342/10000, Training Loss: 3.3649210929870605, Training Accuracy: 0.5024509803921569, Validation Loss: 1.8313621282577515, Validation Accuracy: 0.5\n",
      "Epoch 3343/10000, Training Loss: 3.542081356048584, Training Accuracy: 0.5343137254901961, Validation Loss: 2.314532518386841, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3344/10000, Training Loss: 2.1182024478912354, Training Accuracy: 0.5686274509803921, Validation Loss: 2.391624689102173, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3345/10000, Training Loss: 2.4153053760528564, Training Accuracy: 0.6102941176470589, Validation Loss: 6.116330623626709, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3346/10000, Training Loss: 3.208197832107544, Training Accuracy: 0.553921568627451, Validation Loss: 5.389671802520752, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3347/10000, Training Loss: 2.7359559535980225, Training Accuracy: 0.5612745098039216, Validation Loss: 5.6147027015686035, Validation Accuracy: 0.25\n",
      "Epoch 3348/10000, Training Loss: 1.712435245513916, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1001170873641968, Validation Accuracy: 0.5\n",
      "Epoch 3349/10000, Training Loss: 2.4292993545532227, Training Accuracy: 0.5514705882352942, Validation Loss: 3.9859819412231445, Validation Accuracy: 0.5\n",
      "Epoch 3350/10000, Training Loss: 3.1042091846466064, Training Accuracy: 0.5171568627450981, Validation Loss: 3.664015769958496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3351/10000, Training Loss: 2.4592697620391846, Training Accuracy: 0.571078431372549, Validation Loss: 9.52393913269043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3352/10000, Training Loss: 2.2569141387939453, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0557634830474854, Validation Accuracy: 0.75\n",
      "Epoch 3353/10000, Training Loss: 2.3396778106689453, Training Accuracy: 0.6127450980392157, Validation Loss: 3.4134576320648193, Validation Accuracy: 0.5\n",
      "Epoch 3354/10000, Training Loss: 2.2357497215270996, Training Accuracy: 0.5416666666666666, Validation Loss: 5.743162631988525, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3355/10000, Training Loss: 2.267432451248169, Training Accuracy: 0.5514705882352942, Validation Loss: 1.887314796447754, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3356/10000, Training Loss: 3.119189739227295, Training Accuracy: 0.5294117647058824, Validation Loss: 3.0303094387054443, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3357/10000, Training Loss: 3.5445501804351807, Training Accuracy: 0.5784313725490197, Validation Loss: 2.611079216003418, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3358/10000, Training Loss: 2.867135524749756, Training Accuracy: 0.4730392156862745, Validation Loss: 1.19243586063385, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3359/10000, Training Loss: 1.8930063247680664, Training Accuracy: 0.5759803921568627, Validation Loss: 2.5634400844573975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3360/10000, Training Loss: 2.8362061977386475, Training Accuracy: 0.5588235294117647, Validation Loss: 5.5870232582092285, Validation Accuracy: 0.25\n",
      "Epoch 3361/10000, Training Loss: 1.7636330127716064, Training Accuracy: 0.625, Validation Loss: 4.300751209259033, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3362/10000, Training Loss: 2.2016968727111816, Training Accuracy: 0.5759803921568627, Validation Loss: 3.7285869121551514, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3363/10000, Training Loss: 2.0886833667755127, Training Accuracy: 0.571078431372549, Validation Loss: 3.209378480911255, Validation Accuracy: 0.5\n",
      "Epoch 3364/10000, Training Loss: 1.872251033782959, Training Accuracy: 0.5490196078431373, Validation Loss: 2.179562568664551, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3365/10000, Training Loss: 2.829794406890869, Training Accuracy: 0.5955882352941176, Validation Loss: 2.695770025253296, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3366/10000, Training Loss: 2.7255592346191406, Training Accuracy: 0.6078431372549019, Validation Loss: 1.395199179649353, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3367/10000, Training Loss: 2.493208169937134, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1412997245788574, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3368/10000, Training Loss: 3.1678781509399414, Training Accuracy: 0.5686274509803921, Validation Loss: 5.9158806800842285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3369/10000, Training Loss: 2.1698129177093506, Training Accuracy: 0.6544117647058824, Validation Loss: 3.805795907974243, Validation Accuracy: 0.5\n",
      "Epoch 3370/10000, Training Loss: 3.286470890045166, Training Accuracy: 0.4803921568627451, Validation Loss: 0.6026794910430908, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3371/10000, Training Loss: 3.3245627880096436, Training Accuracy: 0.5514705882352942, Validation Loss: 5.244636535644531, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3372/10000, Training Loss: 2.541938066482544, Training Accuracy: 0.571078431372549, Validation Loss: 2.4233028888702393, Validation Accuracy: 0.5\n",
      "Epoch 3373/10000, Training Loss: 2.9142143726348877, Training Accuracy: 0.5147058823529411, Validation Loss: 4.147592067718506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3374/10000, Training Loss: 1.921318769454956, Training Accuracy: 0.6544117647058824, Validation Loss: 1.8782633543014526, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3375/10000, Training Loss: 3.648893356323242, Training Accuracy: 0.4681372549019608, Validation Loss: 8.138306617736816, Validation Accuracy: 0.25\n",
      "Epoch 3376/10000, Training Loss: 3.1460347175598145, Training Accuracy: 0.6151960784313726, Validation Loss: 7.725462436676025, Validation Accuracy: 0.5\n",
      "Epoch 3377/10000, Training Loss: 1.8238873481750488, Training Accuracy: 0.553921568627451, Validation Loss: 1.7271097898483276, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3378/10000, Training Loss: 2.3154871463775635, Training Accuracy: 0.6151960784313726, Validation Loss: 5.235482692718506, Validation Accuracy: 0.5\n",
      "Epoch 3379/10000, Training Loss: 3.425800085067749, Training Accuracy: 0.5490196078431373, Validation Loss: 2.739773988723755, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3380/10000, Training Loss: 3.0524213314056396, Training Accuracy: 0.5906862745098039, Validation Loss: 5.34343957901001, Validation Accuracy: 0.5\n",
      "Epoch 3381/10000, Training Loss: 3.230445623397827, Training Accuracy: 0.5490196078431373, Validation Loss: 11.200922966003418, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3382/10000, Training Loss: 2.35261607170105, Training Accuracy: 0.6053921568627451, Validation Loss: 1.4377226829528809, Validation Accuracy: 0.25\n",
      "Epoch 3383/10000, Training Loss: 2.915703058242798, Training Accuracy: 0.5563725490196079, Validation Loss: 7.855414867401123, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3384/10000, Training Loss: 3.1820099353790283, Training Accuracy: 0.6151960784313726, Validation Loss: 4.231552600860596, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3385/10000, Training Loss: 2.752321481704712, Training Accuracy: 0.5857843137254902, Validation Loss: 2.139955759048462, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3386/10000, Training Loss: 4.203915596008301, Training Accuracy: 0.571078431372549, Validation Loss: 4.162759304046631, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3387/10000, Training Loss: 2.751730442047119, Training Accuracy: 0.5416666666666666, Validation Loss: 2.745246648788452, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3388/10000, Training Loss: 2.2497665882110596, Training Accuracy: 0.5563725490196079, Validation Loss: 2.32336163520813, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3389/10000, Training Loss: 2.0996389389038086, Training Accuracy: 0.5882352941176471, Validation Loss: 4.023273944854736, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3390/10000, Training Loss: 2.843132257461548, Training Accuracy: 0.5367647058823529, Validation Loss: 3.046919822692871, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3391/10000, Training Loss: 2.912442445755005, Training Accuracy: 0.5171568627450981, Validation Loss: 3.2074451446533203, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3392/10000, Training Loss: 2.2740588188171387, Training Accuracy: 0.6053921568627451, Validation Loss: 1.2162823677062988, Validation Accuracy: 0.75\n",
      "Epoch 3393/10000, Training Loss: 2.9712226390838623, Training Accuracy: 0.5196078431372549, Validation Loss: 3.3220040798187256, Validation Accuracy: 0.5\n",
      "Epoch 3394/10000, Training Loss: 2.445115089416504, Training Accuracy: 0.6053921568627451, Validation Loss: 3.222026824951172, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3395/10000, Training Loss: 2.153550386428833, Training Accuracy: 0.5588235294117647, Validation Loss: 1.6895322799682617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3396/10000, Training Loss: 2.763279676437378, Training Accuracy: 0.6274509803921569, Validation Loss: 2.6621439456939697, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3397/10000, Training Loss: 2.48974347114563, Training Accuracy: 0.6617647058823529, Validation Loss: 7.108801364898682, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3398/10000, Training Loss: 1.8431144952774048, Training Accuracy: 0.5808823529411765, Validation Loss: 2.8940255641937256, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3399/10000, Training Loss: 2.211104393005371, Training Accuracy: 0.5514705882352942, Validation Loss: 2.517671585083008, Validation Accuracy: 0.25\n",
      "Epoch 3400/10000, Training Loss: 2.3352291584014893, Training Accuracy: 0.5392156862745098, Validation Loss: 3.6829988956451416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3401/10000, Training Loss: 1.9122670888900757, Training Accuracy: 0.6225490196078431, Validation Loss: 2.013934850692749, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3402/10000, Training Loss: 3.66331148147583, Training Accuracy: 0.5637254901960784, Validation Loss: 3.022174119949341, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3403/10000, Training Loss: 1.6110824346542358, Training Accuracy: 0.5882352941176471, Validation Loss: 3.1647846698760986, Validation Accuracy: 0.5\n",
      "Epoch 3404/10000, Training Loss: 2.8567140102386475, Training Accuracy: 0.5049019607843137, Validation Loss: 4.149255275726318, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3405/10000, Training Loss: 2.643489360809326, Training Accuracy: 0.5416666666666666, Validation Loss: 2.514305353164673, Validation Accuracy: 0.5\n",
      "Epoch 3406/10000, Training Loss: 3.7937021255493164, Training Accuracy: 0.5808823529411765, Validation Loss: 3.3477094173431396, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3407/10000, Training Loss: 2.508805513381958, Training Accuracy: 0.49264705882352944, Validation Loss: 1.021944284439087, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3408/10000, Training Loss: 1.9204877614974976, Training Accuracy: 0.6200980392156863, Validation Loss: 8.338030815124512, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3409/10000, Training Loss: 2.441208600997925, Training Accuracy: 0.6127450980392157, Validation Loss: 3.5227346420288086, Validation Accuracy: 0.5\n",
      "Epoch 3410/10000, Training Loss: 2.082862615585327, Training Accuracy: 0.5588235294117647, Validation Loss: 6.798386096954346, Validation Accuracy: 0.25\n",
      "Epoch 3411/10000, Training Loss: 2.3551275730133057, Training Accuracy: 0.6200980392156863, Validation Loss: 1.3193398714065552, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3412/10000, Training Loss: 1.9870017766952515, Training Accuracy: 0.6421568627450981, Validation Loss: 2.7729227542877197, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3413/10000, Training Loss: 2.6281089782714844, Training Accuracy: 0.6029411764705882, Validation Loss: 2.8229141235351562, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3414/10000, Training Loss: 1.576932430267334, Training Accuracy: 0.5759803921568627, Validation Loss: 2.115980625152588, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3415/10000, Training Loss: 2.495112895965576, Training Accuracy: 0.5759803921568627, Validation Loss: 2.100101947784424, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3416/10000, Training Loss: 3.919320821762085, Training Accuracy: 0.5833333333333334, Validation Loss: 6.130260944366455, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3417/10000, Training Loss: 2.0354180335998535, Training Accuracy: 0.5857843137254902, Validation Loss: 2.939493179321289, Validation Accuracy: 0.5\n",
      "Epoch 3418/10000, Training Loss: 2.5766425132751465, Training Accuracy: 0.5465686274509803, Validation Loss: 1.4978652000427246, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3419/10000, Training Loss: 2.1652135848999023, Training Accuracy: 0.5980392156862745, Validation Loss: 10.51384162902832, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3420/10000, Training Loss: 2.6069939136505127, Training Accuracy: 0.5759803921568627, Validation Loss: 2.755061388015747, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3421/10000, Training Loss: 3.1321215629577637, Training Accuracy: 0.5588235294117647, Validation Loss: 2.2367100715637207, Validation Accuracy: 0.5\n",
      "Epoch 3422/10000, Training Loss: 3.599984884262085, Training Accuracy: 0.5612745098039216, Validation Loss: 4.812905788421631, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3423/10000, Training Loss: 2.922471523284912, Training Accuracy: 0.5269607843137255, Validation Loss: 2.214817762374878, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3424/10000, Training Loss: 1.9841561317443848, Training Accuracy: 0.6078431372549019, Validation Loss: 4.716955661773682, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3425/10000, Training Loss: 2.261667013168335, Training Accuracy: 0.5784313725490197, Validation Loss: 2.937877893447876, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3426/10000, Training Loss: 2.875978946685791, Training Accuracy: 0.5612745098039216, Validation Loss: 8.792057037353516, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3427/10000, Training Loss: 1.9886164665222168, Training Accuracy: 0.5441176470588235, Validation Loss: 1.6573573350906372, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3428/10000, Training Loss: 2.389300584793091, Training Accuracy: 0.6323529411764706, Validation Loss: 1.3885802030563354, Validation Accuracy: 0.5\n",
      "Epoch 3429/10000, Training Loss: 2.6587064266204834, Training Accuracy: 0.5465686274509803, Validation Loss: 1.9658292531967163, Validation Accuracy: 0.5\n",
      "Epoch 3430/10000, Training Loss: 2.122898578643799, Training Accuracy: 0.5441176470588235, Validation Loss: 1.853044867515564, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3431/10000, Training Loss: 1.721405029296875, Training Accuracy: 0.6127450980392157, Validation Loss: 3.40041184425354, Validation Accuracy: 0.5\n",
      "Epoch 3432/10000, Training Loss: 2.2507779598236084, Training Accuracy: 0.5980392156862745, Validation Loss: 2.4689877033233643, Validation Accuracy: 0.5\n",
      "Epoch 3433/10000, Training Loss: 1.6986138820648193, Training Accuracy: 0.5784313725490197, Validation Loss: 2.9048378467559814, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3434/10000, Training Loss: 3.1138365268707275, Training Accuracy: 0.5686274509803921, Validation Loss: 4.961205959320068, Validation Accuracy: 0.5\n",
      "Epoch 3435/10000, Training Loss: 3.093625545501709, Training Accuracy: 0.5514705882352942, Validation Loss: 2.5118186473846436, Validation Accuracy: 0.25\n",
      "Epoch 3436/10000, Training Loss: 2.629387378692627, Training Accuracy: 0.6102941176470589, Validation Loss: 4.072805881500244, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3437/10000, Training Loss: 2.5026559829711914, Training Accuracy: 0.5392156862745098, Validation Loss: 2.4843876361846924, Validation Accuracy: 0.5\n",
      "Epoch 3438/10000, Training Loss: 2.5273540019989014, Training Accuracy: 0.5490196078431373, Validation Loss: 5.442628383636475, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3439/10000, Training Loss: 2.232370615005493, Training Accuracy: 0.5955882352941176, Validation Loss: 2.4809484481811523, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3440/10000, Training Loss: 3.048654079437256, Training Accuracy: 0.6176470588235294, Validation Loss: 4.986598491668701, Validation Accuracy: 0.5\n",
      "Epoch 3441/10000, Training Loss: 2.2048730850219727, Training Accuracy: 0.5784313725490197, Validation Loss: 2.111401081085205, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3442/10000, Training Loss: 2.1390552520751953, Training Accuracy: 0.5882352941176471, Validation Loss: 4.382559299468994, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3443/10000, Training Loss: 3.0839810371398926, Training Accuracy: 0.6397058823529411, Validation Loss: 4.657791614532471, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3444/10000, Training Loss: 2.36504864692688, Training Accuracy: 0.5588235294117647, Validation Loss: 2.3730931282043457, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3445/10000, Training Loss: 3.50057315826416, Training Accuracy: 0.5514705882352942, Validation Loss: 3.067317008972168, Validation Accuracy: 0.75\n",
      "Epoch 3446/10000, Training Loss: 2.2489655017852783, Training Accuracy: 0.5686274509803921, Validation Loss: 3.6495697498321533, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3447/10000, Training Loss: 2.3097617626190186, Training Accuracy: 0.6078431372549019, Validation Loss: 5.303799629211426, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3448/10000, Training Loss: 2.68640398979187, Training Accuracy: 0.5220588235294118, Validation Loss: 3.557507276535034, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3449/10000, Training Loss: 2.701601266860962, Training Accuracy: 0.5392156862745098, Validation Loss: 1.6645092964172363, Validation Accuracy: 0.5\n",
      "Epoch 3450/10000, Training Loss: 3.7601451873779297, Training Accuracy: 0.5612745098039216, Validation Loss: 3.13981556892395, Validation Accuracy: 0.5\n",
      "Epoch 3451/10000, Training Loss: 2.2205402851104736, Training Accuracy: 0.6348039215686274, Validation Loss: 1.9002467393875122, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3452/10000, Training Loss: 2.3946354389190674, Training Accuracy: 0.5490196078431373, Validation Loss: 4.720367908477783, Validation Accuracy: 0.5\n",
      "Epoch 3453/10000, Training Loss: 2.7151520252227783, Training Accuracy: 0.6029411764705882, Validation Loss: 2.643096923828125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3454/10000, Training Loss: 3.1499412059783936, Training Accuracy: 0.49264705882352944, Validation Loss: 0.36925598978996277, Validation Accuracy: 0.75\n",
      "Epoch 3455/10000, Training Loss: 2.638613224029541, Training Accuracy: 0.5563725490196079, Validation Loss: 3.7532918453216553, Validation Accuracy: 0.25\n",
      "Epoch 3456/10000, Training Loss: 2.6787118911743164, Training Accuracy: 0.5686274509803921, Validation Loss: 4.599380016326904, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3457/10000, Training Loss: 3.185058355331421, Training Accuracy: 0.5882352941176471, Validation Loss: 3.861250162124634, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3458/10000, Training Loss: 2.836669921875, Training Accuracy: 0.5196078431372549, Validation Loss: 5.330839157104492, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3459/10000, Training Loss: 1.6995768547058105, Training Accuracy: 0.5980392156862745, Validation Loss: 4.850555419921875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3460/10000, Training Loss: 1.7565529346466064, Training Accuracy: 0.6127450980392157, Validation Loss: 2.2546603679656982, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3461/10000, Training Loss: 2.94301700592041, Training Accuracy: 0.49754901960784315, Validation Loss: 0.6619719862937927, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3462/10000, Training Loss: 2.9432294368743896, Training Accuracy: 0.5220588235294118, Validation Loss: 12.14067554473877, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3463/10000, Training Loss: 2.405017614364624, Training Accuracy: 0.5588235294117647, Validation Loss: 2.904550552368164, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3464/10000, Training Loss: 2.985029935836792, Training Accuracy: 0.5294117647058824, Validation Loss: 3.268033027648926, Validation Accuracy: 0.25\n",
      "Epoch 3465/10000, Training Loss: 2.912001609802246, Training Accuracy: 0.5906862745098039, Validation Loss: 7.3259663581848145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3466/10000, Training Loss: 1.5904464721679688, Training Accuracy: 0.5171568627450981, Validation Loss: 2.454824686050415, Validation Accuracy: 0.5\n",
      "Epoch 3467/10000, Training Loss: 1.7013119459152222, Training Accuracy: 0.5514705882352942, Validation Loss: 1.277537226676941, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3468/10000, Training Loss: 2.5611655712127686, Training Accuracy: 0.5392156862745098, Validation Loss: 3.5025882720947266, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3469/10000, Training Loss: 3.320903778076172, Training Accuracy: 0.5661764705882353, Validation Loss: 4.2830681800842285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3470/10000, Training Loss: 1.9127389192581177, Training Accuracy: 0.49754901960784315, Validation Loss: 2.142197370529175, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3471/10000, Training Loss: 2.156733512878418, Training Accuracy: 0.5955882352941176, Validation Loss: 2.387108564376831, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3472/10000, Training Loss: 2.963805913925171, Training Accuracy: 0.5514705882352942, Validation Loss: 0.9051227569580078, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3473/10000, Training Loss: 2.2123143672943115, Training Accuracy: 0.5906862745098039, Validation Loss: 2.196187973022461, Validation Accuracy: 0.75\n",
      "Epoch 3474/10000, Training Loss: 2.112344264984131, Training Accuracy: 0.6176470588235294, Validation Loss: 3.757378339767456, Validation Accuracy: 0.5\n",
      "Epoch 3475/10000, Training Loss: 1.85895836353302, Training Accuracy: 0.5857843137254902, Validation Loss: 3.269557237625122, Validation Accuracy: 0.5\n",
      "Epoch 3476/10000, Training Loss: 1.950130581855774, Training Accuracy: 0.553921568627451, Validation Loss: 1.7269926071166992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3477/10000, Training Loss: 1.6999564170837402, Training Accuracy: 0.5294117647058824, Validation Loss: 5.7441229820251465, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3478/10000, Training Loss: 2.8784310817718506, Training Accuracy: 0.5220588235294118, Validation Loss: 5.004111289978027, Validation Accuracy: 0.5\n",
      "Epoch 3479/10000, Training Loss: 2.235490560531616, Training Accuracy: 0.6053921568627451, Validation Loss: 2.0902230739593506, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3480/10000, Training Loss: 2.5029001235961914, Training Accuracy: 0.5784313725490197, Validation Loss: 4.768551349639893, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3481/10000, Training Loss: 2.1986396312713623, Training Accuracy: 0.6421568627450981, Validation Loss: 4.485734462738037, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3482/10000, Training Loss: 2.365922212600708, Training Accuracy: 0.5269607843137255, Validation Loss: 10.911422729492188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3483/10000, Training Loss: 3.621690034866333, Training Accuracy: 0.47058823529411764, Validation Loss: 3.222036123275757, Validation Accuracy: 0.5\n",
      "Epoch 3484/10000, Training Loss: 2.5544700622558594, Training Accuracy: 0.5637254901960784, Validation Loss: 6.220632553100586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3485/10000, Training Loss: 2.187013626098633, Training Accuracy: 0.5122549019607843, Validation Loss: 4.438209533691406, Validation Accuracy: 0.25\n",
      "Epoch 3486/10000, Training Loss: 3.327479839324951, Training Accuracy: 0.5441176470588235, Validation Loss: 2.90639591217041, Validation Accuracy: 0.5\n",
      "Epoch 3487/10000, Training Loss: 2.3646175861358643, Training Accuracy: 0.5882352941176471, Validation Loss: 3.0405654907226562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3488/10000, Training Loss: 3.0793817043304443, Training Accuracy: 0.5612745098039216, Validation Loss: 1.5380908250808716, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3489/10000, Training Loss: 2.448519229888916, Training Accuracy: 0.6348039215686274, Validation Loss: 10.334421157836914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3490/10000, Training Loss: 3.4841787815093994, Training Accuracy: 0.5514705882352942, Validation Loss: 4.1702189445495605, Validation Accuracy: 0.5\n",
      "Epoch 3491/10000, Training Loss: 2.4321210384368896, Training Accuracy: 0.5416666666666666, Validation Loss: 2.111829996109009, Validation Accuracy: 0.5\n",
      "Epoch 3492/10000, Training Loss: 2.6499109268188477, Training Accuracy: 0.5367647058823529, Validation Loss: 2.4535586833953857, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3493/10000, Training Loss: 2.133909225463867, Training Accuracy: 0.5490196078431373, Validation Loss: 2.4489235877990723, Validation Accuracy: 0.5\n",
      "Epoch 3494/10000, Training Loss: 3.000234603881836, Training Accuracy: 0.5857843137254902, Validation Loss: 7.126744747161865, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3495/10000, Training Loss: 2.0409319400787354, Training Accuracy: 0.5612745098039216, Validation Loss: 2.6363375186920166, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3496/10000, Training Loss: 2.266897678375244, Training Accuracy: 0.5931372549019608, Validation Loss: 3.8358047008514404, Validation Accuracy: 0.5\n",
      "Epoch 3497/10000, Training Loss: 2.384864091873169, Training Accuracy: 0.5931372549019608, Validation Loss: 1.9089632034301758, Validation Accuracy: 0.5\n",
      "Epoch 3498/10000, Training Loss: 2.532074213027954, Training Accuracy: 0.5343137254901961, Validation Loss: 4.07876443862915, Validation Accuracy: 0.5\n",
      "Epoch 3499/10000, Training Loss: 3.210326910018921, Training Accuracy: 0.5392156862745098, Validation Loss: 3.5867347717285156, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3500/10000, Training Loss: 3.6523022651672363, Training Accuracy: 0.5294117647058824, Validation Loss: 2.646761417388916, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3501/10000, Training Loss: 2.679861545562744, Training Accuracy: 0.5220588235294118, Validation Loss: 1.946874737739563, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3502/10000, Training Loss: 3.077812671661377, Training Accuracy: 0.5294117647058824, Validation Loss: 6.75684118270874, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3503/10000, Training Loss: 2.357696294784546, Training Accuracy: 0.6004901960784313, Validation Loss: 2.475428342819214, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3504/10000, Training Loss: 3.054201126098633, Training Accuracy: 0.5759803921568627, Validation Loss: 5.390674591064453, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3505/10000, Training Loss: 2.6317312717437744, Training Accuracy: 0.5882352941176471, Validation Loss: 3.4116287231445312, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3506/10000, Training Loss: 1.848195195198059, Training Accuracy: 0.5490196078431373, Validation Loss: 1.2054007053375244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3507/10000, Training Loss: 1.588381052017212, Training Accuracy: 0.5637254901960784, Validation Loss: 1.4105325937271118, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3508/10000, Training Loss: 2.324180841445923, Training Accuracy: 0.5367647058823529, Validation Loss: 2.3083503246307373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3509/10000, Training Loss: 2.729830026626587, Training Accuracy: 0.5637254901960784, Validation Loss: 9.294711112976074, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3510/10000, Training Loss: 1.9856469631195068, Training Accuracy: 0.5808823529411765, Validation Loss: 4.786344051361084, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3511/10000, Training Loss: 2.6110143661499023, Training Accuracy: 0.5637254901960784, Validation Loss: 3.940504789352417, Validation Accuracy: 0.25\n",
      "Epoch 3512/10000, Training Loss: 2.0063462257385254, Training Accuracy: 0.6004901960784313, Validation Loss: 2.7152442932128906, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3513/10000, Training Loss: 3.618410348892212, Training Accuracy: 0.5294117647058824, Validation Loss: 2.735475540161133, Validation Accuracy: 0.5\n",
      "Epoch 3514/10000, Training Loss: 2.54911208152771, Training Accuracy: 0.5882352941176471, Validation Loss: 2.365963935852051, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3515/10000, Training Loss: 2.4768877029418945, Training Accuracy: 0.5784313725490197, Validation Loss: 7.286087512969971, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3516/10000, Training Loss: 2.25345516204834, Training Accuracy: 0.5049019607843137, Validation Loss: 1.8030263185501099, Validation Accuracy: 0.5\n",
      "Epoch 3517/10000, Training Loss: 2.2145323753356934, Training Accuracy: 0.5171568627450981, Validation Loss: 4.160123825073242, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3518/10000, Training Loss: 2.5869832038879395, Training Accuracy: 0.5612745098039216, Validation Loss: 2.5181548595428467, Validation Accuracy: 0.5\n",
      "Epoch 3519/10000, Training Loss: 1.8322694301605225, Training Accuracy: 0.5612745098039216, Validation Loss: 2.4885470867156982, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3520/10000, Training Loss: 2.478370428085327, Training Accuracy: 0.5171568627450981, Validation Loss: 1.5136971473693848, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3521/10000, Training Loss: 2.2820558547973633, Training Accuracy: 0.5759803921568627, Validation Loss: 2.566065549850464, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3522/10000, Training Loss: 2.483351230621338, Training Accuracy: 0.5245098039215687, Validation Loss: 1.3634477853775024, Validation Accuracy: 0.5\n",
      "Epoch 3523/10000, Training Loss: 2.5766050815582275, Training Accuracy: 0.5, Validation Loss: 3.4751596450805664, Validation Accuracy: 0.5\n",
      "Epoch 3524/10000, Training Loss: 2.0473387241363525, Training Accuracy: 0.5367647058823529, Validation Loss: 3.267514944076538, Validation Accuracy: 0.5\n",
      "Epoch 3525/10000, Training Loss: 2.227268695831299, Training Accuracy: 0.6397058823529411, Validation Loss: 3.160513162612915, Validation Accuracy: 0.5\n",
      "Epoch 3526/10000, Training Loss: 2.718513250350952, Training Accuracy: 0.5588235294117647, Validation Loss: 3.098306655883789, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3527/10000, Training Loss: 2.098134994506836, Training Accuracy: 0.6274509803921569, Validation Loss: 2.5176491737365723, Validation Accuracy: 0.75\n",
      "Epoch 3528/10000, Training Loss: 3.089393377304077, Training Accuracy: 0.5147058823529411, Validation Loss: 3.7901792526245117, Validation Accuracy: 0.25\n",
      "Epoch 3529/10000, Training Loss: 1.8355847597122192, Training Accuracy: 0.5808823529411765, Validation Loss: 1.4003496170043945, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3530/10000, Training Loss: 2.124100685119629, Training Accuracy: 0.5906862745098039, Validation Loss: 2.4746522903442383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3531/10000, Training Loss: 3.0496790409088135, Training Accuracy: 0.5833333333333334, Validation Loss: 5.979743480682373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3532/10000, Training Loss: 2.5518856048583984, Training Accuracy: 0.625, Validation Loss: 3.0222065448760986, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3533/10000, Training Loss: 1.971066951751709, Training Accuracy: 0.553921568627451, Validation Loss: 1.9033914804458618, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3534/10000, Training Loss: 3.389051914215088, Training Accuracy: 0.5808823529411765, Validation Loss: 2.7742607593536377, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3535/10000, Training Loss: 1.6268556118011475, Training Accuracy: 0.5588235294117647, Validation Loss: 1.7610703706741333, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3536/10000, Training Loss: 2.1806907653808594, Training Accuracy: 0.5490196078431373, Validation Loss: 1.063842535018921, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3537/10000, Training Loss: 1.6059077978134155, Training Accuracy: 0.5955882352941176, Validation Loss: 2.095170736312866, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3538/10000, Training Loss: 2.848708391189575, Training Accuracy: 0.5196078431372549, Validation Loss: 4.09398889541626, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3539/10000, Training Loss: 1.8806798458099365, Training Accuracy: 0.5759803921568627, Validation Loss: 1.9053677320480347, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3540/10000, Training Loss: 2.0240705013275146, Training Accuracy: 0.6004901960784313, Validation Loss: 2.6086413860321045, Validation Accuracy: 0.5\n",
      "Epoch 3541/10000, Training Loss: 1.3706973791122437, Training Accuracy: 0.5661764705882353, Validation Loss: 4.647136211395264, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 3542/10000, Training Loss: 3.2215800285339355, Training Accuracy: 0.6029411764705882, Validation Loss: 1.6721210479736328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3543/10000, Training Loss: 1.9245901107788086, Training Accuracy: 0.6323529411764706, Validation Loss: 0.41439923644065857, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3544/10000, Training Loss: 3.725964069366455, Training Accuracy: 0.5808823529411765, Validation Loss: 2.6657495498657227, Validation Accuracy: 0.75\n",
      "Epoch 3545/10000, Training Loss: 2.3101415634155273, Training Accuracy: 0.5931372549019608, Validation Loss: 2.835963249206543, Validation Accuracy: 0.5\n",
      "Epoch 3546/10000, Training Loss: 2.5184950828552246, Training Accuracy: 0.6176470588235294, Validation Loss: 3.0300891399383545, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3547/10000, Training Loss: 2.831406354904175, Training Accuracy: 0.5220588235294118, Validation Loss: 1.7404985427856445, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3548/10000, Training Loss: 1.9086350202560425, Training Accuracy: 0.6348039215686274, Validation Loss: 2.605184316635132, Validation Accuracy: 0.25\n",
      "Epoch 3549/10000, Training Loss: 2.703484535217285, Training Accuracy: 0.5490196078431373, Validation Loss: 3.503549575805664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3550/10000, Training Loss: 3.13787579536438, Training Accuracy: 0.5637254901960784, Validation Loss: 1.2487269639968872, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3551/10000, Training Loss: 2.8899450302124023, Training Accuracy: 0.5735294117647058, Validation Loss: 4.512031078338623, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3552/10000, Training Loss: 2.5005242824554443, Training Accuracy: 0.5612745098039216, Validation Loss: 1.439449667930603, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3553/10000, Training Loss: 2.5469257831573486, Training Accuracy: 0.571078431372549, Validation Loss: 2.045668363571167, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3554/10000, Training Loss: 2.628432512283325, Training Accuracy: 0.5343137254901961, Validation Loss: 3.4094550609588623, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3555/10000, Training Loss: 4.389208793640137, Training Accuracy: 0.5857843137254902, Validation Loss: 4.18376350402832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3556/10000, Training Loss: 1.895218014717102, Training Accuracy: 0.5343137254901961, Validation Loss: 1.5085105895996094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3557/10000, Training Loss: 2.526210308074951, Training Accuracy: 0.5514705882352942, Validation Loss: 6.139358997344971, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3558/10000, Training Loss: 2.372088670730591, Training Accuracy: 0.5367647058823529, Validation Loss: 2.405014753341675, Validation Accuracy: 0.5\n",
      "Epoch 3559/10000, Training Loss: 1.8651708364486694, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7319127917289734, Validation Accuracy: 0.75\n",
      "Epoch 3560/10000, Training Loss: 2.63045334815979, Training Accuracy: 0.6029411764705882, Validation Loss: 1.9181900024414062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3561/10000, Training Loss: 2.2099316120147705, Training Accuracy: 0.553921568627451, Validation Loss: 4.1368513107299805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3562/10000, Training Loss: 1.5801732540130615, Training Accuracy: 0.6127450980392157, Validation Loss: 8.209856986999512, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3563/10000, Training Loss: 3.068178415298462, Training Accuracy: 0.5735294117647058, Validation Loss: 2.421060085296631, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3564/10000, Training Loss: 2.1081998348236084, Training Accuracy: 0.5588235294117647, Validation Loss: 3.832714319229126, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3565/10000, Training Loss: 3.3567047119140625, Training Accuracy: 0.5392156862745098, Validation Loss: 7.368990421295166, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3566/10000, Training Loss: 2.709639072418213, Training Accuracy: 0.5343137254901961, Validation Loss: 1.1132020950317383, Validation Accuracy: 0.5\n",
      "Epoch 3567/10000, Training Loss: 2.028921365737915, Training Accuracy: 0.5784313725490197, Validation Loss: 1.7190459966659546, Validation Accuracy: 0.5\n",
      "Epoch 3568/10000, Training Loss: 2.103849172592163, Training Accuracy: 0.5220588235294118, Validation Loss: 1.411903977394104, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3569/10000, Training Loss: 2.4705917835235596, Training Accuracy: 0.5759803921568627, Validation Loss: 2.289539337158203, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3570/10000, Training Loss: 2.4855899810791016, Training Accuracy: 0.5882352941176471, Validation Loss: 2.4526207447052, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3571/10000, Training Loss: 1.7098511457443237, Training Accuracy: 0.6397058823529411, Validation Loss: 2.8150501251220703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3572/10000, Training Loss: 1.9846206903457642, Training Accuracy: 0.5318627450980392, Validation Loss: 1.6061760187149048, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3573/10000, Training Loss: 2.025446653366089, Training Accuracy: 0.5588235294117647, Validation Loss: 2.3509087562561035, Validation Accuracy: 0.5\n",
      "Epoch 3574/10000, Training Loss: 2.8962814807891846, Training Accuracy: 0.5, Validation Loss: 5.192573070526123, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3575/10000, Training Loss: 1.9013532400131226, Training Accuracy: 0.5245098039215687, Validation Loss: 4.181250095367432, Validation Accuracy: 0.5\n",
      "Epoch 3576/10000, Training Loss: 2.8850698471069336, Training Accuracy: 0.5686274509803921, Validation Loss: 6.524562358856201, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3577/10000, Training Loss: 2.282015562057495, Training Accuracy: 0.5294117647058824, Validation Loss: 2.8023178577423096, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3578/10000, Training Loss: 1.9773765802383423, Training Accuracy: 0.5759803921568627, Validation Loss: 4.041907787322998, Validation Accuracy: 0.25\n",
      "Epoch 3579/10000, Training Loss: 2.100123167037964, Training Accuracy: 0.6029411764705882, Validation Loss: 3.6282804012298584, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3580/10000, Training Loss: 2.6822516918182373, Training Accuracy: 0.5759803921568627, Validation Loss: 2.5237009525299072, Validation Accuracy: 0.75\n",
      "Epoch 3581/10000, Training Loss: 2.420180559158325, Training Accuracy: 0.5245098039215687, Validation Loss: 2.893390655517578, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3582/10000, Training Loss: 2.718357563018799, Training Accuracy: 0.5245098039215687, Validation Loss: 1.8319114446640015, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3583/10000, Training Loss: 2.1637861728668213, Training Accuracy: 0.5686274509803921, Validation Loss: 2.320502519607544, Validation Accuracy: 0.5\n",
      "Epoch 3584/10000, Training Loss: 2.2925734519958496, Training Accuracy: 0.5980392156862745, Validation Loss: 2.816586494445801, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3585/10000, Training Loss: 2.8579912185668945, Training Accuracy: 0.5808823529411765, Validation Loss: 1.7351819276809692, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3586/10000, Training Loss: 2.1516737937927246, Training Accuracy: 0.5367647058823529, Validation Loss: 2.777935028076172, Validation Accuracy: 0.5\n",
      "Epoch 3587/10000, Training Loss: 2.770390033721924, Training Accuracy: 0.5196078431372549, Validation Loss: 4.245008945465088, Validation Accuracy: 0.5\n",
      "Epoch 3588/10000, Training Loss: 2.7865381240844727, Training Accuracy: 0.5122549019607843, Validation Loss: 1.8040581941604614, Validation Accuracy: 0.5\n",
      "Epoch 3589/10000, Training Loss: 2.8172433376312256, Training Accuracy: 0.5294117647058824, Validation Loss: 4.042237758636475, Validation Accuracy: 0.25\n",
      "Epoch 3590/10000, Training Loss: 2.88713002204895, Training Accuracy: 0.5416666666666666, Validation Loss: 2.631838083267212, Validation Accuracy: 0.5\n",
      "Epoch 3591/10000, Training Loss: 2.955124855041504, Training Accuracy: 0.5269607843137255, Validation Loss: 5.009719371795654, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3592/10000, Training Loss: 1.8638759851455688, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6867013573646545, Validation Accuracy: 0.5\n",
      "Epoch 3593/10000, Training Loss: 2.0333118438720703, Training Accuracy: 0.5882352941176471, Validation Loss: 4.752305507659912, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3594/10000, Training Loss: 3.306769371032715, Training Accuracy: 0.5343137254901961, Validation Loss: 3.172261953353882, Validation Accuracy: 0.25\n",
      "Epoch 3595/10000, Training Loss: 2.3002724647521973, Training Accuracy: 0.5563725490196079, Validation Loss: 5.42322301864624, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3596/10000, Training Loss: 2.6870293617248535, Training Accuracy: 0.49754901960784315, Validation Loss: 2.7941057682037354, Validation Accuracy: 0.5\n",
      "Epoch 3597/10000, Training Loss: 2.4522342681884766, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6940045356750488, Validation Accuracy: 0.75\n",
      "Epoch 3598/10000, Training Loss: 1.9007526636123657, Training Accuracy: 0.5465686274509803, Validation Loss: 1.862388014793396, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3599/10000, Training Loss: 2.130173921585083, Training Accuracy: 0.5563725490196079, Validation Loss: 3.7088301181793213, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3600/10000, Training Loss: 1.6104477643966675, Training Accuracy: 0.5931372549019608, Validation Loss: 6.674818515777588, Validation Accuracy: 0.25\n",
      "Epoch 3601/10000, Training Loss: 1.7005501985549927, Training Accuracy: 0.5367647058823529, Validation Loss: 6.1227874755859375, Validation Accuracy: 0.25\n",
      "Epoch 3602/10000, Training Loss: 2.037215232849121, Training Accuracy: 0.6151960784313726, Validation Loss: 1.187454342842102, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3603/10000, Training Loss: 1.892594337463379, Training Accuracy: 0.5882352941176471, Validation Loss: 1.8013314008712769, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3604/10000, Training Loss: 3.1776578426361084, Training Accuracy: 0.5269607843137255, Validation Loss: 3.859224319458008, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3605/10000, Training Loss: 2.282733917236328, Training Accuracy: 0.5343137254901961, Validation Loss: 4.430860996246338, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3606/10000, Training Loss: 2.3836758136749268, Training Accuracy: 0.571078431372549, Validation Loss: 3.6848554611206055, Validation Accuracy: 0.5\n",
      "Epoch 3607/10000, Training Loss: 2.4278836250305176, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7587690949440002, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3608/10000, Training Loss: 2.86928653717041, Training Accuracy: 0.5318627450980392, Validation Loss: 2.6852362155914307, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3609/10000, Training Loss: 2.787545680999756, Training Accuracy: 0.5735294117647058, Validation Loss: 2.688225507736206, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3610/10000, Training Loss: 1.9462279081344604, Training Accuracy: 0.49754901960784315, Validation Loss: 3.777789354324341, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3611/10000, Training Loss: 2.630584716796875, Training Accuracy: 0.571078431372549, Validation Loss: 4.8755269050598145, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3612/10000, Training Loss: 1.6372066736221313, Training Accuracy: 0.5, Validation Loss: 2.424210548400879, Validation Accuracy: 0.5\n",
      "Epoch 3613/10000, Training Loss: 3.1926610469818115, Training Accuracy: 0.5269607843137255, Validation Loss: 4.135200023651123, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3614/10000, Training Loss: 1.447949767112732, Training Accuracy: 0.5490196078431373, Validation Loss: 1.309393286705017, Validation Accuracy: 0.5\n",
      "Epoch 3615/10000, Training Loss: 2.0512773990631104, Training Accuracy: 0.5416666666666666, Validation Loss: 6.263084411621094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3616/10000, Training Loss: 1.934945821762085, Training Accuracy: 0.6078431372549019, Validation Loss: 3.67441463470459, Validation Accuracy: 0.5\n",
      "Epoch 3617/10000, Training Loss: 2.16825532913208, Training Accuracy: 0.5220588235294118, Validation Loss: 6.065403461456299, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3618/10000, Training Loss: 1.7247724533081055, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9557361602783203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3619/10000, Training Loss: 2.2144134044647217, Training Accuracy: 0.5514705882352942, Validation Loss: 3.4289047718048096, Validation Accuracy: 0.25\n",
      "Epoch 3620/10000, Training Loss: 1.8635663986206055, Training Accuracy: 0.5686274509803921, Validation Loss: 1.656907558441162, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3621/10000, Training Loss: 2.056593656539917, Training Accuracy: 0.5220588235294118, Validation Loss: 3.0767109394073486, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3622/10000, Training Loss: 2.1220970153808594, Training Accuracy: 0.5122549019607843, Validation Loss: 1.5935745239257812, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3623/10000, Training Loss: 3.121654510498047, Training Accuracy: 0.5220588235294118, Validation Loss: 3.6282575130462646, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3624/10000, Training Loss: 2.330657720565796, Training Accuracy: 0.5416666666666666, Validation Loss: 3.090703010559082, Validation Accuracy: 0.5\n",
      "Epoch 3625/10000, Training Loss: 2.1367318630218506, Training Accuracy: 0.5857843137254902, Validation Loss: 5.5524115562438965, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3626/10000, Training Loss: 1.796148419380188, Training Accuracy: 0.5661764705882353, Validation Loss: 3.35595965385437, Validation Accuracy: 0.5\n",
      "Epoch 3627/10000, Training Loss: 1.788198709487915, Training Accuracy: 0.6323529411764706, Validation Loss: 4.875362873077393, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3628/10000, Training Loss: 1.6032545566558838, Training Accuracy: 0.5392156862745098, Validation Loss: 3.2194736003875732, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3629/10000, Training Loss: 2.5376365184783936, Training Accuracy: 0.6102941176470589, Validation Loss: 2.703119993209839, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3630/10000, Training Loss: 2.179619073867798, Training Accuracy: 0.4950980392156863, Validation Loss: 3.2219536304473877, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3631/10000, Training Loss: 2.5632989406585693, Training Accuracy: 0.571078431372549, Validation Loss: 8.106776237487793, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3632/10000, Training Loss: 2.456897020339966, Training Accuracy: 0.5367647058823529, Validation Loss: 3.035536050796509, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3633/10000, Training Loss: 2.5357539653778076, Training Accuracy: 0.571078431372549, Validation Loss: 0.8912820816040039, Validation Accuracy: 0.75\n",
      "Epoch 3634/10000, Training Loss: 2.3646774291992188, Training Accuracy: 0.5220588235294118, Validation Loss: 4.400790691375732, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3635/10000, Training Loss: 2.419471025466919, Training Accuracy: 0.5196078431372549, Validation Loss: 3.2562201023101807, Validation Accuracy: 0.5\n",
      "Epoch 3636/10000, Training Loss: 2.1699941158294678, Training Accuracy: 0.5024509803921569, Validation Loss: 2.080758810043335, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3637/10000, Training Loss: 2.4692416191101074, Training Accuracy: 0.571078431372549, Validation Loss: 4.085430145263672, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3638/10000, Training Loss: 1.7196460962295532, Training Accuracy: 0.5735294117647058, Validation Loss: 2.6051149368286133, Validation Accuracy: 0.5\n",
      "Epoch 3639/10000, Training Loss: 2.8032989501953125, Training Accuracy: 0.5735294117647058, Validation Loss: 6.731632232666016, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3640/10000, Training Loss: 2.032057285308838, Training Accuracy: 0.5857843137254902, Validation Loss: 4.02929162979126, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3641/10000, Training Loss: 2.7336978912353516, Training Accuracy: 0.5490196078431373, Validation Loss: 3.1578967571258545, Validation Accuracy: 0.5\n",
      "Epoch 3642/10000, Training Loss: 2.669429063796997, Training Accuracy: 0.5931372549019608, Validation Loss: 1.9457820653915405, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3643/10000, Training Loss: 2.271815776824951, Training Accuracy: 0.5441176470588235, Validation Loss: 2.621497631072998, Validation Accuracy: 0.5\n",
      "Epoch 3644/10000, Training Loss: 2.6515636444091797, Training Accuracy: 0.4950980392156863, Validation Loss: 2.2807271480560303, Validation Accuracy: 0.25\n",
      "Epoch 3645/10000, Training Loss: 2.8787806034088135, Training Accuracy: 0.5563725490196079, Validation Loss: 4.418957233428955, Validation Accuracy: 0.75\n",
      "Epoch 3646/10000, Training Loss: 2.5480175018310547, Training Accuracy: 0.6078431372549019, Validation Loss: 1.3861517906188965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3647/10000, Training Loss: 1.724228858947754, Training Accuracy: 0.6102941176470589, Validation Loss: 2.815753698348999, Validation Accuracy: 0.25\n",
      "Epoch 3648/10000, Training Loss: 2.973468780517578, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8812807202339172, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3649/10000, Training Loss: 1.4742273092269897, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7496249675750732, Validation Accuracy: 0.75\n",
      "Epoch 3650/10000, Training Loss: 2.085975408554077, Training Accuracy: 0.5490196078431373, Validation Loss: 2.7483317852020264, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3651/10000, Training Loss: 2.6553356647491455, Training Accuracy: 0.5980392156862745, Validation Loss: 4.736586570739746, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3652/10000, Training Loss: 2.12514066696167, Training Accuracy: 0.5441176470588235, Validation Loss: 3.8463785648345947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3653/10000, Training Loss: 2.193936824798584, Training Accuracy: 0.5882352941176471, Validation Loss: 2.4211456775665283, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3654/10000, Training Loss: 1.7717995643615723, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0201350450515747, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3655/10000, Training Loss: 2.2277748584747314, Training Accuracy: 0.5808823529411765, Validation Loss: 6.953033924102783, Validation Accuracy: 0.5\n",
      "Epoch 3656/10000, Training Loss: 2.12672758102417, Training Accuracy: 0.5563725490196079, Validation Loss: 1.3008112907409668, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3657/10000, Training Loss: 2.5435447692871094, Training Accuracy: 0.5833333333333334, Validation Loss: 3.603740692138672, Validation Accuracy: 0.5\n",
      "Epoch 3658/10000, Training Loss: 2.135700225830078, Training Accuracy: 0.6004901960784313, Validation Loss: 3.39949107170105, Validation Accuracy: 0.5\n",
      "Epoch 3659/10000, Training Loss: 1.909470796585083, Training Accuracy: 0.5416666666666666, Validation Loss: 2.1461246013641357, Validation Accuracy: 0.5\n",
      "Epoch 3660/10000, Training Loss: 2.098423957824707, Training Accuracy: 0.5637254901960784, Validation Loss: 3.988748788833618, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3661/10000, Training Loss: 2.58190655708313, Training Accuracy: 0.49754901960784315, Validation Loss: 4.084329128265381, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3662/10000, Training Loss: 2.249199151992798, Training Accuracy: 0.5735294117647058, Validation Loss: 4.071969509124756, Validation Accuracy: 0.5\n",
      "Epoch 3663/10000, Training Loss: 2.315472364425659, Training Accuracy: 0.5808823529411765, Validation Loss: 2.7272825241088867, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3664/10000, Training Loss: 2.574450969696045, Training Accuracy: 0.5661764705882353, Validation Loss: 2.1170616149902344, Validation Accuracy: 0.75\n",
      "Epoch 3665/10000, Training Loss: 2.3027875423431396, Training Accuracy: 0.6323529411764706, Validation Loss: 2.3103115558624268, Validation Accuracy: 0.5\n",
      "Epoch 3666/10000, Training Loss: 2.3281283378601074, Training Accuracy: 0.5686274509803921, Validation Loss: 3.172921895980835, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3667/10000, Training Loss: 2.023343324661255, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8762525916099548, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3668/10000, Training Loss: 2.298511028289795, Training Accuracy: 0.5588235294117647, Validation Loss: 4.551904201507568, Validation Accuracy: 0.25\n",
      "Epoch 3669/10000, Training Loss: 2.179103374481201, Training Accuracy: 0.5612745098039216, Validation Loss: 2.3415536880493164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3670/10000, Training Loss: 1.8744611740112305, Training Accuracy: 0.571078431372549, Validation Loss: 1.532554030418396, Validation Accuracy: 0.75\n",
      "Epoch 3671/10000, Training Loss: 3.005626916885376, Training Accuracy: 0.5098039215686274, Validation Loss: 3.355830430984497, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3672/10000, Training Loss: 3.035161018371582, Training Accuracy: 0.5882352941176471, Validation Loss: 5.484864711761475, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3673/10000, Training Loss: 2.0035319328308105, Training Accuracy: 0.6078431372549019, Validation Loss: 2.7450504302978516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3674/10000, Training Loss: 1.5123348236083984, Training Accuracy: 0.6102941176470589, Validation Loss: 2.98248553276062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3675/10000, Training Loss: 2.502842903137207, Training Accuracy: 0.553921568627451, Validation Loss: 3.8304126262664795, Validation Accuracy: 0.5\n",
      "Epoch 3676/10000, Training Loss: 2.617748737335205, Training Accuracy: 0.49264705882352944, Validation Loss: 1.2831627130508423, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3677/10000, Training Loss: 1.7198456525802612, Training Accuracy: 0.6176470588235294, Validation Loss: 2.90970778465271, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3678/10000, Training Loss: 1.8291031122207642, Training Accuracy: 0.6127450980392157, Validation Loss: 6.596411228179932, Validation Accuracy: 0.5\n",
      "Epoch 3679/10000, Training Loss: 1.8317443132400513, Training Accuracy: 0.5882352941176471, Validation Loss: 4.0154337882995605, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3680/10000, Training Loss: 2.2922523021698, Training Accuracy: 0.5392156862745098, Validation Loss: 1.471092700958252, Validation Accuracy: 0.75\n",
      "Epoch 3681/10000, Training Loss: 2.054511308670044, Training Accuracy: 0.553921568627451, Validation Loss: 4.572879314422607, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 3682/10000, Training Loss: 2.0132665634155273, Training Accuracy: 0.6127450980392157, Validation Loss: 2.5608367919921875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3683/10000, Training Loss: 3.0443127155303955, Training Accuracy: 0.5343137254901961, Validation Loss: 2.1364617347717285, Validation Accuracy: 0.5\n",
      "Epoch 3684/10000, Training Loss: 1.717429518699646, Training Accuracy: 0.5686274509803921, Validation Loss: 1.8960744142532349, Validation Accuracy: 0.5\n",
      "Epoch 3685/10000, Training Loss: 1.89067804813385, Training Accuracy: 0.5882352941176471, Validation Loss: 4.427404880523682, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3686/10000, Training Loss: 2.6999595165252686, Training Accuracy: 0.5465686274509803, Validation Loss: 1.869041085243225, Validation Accuracy: 0.5\n",
      "Epoch 3687/10000, Training Loss: 1.96238112449646, Training Accuracy: 0.5931372549019608, Validation Loss: 1.6489218473434448, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3688/10000, Training Loss: 2.6830599308013916, Training Accuracy: 0.5367647058823529, Validation Loss: 2.9944543838500977, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3689/10000, Training Loss: 2.0448975563049316, Training Accuracy: 0.5808823529411765, Validation Loss: 1.5421773195266724, Validation Accuracy: 0.5\n",
      "Epoch 3690/10000, Training Loss: 2.115204095840454, Training Accuracy: 0.6078431372549019, Validation Loss: 4.222955226898193, Validation Accuracy: 0.5\n",
      "Epoch 3691/10000, Training Loss: 1.5820716619491577, Training Accuracy: 0.6004901960784313, Validation Loss: 2.377143144607544, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3692/10000, Training Loss: 1.6035157442092896, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3116027116775513, Validation Accuracy: 0.75\n",
      "Epoch 3693/10000, Training Loss: 1.6582677364349365, Training Accuracy: 0.625, Validation Loss: 6.925348281860352, Validation Accuracy: 0.25\n",
      "Epoch 3694/10000, Training Loss: 2.634293556213379, Training Accuracy: 0.5637254901960784, Validation Loss: 5.033714294433594, Validation Accuracy: 0.5\n",
      "Epoch 3695/10000, Training Loss: 2.7559893131256104, Training Accuracy: 0.5563725490196079, Validation Loss: 2.48734450340271, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3696/10000, Training Loss: 1.9578659534454346, Training Accuracy: 0.5759803921568627, Validation Loss: 2.1509196758270264, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3697/10000, Training Loss: 1.4240548610687256, Training Accuracy: 0.6176470588235294, Validation Loss: 5.9639763832092285, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 3698/10000, Training Loss: 2.173466444015503, Training Accuracy: 0.5833333333333334, Validation Loss: 3.2448034286499023, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3699/10000, Training Loss: 2.6559154987335205, Training Accuracy: 0.5882352941176471, Validation Loss: 6.491133213043213, Validation Accuracy: 0.5\n",
      "Epoch 3700/10000, Training Loss: 2.370682954788208, Training Accuracy: 0.5024509803921569, Validation Loss: 3.777496337890625, Validation Accuracy: 0.5\n",
      "Epoch 3701/10000, Training Loss: 1.651647686958313, Training Accuracy: 0.5955882352941176, Validation Loss: 2.9654998779296875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3702/10000, Training Loss: 2.0453202724456787, Training Accuracy: 0.5465686274509803, Validation Loss: 1.7766410112380981, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3703/10000, Training Loss: 1.3938359022140503, Training Accuracy: 0.5490196078431373, Validation Loss: 2.451467275619507, Validation Accuracy: 0.5\n",
      "Epoch 3704/10000, Training Loss: 2.0787858963012695, Training Accuracy: 0.5637254901960784, Validation Loss: 2.385294198989868, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3705/10000, Training Loss: 2.0245070457458496, Training Accuracy: 0.5514705882352942, Validation Loss: 2.868715524673462, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3706/10000, Training Loss: 2.4966001510620117, Training Accuracy: 0.5245098039215687, Validation Loss: 1.5742778778076172, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3707/10000, Training Loss: 1.9491358995437622, Training Accuracy: 0.5024509803921569, Validation Loss: 6.418301105499268, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3708/10000, Training Loss: 2.582791566848755, Training Accuracy: 0.5196078431372549, Validation Loss: 1.0309810638427734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3709/10000, Training Loss: 2.194967746734619, Training Accuracy: 0.5906862745098039, Validation Loss: 2.8194210529327393, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3710/10000, Training Loss: 2.6545214653015137, Training Accuracy: 0.5833333333333334, Validation Loss: 5.717540740966797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3711/10000, Training Loss: 2.158658981323242, Training Accuracy: 0.553921568627451, Validation Loss: 4.684651851654053, Validation Accuracy: 0.5\n",
      "Epoch 3712/10000, Training Loss: 2.154749631881714, Training Accuracy: 0.5612745098039216, Validation Loss: 1.7145136594772339, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3713/10000, Training Loss: 2.960566759109497, Training Accuracy: 0.5637254901960784, Validation Loss: 3.220923662185669, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3714/10000, Training Loss: 2.3200979232788086, Training Accuracy: 0.6225490196078431, Validation Loss: 1.5762637853622437, Validation Accuracy: 0.5\n",
      "Epoch 3715/10000, Training Loss: 2.8012726306915283, Training Accuracy: 0.5980392156862745, Validation Loss: 6.1013264656066895, Validation Accuracy: 0.5\n",
      "Epoch 3716/10000, Training Loss: 1.4919748306274414, Training Accuracy: 0.5808823529411765, Validation Loss: 2.3764405250549316, Validation Accuracy: 0.25\n",
      "Epoch 3717/10000, Training Loss: 2.099545478820801, Training Accuracy: 0.49754901960784315, Validation Loss: 2.3043429851531982, Validation Accuracy: 0.5\n",
      "Epoch 3718/10000, Training Loss: 1.7161107063293457, Training Accuracy: 0.5931372549019608, Validation Loss: 1.4168020486831665, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3719/10000, Training Loss: 2.059136152267456, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0561341047286987, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3720/10000, Training Loss: 2.1168806552886963, Training Accuracy: 0.571078431372549, Validation Loss: 4.853744029998779, Validation Accuracy: 0.5\n",
      "Epoch 3721/10000, Training Loss: 1.8620586395263672, Training Accuracy: 0.6421568627450981, Validation Loss: 7.014414310455322, Validation Accuracy: 0.25\n",
      "Epoch 3722/10000, Training Loss: 1.972786545753479, Training Accuracy: 0.5392156862745098, Validation Loss: 3.7945239543914795, Validation Accuracy: 0.25\n",
      "Epoch 3723/10000, Training Loss: 1.9009500741958618, Training Accuracy: 0.5661764705882353, Validation Loss: 2.1565487384796143, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3724/10000, Training Loss: 1.4897643327713013, Training Accuracy: 0.5367647058823529, Validation Loss: 3.349271535873413, Validation Accuracy: 0.5\n",
      "Epoch 3725/10000, Training Loss: 2.400052547454834, Training Accuracy: 0.5294117647058824, Validation Loss: 3.3909597396850586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3726/10000, Training Loss: 1.6083613634109497, Training Accuracy: 0.5269607843137255, Validation Loss: 2.2689526081085205, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3727/10000, Training Loss: 1.8839635848999023, Training Accuracy: 0.5661764705882353, Validation Loss: 3.5672333240509033, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3728/10000, Training Loss: 2.113799571990967, Training Accuracy: 0.6053921568627451, Validation Loss: 2.415438652038574, Validation Accuracy: 0.5\n",
      "Epoch 3729/10000, Training Loss: 1.9528170824050903, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3593769073486328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3730/10000, Training Loss: 2.5814645290374756, Training Accuracy: 0.5490196078431373, Validation Loss: 4.449532985687256, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3731/10000, Training Loss: 3.6631782054901123, Training Accuracy: 0.5588235294117647, Validation Loss: 1.6190916299819946, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3732/10000, Training Loss: 1.8826442956924438, Training Accuracy: 0.5808823529411765, Validation Loss: 1.4261163473129272, Validation Accuracy: 0.5\n",
      "Epoch 3733/10000, Training Loss: 2.464191436767578, Training Accuracy: 0.5367647058823529, Validation Loss: 2.799405813217163, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3734/10000, Training Loss: 1.6988744735717773, Training Accuracy: 0.5735294117647058, Validation Loss: 4.379598140716553, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3735/10000, Training Loss: 2.7399327754974365, Training Accuracy: 0.5441176470588235, Validation Loss: 5.310335636138916, Validation Accuracy: 0.5\n",
      "Epoch 3736/10000, Training Loss: 1.5244451761245728, Training Accuracy: 0.5857843137254902, Validation Loss: 4.336111068725586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3737/10000, Training Loss: 1.870874047279358, Training Accuracy: 0.5588235294117647, Validation Loss: 2.578563928604126, Validation Accuracy: 0.5\n",
      "Epoch 3738/10000, Training Loss: 2.1027920246124268, Training Accuracy: 0.5269607843137255, Validation Loss: 1.4320529699325562, Validation Accuracy: 0.75\n",
      "Epoch 3739/10000, Training Loss: 1.9060797691345215, Training Accuracy: 0.5906862745098039, Validation Loss: 1.252261996269226, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3740/10000, Training Loss: 1.5917823314666748, Training Accuracy: 0.5563725490196079, Validation Loss: 1.3640414476394653, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3741/10000, Training Loss: 1.8638665676116943, Training Accuracy: 0.5490196078431373, Validation Loss: 3.8577394485473633, Validation Accuracy: 0.25\n",
      "Epoch 3742/10000, Training Loss: 2.2900664806365967, Training Accuracy: 0.5686274509803921, Validation Loss: 8.290850639343262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3743/10000, Training Loss: 2.3721189498901367, Training Accuracy: 0.5833333333333334, Validation Loss: 1.3729428052902222, Validation Accuracy: 0.5\n",
      "Epoch 3744/10000, Training Loss: 2.180124282836914, Training Accuracy: 0.5490196078431373, Validation Loss: 2.708812952041626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3745/10000, Training Loss: 2.3726062774658203, Training Accuracy: 0.5931372549019608, Validation Loss: 2.5642688274383545, Validation Accuracy: 0.5\n",
      "Epoch 3746/10000, Training Loss: 1.966429591178894, Training Accuracy: 0.571078431372549, Validation Loss: 0.9105715155601501, Validation Accuracy: 0.5\n",
      "Epoch 3747/10000, Training Loss: 2.2284538745880127, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9131758213043213, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3748/10000, Training Loss: 1.9640549421310425, Training Accuracy: 0.6053921568627451, Validation Loss: 1.7314815521240234, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3749/10000, Training Loss: 1.7583730220794678, Training Accuracy: 0.5759803921568627, Validation Loss: 2.790886878967285, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3750/10000, Training Loss: 1.7870992422103882, Training Accuracy: 0.5980392156862745, Validation Loss: 4.128707408905029, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3751/10000, Training Loss: 1.6744881868362427, Training Accuracy: 0.5245098039215687, Validation Loss: 1.14124596118927, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3752/10000, Training Loss: 2.3685741424560547, Training Accuracy: 0.553921568627451, Validation Loss: 1.8191123008728027, Validation Accuracy: 0.5\n",
      "Epoch 3753/10000, Training Loss: 1.802444577217102, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0064760446548462, Validation Accuracy: 0.5\n",
      "Epoch 3754/10000, Training Loss: 2.213756799697876, Training Accuracy: 0.5392156862745098, Validation Loss: 2.54984450340271, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3755/10000, Training Loss: 1.5711605548858643, Training Accuracy: 0.6372549019607843, Validation Loss: 2.587576150894165, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3756/10000, Training Loss: 1.5297460556030273, Training Accuracy: 0.48284313725490197, Validation Loss: 0.664557933807373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3757/10000, Training Loss: 2.462524175643921, Training Accuracy: 0.5343137254901961, Validation Loss: 2.4288082122802734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3758/10000, Training Loss: 3.1758501529693604, Training Accuracy: 0.5147058823529411, Validation Loss: 3.6899595260620117, Validation Accuracy: 0.5\n",
      "Epoch 3759/10000, Training Loss: 2.1239452362060547, Training Accuracy: 0.5906862745098039, Validation Loss: 2.9107844829559326, Validation Accuracy: 0.5\n",
      "Epoch 3760/10000, Training Loss: 2.252286672592163, Training Accuracy: 0.553921568627451, Validation Loss: 3.2654306888580322, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3761/10000, Training Loss: 1.9671329259872437, Training Accuracy: 0.5735294117647058, Validation Loss: 3.0736429691314697, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3762/10000, Training Loss: 2.051541805267334, Training Accuracy: 0.553921568627451, Validation Loss: 8.176630973815918, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3763/10000, Training Loss: 1.8346811532974243, Training Accuracy: 0.5122549019607843, Validation Loss: 1.2406808137893677, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3764/10000, Training Loss: 2.204982042312622, Training Accuracy: 0.5808823529411765, Validation Loss: 5.872670650482178, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3765/10000, Training Loss: 1.8561264276504517, Training Accuracy: 0.5612745098039216, Validation Loss: 2.2217037677764893, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3766/10000, Training Loss: 1.4977282285690308, Training Accuracy: 0.5343137254901961, Validation Loss: 3.788341522216797, Validation Accuracy: 0.5\n",
      "Epoch 3767/10000, Training Loss: 1.579646348953247, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6640599966049194, Validation Accuracy: 0.25\n",
      "Epoch 3768/10000, Training Loss: 2.6129865646362305, Training Accuracy: 0.5735294117647058, Validation Loss: 1.7521103620529175, Validation Accuracy: 0.75\n",
      "Epoch 3769/10000, Training Loss: 2.123906373977661, Training Accuracy: 0.5808823529411765, Validation Loss: 2.312161445617676, Validation Accuracy: 0.25\n",
      "Epoch 3770/10000, Training Loss: 1.9522899389266968, Training Accuracy: 0.5612745098039216, Validation Loss: 3.2554080486297607, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3771/10000, Training Loss: 2.293166399002075, Training Accuracy: 0.5147058823529411, Validation Loss: 2.6075141429901123, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3772/10000, Training Loss: 2.0055718421936035, Training Accuracy: 0.6495098039215687, Validation Loss: 5.456973552703857, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3773/10000, Training Loss: 1.8218179941177368, Training Accuracy: 0.5392156862745098, Validation Loss: 1.0095083713531494, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3774/10000, Training Loss: 2.1421260833740234, Training Accuracy: 0.5367647058823529, Validation Loss: 8.3749418258667, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3775/10000, Training Loss: 2.1802263259887695, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8698512315750122, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3776/10000, Training Loss: 2.053144931793213, Training Accuracy: 0.5171568627450981, Validation Loss: 2.5947790145874023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3777/10000, Training Loss: 2.0256707668304443, Training Accuracy: 0.571078431372549, Validation Loss: 2.314969539642334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3778/10000, Training Loss: 2.287013292312622, Training Accuracy: 0.5465686274509803, Validation Loss: 4.695188999176025, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3779/10000, Training Loss: 2.5000786781311035, Training Accuracy: 0.5024509803921569, Validation Loss: 2.1394007205963135, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3780/10000, Training Loss: 2.3001086711883545, Training Accuracy: 0.6176470588235294, Validation Loss: 1.2639840841293335, Validation Accuracy: 0.75\n",
      "Epoch 3781/10000, Training Loss: 2.3591628074645996, Training Accuracy: 0.5196078431372549, Validation Loss: 1.278455138206482, Validation Accuracy: 0.75\n",
      "Epoch 3782/10000, Training Loss: 1.9653584957122803, Training Accuracy: 0.5784313725490197, Validation Loss: 1.090511441230774, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3783/10000, Training Loss: 1.965786099433899, Training Accuracy: 0.5637254901960784, Validation Loss: 2.441908836364746, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3784/10000, Training Loss: 1.5634506940841675, Training Accuracy: 0.5514705882352942, Validation Loss: 1.1243339776992798, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3785/10000, Training Loss: 1.980708360671997, Training Accuracy: 0.5490196078431373, Validation Loss: 0.7752918601036072, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3786/10000, Training Loss: 2.1980628967285156, Training Accuracy: 0.5955882352941176, Validation Loss: 5.555944919586182, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3787/10000, Training Loss: 1.9235676527023315, Training Accuracy: 0.5514705882352942, Validation Loss: 2.693899154663086, Validation Accuracy: 0.5\n",
      "Epoch 3788/10000, Training Loss: 2.351983070373535, Training Accuracy: 0.5563725490196079, Validation Loss: 6.126562595367432, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3789/10000, Training Loss: 2.331591844558716, Training Accuracy: 0.5588235294117647, Validation Loss: 1.6804567575454712, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3790/10000, Training Loss: 2.041581392288208, Training Accuracy: 0.6323529411764706, Validation Loss: 2.0056264400482178, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3791/10000, Training Loss: 1.7691481113433838, Training Accuracy: 0.5514705882352942, Validation Loss: 1.706697940826416, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3792/10000, Training Loss: 2.1934056282043457, Training Accuracy: 0.5343137254901961, Validation Loss: 1.8335466384887695, Validation Accuracy: 0.5\n",
      "Epoch 3793/10000, Training Loss: 2.307345390319824, Training Accuracy: 0.5784313725490197, Validation Loss: 3.711101531982422, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3794/10000, Training Loss: 1.975753664970398, Training Accuracy: 0.553921568627451, Validation Loss: 0.9983713626861572, Validation Accuracy: 0.5\n",
      "Epoch 3795/10000, Training Loss: 1.2135915756225586, Training Accuracy: 0.5735294117647058, Validation Loss: 1.4564789533615112, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3796/10000, Training Loss: 1.9778941869735718, Training Accuracy: 0.5343137254901961, Validation Loss: 2.0494744777679443, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3797/10000, Training Loss: 1.847786545753479, Training Accuracy: 0.5416666666666666, Validation Loss: 2.944169759750366, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3798/10000, Training Loss: 2.2863314151763916, Training Accuracy: 0.4877450980392157, Validation Loss: 3.4663820266723633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3799/10000, Training Loss: 1.7696484327316284, Training Accuracy: 0.5367647058823529, Validation Loss: 0.5634858012199402, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3800/10000, Training Loss: 2.429776668548584, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7537828087806702, Validation Accuracy: 0.75\n",
      "Epoch 3801/10000, Training Loss: 1.9515856504440308, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0897879600524902, Validation Accuracy: 0.75\n",
      "Epoch 3802/10000, Training Loss: 2.9065349102020264, Training Accuracy: 0.6127450980392157, Validation Loss: 1.6707912683486938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3803/10000, Training Loss: 2.0150301456451416, Training Accuracy: 0.5269607843137255, Validation Loss: 2.0289878845214844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3804/10000, Training Loss: 2.156402826309204, Training Accuracy: 0.5784313725490197, Validation Loss: 2.5572829246520996, Validation Accuracy: 0.5\n",
      "Epoch 3805/10000, Training Loss: 1.5434964895248413, Training Accuracy: 0.5833333333333334, Validation Loss: 3.243600606918335, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3806/10000, Training Loss: 1.555204153060913, Training Accuracy: 0.5882352941176471, Validation Loss: 5.59379768371582, Validation Accuracy: 0.5\n",
      "Epoch 3807/10000, Training Loss: 2.2881789207458496, Training Accuracy: 0.5098039215686274, Validation Loss: 1.714173436164856, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3808/10000, Training Loss: 2.0458872318267822, Training Accuracy: 0.5759803921568627, Validation Loss: 4.5973124504089355, Validation Accuracy: 0.5\n",
      "Epoch 3809/10000, Training Loss: 1.9025205373764038, Training Accuracy: 0.5122549019607843, Validation Loss: 1.3305727243423462, Validation Accuracy: 0.5\n",
      "Epoch 3810/10000, Training Loss: 1.8508312702178955, Training Accuracy: 0.5441176470588235, Validation Loss: 2.4268620014190674, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3811/10000, Training Loss: 2.2002129554748535, Training Accuracy: 0.5759803921568627, Validation Loss: 6.376112461090088, Validation Accuracy: 0.25\n",
      "Epoch 3812/10000, Training Loss: 2.045604705810547, Training Accuracy: 0.6102941176470589, Validation Loss: 3.823915481567383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3813/10000, Training Loss: 2.499504566192627, Training Accuracy: 0.5147058823529411, Validation Loss: 2.6489689350128174, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3814/10000, Training Loss: 2.2770836353302, Training Accuracy: 0.5759803921568627, Validation Loss: 2.3614132404327393, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3815/10000, Training Loss: 1.618736743927002, Training Accuracy: 0.5784313725490197, Validation Loss: 3.3239829540252686, Validation Accuracy: 0.5\n",
      "Epoch 3816/10000, Training Loss: 2.3493025302886963, Training Accuracy: 0.5563725490196079, Validation Loss: 1.7781037092208862, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3817/10000, Training Loss: 2.1570301055908203, Training Accuracy: 0.553921568627451, Validation Loss: 3.2155323028564453, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3818/10000, Training Loss: 1.776426911354065, Training Accuracy: 0.5882352941176471, Validation Loss: 3.0744898319244385, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3819/10000, Training Loss: 1.5050910711288452, Training Accuracy: 0.6127450980392157, Validation Loss: 1.5096477270126343, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3820/10000, Training Loss: 1.5349013805389404, Training Accuracy: 0.6348039215686274, Validation Loss: 4.164125919342041, Validation Accuracy: 0.5\n",
      "Epoch 3821/10000, Training Loss: 1.5563173294067383, Training Accuracy: 0.6151960784313726, Validation Loss: 1.6977308988571167, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3822/10000, Training Loss: 2.435850143432617, Training Accuracy: 0.5245098039215687, Validation Loss: 2.663149833679199, Validation Accuracy: 0.75\n",
      "Epoch 3823/10000, Training Loss: 1.9608230590820312, Training Accuracy: 0.5686274509803921, Validation Loss: 3.3867580890655518, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3824/10000, Training Loss: 2.238642454147339, Training Accuracy: 0.5392156862745098, Validation Loss: 1.6625326871871948, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3825/10000, Training Loss: 2.1215734481811523, Training Accuracy: 0.4950980392156863, Validation Loss: 4.085636138916016, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3826/10000, Training Loss: 1.4227522611618042, Training Accuracy: 0.5098039215686274, Validation Loss: 1.0523937940597534, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3827/10000, Training Loss: 1.9980570077896118, Training Accuracy: 0.5563725490196079, Validation Loss: 2.8313655853271484, Validation Accuracy: 0.5\n",
      "Epoch 3828/10000, Training Loss: 2.6693997383117676, Training Accuracy: 0.4803921568627451, Validation Loss: 3.4848482608795166, Validation Accuracy: 0.5\n",
      "Epoch 3829/10000, Training Loss: 1.4864826202392578, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8641806244850159, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3830/10000, Training Loss: 1.9306894540786743, Training Accuracy: 0.5367647058823529, Validation Loss: 1.7788610458374023, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3831/10000, Training Loss: 2.2779111862182617, Training Accuracy: 0.47549019607843135, Validation Loss: 1.1091833114624023, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3832/10000, Training Loss: 1.6893038749694824, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9213972091674805, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3833/10000, Training Loss: 1.743685245513916, Training Accuracy: 0.5392156862745098, Validation Loss: 1.7393633127212524, Validation Accuracy: 0.5\n",
      "Epoch 3834/10000, Training Loss: 2.6787588596343994, Training Accuracy: 0.5735294117647058, Validation Loss: 7.266144275665283, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3835/10000, Training Loss: 1.5929665565490723, Training Accuracy: 0.5882352941176471, Validation Loss: 1.5098413228988647, Validation Accuracy: 0.5\n",
      "Epoch 3836/10000, Training Loss: 2.1128711700439453, Training Accuracy: 0.553921568627451, Validation Loss: 2.051576852798462, Validation Accuracy: 0.5\n",
      "Epoch 3837/10000, Training Loss: 1.9528545141220093, Training Accuracy: 0.5049019607843137, Validation Loss: 2.949115514755249, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3838/10000, Training Loss: 2.835230588912964, Training Accuracy: 0.5171568627450981, Validation Loss: 3.8114821910858154, Validation Accuracy: 0.5\n",
      "Epoch 3839/10000, Training Loss: 2.0409958362579346, Training Accuracy: 0.5735294117647058, Validation Loss: 3.572946548461914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3840/10000, Training Loss: 1.7848200798034668, Training Accuracy: 0.6274509803921569, Validation Loss: 1.5240398645401, Validation Accuracy: 0.5\n",
      "Epoch 3841/10000, Training Loss: 2.1312255859375, Training Accuracy: 0.5073529411764706, Validation Loss: 2.833425283432007, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3842/10000, Training Loss: 1.4236761331558228, Training Accuracy: 0.5735294117647058, Validation Loss: 0.4215591847896576, Validation Accuracy: 0.75\n",
      "Epoch 3843/10000, Training Loss: 2.010920286178589, Training Accuracy: 0.5392156862745098, Validation Loss: 3.704087257385254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3844/10000, Training Loss: 2.2676169872283936, Training Accuracy: 0.6274509803921569, Validation Loss: 12.326400756835938, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3845/10000, Training Loss: 2.605224609375, Training Accuracy: 0.5661764705882353, Validation Loss: 4.250408172607422, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3846/10000, Training Loss: 1.7225077152252197, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7857564687728882, Validation Accuracy: 0.5\n",
      "Epoch 3847/10000, Training Loss: 1.8999853134155273, Training Accuracy: 0.5612745098039216, Validation Loss: 1.7967227697372437, Validation Accuracy: 0.5\n",
      "Epoch 3848/10000, Training Loss: 1.5207256078720093, Training Accuracy: 0.6053921568627451, Validation Loss: 3.0375988483428955, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3849/10000, Training Loss: 1.6973910331726074, Training Accuracy: 0.5514705882352942, Validation Loss: 1.8379071950912476, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3850/10000, Training Loss: 2.0054800510406494, Training Accuracy: 0.5367647058823529, Validation Loss: 1.1694624423980713, Validation Accuracy: 0.5\n",
      "Epoch 3851/10000, Training Loss: 1.932210087776184, Training Accuracy: 0.5441176470588235, Validation Loss: 1.828856110572815, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3852/10000, Training Loss: 1.7563556432724, Training Accuracy: 0.5367647058823529, Validation Loss: 1.6177253723144531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3853/10000, Training Loss: 1.5287972688674927, Training Accuracy: 0.6421568627450981, Validation Loss: 2.7966842651367188, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3854/10000, Training Loss: 2.565048933029175, Training Accuracy: 0.6004901960784313, Validation Loss: 8.028971672058105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3855/10000, Training Loss: 1.7827436923980713, Training Accuracy: 0.5588235294117647, Validation Loss: 0.727307140827179, Validation Accuracy: 0.75\n",
      "Epoch 3856/10000, Training Loss: 1.61134934425354, Training Accuracy: 0.5833333333333334, Validation Loss: 2.3062350749969482, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3857/10000, Training Loss: 2.0908939838409424, Training Accuracy: 0.5686274509803921, Validation Loss: 4.072685241699219, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3858/10000, Training Loss: 2.185248613357544, Training Accuracy: 0.5490196078431373, Validation Loss: 2.073076009750366, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3859/10000, Training Loss: 2.693256378173828, Training Accuracy: 0.5661764705882353, Validation Loss: 3.947415351867676, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3860/10000, Training Loss: 2.079103708267212, Training Accuracy: 0.5588235294117647, Validation Loss: 4.374050140380859, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3861/10000, Training Loss: 1.7392185926437378, Training Accuracy: 0.5318627450980392, Validation Loss: 3.821479558944702, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3862/10000, Training Loss: 2.0663013458251953, Training Accuracy: 0.5686274509803921, Validation Loss: 3.8604443073272705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3863/10000, Training Loss: 1.5784101486206055, Training Accuracy: 0.6102941176470589, Validation Loss: 3.872098207473755, Validation Accuracy: 0.5\n",
      "Epoch 3864/10000, Training Loss: 1.9875329732894897, Training Accuracy: 0.5735294117647058, Validation Loss: 3.261103630065918, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3865/10000, Training Loss: 1.5596383810043335, Training Accuracy: 0.5612745098039216, Validation Loss: 1.5327590703964233, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3866/10000, Training Loss: 1.8791381120681763, Training Accuracy: 0.5367647058823529, Validation Loss: 1.1348408460617065, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3867/10000, Training Loss: 1.6132203340530396, Training Accuracy: 0.6127450980392157, Validation Loss: 2.8411481380462646, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3868/10000, Training Loss: 2.605689525604248, Training Accuracy: 0.5098039215686274, Validation Loss: 3.245027542114258, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3869/10000, Training Loss: 1.5593345165252686, Training Accuracy: 0.5955882352941176, Validation Loss: 1.8798751831054688, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3870/10000, Training Loss: 2.050955295562744, Training Accuracy: 0.5196078431372549, Validation Loss: 2.192760705947876, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3871/10000, Training Loss: 1.639590859413147, Training Accuracy: 0.5612745098039216, Validation Loss: 4.046995639801025, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3872/10000, Training Loss: 1.610486626625061, Training Accuracy: 0.553921568627451, Validation Loss: 1.5512685775756836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3873/10000, Training Loss: 1.9131996631622314, Training Accuracy: 0.6004901960784313, Validation Loss: 2.4960319995880127, Validation Accuracy: 0.25\n",
      "Epoch 3874/10000, Training Loss: 1.3345376253128052, Training Accuracy: 0.5931372549019608, Validation Loss: 3.8007383346557617, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3875/10000, Training Loss: 1.7374852895736694, Training Accuracy: 0.5857843137254902, Validation Loss: 2.0059797763824463, Validation Accuracy: 0.5\n",
      "Epoch 3876/10000, Training Loss: 1.6452547311782837, Training Accuracy: 0.5318627450980392, Validation Loss: 2.1591837406158447, Validation Accuracy: 0.5\n",
      "Epoch 3877/10000, Training Loss: 1.824898362159729, Training Accuracy: 0.6004901960784313, Validation Loss: 1.7263585329055786, Validation Accuracy: 0.5\n",
      "Epoch 3878/10000, Training Loss: 2.056316375732422, Training Accuracy: 0.5514705882352942, Validation Loss: 2.828500986099243, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3879/10000, Training Loss: 1.8066083192825317, Training Accuracy: 0.5931372549019608, Validation Loss: 1.4574512243270874, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3880/10000, Training Loss: 1.7827932834625244, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0653294324874878, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3881/10000, Training Loss: 1.892241358757019, Training Accuracy: 0.5465686274509803, Validation Loss: 2.7412407398223877, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3882/10000, Training Loss: 2.255049228668213, Training Accuracy: 0.6176470588235294, Validation Loss: 4.863719463348389, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3883/10000, Training Loss: 1.387641191482544, Training Accuracy: 0.5882352941176471, Validation Loss: 1.136918544769287, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3884/10000, Training Loss: 2.7207019329071045, Training Accuracy: 0.5367647058823529, Validation Loss: 3.6519768238067627, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3885/10000, Training Loss: 3.217127561569214, Training Accuracy: 0.5784313725490197, Validation Loss: 5.411798477172852, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3886/10000, Training Loss: 1.2862708568572998, Training Accuracy: 0.6078431372549019, Validation Loss: 0.3015163242816925, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 3887/10000, Training Loss: 1.3729616403579712, Training Accuracy: 0.571078431372549, Validation Loss: 3.2338666915893555, Validation Accuracy: 0.25\n",
      "Epoch 3888/10000, Training Loss: 1.7466076612472534, Training Accuracy: 0.5490196078431373, Validation Loss: 1.3166722059249878, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3889/10000, Training Loss: 1.431988000869751, Training Accuracy: 0.5808823529411765, Validation Loss: 2.273709774017334, Validation Accuracy: 0.25\n",
      "Epoch 3890/10000, Training Loss: 2.150887966156006, Training Accuracy: 0.5735294117647058, Validation Loss: 6.099339008331299, Validation Accuracy: 0.25\n",
      "Epoch 3891/10000, Training Loss: 1.6517869234085083, Training Accuracy: 0.5367647058823529, Validation Loss: 2.0539653301239014, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3892/10000, Training Loss: 2.387021780014038, Training Accuracy: 0.5612745098039216, Validation Loss: 5.941281795501709, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 3893/10000, Training Loss: 1.635909080505371, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1634013652801514, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3894/10000, Training Loss: 1.7887979745864868, Training Accuracy: 0.6078431372549019, Validation Loss: 1.4424281120300293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3895/10000, Training Loss: 2.276862144470215, Training Accuracy: 0.5294117647058824, Validation Loss: 2.343081474304199, Validation Accuracy: 0.5\n",
      "Epoch 3896/10000, Training Loss: 1.549764633178711, Training Accuracy: 0.5367647058823529, Validation Loss: 1.906969666481018, Validation Accuracy: 0.5\n",
      "Epoch 3897/10000, Training Loss: 1.700573444366455, Training Accuracy: 0.571078431372549, Validation Loss: 1.8447551727294922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3898/10000, Training Loss: 2.176499128341675, Training Accuracy: 0.5980392156862745, Validation Loss: 5.559083938598633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3899/10000, Training Loss: 2.8388116359710693, Training Accuracy: 0.5490196078431373, Validation Loss: 1.5749977827072144, Validation Accuracy: 0.5\n",
      "Epoch 3900/10000, Training Loss: 2.096484661102295, Training Accuracy: 0.5343137254901961, Validation Loss: 1.0676628351211548, Validation Accuracy: 0.75\n",
      "Epoch 3901/10000, Training Loss: 2.2916648387908936, Training Accuracy: 0.48284313725490197, Validation Loss: 1.6298261880874634, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3902/10000, Training Loss: 1.2615104913711548, Training Accuracy: 0.5147058823529411, Validation Loss: 1.083902359008789, Validation Accuracy: 0.5\n",
      "Epoch 3903/10000, Training Loss: 1.3430252075195312, Training Accuracy: 0.5833333333333334, Validation Loss: 1.6620081663131714, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3904/10000, Training Loss: 1.8600095510482788, Training Accuracy: 0.5171568627450981, Validation Loss: 0.8224051594734192, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3905/10000, Training Loss: 2.027620315551758, Training Accuracy: 0.5980392156862745, Validation Loss: 1.956452488899231, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3906/10000, Training Loss: 2.2088961601257324, Training Accuracy: 0.5857843137254902, Validation Loss: 2.0143377780914307, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3907/10000, Training Loss: 1.6322721242904663, Training Accuracy: 0.5637254901960784, Validation Loss: 2.465057134628296, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3908/10000, Training Loss: 1.93686842918396, Training Accuracy: 0.5024509803921569, Validation Loss: 3.094122886657715, Validation Accuracy: 0.25\n",
      "Epoch 3909/10000, Training Loss: 2.212613582611084, Training Accuracy: 0.5294117647058824, Validation Loss: 4.166635990142822, Validation Accuracy: 0.25\n",
      "Epoch 3910/10000, Training Loss: 1.888075590133667, Training Accuracy: 0.5269607843137255, Validation Loss: 2.644368886947632, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3911/10000, Training Loss: 1.4841976165771484, Training Accuracy: 0.5931372549019608, Validation Loss: 3.33233642578125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3912/10000, Training Loss: 1.554747462272644, Training Accuracy: 0.5833333333333334, Validation Loss: 3.968226194381714, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3913/10000, Training Loss: 1.6711993217468262, Training Accuracy: 0.5833333333333334, Validation Loss: 4.962657928466797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3914/10000, Training Loss: 2.5038185119628906, Training Accuracy: 0.5294117647058824, Validation Loss: 3.830484628677368, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3915/10000, Training Loss: 2.0071401596069336, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3706587553024292, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3916/10000, Training Loss: 2.0302069187164307, Training Accuracy: 0.5784313725490197, Validation Loss: 1.0463542938232422, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3917/10000, Training Loss: 1.4354469776153564, Training Accuracy: 0.5171568627450981, Validation Loss: 3.2675812244415283, Validation Accuracy: 0.25\n",
      "Epoch 3918/10000, Training Loss: 2.350872039794922, Training Accuracy: 0.5245098039215687, Validation Loss: 2.8135745525360107, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3919/10000, Training Loss: 1.7713254690170288, Training Accuracy: 0.5269607843137255, Validation Loss: 2.5591769218444824, Validation Accuracy: 0.5\n",
      "Epoch 3920/10000, Training Loss: 3.0375123023986816, Training Accuracy: 0.5392156862745098, Validation Loss: 2.431053400039673, Validation Accuracy: 0.5\n",
      "Epoch 3921/10000, Training Loss: 2.290616989135742, Training Accuracy: 0.5808823529411765, Validation Loss: 6.440330505371094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3922/10000, Training Loss: 1.8486796617507935, Training Accuracy: 0.5637254901960784, Validation Loss: 2.806072950363159, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3923/10000, Training Loss: 2.2104122638702393, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2930688858032227, Validation Accuracy: 0.75\n",
      "Epoch 3924/10000, Training Loss: 2.4567201137542725, Training Accuracy: 0.44362745098039214, Validation Loss: 1.6182492971420288, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3925/10000, Training Loss: 1.4439936876296997, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9201553463935852, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3926/10000, Training Loss: 1.1963807344436646, Training Accuracy: 0.5857843137254902, Validation Loss: 1.9995321035385132, Validation Accuracy: 0.5\n",
      "Epoch 3927/10000, Training Loss: 2.0046145915985107, Training Accuracy: 0.5612745098039216, Validation Loss: 1.7326102256774902, Validation Accuracy: 0.5\n",
      "Epoch 3928/10000, Training Loss: 1.8859751224517822, Training Accuracy: 0.6446078431372549, Validation Loss: 2.64178204536438, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3929/10000, Training Loss: 2.2888708114624023, Training Accuracy: 0.5906862745098039, Validation Loss: 1.510597825050354, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3930/10000, Training Loss: 1.8706248998641968, Training Accuracy: 0.5171568627450981, Validation Loss: 3.3224661350250244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3931/10000, Training Loss: 1.98673677444458, Training Accuracy: 0.5294117647058824, Validation Loss: 2.9269638061523438, Validation Accuracy: 0.25\n",
      "Epoch 3932/10000, Training Loss: 2.375006914138794, Training Accuracy: 0.5612745098039216, Validation Loss: 1.815283179283142, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3933/10000, Training Loss: 1.7078884840011597, Training Accuracy: 0.5490196078431373, Validation Loss: 2.9620392322540283, Validation Accuracy: 0.5\n",
      "Epoch 3934/10000, Training Loss: 1.4883209466934204, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9654722213745117, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3935/10000, Training Loss: 1.8019977807998657, Training Accuracy: 0.5637254901960784, Validation Loss: 4.204006671905518, Validation Accuracy: 0.5\n",
      "Epoch 3936/10000, Training Loss: 1.7090567350387573, Training Accuracy: 0.6127450980392157, Validation Loss: 3.225295305252075, Validation Accuracy: 0.5\n",
      "Epoch 3937/10000, Training Loss: 1.973138689994812, Training Accuracy: 0.6446078431372549, Validation Loss: 2.5304415225982666, Validation Accuracy: 0.5\n",
      "Epoch 3938/10000, Training Loss: 1.5565239191055298, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2268306016921997, Validation Accuracy: 0.5\n",
      "Epoch 3939/10000, Training Loss: 1.6082512140274048, Training Accuracy: 0.5882352941176471, Validation Loss: 1.9547171592712402, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3940/10000, Training Loss: 2.0001699924468994, Training Accuracy: 0.5514705882352942, Validation Loss: 5.359100818634033, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3941/10000, Training Loss: 1.9711557626724243, Training Accuracy: 0.5808823529411765, Validation Loss: 2.785585403442383, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3942/10000, Training Loss: 1.5222102403640747, Training Accuracy: 0.6004901960784313, Validation Loss: 2.174699068069458, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3943/10000, Training Loss: 2.4274890422821045, Training Accuracy: 0.5294117647058824, Validation Loss: 1.9122816324234009, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3944/10000, Training Loss: 1.7536598443984985, Training Accuracy: 0.5931372549019608, Validation Loss: 1.7468571662902832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3945/10000, Training Loss: 1.7753409147262573, Training Accuracy: 0.5465686274509803, Validation Loss: 4.016003131866455, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3946/10000, Training Loss: 1.925290822982788, Training Accuracy: 0.5735294117647058, Validation Loss: 1.1839731931686401, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3947/10000, Training Loss: 1.8136392831802368, Training Accuracy: 0.553921568627451, Validation Loss: 2.200199842453003, Validation Accuracy: 0.5\n",
      "Epoch 3948/10000, Training Loss: 1.911391019821167, Training Accuracy: 0.5637254901960784, Validation Loss: 2.3569347858428955, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3949/10000, Training Loss: 2.2010133266448975, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2629907131195068, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3950/10000, Training Loss: 1.807682991027832, Training Accuracy: 0.5588235294117647, Validation Loss: 1.3322817087173462, Validation Accuracy: 0.75\n",
      "Epoch 3951/10000, Training Loss: 1.1492687463760376, Training Accuracy: 0.6004901960784313, Validation Loss: 2.6675968170166016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3952/10000, Training Loss: 1.2415132522583008, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7447938919067383, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3953/10000, Training Loss: 1.941147804260254, Training Accuracy: 0.6200980392156863, Validation Loss: 2.8507392406463623, Validation Accuracy: 0.5\n",
      "Epoch 3954/10000, Training Loss: 2.08933162689209, Training Accuracy: 0.5122549019607843, Validation Loss: 0.6494016647338867, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3955/10000, Training Loss: 2.087636709213257, Training Accuracy: 0.5147058823529411, Validation Loss: 2.704498052597046, Validation Accuracy: 0.5\n",
      "Epoch 3956/10000, Training Loss: 1.5211697816848755, Training Accuracy: 0.5857843137254902, Validation Loss: 2.56317400932312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3957/10000, Training Loss: 1.431330680847168, Training Accuracy: 0.5784313725490197, Validation Loss: 6.912349700927734, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3958/10000, Training Loss: 1.9597761631011963, Training Accuracy: 0.49264705882352944, Validation Loss: 2.6449015140533447, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3959/10000, Training Loss: 2.3912487030029297, Training Accuracy: 0.5416666666666666, Validation Loss: 2.6963112354278564, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3960/10000, Training Loss: 1.4905446767807007, Training Accuracy: 0.6029411764705882, Validation Loss: 4.833724498748779, Validation Accuracy: 0.25\n",
      "Epoch 3961/10000, Training Loss: 1.8439534902572632, Training Accuracy: 0.5882352941176471, Validation Loss: 1.6313375234603882, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3962/10000, Training Loss: 2.026144027709961, Training Accuracy: 0.5465686274509803, Validation Loss: 1.3136106729507446, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3963/10000, Training Loss: 1.6621006727218628, Training Accuracy: 0.5514705882352942, Validation Loss: 3.3598291873931885, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3964/10000, Training Loss: 1.7610418796539307, Training Accuracy: 0.5931372549019608, Validation Loss: 2.0948147773742676, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3965/10000, Training Loss: 2.1046364307403564, Training Accuracy: 0.5588235294117647, Validation Loss: 3.07855486869812, Validation Accuracy: 0.25\n",
      "Epoch 3966/10000, Training Loss: 1.561482310295105, Training Accuracy: 0.6029411764705882, Validation Loss: 1.6528205871582031, Validation Accuracy: 0.5\n",
      "Epoch 3967/10000, Training Loss: 2.0053646564483643, Training Accuracy: 0.5441176470588235, Validation Loss: 3.1561710834503174, Validation Accuracy: 0.5\n",
      "Epoch 3968/10000, Training Loss: 1.6141890287399292, Training Accuracy: 0.5220588235294118, Validation Loss: 2.328944444656372, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3969/10000, Training Loss: 1.4091936349868774, Training Accuracy: 0.5563725490196079, Validation Loss: 1.8685506582260132, Validation Accuracy: 0.25\n",
      "Epoch 3970/10000, Training Loss: 2.2493863105773926, Training Accuracy: 0.5637254901960784, Validation Loss: 3.6076080799102783, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3971/10000, Training Loss: 1.5344594717025757, Training Accuracy: 0.5514705882352942, Validation Loss: 1.246729850769043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3972/10000, Training Loss: 2.3987672328948975, Training Accuracy: 0.5661764705882353, Validation Loss: 8.723108291625977, Validation Accuracy: 0.5\n",
      "Epoch 3973/10000, Training Loss: 1.1196142435073853, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7804796099662781, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3974/10000, Training Loss: 1.8064489364624023, Training Accuracy: 0.553921568627451, Validation Loss: 3.7083966732025146, Validation Accuracy: 0.5\n",
      "Epoch 3975/10000, Training Loss: 1.5002398490905762, Training Accuracy: 0.5661764705882353, Validation Loss: 2.2062366008758545, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3976/10000, Training Loss: 1.462365984916687, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9146642684936523, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3977/10000, Training Loss: 2.0017948150634766, Training Accuracy: 0.5686274509803921, Validation Loss: 1.4803614616394043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3978/10000, Training Loss: 1.7710464000701904, Training Accuracy: 0.5686274509803921, Validation Loss: 2.4511566162109375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3979/10000, Training Loss: 1.4497079849243164, Training Accuracy: 0.571078431372549, Validation Loss: 2.4261043071746826, Validation Accuracy: 0.5\n",
      "Epoch 3980/10000, Training Loss: 1.6871579885482788, Training Accuracy: 0.6102941176470589, Validation Loss: 2.23388934135437, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3981/10000, Training Loss: 1.8151651620864868, Training Accuracy: 0.5759803921568627, Validation Loss: 3.9247207641601562, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3982/10000, Training Loss: 1.0665652751922607, Training Accuracy: 0.6004901960784313, Validation Loss: 1.5162768363952637, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3983/10000, Training Loss: 1.9427183866500854, Training Accuracy: 0.5318627450980392, Validation Loss: 4.037393093109131, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3984/10000, Training Loss: 2.823516845703125, Training Accuracy: 0.5490196078431373, Validation Loss: 3.1156673431396484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3985/10000, Training Loss: 1.770265817642212, Training Accuracy: 0.5563725490196079, Validation Loss: 2.0101308822631836, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3986/10000, Training Loss: 1.9477585554122925, Training Accuracy: 0.5661764705882353, Validation Loss: 2.7026774883270264, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3987/10000, Training Loss: 1.5547199249267578, Training Accuracy: 0.6421568627450981, Validation Loss: 1.2983781099319458, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3988/10000, Training Loss: 1.6747523546218872, Training Accuracy: 0.5612745098039216, Validation Loss: 2.628748893737793, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 3989/10000, Training Loss: 1.7458163499832153, Training Accuracy: 0.5563725490196079, Validation Loss: 1.5278674364089966, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3990/10000, Training Loss: 1.9485992193222046, Training Accuracy: 0.6200980392156863, Validation Loss: 2.2961695194244385, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3991/10000, Training Loss: 1.3060643672943115, Training Accuracy: 0.5612745098039216, Validation Loss: 2.3740410804748535, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3992/10000, Training Loss: 2.4069020748138428, Training Accuracy: 0.6274509803921569, Validation Loss: 3.20243763923645, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3993/10000, Training Loss: 1.897681713104248, Training Accuracy: 0.5514705882352942, Validation Loss: 2.6097981929779053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 3994/10000, Training Loss: 1.183742880821228, Training Accuracy: 0.6053921568627451, Validation Loss: 2.6231019496917725, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 3995/10000, Training Loss: 1.6710561513900757, Training Accuracy: 0.5661764705882353, Validation Loss: 1.9601445198059082, Validation Accuracy: 0.5\n",
      "Epoch 3996/10000, Training Loss: 2.184293031692505, Training Accuracy: 0.6004901960784313, Validation Loss: 1.4823857545852661, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 3997/10000, Training Loss: 1.407346248626709, Training Accuracy: 0.5588235294117647, Validation Loss: 0.9890801906585693, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 3998/10000, Training Loss: 2.001572608947754, Training Accuracy: 0.5931372549019608, Validation Loss: 2.3667078018188477, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 3999/10000, Training Loss: 1.3613361120224, Training Accuracy: 0.6102941176470589, Validation Loss: 2.245716094970703, Validation Accuracy: 0.25\n",
      "Epoch 4000/10000, Training Loss: 1.4795085191726685, Training Accuracy: 0.6029411764705882, Validation Loss: 3.951061964035034, Validation Accuracy: 0.5\n",
      "Epoch 4001/10000, Training Loss: 1.3445004224777222, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0801702737808228, Validation Accuracy: 0.5\n",
      "Epoch 4002/10000, Training Loss: 2.229771614074707, Training Accuracy: 0.6078431372549019, Validation Loss: 1.6080046892166138, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4003/10000, Training Loss: 1.3568776845932007, Training Accuracy: 0.5465686274509803, Validation Loss: 1.304656982421875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4004/10000, Training Loss: 1.3433210849761963, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1090017557144165, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4005/10000, Training Loss: 1.8981049060821533, Training Accuracy: 0.6446078431372549, Validation Loss: 2.3655755519866943, Validation Accuracy: 0.5\n",
      "Epoch 4006/10000, Training Loss: 1.565155029296875, Training Accuracy: 0.5294117647058824, Validation Loss: 0.5316582322120667, Validation Accuracy: 0.5\n",
      "Epoch 4007/10000, Training Loss: 1.464617371559143, Training Accuracy: 0.6225490196078431, Validation Loss: 1.5303888320922852, Validation Accuracy: 0.5\n",
      "Epoch 4008/10000, Training Loss: 2.0948758125305176, Training Accuracy: 0.5637254901960784, Validation Loss: 3.4894073009490967, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4009/10000, Training Loss: 2.4861419200897217, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3299933671951294, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4010/10000, Training Loss: 1.921252965927124, Training Accuracy: 0.5808823529411765, Validation Loss: 1.8347622156143188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4011/10000, Training Loss: 1.2686246633529663, Training Accuracy: 0.625, Validation Loss: 1.2599726915359497, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4012/10000, Training Loss: 1.806602120399475, Training Accuracy: 0.5784313725490197, Validation Loss: 2.8164803981781006, Validation Accuracy: 0.5\n",
      "Epoch 4013/10000, Training Loss: 2.2283480167388916, Training Accuracy: 0.5343137254901961, Validation Loss: 5.696811199188232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4014/10000, Training Loss: 2.18324613571167, Training Accuracy: 0.6151960784313726, Validation Loss: 3.1722936630249023, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4015/10000, Training Loss: 1.7891457080841064, Training Accuracy: 0.5833333333333334, Validation Loss: 6.5467658042907715, Validation Accuracy: 0.5\n",
      "Epoch 4016/10000, Training Loss: 1.2949223518371582, Training Accuracy: 0.625, Validation Loss: 1.0357471704483032, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4017/10000, Training Loss: 1.8381043672561646, Training Accuracy: 0.5245098039215687, Validation Loss: 2.7893028259277344, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4018/10000, Training Loss: 1.549666166305542, Training Accuracy: 0.5637254901960784, Validation Loss: 1.3339548110961914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4019/10000, Training Loss: 1.6280285120010376, Training Accuracy: 0.5392156862745098, Validation Loss: 1.0109864473342896, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4020/10000, Training Loss: 1.6850522756576538, Training Accuracy: 0.5759803921568627, Validation Loss: 2.438661813735962, Validation Accuracy: 0.5\n",
      "Epoch 4021/10000, Training Loss: 1.5888206958770752, Training Accuracy: 0.5808823529411765, Validation Loss: 1.8755985498428345, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4022/10000, Training Loss: 1.5459097623825073, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6957640051841736, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4023/10000, Training Loss: 1.7281967401504517, Training Accuracy: 0.5882352941176471, Validation Loss: 2.130671739578247, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4024/10000, Training Loss: 1.8337578773498535, Training Accuracy: 0.5882352941176471, Validation Loss: 1.2479891777038574, Validation Accuracy: 0.5\n",
      "Epoch 4025/10000, Training Loss: 1.6042382717132568, Training Accuracy: 0.6053921568627451, Validation Loss: 1.9464839696884155, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4026/10000, Training Loss: 1.8997291326522827, Training Accuracy: 0.5343137254901961, Validation Loss: 1.1311513185501099, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4027/10000, Training Loss: 1.9244881868362427, Training Accuracy: 0.5808823529411765, Validation Loss: 2.8760645389556885, Validation Accuracy: 0.25\n",
      "Epoch 4028/10000, Training Loss: 1.7837902307510376, Training Accuracy: 0.5612745098039216, Validation Loss: 2.160503625869751, Validation Accuracy: 0.5\n",
      "Epoch 4029/10000, Training Loss: 1.8093163967132568, Training Accuracy: 0.5955882352941176, Validation Loss: 2.845905303955078, Validation Accuracy: 0.5\n",
      "Epoch 4030/10000, Training Loss: 1.4714548587799072, Training Accuracy: 0.5980392156862745, Validation Loss: 4.327090263366699, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4031/10000, Training Loss: 1.4693585634231567, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8662538528442383, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4032/10000, Training Loss: 1.9416980743408203, Training Accuracy: 0.5465686274509803, Validation Loss: 4.007013320922852, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4033/10000, Training Loss: 1.3710896968841553, Training Accuracy: 0.5392156862745098, Validation Loss: 0.7775797843933105, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4034/10000, Training Loss: 1.461564302444458, Training Accuracy: 0.5416666666666666, Validation Loss: 2.890451192855835, Validation Accuracy: 0.5\n",
      "Epoch 4035/10000, Training Loss: 1.3914291858673096, Training Accuracy: 0.5833333333333334, Validation Loss: 3.719728469848633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4036/10000, Training Loss: 1.5723966360092163, Training Accuracy: 0.5392156862745098, Validation Loss: 2.585779905319214, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4037/10000, Training Loss: 1.6926804780960083, Training Accuracy: 0.5955882352941176, Validation Loss: 1.6386336088180542, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4038/10000, Training Loss: 1.6860991716384888, Training Accuracy: 0.5416666666666666, Validation Loss: 1.3457428216934204, Validation Accuracy: 0.5\n",
      "Epoch 4039/10000, Training Loss: 1.5287811756134033, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6309882402420044, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4040/10000, Training Loss: 1.7297821044921875, Training Accuracy: 0.49264705882352944, Validation Loss: 2.2632720470428467, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4041/10000, Training Loss: 1.508573055267334, Training Accuracy: 0.5759803921568627, Validation Loss: 1.4979254007339478, Validation Accuracy: 0.75\n",
      "Epoch 4042/10000, Training Loss: 1.6580944061279297, Training Accuracy: 0.49754901960784315, Validation Loss: 2.0117509365081787, Validation Accuracy: 0.5\n",
      "Epoch 4043/10000, Training Loss: 1.5772727727890015, Training Accuracy: 0.5588235294117647, Validation Loss: 2.7000274658203125, Validation Accuracy: 0.5\n",
      "Epoch 4044/10000, Training Loss: 2.594902753829956, Training Accuracy: 0.5759803921568627, Validation Loss: 3.428306818008423, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4045/10000, Training Loss: 1.3260324001312256, Training Accuracy: 0.5637254901960784, Validation Loss: 1.332194209098816, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4046/10000, Training Loss: 2.2053306102752686, Training Accuracy: 0.5563725490196079, Validation Loss: 4.081073760986328, Validation Accuracy: 0.5\n",
      "Epoch 4047/10000, Training Loss: 1.4351030588150024, Training Accuracy: 0.5220588235294118, Validation Loss: 1.8731470108032227, Validation Accuracy: 0.5\n",
      "Epoch 4048/10000, Training Loss: 1.226240873336792, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0584375858306885, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4049/10000, Training Loss: 1.7209937572479248, Training Accuracy: 0.5490196078431373, Validation Loss: 1.7665033340454102, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4050/10000, Training Loss: 2.0804035663604736, Training Accuracy: 0.5784313725490197, Validation Loss: 3.751851797103882, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4051/10000, Training Loss: 1.5330175161361694, Training Accuracy: 0.5661764705882353, Validation Loss: 1.4208449125289917, Validation Accuracy: 0.5\n",
      "Epoch 4052/10000, Training Loss: 1.5640459060668945, Training Accuracy: 0.5882352941176471, Validation Loss: 1.9177861213684082, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4053/10000, Training Loss: 1.47263765335083, Training Accuracy: 0.5367647058823529, Validation Loss: 2.7277393341064453, Validation Accuracy: 0.5\n",
      "Epoch 4054/10000, Training Loss: 1.3680320978164673, Training Accuracy: 0.6127450980392157, Validation Loss: 2.4455747604370117, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4055/10000, Training Loss: 1.2948801517486572, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7034279704093933, Validation Accuracy: 0.75\n",
      "Epoch 4056/10000, Training Loss: 1.730420470237732, Training Accuracy: 0.6078431372549019, Validation Loss: 2.085097074508667, Validation Accuracy: 0.5\n",
      "Epoch 4057/10000, Training Loss: 1.411110281944275, Training Accuracy: 0.5441176470588235, Validation Loss: 3.1235268115997314, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4058/10000, Training Loss: 1.6168030500411987, Training Accuracy: 0.5661764705882353, Validation Loss: 3.6025049686431885, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4059/10000, Training Loss: 2.493407964706421, Training Accuracy: 0.5759803921568627, Validation Loss: 2.4252560138702393, Validation Accuracy: 0.5\n",
      "Epoch 4060/10000, Training Loss: 1.962902545928955, Training Accuracy: 0.5269607843137255, Validation Loss: 4.099058628082275, Validation Accuracy: 0.5\n",
      "Epoch 4061/10000, Training Loss: 1.852626919746399, Training Accuracy: 0.5147058823529411, Validation Loss: 1.7617955207824707, Validation Accuracy: 0.5\n",
      "Epoch 4062/10000, Training Loss: 1.2087348699569702, Training Accuracy: 0.5882352941176471, Validation Loss: 1.6815065145492554, Validation Accuracy: 0.5\n",
      "Epoch 4063/10000, Training Loss: 1.625089406967163, Training Accuracy: 0.5318627450980392, Validation Loss: 2.337939977645874, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4064/10000, Training Loss: 1.8004037141799927, Training Accuracy: 0.5416666666666666, Validation Loss: 2.9230129718780518, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4065/10000, Training Loss: 1.544332504272461, Training Accuracy: 0.5808823529411765, Validation Loss: 2.9993810653686523, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4066/10000, Training Loss: 1.7807599306106567, Training Accuracy: 0.6029411764705882, Validation Loss: 1.5538544654846191, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4067/10000, Training Loss: 1.2607393264770508, Training Accuracy: 0.6078431372549019, Validation Loss: 1.4979904890060425, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4068/10000, Training Loss: 1.9425108432769775, Training Accuracy: 0.5514705882352942, Validation Loss: 5.590287685394287, Validation Accuracy: 0.5\n",
      "Epoch 4069/10000, Training Loss: 1.9232659339904785, Training Accuracy: 0.5931372549019608, Validation Loss: 1.5524989366531372, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4070/10000, Training Loss: 1.85270357131958, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8094855546951294, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4071/10000, Training Loss: 1.4088411331176758, Training Accuracy: 0.5931372549019608, Validation Loss: 1.5343971252441406, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4072/10000, Training Loss: 2.1410470008850098, Training Accuracy: 0.6151960784313726, Validation Loss: 3.1272213459014893, Validation Accuracy: 0.5\n",
      "Epoch 4073/10000, Training Loss: 2.1845860481262207, Training Accuracy: 0.5514705882352942, Validation Loss: 3.6804263591766357, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4074/10000, Training Loss: 1.7679353952407837, Training Accuracy: 0.5808823529411765, Validation Loss: 1.3482626676559448, Validation Accuracy: 0.75\n",
      "Epoch 4075/10000, Training Loss: 1.5185216665267944, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8498227000236511, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4076/10000, Training Loss: 1.7492903470993042, Training Accuracy: 0.5857843137254902, Validation Loss: 2.6699094772338867, Validation Accuracy: 0.5\n",
      "Epoch 4077/10000, Training Loss: 2.235529661178589, Training Accuracy: 0.5955882352941176, Validation Loss: 2.98063588142395, Validation Accuracy: 0.5\n",
      "Epoch 4078/10000, Training Loss: 1.3723102807998657, Training Accuracy: 0.5857843137254902, Validation Loss: 2.707221031188965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4079/10000, Training Loss: 1.5679737329483032, Training Accuracy: 0.5049019607843137, Validation Loss: 1.0543098449707031, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4080/10000, Training Loss: 2.2096800804138184, Training Accuracy: 0.5980392156862745, Validation Loss: 3.634157419204712, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4081/10000, Training Loss: 1.3807846307754517, Training Accuracy: 0.5784313725490197, Validation Loss: 2.0659377574920654, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4082/10000, Training Loss: 2.273540496826172, Training Accuracy: 0.571078431372549, Validation Loss: 2.39184308052063, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4083/10000, Training Loss: 1.5932296514511108, Training Accuracy: 0.6053921568627451, Validation Loss: 3.6736574172973633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4084/10000, Training Loss: 1.8586467504501343, Training Accuracy: 0.553921568627451, Validation Loss: 1.1015832424163818, Validation Accuracy: 0.5\n",
      "Epoch 4085/10000, Training Loss: 1.738913893699646, Training Accuracy: 0.5392156862745098, Validation Loss: 6.690395355224609, Validation Accuracy: 0.25\n",
      "Epoch 4086/10000, Training Loss: 1.1427552700042725, Training Accuracy: 0.5833333333333334, Validation Loss: 2.07378888130188, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4087/10000, Training Loss: 1.4267672300338745, Training Accuracy: 0.6348039215686274, Validation Loss: 2.960369110107422, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4088/10000, Training Loss: 1.297865867614746, Training Accuracy: 0.5637254901960784, Validation Loss: 1.7109394073486328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4089/10000, Training Loss: 1.5747779607772827, Training Accuracy: 0.5367647058823529, Validation Loss: 1.608273983001709, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4090/10000, Training Loss: 1.3537116050720215, Training Accuracy: 0.5808823529411765, Validation Loss: 1.9176020622253418, Validation Accuracy: 0.5\n",
      "Epoch 4091/10000, Training Loss: 1.7136223316192627, Training Accuracy: 0.5980392156862745, Validation Loss: 1.663390040397644, Validation Accuracy: 0.5\n",
      "Epoch 4092/10000, Training Loss: 1.9623173475265503, Training Accuracy: 0.571078431372549, Validation Loss: 2.514174222946167, Validation Accuracy: 0.5\n",
      "Epoch 4093/10000, Training Loss: 1.9567373991012573, Training Accuracy: 0.5367647058823529, Validation Loss: 1.2673300504684448, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4094/10000, Training Loss: 1.7080265283584595, Training Accuracy: 0.5612745098039216, Validation Loss: 3.338107109069824, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4095/10000, Training Loss: 1.533808946609497, Training Accuracy: 0.6004901960784313, Validation Loss: 1.674025058746338, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4096/10000, Training Loss: 1.3154841661453247, Training Accuracy: 0.6078431372549019, Validation Loss: 1.7259597778320312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4097/10000, Training Loss: 1.6312432289123535, Training Accuracy: 0.5343137254901961, Validation Loss: 2.7885284423828125, Validation Accuracy: 0.5\n",
      "Epoch 4098/10000, Training Loss: 1.4033938646316528, Training Accuracy: 0.5808823529411765, Validation Loss: 3.0965662002563477, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4099/10000, Training Loss: 1.963014841079712, Training Accuracy: 0.5612745098039216, Validation Loss: 3.4958889484405518, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4100/10000, Training Loss: 2.0915894508361816, Training Accuracy: 0.6176470588235294, Validation Loss: 3.192199945449829, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4101/10000, Training Loss: 1.8404018878936768, Training Accuracy: 0.6397058823529411, Validation Loss: 3.350632429122925, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4102/10000, Training Loss: 1.4255547523498535, Training Accuracy: 0.5759803921568627, Validation Loss: 1.2571886777877808, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4103/10000, Training Loss: 1.1561559438705444, Training Accuracy: 0.6421568627450981, Validation Loss: 4.0233635902404785, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4104/10000, Training Loss: 1.5459736585617065, Training Accuracy: 0.5441176470588235, Validation Loss: 2.230895519256592, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4105/10000, Training Loss: 0.9534773230552673, Training Accuracy: 0.6274509803921569, Validation Loss: 1.3137017488479614, Validation Accuracy: 0.5\n",
      "Epoch 4106/10000, Training Loss: 1.4482380151748657, Training Accuracy: 0.5098039215686274, Validation Loss: 1.1836256980895996, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4107/10000, Training Loss: 1.5029566287994385, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8424065709114075, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4108/10000, Training Loss: 1.5808769464492798, Training Accuracy: 0.5392156862745098, Validation Loss: 1.4331108331680298, Validation Accuracy: 0.5\n",
      "Epoch 4109/10000, Training Loss: 1.7772761583328247, Training Accuracy: 0.4852941176470588, Validation Loss: 1.806279182434082, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4110/10000, Training Loss: 1.7921078205108643, Training Accuracy: 0.5612745098039216, Validation Loss: 2.726379156112671, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4111/10000, Training Loss: 1.44777250289917, Training Accuracy: 0.5980392156862745, Validation Loss: 3.3257482051849365, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4112/10000, Training Loss: 1.6446789503097534, Training Accuracy: 0.5343137254901961, Validation Loss: 1.8512510061264038, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4113/10000, Training Loss: 1.3865387439727783, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9002883434295654, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4114/10000, Training Loss: 1.3456716537475586, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1654244661331177, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4115/10000, Training Loss: 1.8735907077789307, Training Accuracy: 0.49264705882352944, Validation Loss: 0.613117516040802, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4116/10000, Training Loss: 1.7128243446350098, Training Accuracy: 0.5857843137254902, Validation Loss: 2.179753541946411, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4117/10000, Training Loss: 1.2516900300979614, Training Accuracy: 0.5563725490196079, Validation Loss: 1.08444082736969, Validation Accuracy: 0.5\n",
      "Epoch 4118/10000, Training Loss: 1.88308846950531, Training Accuracy: 0.5122549019607843, Validation Loss: 4.275546550750732, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4119/10000, Training Loss: 1.1758253574371338, Training Accuracy: 0.625, Validation Loss: 1.6237221956253052, Validation Accuracy: 0.5\n",
      "Epoch 4120/10000, Training Loss: 1.52931809425354, Training Accuracy: 0.5735294117647058, Validation Loss: 2.1420953273773193, Validation Accuracy: 0.5\n",
      "Epoch 4121/10000, Training Loss: 1.752626657485962, Training Accuracy: 0.5612745098039216, Validation Loss: 2.059413194656372, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4122/10000, Training Loss: 1.7422837018966675, Training Accuracy: 0.5784313725490197, Validation Loss: 1.0899608135223389, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4123/10000, Training Loss: 1.512497067451477, Training Accuracy: 0.5563725490196079, Validation Loss: 3.6142337322235107, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4124/10000, Training Loss: 1.7736315727233887, Training Accuracy: 0.6200980392156863, Validation Loss: 3.1614532470703125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4125/10000, Training Loss: 1.430639624595642, Training Accuracy: 0.5588235294117647, Validation Loss: 1.9810434579849243, Validation Accuracy: 0.5\n",
      "Epoch 4126/10000, Training Loss: 1.2691223621368408, Training Accuracy: 0.5882352941176471, Validation Loss: 1.198872447013855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4127/10000, Training Loss: 1.869521141052246, Training Accuracy: 0.5220588235294118, Validation Loss: 2.4019339084625244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4128/10000, Training Loss: 1.7506372928619385, Training Accuracy: 0.5318627450980392, Validation Loss: 5.056727886199951, Validation Accuracy: 0.25\n",
      "Epoch 4129/10000, Training Loss: 1.317589521408081, Training Accuracy: 0.5588235294117647, Validation Loss: 2.3736283779144287, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4130/10000, Training Loss: 1.2448039054870605, Training Accuracy: 0.5808823529411765, Validation Loss: 3.291666269302368, Validation Accuracy: 0.25\n",
      "Epoch 4131/10000, Training Loss: 1.3828781843185425, Training Accuracy: 0.571078431372549, Validation Loss: 1.8159104585647583, Validation Accuracy: 0.25\n",
      "Epoch 4132/10000, Training Loss: 1.1518667936325073, Training Accuracy: 0.6078431372549019, Validation Loss: 1.2118070125579834, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4133/10000, Training Loss: 1.9143096208572388, Training Accuracy: 0.6421568627450981, Validation Loss: 4.373664379119873, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4134/10000, Training Loss: 1.6151517629623413, Training Accuracy: 0.571078431372549, Validation Loss: 2.059983015060425, Validation Accuracy: 0.5\n",
      "Epoch 4135/10000, Training Loss: 1.9197388887405396, Training Accuracy: 0.553921568627451, Validation Loss: 2.9974870681762695, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4136/10000, Training Loss: 1.654848575592041, Training Accuracy: 0.5906862745098039, Validation Loss: 1.9150539636611938, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4137/10000, Training Loss: 2.1017470359802246, Training Accuracy: 0.5980392156862745, Validation Loss: 1.5739670991897583, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4138/10000, Training Loss: 1.638001799583435, Training Accuracy: 0.6372549019607843, Validation Loss: 2.715747594833374, Validation Accuracy: 0.5\n",
      "Epoch 4139/10000, Training Loss: 1.9046248197555542, Training Accuracy: 0.5661764705882353, Validation Loss: 2.845802068710327, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4140/10000, Training Loss: 1.8671679496765137, Training Accuracy: 0.6004901960784313, Validation Loss: 1.9026403427124023, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4141/10000, Training Loss: 2.0400753021240234, Training Accuracy: 0.5514705882352942, Validation Loss: 1.6675022840499878, Validation Accuracy: 0.5\n",
      "Epoch 4142/10000, Training Loss: 1.5375558137893677, Training Accuracy: 0.5514705882352942, Validation Loss: 1.430208683013916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4143/10000, Training Loss: 1.4730652570724487, Training Accuracy: 0.5955882352941176, Validation Loss: 1.492965817451477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4144/10000, Training Loss: 1.510064721107483, Training Accuracy: 0.5759803921568627, Validation Loss: 1.8016213178634644, Validation Accuracy: 0.5\n",
      "Epoch 4145/10000, Training Loss: 1.4496036767959595, Training Accuracy: 0.5588235294117647, Validation Loss: 2.81075119972229, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4146/10000, Training Loss: 1.2636823654174805, Training Accuracy: 0.5294117647058824, Validation Loss: 0.7645809650421143, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4147/10000, Training Loss: 1.7133660316467285, Training Accuracy: 0.5686274509803921, Validation Loss: 3.4472782611846924, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4148/10000, Training Loss: 1.3734806776046753, Training Accuracy: 0.6004901960784313, Validation Loss: 2.5386593341827393, Validation Accuracy: 0.5\n",
      "Epoch 4149/10000, Training Loss: 2.1452910900115967, Training Accuracy: 0.5024509803921569, Validation Loss: 3.1821072101593018, Validation Accuracy: 0.5\n",
      "Epoch 4150/10000, Training Loss: 1.7855905294418335, Training Accuracy: 0.5906862745098039, Validation Loss: 2.241285800933838, Validation Accuracy: 0.5\n",
      "Epoch 4151/10000, Training Loss: 1.5779212713241577, Training Accuracy: 0.5416666666666666, Validation Loss: 1.2718853950500488, Validation Accuracy: 0.5\n",
      "Epoch 4152/10000, Training Loss: 1.3810393810272217, Training Accuracy: 0.6274509803921569, Validation Loss: 1.4901398420333862, Validation Accuracy: 0.75\n",
      "Epoch 4153/10000, Training Loss: 1.3890377283096313, Training Accuracy: 0.553921568627451, Validation Loss: 0.6560032963752747, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4154/10000, Training Loss: 2.040029287338257, Training Accuracy: 0.49754901960784315, Validation Loss: 2.1135566234588623, Validation Accuracy: 0.5\n",
      "Epoch 4155/10000, Training Loss: 1.3914636373519897, Training Accuracy: 0.5416666666666666, Validation Loss: 1.577229619026184, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4156/10000, Training Loss: 2.1362996101379395, Training Accuracy: 0.5441176470588235, Validation Loss: 1.6245509386062622, Validation Accuracy: 0.5\n",
      "Epoch 4157/10000, Training Loss: 1.2496042251586914, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9215466976165771, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4158/10000, Training Loss: 1.880549669265747, Training Accuracy: 0.5514705882352942, Validation Loss: 2.1611623764038086, Validation Accuracy: 0.25\n",
      "Epoch 4159/10000, Training Loss: 1.5070478916168213, Training Accuracy: 0.5759803921568627, Validation Loss: 2.257798433303833, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4160/10000, Training Loss: 1.890876293182373, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3596206903457642, Validation Accuracy: 0.5\n",
      "Epoch 4161/10000, Training Loss: 1.90967857837677, Training Accuracy: 0.47058823529411764, Validation Loss: 3.3236472606658936, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4162/10000, Training Loss: 1.540670394897461, Training Accuracy: 0.5980392156862745, Validation Loss: 2.474421501159668, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4163/10000, Training Loss: 2.6299734115600586, Training Accuracy: 0.5563725490196079, Validation Loss: 2.9033548831939697, Validation Accuracy: 0.5\n",
      "Epoch 4164/10000, Training Loss: 1.3170150518417358, Training Accuracy: 0.5882352941176471, Validation Loss: 1.8969916105270386, Validation Accuracy: 0.5\n",
      "Epoch 4165/10000, Training Loss: 1.9920810461044312, Training Accuracy: 0.5833333333333334, Validation Loss: 1.8259745836257935, Validation Accuracy: 0.5\n",
      "Epoch 4166/10000, Training Loss: 1.8596175909042358, Training Accuracy: 0.5637254901960784, Validation Loss: 2.733530282974243, Validation Accuracy: 0.25\n",
      "Epoch 4167/10000, Training Loss: 1.9698238372802734, Training Accuracy: 0.5759803921568627, Validation Loss: 3.499688148498535, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4168/10000, Training Loss: 1.6935882568359375, Training Accuracy: 0.5857843137254902, Validation Loss: 2.2101309299468994, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4169/10000, Training Loss: 1.5285751819610596, Training Accuracy: 0.6029411764705882, Validation Loss: 2.201115369796753, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4170/10000, Training Loss: 1.7013362646102905, Training Accuracy: 0.5735294117647058, Validation Loss: 2.462996006011963, Validation Accuracy: 0.25\n",
      "Epoch 4171/10000, Training Loss: 1.3999356031417847, Training Accuracy: 0.5637254901960784, Validation Loss: 2.3111891746520996, Validation Accuracy: 0.5\n",
      "Epoch 4172/10000, Training Loss: 1.4818521738052368, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8824014067649841, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4173/10000, Training Loss: 1.8218237161636353, Training Accuracy: 0.553921568627451, Validation Loss: 2.6849164962768555, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4174/10000, Training Loss: 1.3489806652069092, Training Accuracy: 0.5294117647058824, Validation Loss: 1.5573816299438477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4175/10000, Training Loss: 1.620844841003418, Training Accuracy: 0.5367647058823529, Validation Loss: 1.4774636030197144, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4176/10000, Training Loss: 1.5377155542373657, Training Accuracy: 0.5612745098039216, Validation Loss: 2.8786046504974365, Validation Accuracy: 0.25\n",
      "Epoch 4177/10000, Training Loss: 1.8421955108642578, Training Accuracy: 0.5490196078431373, Validation Loss: 3.427807092666626, Validation Accuracy: 0.5\n",
      "Epoch 4178/10000, Training Loss: 1.7282696962356567, Training Accuracy: 0.553921568627451, Validation Loss: 2.4007692337036133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4179/10000, Training Loss: 1.3517858982086182, Training Accuracy: 0.5906862745098039, Validation Loss: 1.671513557434082, Validation Accuracy: 0.5\n",
      "Epoch 4180/10000, Training Loss: 1.3074301481246948, Training Accuracy: 0.5980392156862745, Validation Loss: 1.9957901239395142, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4181/10000, Training Loss: 1.630079984664917, Training Accuracy: 0.625, Validation Loss: 1.357932209968567, Validation Accuracy: 0.5\n",
      "Epoch 4182/10000, Training Loss: 1.291126012802124, Training Accuracy: 0.5759803921568627, Validation Loss: 1.2518752813339233, Validation Accuracy: 0.5\n",
      "Epoch 4183/10000, Training Loss: 1.6350373029708862, Training Accuracy: 0.5833333333333334, Validation Loss: 1.112488031387329, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4184/10000, Training Loss: 1.6318821907043457, Training Accuracy: 0.5808823529411765, Validation Loss: 1.4333046674728394, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4185/10000, Training Loss: 1.7437573671340942, Training Accuracy: 0.5416666666666666, Validation Loss: 1.0016363859176636, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4186/10000, Training Loss: 1.7140427827835083, Training Accuracy: 0.5098039215686274, Validation Loss: 2.127220869064331, Validation Accuracy: 0.5\n",
      "Epoch 4187/10000, Training Loss: 2.4327988624572754, Training Accuracy: 0.553921568627451, Validation Loss: 2.2609057426452637, Validation Accuracy: 0.5\n",
      "Epoch 4188/10000, Training Loss: 1.2969108819961548, Training Accuracy: 0.6151960784313726, Validation Loss: 1.4921125173568726, Validation Accuracy: 0.5\n",
      "Epoch 4189/10000, Training Loss: 1.9698877334594727, Training Accuracy: 0.5514705882352942, Validation Loss: 1.8376237154006958, Validation Accuracy: 0.5\n",
      "Epoch 4190/10000, Training Loss: 2.1485605239868164, Training Accuracy: 0.5857843137254902, Validation Loss: 3.3957881927490234, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4191/10000, Training Loss: 1.3666635751724243, Training Accuracy: 0.5416666666666666, Validation Loss: 2.1480553150177, Validation Accuracy: 0.5\n",
      "Epoch 4192/10000, Training Loss: 1.3501461744308472, Training Accuracy: 0.571078431372549, Validation Loss: 2.279663324356079, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4193/10000, Training Loss: 1.2073863744735718, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7574931383132935, Validation Accuracy: 0.5\n",
      "Epoch 4194/10000, Training Loss: 1.5360242128372192, Training Accuracy: 0.5196078431372549, Validation Loss: 1.4740420579910278, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4195/10000, Training Loss: 1.5759968757629395, Training Accuracy: 0.5441176470588235, Validation Loss: 2.8836829662323, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4196/10000, Training Loss: 1.3328779935836792, Training Accuracy: 0.571078431372549, Validation Loss: 2.959289789199829, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4197/10000, Training Loss: 1.242125153541565, Training Accuracy: 0.5563725490196079, Validation Loss: 2.2651798725128174, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4198/10000, Training Loss: 1.8319982290267944, Training Accuracy: 0.45588235294117646, Validation Loss: 1.0760772228240967, Validation Accuracy: 0.75\n",
      "Epoch 4199/10000, Training Loss: 1.341029405593872, Training Accuracy: 0.5931372549019608, Validation Loss: 2.0112364292144775, Validation Accuracy: 0.5\n",
      "Epoch 4200/10000, Training Loss: 1.7871452569961548, Training Accuracy: 0.5563725490196079, Validation Loss: 1.458474040031433, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4201/10000, Training Loss: 2.3134241104125977, Training Accuracy: 0.5808823529411765, Validation Loss: 2.5840682983398438, Validation Accuracy: 0.5\n",
      "Epoch 4202/10000, Training Loss: 1.2517013549804688, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0137451887130737, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4203/10000, Training Loss: 1.6128036975860596, Training Accuracy: 0.5318627450980392, Validation Loss: 2.4683997631073, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4204/10000, Training Loss: 1.199048399925232, Training Accuracy: 0.5416666666666666, Validation Loss: 1.3951300382614136, Validation Accuracy: 0.25\n",
      "Epoch 4205/10000, Training Loss: 1.9965234994888306, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8713467717170715, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4206/10000, Training Loss: 1.55605149269104, Training Accuracy: 0.6029411764705882, Validation Loss: 1.2365318536758423, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4207/10000, Training Loss: 1.6590383052825928, Training Accuracy: 0.5735294117647058, Validation Loss: 3.165262460708618, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4208/10000, Training Loss: 1.8381717205047607, Training Accuracy: 0.49754901960784315, Validation Loss: 1.0793285369873047, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4209/10000, Training Loss: 1.3307123184204102, Training Accuracy: 0.5490196078431373, Validation Loss: 1.25486421585083, Validation Accuracy: 0.5\n",
      "Epoch 4210/10000, Training Loss: 1.566777229309082, Training Accuracy: 0.5882352941176471, Validation Loss: 3.450857400894165, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4211/10000, Training Loss: 1.1675055027008057, Training Accuracy: 0.5245098039215687, Validation Loss: 1.1115013360977173, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4212/10000, Training Loss: 1.2958701848983765, Training Accuracy: 0.625, Validation Loss: 1.2863192558288574, Validation Accuracy: 0.25\n",
      "Epoch 4213/10000, Training Loss: 1.5777736902236938, Training Accuracy: 0.5637254901960784, Validation Loss: 1.897023320198059, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4214/10000, Training Loss: 1.7365257740020752, Training Accuracy: 0.5122549019607843, Validation Loss: 0.5437891483306885, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4215/10000, Training Loss: 1.4002063274383545, Training Accuracy: 0.5514705882352942, Validation Loss: 2.7578773498535156, Validation Accuracy: 0.25\n",
      "Epoch 4216/10000, Training Loss: 1.7562576532363892, Training Accuracy: 0.5147058823529411, Validation Loss: 2.179755449295044, Validation Accuracy: 0.5\n",
      "Epoch 4217/10000, Training Loss: 1.516366720199585, Training Accuracy: 0.5612745098039216, Validation Loss: 1.6561163663864136, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4218/10000, Training Loss: 1.7979400157928467, Training Accuracy: 0.5661764705882353, Validation Loss: 1.4323292970657349, Validation Accuracy: 0.25\n",
      "Epoch 4219/10000, Training Loss: 1.6074525117874146, Training Accuracy: 0.6470588235294118, Validation Loss: 2.331812620162964, Validation Accuracy: 0.5\n",
      "Epoch 4220/10000, Training Loss: 1.1384693384170532, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0325183868408203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4221/10000, Training Loss: 1.7546931505203247, Training Accuracy: 0.5735294117647058, Validation Loss: 1.1307488679885864, Validation Accuracy: 0.75\n",
      "Epoch 4222/10000, Training Loss: 1.9666235446929932, Training Accuracy: 0.5661764705882353, Validation Loss: 4.365549087524414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4223/10000, Training Loss: 1.2937570810317993, Training Accuracy: 0.571078431372549, Validation Loss: 1.6146878004074097, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4224/10000, Training Loss: 1.737004280090332, Training Accuracy: 0.5490196078431373, Validation Loss: 3.203362464904785, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4225/10000, Training Loss: 1.5558600425720215, Training Accuracy: 0.553921568627451, Validation Loss: 2.7981479167938232, Validation Accuracy: 0.5\n",
      "Epoch 4226/10000, Training Loss: 1.5749595165252686, Training Accuracy: 0.5, Validation Loss: 1.819523811340332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4227/10000, Training Loss: 1.4296693801879883, Training Accuracy: 0.5465686274509803, Validation Loss: 1.922113060951233, Validation Accuracy: 0.25\n",
      "Epoch 4228/10000, Training Loss: 1.7768590450286865, Training Accuracy: 0.5171568627450981, Validation Loss: 1.2261356115341187, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4229/10000, Training Loss: 1.2413594722747803, Training Accuracy: 0.5980392156862745, Validation Loss: 1.3860806226730347, Validation Accuracy: 0.75\n",
      "Epoch 4230/10000, Training Loss: 2.27695631980896, Training Accuracy: 0.5441176470588235, Validation Loss: 2.248020648956299, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4231/10000, Training Loss: 1.4833974838256836, Training Accuracy: 0.553921568627451, Validation Loss: 1.3360017538070679, Validation Accuracy: 0.5\n",
      "Epoch 4232/10000, Training Loss: 1.358411431312561, Training Accuracy: 0.5661764705882353, Validation Loss: 0.5738622546195984, Validation Accuracy: 0.75\n",
      "Epoch 4233/10000, Training Loss: 1.1879873275756836, Training Accuracy: 0.5612745098039216, Validation Loss: 1.9917612075805664, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4234/10000, Training Loss: 1.2655500173568726, Training Accuracy: 0.5245098039215687, Validation Loss: 1.0135279893875122, Validation Accuracy: 0.5\n",
      "Epoch 4235/10000, Training Loss: 1.6600662469863892, Training Accuracy: 0.5147058823529411, Validation Loss: 1.389687180519104, Validation Accuracy: 0.5\n",
      "Epoch 4236/10000, Training Loss: 1.7696462869644165, Training Accuracy: 0.5147058823529411, Validation Loss: 3.412199020385742, Validation Accuracy: 0.5\n",
      "Epoch 4237/10000, Training Loss: 1.546399712562561, Training Accuracy: 0.5612745098039216, Validation Loss: 1.2945142984390259, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4238/10000, Training Loss: 1.1829777956008911, Training Accuracy: 0.6176470588235294, Validation Loss: 2.4827122688293457, Validation Accuracy: 0.5\n",
      "Epoch 4239/10000, Training Loss: 1.7954366207122803, Training Accuracy: 0.6421568627450981, Validation Loss: 3.7926299571990967, Validation Accuracy: 0.5\n",
      "Epoch 4240/10000, Training Loss: 2.063220739364624, Training Accuracy: 0.5269607843137255, Validation Loss: 2.710078001022339, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4241/10000, Training Loss: 1.1306790113449097, Training Accuracy: 0.5980392156862745, Validation Loss: 1.7878503799438477, Validation Accuracy: 0.5\n",
      "Epoch 4242/10000, Training Loss: 1.0993770360946655, Training Accuracy: 0.5049019607843137, Validation Loss: 1.6425546407699585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4243/10000, Training Loss: 1.3265596628189087, Training Accuracy: 0.6078431372549019, Validation Loss: 1.7520297765731812, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4244/10000, Training Loss: 1.4674876928329468, Training Accuracy: 0.6225490196078431, Validation Loss: 2.1067111492156982, Validation Accuracy: 0.5\n",
      "Epoch 4245/10000, Training Loss: 1.3320674896240234, Training Accuracy: 0.5563725490196079, Validation Loss: 1.136694073677063, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4246/10000, Training Loss: 1.3150911331176758, Training Accuracy: 0.5955882352941176, Validation Loss: 2.0243048667907715, Validation Accuracy: 0.5\n",
      "Epoch 4247/10000, Training Loss: 1.4127379655838013, Training Accuracy: 0.5514705882352942, Validation Loss: 3.2862436771392822, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4248/10000, Training Loss: 1.479705810546875, Training Accuracy: 0.5416666666666666, Validation Loss: 2.5362462997436523, Validation Accuracy: 0.5\n",
      "Epoch 4249/10000, Training Loss: 1.3998233079910278, Training Accuracy: 0.5367647058823529, Validation Loss: 2.5548107624053955, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4250/10000, Training Loss: 1.2130861282348633, Training Accuracy: 0.5563725490196079, Validation Loss: 2.378995180130005, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4251/10000, Training Loss: 1.5306954383850098, Training Accuracy: 0.6274509803921569, Validation Loss: 2.1461222171783447, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4252/10000, Training Loss: 1.324539303779602, Training Accuracy: 0.5882352941176471, Validation Loss: 1.132015585899353, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4253/10000, Training Loss: 1.4437339305877686, Training Accuracy: 0.625, Validation Loss: 4.312832355499268, Validation Accuracy: 0.25\n",
      "Epoch 4254/10000, Training Loss: 1.6804088354110718, Training Accuracy: 0.5122549019607843, Validation Loss: 1.3874573707580566, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4255/10000, Training Loss: 1.043453335762024, Training Accuracy: 0.6470588235294118, Validation Loss: 1.6738640069961548, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4256/10000, Training Loss: 1.1621540784835815, Training Accuracy: 0.5931372549019608, Validation Loss: 1.6301031112670898, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4257/10000, Training Loss: 1.2831286191940308, Training Accuracy: 0.5661764705882353, Validation Loss: 1.5666146278381348, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4258/10000, Training Loss: 1.6078263521194458, Training Accuracy: 0.571078431372549, Validation Loss: 1.9524345397949219, Validation Accuracy: 0.5\n",
      "Epoch 4259/10000, Training Loss: 1.1837412118911743, Training Accuracy: 0.5686274509803921, Validation Loss: 1.9952268600463867, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4260/10000, Training Loss: 1.2590301036834717, Training Accuracy: 0.5882352941176471, Validation Loss: 1.7829121351242065, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4261/10000, Training Loss: 1.5283520221710205, Training Accuracy: 0.5269607843137255, Validation Loss: 1.70774507522583, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4262/10000, Training Loss: 1.490593671798706, Training Accuracy: 0.5808823529411765, Validation Loss: 2.143815755844116, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4263/10000, Training Loss: 1.6173431873321533, Training Accuracy: 0.5588235294117647, Validation Loss: 2.5367958545684814, Validation Accuracy: 0.5\n",
      "Epoch 4264/10000, Training Loss: 2.0462262630462646, Training Accuracy: 0.5245098039215687, Validation Loss: 2.7783796787261963, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4265/10000, Training Loss: 1.5938411951065063, Training Accuracy: 0.4950980392156863, Validation Loss: 2.406475782394409, Validation Accuracy: 0.5\n",
      "Epoch 4266/10000, Training Loss: 1.2582064867019653, Training Accuracy: 0.6004901960784313, Validation Loss: 1.9483027458190918, Validation Accuracy: 0.5\n",
      "Epoch 4267/10000, Training Loss: 1.4095486402511597, Training Accuracy: 0.5612745098039216, Validation Loss: 2.225039005279541, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4268/10000, Training Loss: 1.705826997756958, Training Accuracy: 0.5416666666666666, Validation Loss: 3.229673385620117, Validation Accuracy: 0.5\n",
      "Epoch 4269/10000, Training Loss: 1.4287627935409546, Training Accuracy: 0.5759803921568627, Validation Loss: 1.1854766607284546, Validation Accuracy: 0.5\n",
      "Epoch 4270/10000, Training Loss: 1.1840569972991943, Training Accuracy: 0.5049019607843137, Validation Loss: 2.066673517227173, Validation Accuracy: 0.25\n",
      "Epoch 4271/10000, Training Loss: 1.5325099229812622, Training Accuracy: 0.5808823529411765, Validation Loss: 2.7495803833007812, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4272/10000, Training Loss: 2.63131046295166, Training Accuracy: 0.5171568627450981, Validation Loss: 1.074631690979004, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4273/10000, Training Loss: 1.4186561107635498, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6834726333618164, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4274/10000, Training Loss: 1.6505773067474365, Training Accuracy: 0.5122549019607843, Validation Loss: 1.8653680086135864, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4275/10000, Training Loss: 1.3937478065490723, Training Accuracy: 0.6299019607843137, Validation Loss: 2.8989217281341553, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4276/10000, Training Loss: 1.3579238653182983, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7680394053459167, Validation Accuracy: 0.5\n",
      "Epoch 4277/10000, Training Loss: 1.5859345197677612, Training Accuracy: 0.5514705882352942, Validation Loss: 1.7955341339111328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4278/10000, Training Loss: 1.5108383893966675, Training Accuracy: 0.5735294117647058, Validation Loss: 1.8496804237365723, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4279/10000, Training Loss: 1.528963327407837, Training Accuracy: 0.5735294117647058, Validation Loss: 2.4455530643463135, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4280/10000, Training Loss: 1.3669997453689575, Training Accuracy: 0.5441176470588235, Validation Loss: 1.495355248451233, Validation Accuracy: 0.5\n",
      "Epoch 4281/10000, Training Loss: 1.6237058639526367, Training Accuracy: 0.571078431372549, Validation Loss: 1.4976869821548462, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4282/10000, Training Loss: 1.3772447109222412, Training Accuracy: 0.5392156862745098, Validation Loss: 2.018817663192749, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4283/10000, Training Loss: 1.6153864860534668, Training Accuracy: 0.4730392156862745, Validation Loss: 1.5982006788253784, Validation Accuracy: 0.5\n",
      "Epoch 4284/10000, Training Loss: 1.1955230236053467, Training Accuracy: 0.5661764705882353, Validation Loss: 1.4146174192428589, Validation Accuracy: 0.5\n",
      "Epoch 4285/10000, Training Loss: 1.5829718112945557, Training Accuracy: 0.5465686274509803, Validation Loss: 1.551531195640564, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4286/10000, Training Loss: 1.829099416732788, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8975086212158203, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4287/10000, Training Loss: 1.475521445274353, Training Accuracy: 0.5563725490196079, Validation Loss: 1.7274991273880005, Validation Accuracy: 0.5\n",
      "Epoch 4288/10000, Training Loss: 1.15225350856781, Training Accuracy: 0.6200980392156863, Validation Loss: 2.593648672103882, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4289/10000, Training Loss: 1.824272871017456, Training Accuracy: 0.6102941176470589, Validation Loss: 4.137516021728516, Validation Accuracy: 0.25\n",
      "Epoch 4290/10000, Training Loss: 1.1647504568099976, Training Accuracy: 0.6053921568627451, Validation Loss: 2.465212106704712, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4291/10000, Training Loss: 1.7004116773605347, Training Accuracy: 0.5759803921568627, Validation Loss: 4.683316707611084, Validation Accuracy: 0.25\n",
      "Epoch 4292/10000, Training Loss: 1.6437853574752808, Training Accuracy: 0.5906862745098039, Validation Loss: 2.2847211360931396, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4293/10000, Training Loss: 1.9930908679962158, Training Accuracy: 0.5612745098039216, Validation Loss: 2.565833806991577, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4294/10000, Training Loss: 1.1345990896224976, Training Accuracy: 0.5759803921568627, Validation Loss: 1.7988548278808594, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4295/10000, Training Loss: 1.4617657661437988, Training Accuracy: 0.625, Validation Loss: 1.7196823358535767, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4296/10000, Training Loss: 1.3445430994033813, Training Accuracy: 0.5857843137254902, Validation Loss: 4.604708671569824, Validation Accuracy: 0.25\n",
      "Epoch 4297/10000, Training Loss: 1.3073978424072266, Training Accuracy: 0.6004901960784313, Validation Loss: 1.7206425666809082, Validation Accuracy: 0.5\n",
      "Epoch 4298/10000, Training Loss: 1.3962008953094482, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1341536045074463, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4299/10000, Training Loss: 1.087350606918335, Training Accuracy: 0.5808823529411765, Validation Loss: 1.8026970624923706, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4300/10000, Training Loss: 1.3353790044784546, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2775533199310303, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4301/10000, Training Loss: 1.6006364822387695, Training Accuracy: 0.5147058823529411, Validation Loss: 1.5741772651672363, Validation Accuracy: 0.5\n",
      "Epoch 4302/10000, Training Loss: 1.360819935798645, Training Accuracy: 0.5980392156862745, Validation Loss: 3.8123939037323, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4303/10000, Training Loss: 1.3044930696487427, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9969969391822815, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4304/10000, Training Loss: 1.5782536268234253, Training Accuracy: 0.5759803921568627, Validation Loss: 9.665410995483398, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4305/10000, Training Loss: 1.9229480028152466, Training Accuracy: 0.5024509803921569, Validation Loss: 1.8674577474594116, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4306/10000, Training Loss: 1.988036036491394, Training Accuracy: 0.5784313725490197, Validation Loss: 2.5647706985473633, Validation Accuracy: 0.5\n",
      "Epoch 4307/10000, Training Loss: 1.316335678100586, Training Accuracy: 0.6200980392156863, Validation Loss: 1.9529744386672974, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4308/10000, Training Loss: 1.501277208328247, Training Accuracy: 0.5563725490196079, Validation Loss: 1.3282182216644287, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4309/10000, Training Loss: 1.1949760913848877, Training Accuracy: 0.6348039215686274, Validation Loss: 1.6135153770446777, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4310/10000, Training Loss: 1.2252018451690674, Training Accuracy: 0.5808823529411765, Validation Loss: 0.733651340007782, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4311/10000, Training Loss: 1.7433112859725952, Training Accuracy: 0.6691176470588235, Validation Loss: 2.283478021621704, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4312/10000, Training Loss: 1.2860008478164673, Training Accuracy: 0.5588235294117647, Validation Loss: 2.4949212074279785, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4313/10000, Training Loss: 1.1610252857208252, Training Accuracy: 0.6127450980392157, Validation Loss: 3.6609952449798584, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4314/10000, Training Loss: 1.65614914894104, Training Accuracy: 0.5563725490196079, Validation Loss: 1.3896385431289673, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4315/10000, Training Loss: 1.3748921155929565, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7508357763290405, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4316/10000, Training Loss: 1.185002326965332, Training Accuracy: 0.6446078431372549, Validation Loss: 2.1011390686035156, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4317/10000, Training Loss: 1.509780764579773, Training Accuracy: 0.5514705882352942, Validation Loss: 1.59958016872406, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4318/10000, Training Loss: 1.2716972827911377, Training Accuracy: 0.5784313725490197, Validation Loss: 1.379687786102295, Validation Accuracy: 0.5\n",
      "Epoch 4319/10000, Training Loss: 1.2605175971984863, Training Accuracy: 0.5980392156862745, Validation Loss: 2.601043701171875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4320/10000, Training Loss: 1.4599990844726562, Training Accuracy: 0.5588235294117647, Validation Loss: 2.892164945602417, Validation Accuracy: 0.5\n",
      "Epoch 4321/10000, Training Loss: 1.6716604232788086, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8462175130844116, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4322/10000, Training Loss: 1.1313197612762451, Training Accuracy: 0.5759803921568627, Validation Loss: 1.216878890991211, Validation Accuracy: 0.5\n",
      "Epoch 4323/10000, Training Loss: 1.131946325302124, Training Accuracy: 0.6323529411764706, Validation Loss: 1.9836527109146118, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4324/10000, Training Loss: 1.6174322366714478, Training Accuracy: 0.5637254901960784, Validation Loss: 1.9836105108261108, Validation Accuracy: 0.5\n",
      "Epoch 4325/10000, Training Loss: 1.502334713935852, Training Accuracy: 0.5514705882352942, Validation Loss: 1.9731464385986328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4326/10000, Training Loss: 1.8389644622802734, Training Accuracy: 0.5955882352941176, Validation Loss: 5.490169525146484, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4327/10000, Training Loss: 1.4343621730804443, Training Accuracy: 0.6029411764705882, Validation Loss: 2.731309652328491, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4328/10000, Training Loss: 1.2777365446090698, Training Accuracy: 0.6715686274509803, Validation Loss: 3.876465082168579, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4329/10000, Training Loss: 1.633217453956604, Training Accuracy: 0.5563725490196079, Validation Loss: 1.8217743635177612, Validation Accuracy: 0.5\n",
      "Epoch 4330/10000, Training Loss: 1.4625238180160522, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1948384046554565, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4331/10000, Training Loss: 1.7241737842559814, Training Accuracy: 0.6176470588235294, Validation Loss: 0.5977127552032471, Validation Accuracy: 0.75\n",
      "Epoch 4332/10000, Training Loss: 1.739645004272461, Training Accuracy: 0.5563725490196079, Validation Loss: 3.308809518814087, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4333/10000, Training Loss: 1.4939745664596558, Training Accuracy: 0.5980392156862745, Validation Loss: 1.3042744398117065, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4334/10000, Training Loss: 1.500368595123291, Training Accuracy: 0.5122549019607843, Validation Loss: 1.6686142683029175, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4335/10000, Training Loss: 1.4002630710601807, Training Accuracy: 0.5416666666666666, Validation Loss: 3.547902822494507, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4336/10000, Training Loss: 1.0377143621444702, Training Accuracy: 0.6176470588235294, Validation Loss: 1.6901265382766724, Validation Accuracy: 0.25\n",
      "Epoch 4337/10000, Training Loss: 1.2542285919189453, Training Accuracy: 0.5294117647058824, Validation Loss: 2.4930522441864014, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4338/10000, Training Loss: 1.4799832105636597, Training Accuracy: 0.5612745098039216, Validation Loss: 3.6266915798187256, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4339/10000, Training Loss: 1.3496979475021362, Training Accuracy: 0.5857843137254902, Validation Loss: 1.4138103723526, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4340/10000, Training Loss: 1.3874598741531372, Training Accuracy: 0.553921568627451, Validation Loss: 1.120314121246338, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4341/10000, Training Loss: 1.3714165687561035, Training Accuracy: 0.5759803921568627, Validation Loss: 1.331295132637024, Validation Accuracy: 0.5\n",
      "Epoch 4342/10000, Training Loss: 1.3714723587036133, Training Accuracy: 0.5686274509803921, Validation Loss: 2.020592212677002, Validation Accuracy: 0.25\n",
      "Epoch 4343/10000, Training Loss: 1.2196595668792725, Training Accuracy: 0.6078431372549019, Validation Loss: 1.3844548463821411, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4344/10000, Training Loss: 1.6503262519836426, Training Accuracy: 0.5122549019607843, Validation Loss: 4.321415424346924, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4345/10000, Training Loss: 1.679958701133728, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1150192022323608, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4346/10000, Training Loss: 1.2875020503997803, Training Accuracy: 0.5931372549019608, Validation Loss: 1.916568398475647, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4347/10000, Training Loss: 1.282669186592102, Training Accuracy: 0.5857843137254902, Validation Loss: 1.450015664100647, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4348/10000, Training Loss: 2.1156959533691406, Training Accuracy: 0.5514705882352942, Validation Loss: 1.7678693532943726, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4349/10000, Training Loss: 1.3231571912765503, Training Accuracy: 0.5465686274509803, Validation Loss: 1.9604066610336304, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4350/10000, Training Loss: 1.4627574682235718, Training Accuracy: 0.5735294117647058, Validation Loss: 1.2704390287399292, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4351/10000, Training Loss: 1.1811400651931763, Training Accuracy: 0.6078431372549019, Validation Loss: 1.9233211278915405, Validation Accuracy: 0.25\n",
      "Epoch 4352/10000, Training Loss: 0.9032671451568604, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3440128564834595, Validation Accuracy: 0.5\n",
      "Epoch 4353/10000, Training Loss: 1.226527452468872, Training Accuracy: 0.5637254901960784, Validation Loss: 1.3074740171432495, Validation Accuracy: 0.5\n",
      "Epoch 4354/10000, Training Loss: 1.5057644844055176, Training Accuracy: 0.5465686274509803, Validation Loss: 2.8777952194213867, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4355/10000, Training Loss: 1.4344381093978882, Training Accuracy: 0.6029411764705882, Validation Loss: 1.9515252113342285, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4356/10000, Training Loss: 1.4852269887924194, Training Accuracy: 0.6004901960784313, Validation Loss: 1.5392818450927734, Validation Accuracy: 0.5\n",
      "Epoch 4357/10000, Training Loss: 1.2357319593429565, Training Accuracy: 0.6299019607843137, Validation Loss: 1.6895867586135864, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4358/10000, Training Loss: 1.1189950704574585, Training Accuracy: 0.6078431372549019, Validation Loss: 1.6885300874710083, Validation Accuracy: 0.5\n",
      "Epoch 4359/10000, Training Loss: 1.573411226272583, Training Accuracy: 0.5147058823529411, Validation Loss: 1.6401869058609009, Validation Accuracy: 0.25\n",
      "Epoch 4360/10000, Training Loss: 0.9287496209144592, Training Accuracy: 0.6127450980392157, Validation Loss: 1.4503573179244995, Validation Accuracy: 0.25\n",
      "Epoch 4361/10000, Training Loss: 1.5761394500732422, Training Accuracy: 0.5269607843137255, Validation Loss: 1.898488998413086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4362/10000, Training Loss: 1.190855860710144, Training Accuracy: 0.6029411764705882, Validation Loss: 1.5624619722366333, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4363/10000, Training Loss: 1.260421872138977, Training Accuracy: 0.5465686274509803, Validation Loss: 0.807243824005127, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4364/10000, Training Loss: 1.169020652770996, Training Accuracy: 0.625, Validation Loss: 2.3740522861480713, Validation Accuracy: 0.5\n",
      "Epoch 4365/10000, Training Loss: 1.0756391286849976, Training Accuracy: 0.5490196078431373, Validation Loss: 0.396697074174881, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4366/10000, Training Loss: 1.3024743795394897, Training Accuracy: 0.571078431372549, Validation Loss: 1.4525402784347534, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4367/10000, Training Loss: 1.3786871433258057, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0618956089019775, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4368/10000, Training Loss: 1.4376732110977173, Training Accuracy: 0.5661764705882353, Validation Loss: 4.184328079223633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4369/10000, Training Loss: 1.2994987964630127, Training Accuracy: 0.5294117647058824, Validation Loss: 1.7083162069320679, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4370/10000, Training Loss: 1.502124309539795, Training Accuracy: 0.5637254901960784, Validation Loss: 1.4097779989242554, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4371/10000, Training Loss: 1.599805474281311, Training Accuracy: 0.5073529411764706, Validation Loss: 1.351088047027588, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4372/10000, Training Loss: 1.1190742254257202, Training Accuracy: 0.6274509803921569, Validation Loss: 2.1280219554901123, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4373/10000, Training Loss: 1.3016775846481323, Training Accuracy: 0.5637254901960784, Validation Loss: 1.3121626377105713, Validation Accuracy: 0.5\n",
      "Epoch 4374/10000, Training Loss: 1.7313737869262695, Training Accuracy: 0.571078431372549, Validation Loss: 3.1220929622650146, Validation Accuracy: 0.25\n",
      "Epoch 4375/10000, Training Loss: 1.3289811611175537, Training Accuracy: 0.5808823529411765, Validation Loss: 1.6152935028076172, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4376/10000, Training Loss: 1.3777306079864502, Training Accuracy: 0.5122549019607843, Validation Loss: 1.4945780038833618, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4377/10000, Training Loss: 1.5410089492797852, Training Accuracy: 0.5833333333333334, Validation Loss: 1.0454585552215576, Validation Accuracy: 0.75\n",
      "Epoch 4378/10000, Training Loss: 1.2970434427261353, Training Accuracy: 0.5147058823529411, Validation Loss: 1.8777092695236206, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4379/10000, Training Loss: 1.5621720552444458, Training Accuracy: 0.5024509803921569, Validation Loss: 2.0556983947753906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4380/10000, Training Loss: 1.293004035949707, Training Accuracy: 0.5661764705882353, Validation Loss: 3.526397705078125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4381/10000, Training Loss: 1.5147193670272827, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9908883571624756, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4382/10000, Training Loss: 1.129653811454773, Training Accuracy: 0.5686274509803921, Validation Loss: 0.928473174571991, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4383/10000, Training Loss: 1.0941051244735718, Training Accuracy: 0.6151960784313726, Validation Loss: 1.224388599395752, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4384/10000, Training Loss: 1.2618497610092163, Training Accuracy: 0.5514705882352942, Validation Loss: 1.9763221740722656, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4385/10000, Training Loss: 1.317279577255249, Training Accuracy: 0.6102941176470589, Validation Loss: 1.7110867500305176, Validation Accuracy: 0.5\n",
      "Epoch 4386/10000, Training Loss: 1.484093427658081, Training Accuracy: 0.5367647058823529, Validation Loss: 4.132059574127197, Validation Accuracy: 0.5\n",
      "Epoch 4387/10000, Training Loss: 1.2193795442581177, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6074024438858032, Validation Accuracy: 0.5\n",
      "Epoch 4388/10000, Training Loss: 1.8168548345565796, Training Accuracy: 0.5588235294117647, Validation Loss: 1.8640929460525513, Validation Accuracy: 0.5\n",
      "Epoch 4389/10000, Training Loss: 1.6716973781585693, Training Accuracy: 0.6029411764705882, Validation Loss: 3.8103091716766357, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4390/10000, Training Loss: 1.6089242696762085, Training Accuracy: 0.5759803921568627, Validation Loss: 1.4972444772720337, Validation Accuracy: 0.75\n",
      "Epoch 4391/10000, Training Loss: 1.2998188734054565, Training Accuracy: 0.5735294117647058, Validation Loss: 0.5553655624389648, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4392/10000, Training Loss: 1.2750850915908813, Training Accuracy: 0.5588235294117647, Validation Loss: 2.9465978145599365, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4393/10000, Training Loss: 1.4932554960250854, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3177002668380737, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4394/10000, Training Loss: 0.9034475684165955, Training Accuracy: 0.6372549019607843, Validation Loss: 1.2647645473480225, Validation Accuracy: 0.5\n",
      "Epoch 4395/10000, Training Loss: 1.1501662731170654, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0006684064865112, Validation Accuracy: 0.5\n",
      "Epoch 4396/10000, Training Loss: 1.5087475776672363, Training Accuracy: 0.5857843137254902, Validation Loss: 2.9665327072143555, Validation Accuracy: 0.5\n",
      "Epoch 4397/10000, Training Loss: 1.1573376655578613, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9179260730743408, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4398/10000, Training Loss: 1.1297048330307007, Training Accuracy: 0.5416666666666666, Validation Loss: 2.0072555541992188, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4399/10000, Training Loss: 1.1402941942214966, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0392075777053833, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4400/10000, Training Loss: 1.4373023509979248, Training Accuracy: 0.5686274509803921, Validation Loss: 1.6578264236450195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4401/10000, Training Loss: 1.3012378215789795, Training Accuracy: 0.5098039215686274, Validation Loss: 4.186315059661865, Validation Accuracy: 0.25\n",
      "Epoch 4402/10000, Training Loss: 1.220239281654358, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6554972529411316, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4403/10000, Training Loss: 1.6062723398208618, Training Accuracy: 0.49264705882352944, Validation Loss: 1.4832555055618286, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4404/10000, Training Loss: 1.2542082071304321, Training Accuracy: 0.5661764705882353, Validation Loss: 1.6489402055740356, Validation Accuracy: 0.5\n",
      "Epoch 4405/10000, Training Loss: 1.3104023933410645, Training Accuracy: 0.5637254901960784, Validation Loss: 1.7267041206359863, Validation Accuracy: 0.5\n",
      "Epoch 4406/10000, Training Loss: 1.3338090181350708, Training Accuracy: 0.5906862745098039, Validation Loss: 2.5585777759552, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4407/10000, Training Loss: 1.4442391395568848, Training Accuracy: 0.49754901960784315, Validation Loss: 0.776897132396698, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4408/10000, Training Loss: 1.2132073640823364, Training Accuracy: 0.6348039215686274, Validation Loss: 4.8863043785095215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4409/10000, Training Loss: 1.573409914970398, Training Accuracy: 0.5269607843137255, Validation Loss: 1.0364270210266113, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4410/10000, Training Loss: 1.449588656425476, Training Accuracy: 0.571078431372549, Validation Loss: 1.731869101524353, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4411/10000, Training Loss: 2.0138909816741943, Training Accuracy: 0.5147058823529411, Validation Loss: 3.661393165588379, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4412/10000, Training Loss: 1.4270707368850708, Training Accuracy: 0.5588235294117647, Validation Loss: 2.2519145011901855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4413/10000, Training Loss: 1.4021419286727905, Training Accuracy: 0.6372549019607843, Validation Loss: 2.658879041671753, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4414/10000, Training Loss: 1.156111717224121, Training Accuracy: 0.5735294117647058, Validation Loss: 1.3533021211624146, Validation Accuracy: 0.5\n",
      "Epoch 4415/10000, Training Loss: 2.178471565246582, Training Accuracy: 0.5343137254901961, Validation Loss: 2.093496084213257, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4416/10000, Training Loss: 1.3501709699630737, Training Accuracy: 0.5661764705882353, Validation Loss: 2.7956340312957764, Validation Accuracy: 0.5\n",
      "Epoch 4417/10000, Training Loss: 1.2057807445526123, Training Accuracy: 0.5612745098039216, Validation Loss: 1.9017277956008911, Validation Accuracy: 0.5\n",
      "Epoch 4418/10000, Training Loss: 1.2430427074432373, Training Accuracy: 0.6200980392156863, Validation Loss: 1.1236051321029663, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4419/10000, Training Loss: 1.1491060256958008, Training Accuracy: 0.5661764705882353, Validation Loss: 1.6965972185134888, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4420/10000, Training Loss: 1.059438943862915, Training Accuracy: 0.5857843137254902, Validation Loss: 1.7797068357467651, Validation Accuracy: 0.5\n",
      "Epoch 4421/10000, Training Loss: 1.352074146270752, Training Accuracy: 0.5931372549019608, Validation Loss: 1.7737230062484741, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4422/10000, Training Loss: 1.4208314418792725, Training Accuracy: 0.5661764705882353, Validation Loss: 2.489389181137085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4423/10000, Training Loss: 1.3600550889968872, Training Accuracy: 0.5367647058823529, Validation Loss: 3.2099826335906982, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4424/10000, Training Loss: 1.3512402772903442, Training Accuracy: 0.5514705882352942, Validation Loss: 1.501757264137268, Validation Accuracy: 0.5\n",
      "Epoch 4425/10000, Training Loss: 1.0467720031738281, Training Accuracy: 0.6053921568627451, Validation Loss: 1.151110053062439, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4426/10000, Training Loss: 1.6153723001480103, Training Accuracy: 0.49264705882352944, Validation Loss: 2.186687707901001, Validation Accuracy: 0.5\n",
      "Epoch 4427/10000, Training Loss: 1.2949782609939575, Training Accuracy: 0.5735294117647058, Validation Loss: 3.0746657848358154, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4428/10000, Training Loss: 1.6072131395339966, Training Accuracy: 0.5931372549019608, Validation Loss: 3.721099615097046, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4429/10000, Training Loss: 1.528151512145996, Training Accuracy: 0.5784313725490197, Validation Loss: 3.377157211303711, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4430/10000, Training Loss: 1.3339126110076904, Training Accuracy: 0.5318627450980392, Validation Loss: 3.2226693630218506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4431/10000, Training Loss: 1.5474787950515747, Training Accuracy: 0.5171568627450981, Validation Loss: 1.4086028337478638, Validation Accuracy: 0.5\n",
      "Epoch 4432/10000, Training Loss: 1.2486631870269775, Training Accuracy: 0.553921568627451, Validation Loss: 1.0000711679458618, Validation Accuracy: 0.75\n",
      "Epoch 4433/10000, Training Loss: 1.3225327730178833, Training Accuracy: 0.5759803921568627, Validation Loss: 1.4049967527389526, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4434/10000, Training Loss: 1.6280640363693237, Training Accuracy: 0.5955882352941176, Validation Loss: 4.122847080230713, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4435/10000, Training Loss: 1.2250734567642212, Training Accuracy: 0.5612745098039216, Validation Loss: 1.0456023216247559, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4436/10000, Training Loss: 1.4453734159469604, Training Accuracy: 0.5196078431372549, Validation Loss: 2.1337625980377197, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4437/10000, Training Loss: 1.5227128267288208, Training Accuracy: 0.6176470588235294, Validation Loss: 1.9115134477615356, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4438/10000, Training Loss: 1.391646385192871, Training Accuracy: 0.5661764705882353, Validation Loss: 2.6372873783111572, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4439/10000, Training Loss: 1.3322620391845703, Training Accuracy: 0.5955882352941176, Validation Loss: 1.8643436431884766, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4440/10000, Training Loss: 1.085111379623413, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9578379988670349, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4441/10000, Training Loss: 1.279634714126587, Training Accuracy: 0.6102941176470589, Validation Loss: 2.4899580478668213, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4442/10000, Training Loss: 1.2559508085250854, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6987239718437195, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4443/10000, Training Loss: 1.0610542297363281, Training Accuracy: 0.6200980392156863, Validation Loss: 1.6101092100143433, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4444/10000, Training Loss: 0.9546486139297485, Training Accuracy: 0.5784313725490197, Validation Loss: 1.305272102355957, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4445/10000, Training Loss: 1.1894668340682983, Training Accuracy: 0.5612745098039216, Validation Loss: 2.3462350368499756, Validation Accuracy: 0.25\n",
      "Epoch 4446/10000, Training Loss: 1.7029072046279907, Training Accuracy: 0.5612745098039216, Validation Loss: 2.7693593502044678, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4447/10000, Training Loss: 1.1053255796432495, Training Accuracy: 0.5980392156862745, Validation Loss: 0.700737714767456, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4448/10000, Training Loss: 1.1932460069656372, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1231846809387207, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4449/10000, Training Loss: 1.1182444095611572, Training Accuracy: 0.5661764705882353, Validation Loss: 1.123956322669983, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4450/10000, Training Loss: 1.2934130430221558, Training Accuracy: 0.6102941176470589, Validation Loss: 2.9307262897491455, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4451/10000, Training Loss: 1.5432538986206055, Training Accuracy: 0.49019607843137253, Validation Loss: 1.9001566171646118, Validation Accuracy: 0.5\n",
      "Epoch 4452/10000, Training Loss: 2.223437786102295, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1896064281463623, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4453/10000, Training Loss: 1.4003353118896484, Training Accuracy: 0.5612745098039216, Validation Loss: 1.1570101976394653, Validation Accuracy: 0.5\n",
      "Epoch 4454/10000, Training Loss: 1.2668615579605103, Training Accuracy: 0.5882352941176471, Validation Loss: 1.2208095788955688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4455/10000, Training Loss: 1.5771583318710327, Training Accuracy: 0.5735294117647058, Validation Loss: 2.5174176692962646, Validation Accuracy: 0.25\n",
      "Epoch 4456/10000, Training Loss: 1.9714438915252686, Training Accuracy: 0.5686274509803921, Validation Loss: 2.3523170948028564, Validation Accuracy: 0.5\n",
      "Epoch 4457/10000, Training Loss: 1.568700909614563, Training Accuracy: 0.5833333333333334, Validation Loss: 1.469896674156189, Validation Accuracy: 0.75\n",
      "Epoch 4458/10000, Training Loss: 1.5479910373687744, Training Accuracy: 0.5465686274509803, Validation Loss: 1.6395362615585327, Validation Accuracy: 0.5\n",
      "Epoch 4459/10000, Training Loss: 1.1055914163589478, Training Accuracy: 0.5294117647058824, Validation Loss: 0.9173083901405334, Validation Accuracy: 0.75\n",
      "Epoch 4460/10000, Training Loss: 1.512807846069336, Training Accuracy: 0.5955882352941176, Validation Loss: 3.5420138835906982, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4461/10000, Training Loss: 1.324017882347107, Training Accuracy: 0.5980392156862745, Validation Loss: 5.314393520355225, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4462/10000, Training Loss: 1.391433835029602, Training Accuracy: 0.5367647058823529, Validation Loss: 1.5503915548324585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4463/10000, Training Loss: 0.929888129234314, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6277459859848022, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4464/10000, Training Loss: 1.706753134727478, Training Accuracy: 0.5318627450980392, Validation Loss: 1.1156624555587769, Validation Accuracy: 0.5\n",
      "Epoch 4465/10000, Training Loss: 1.148767113685608, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7678937911987305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4466/10000, Training Loss: 1.3655036687850952, Training Accuracy: 0.6029411764705882, Validation Loss: 1.8995836973190308, Validation Accuracy: 0.5\n",
      "Epoch 4467/10000, Training Loss: 1.3897613286972046, Training Accuracy: 0.5269607843137255, Validation Loss: 1.4369224309921265, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4468/10000, Training Loss: 1.5464870929718018, Training Accuracy: 0.6053921568627451, Validation Loss: 1.4655042886734009, Validation Accuracy: 0.5\n",
      "Epoch 4469/10000, Training Loss: 0.9809529781341553, Training Accuracy: 0.6299019607843137, Validation Loss: 2.642812728881836, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4470/10000, Training Loss: 1.4279173612594604, Training Accuracy: 0.5563725490196079, Validation Loss: 1.0245715379714966, Validation Accuracy: 0.75\n",
      "Epoch 4471/10000, Training Loss: 1.091141939163208, Training Accuracy: 0.5563725490196079, Validation Loss: 1.125244140625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4472/10000, Training Loss: 1.124076247215271, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1026808023452759, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4473/10000, Training Loss: 1.7043942213058472, Training Accuracy: 0.5073529411764706, Validation Loss: 1.5780129432678223, Validation Accuracy: 0.5\n",
      "Epoch 4474/10000, Training Loss: 1.4253164529800415, Training Accuracy: 0.5245098039215687, Validation Loss: 1.4510318040847778, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4475/10000, Training Loss: 1.1467310190200806, Training Accuracy: 0.6004901960784313, Validation Loss: 1.7773183584213257, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4476/10000, Training Loss: 1.6180520057678223, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7932663559913635, Validation Accuracy: 0.5\n",
      "Epoch 4477/10000, Training Loss: 1.2607821226119995, Training Accuracy: 0.5955882352941176, Validation Loss: 3.1274681091308594, Validation Accuracy: 0.25\n",
      "Epoch 4478/10000, Training Loss: 1.3872387409210205, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7031840682029724, Validation Accuracy: 0.75\n",
      "Epoch 4479/10000, Training Loss: 1.6828317642211914, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9479248523712158, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4480/10000, Training Loss: 1.3920303583145142, Training Accuracy: 0.6078431372549019, Validation Loss: 1.8824940919876099, Validation Accuracy: 0.5\n",
      "Epoch 4481/10000, Training Loss: 1.2368874549865723, Training Accuracy: 0.6274509803921569, Validation Loss: 2.2291712760925293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4482/10000, Training Loss: 1.2732099294662476, Training Accuracy: 0.5563725490196079, Validation Loss: 1.416265845298767, Validation Accuracy: 0.25\n",
      "Epoch 4483/10000, Training Loss: 1.4050381183624268, Training Accuracy: 0.5906862745098039, Validation Loss: 2.1760940551757812, Validation Accuracy: 0.5\n",
      "Epoch 4484/10000, Training Loss: 2.0870585441589355, Training Accuracy: 0.5318627450980392, Validation Loss: 1.4523550271987915, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4485/10000, Training Loss: 1.4710721969604492, Training Accuracy: 0.5416666666666666, Validation Loss: 1.923417568206787, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4486/10000, Training Loss: 1.5722488164901733, Training Accuracy: 0.4877450980392157, Validation Loss: 0.7536728978157043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4487/10000, Training Loss: 1.0950844287872314, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8345666527748108, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4488/10000, Training Loss: 1.4331998825073242, Training Accuracy: 0.5245098039215687, Validation Loss: 2.197981595993042, Validation Accuracy: 0.5\n",
      "Epoch 4489/10000, Training Loss: 1.2193596363067627, Training Accuracy: 0.5367647058823529, Validation Loss: 1.2356427907943726, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4490/10000, Training Loss: 1.2627633810043335, Training Accuracy: 0.5980392156862745, Validation Loss: 1.2343721389770508, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4491/10000, Training Loss: 1.0357967615127563, Training Accuracy: 0.6078431372549019, Validation Loss: 1.172937273979187, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4492/10000, Training Loss: 1.229300856590271, Training Accuracy: 0.5833333333333334, Validation Loss: 1.8237963914871216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4493/10000, Training Loss: 1.3266476392745972, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3181284666061401, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4494/10000, Training Loss: 1.0607393980026245, Training Accuracy: 0.6200980392156863, Validation Loss: 0.5280956625938416, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4495/10000, Training Loss: 1.5897185802459717, Training Accuracy: 0.5514705882352942, Validation Loss: 4.356902599334717, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4496/10000, Training Loss: 1.0590239763259888, Training Accuracy: 0.5784313725490197, Validation Loss: 1.7907180786132812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4497/10000, Training Loss: 1.6199779510498047, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1240087747573853, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4498/10000, Training Loss: 1.4009793996810913, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8055872917175293, Validation Accuracy: 0.5\n",
      "Epoch 4499/10000, Training Loss: 1.26604163646698, Training Accuracy: 0.553921568627451, Validation Loss: 1.980674386024475, Validation Accuracy: 0.5\n",
      "Epoch 4500/10000, Training Loss: 1.3131706714630127, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1679922342300415, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4501/10000, Training Loss: 1.0981570482254028, Training Accuracy: 0.5833333333333334, Validation Loss: 2.625264883041382, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4502/10000, Training Loss: 0.9519048929214478, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9780502319335938, Validation Accuracy: 0.5\n",
      "Epoch 4503/10000, Training Loss: 1.0924423933029175, Training Accuracy: 0.5931372549019608, Validation Loss: 2.364496946334839, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4504/10000, Training Loss: 1.008862853050232, Training Accuracy: 0.5808823529411765, Validation Loss: 1.4082012176513672, Validation Accuracy: 0.75\n",
      "Epoch 4505/10000, Training Loss: 1.103330135345459, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9832499027252197, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4506/10000, Training Loss: 1.0816783905029297, Training Accuracy: 0.6274509803921569, Validation Loss: 1.013076663017273, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4507/10000, Training Loss: 1.4335399866104126, Training Accuracy: 0.5906862745098039, Validation Loss: 1.474889874458313, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4508/10000, Training Loss: 1.0091909170150757, Training Accuracy: 0.6078431372549019, Validation Loss: 1.5753412246704102, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4509/10000, Training Loss: 1.1119582653045654, Training Accuracy: 0.5857843137254902, Validation Loss: 1.1097995042800903, Validation Accuracy: 0.5\n",
      "Epoch 4510/10000, Training Loss: 1.3038699626922607, Training Accuracy: 0.5024509803921569, Validation Loss: 2.2296416759490967, Validation Accuracy: 0.5\n",
      "Epoch 4511/10000, Training Loss: 0.9491532444953918, Training Accuracy: 0.625, Validation Loss: 1.3432029485702515, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4512/10000, Training Loss: 1.1386232376098633, Training Accuracy: 0.5686274509803921, Validation Loss: 2.0854527950286865, Validation Accuracy: 0.5\n",
      "Epoch 4513/10000, Training Loss: 1.2513291835784912, Training Accuracy: 0.553921568627451, Validation Loss: 1.4301174879074097, Validation Accuracy: 0.75\n",
      "Epoch 4514/10000, Training Loss: 1.48848557472229, Training Accuracy: 0.5318627450980392, Validation Loss: 1.3756383657455444, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4515/10000, Training Loss: 1.2306805849075317, Training Accuracy: 0.625, Validation Loss: 0.8373773097991943, Validation Accuracy: 0.75\n",
      "Epoch 4516/10000, Training Loss: 1.4573280811309814, Training Accuracy: 0.5686274509803921, Validation Loss: 3.118614435195923, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4517/10000, Training Loss: 1.4099572896957397, Training Accuracy: 0.5441176470588235, Validation Loss: 1.9878345727920532, Validation Accuracy: 0.5\n",
      "Epoch 4518/10000, Training Loss: 2.106895685195923, Training Accuracy: 0.553921568627451, Validation Loss: 1.718937873840332, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4519/10000, Training Loss: 1.8295871019363403, Training Accuracy: 0.4877450980392157, Validation Loss: 3.296154260635376, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4520/10000, Training Loss: 1.330419898033142, Training Accuracy: 0.5416666666666666, Validation Loss: 1.6350644826889038, Validation Accuracy: 0.5\n",
      "Epoch 4521/10000, Training Loss: 1.1474064588546753, Training Accuracy: 0.5857843137254902, Validation Loss: 2.497358560562134, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4522/10000, Training Loss: 1.1976697444915771, Training Accuracy: 0.5318627450980392, Validation Loss: 1.1189296245574951, Validation Accuracy: 0.5\n",
      "Epoch 4523/10000, Training Loss: 1.2316333055496216, Training Accuracy: 0.5318627450980392, Validation Loss: 1.9124292135238647, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4524/10000, Training Loss: 1.0149285793304443, Training Accuracy: 0.5931372549019608, Validation Loss: 1.4350166320800781, Validation Accuracy: 0.5\n",
      "Epoch 4525/10000, Training Loss: 1.2184200286865234, Training Accuracy: 0.6127450980392157, Validation Loss: 1.6598925590515137, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4526/10000, Training Loss: 1.117849588394165, Training Accuracy: 0.6053921568627451, Validation Loss: 1.9897915124893188, Validation Accuracy: 0.5\n",
      "Epoch 4527/10000, Training Loss: 1.1131073236465454, Training Accuracy: 0.5563725490196079, Validation Loss: 0.6704404354095459, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4528/10000, Training Loss: 1.3557868003845215, Training Accuracy: 0.571078431372549, Validation Loss: 2.943917989730835, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4529/10000, Training Loss: 1.4753096103668213, Training Accuracy: 0.5784313725490197, Validation Loss: 2.5735247135162354, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4530/10000, Training Loss: 1.510705828666687, Training Accuracy: 0.45098039215686275, Validation Loss: 2.3750016689300537, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4531/10000, Training Loss: 1.1961019039154053, Training Accuracy: 0.5955882352941176, Validation Loss: 2.392259120941162, Validation Accuracy: 0.25\n",
      "Epoch 4532/10000, Training Loss: 1.0901561975479126, Training Accuracy: 0.5784313725490197, Validation Loss: 1.443668246269226, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4533/10000, Training Loss: 1.479501724243164, Training Accuracy: 0.5931372549019608, Validation Loss: 1.7420387268066406, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4534/10000, Training Loss: 1.027505874633789, Training Accuracy: 0.6053921568627451, Validation Loss: 1.2918564081192017, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4535/10000, Training Loss: 1.286544680595398, Training Accuracy: 0.6029411764705882, Validation Loss: 1.3793805837631226, Validation Accuracy: 0.5\n",
      "Epoch 4536/10000, Training Loss: 1.3505772352218628, Training Accuracy: 0.5441176470588235, Validation Loss: 1.8812659978866577, Validation Accuracy: 0.5\n",
      "Epoch 4537/10000, Training Loss: 1.0806406736373901, Training Accuracy: 0.5784313725490197, Validation Loss: 1.035473346710205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4538/10000, Training Loss: 0.9393499493598938, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1767905950546265, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4539/10000, Training Loss: 1.1053334474563599, Training Accuracy: 0.5269607843137255, Validation Loss: 1.6081047058105469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4540/10000, Training Loss: 1.0230140686035156, Training Accuracy: 0.6078431372549019, Validation Loss: 1.2833393812179565, Validation Accuracy: 0.5\n",
      "Epoch 4541/10000, Training Loss: 1.1179202795028687, Training Accuracy: 0.5833333333333334, Validation Loss: 1.921805500984192, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4542/10000, Training Loss: 1.1351548433303833, Training Accuracy: 0.5294117647058824, Validation Loss: 1.0137063264846802, Validation Accuracy: 0.5\n",
      "Epoch 4543/10000, Training Loss: 1.4259614944458008, Training Accuracy: 0.5465686274509803, Validation Loss: 1.8793176412582397, Validation Accuracy: 0.5\n",
      "Epoch 4544/10000, Training Loss: 1.3995059728622437, Training Accuracy: 0.5833333333333334, Validation Loss: 2.873450994491577, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4545/10000, Training Loss: 1.5563361644744873, Training Accuracy: 0.6078431372549019, Validation Loss: 3.3238518238067627, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4546/10000, Training Loss: 1.192548155784607, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0956906080245972, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4547/10000, Training Loss: 1.4064459800720215, Training Accuracy: 0.6299019607843137, Validation Loss: 2.7978599071502686, Validation Accuracy: 0.5\n",
      "Epoch 4548/10000, Training Loss: 1.3831920623779297, Training Accuracy: 0.5, Validation Loss: 2.2365269660949707, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4549/10000, Training Loss: 0.8983545303344727, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7214803695678711, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4550/10000, Training Loss: 1.2847102880477905, Training Accuracy: 0.49754901960784315, Validation Loss: 1.762007236480713, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4551/10000, Training Loss: 1.0751519203186035, Training Accuracy: 0.5220588235294118, Validation Loss: 0.7253284454345703, Validation Accuracy: 0.75\n",
      "Epoch 4552/10000, Training Loss: 1.160512089729309, Training Accuracy: 0.5784313725490197, Validation Loss: 1.8506606817245483, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4553/10000, Training Loss: 1.2935584783554077, Training Accuracy: 0.6225490196078431, Validation Loss: 2.035285711288452, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4554/10000, Training Loss: 1.4591755867004395, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8981013298034668, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4555/10000, Training Loss: 1.3278028964996338, Training Accuracy: 0.5563725490196079, Validation Loss: 1.9094246625900269, Validation Accuracy: 0.5\n",
      "Epoch 4556/10000, Training Loss: 1.1431775093078613, Training Accuracy: 0.5441176470588235, Validation Loss: 2.2162773609161377, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4557/10000, Training Loss: 1.437703251838684, Training Accuracy: 0.5784313725490197, Validation Loss: 1.812854290008545, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4558/10000, Training Loss: 1.3024821281433105, Training Accuracy: 0.5686274509803921, Validation Loss: 2.521540641784668, Validation Accuracy: 0.25\n",
      "Epoch 4559/10000, Training Loss: 1.3155765533447266, Training Accuracy: 0.5392156862745098, Validation Loss: 2.190485954284668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4560/10000, Training Loss: 1.252683162689209, Training Accuracy: 0.6176470588235294, Validation Loss: 1.979180932044983, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4561/10000, Training Loss: 1.082352876663208, Training Accuracy: 0.625, Validation Loss: 2.9782676696777344, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4562/10000, Training Loss: 1.1316163539886475, Training Accuracy: 0.5857843137254902, Validation Loss: 1.6002787351608276, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4563/10000, Training Loss: 1.5197887420654297, Training Accuracy: 0.5196078431372549, Validation Loss: 1.6408511400222778, Validation Accuracy: 0.5\n",
      "Epoch 4564/10000, Training Loss: 1.1249083280563354, Training Accuracy: 0.5588235294117647, Validation Loss: 1.739782452583313, Validation Accuracy: 0.5\n",
      "Epoch 4565/10000, Training Loss: 1.1648778915405273, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1507967710494995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4566/10000, Training Loss: 1.4878743886947632, Training Accuracy: 0.6053921568627451, Validation Loss: 3.201312303543091, Validation Accuracy: 0.5\n",
      "Epoch 4567/10000, Training Loss: 1.271610975265503, Training Accuracy: 0.571078431372549, Validation Loss: 2.1749231815338135, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4568/10000, Training Loss: 1.0697696208953857, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3679208755493164, Validation Accuracy: 0.5\n",
      "Epoch 4569/10000, Training Loss: 1.080966591835022, Training Accuracy: 0.5563725490196079, Validation Loss: 2.4517643451690674, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4570/10000, Training Loss: 1.3710012435913086, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8836591839790344, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4571/10000, Training Loss: 1.1338714361190796, Training Accuracy: 0.5563725490196079, Validation Loss: 1.1852482557296753, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4572/10000, Training Loss: 1.0559685230255127, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8428397178649902, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4573/10000, Training Loss: 1.1711063385009766, Training Accuracy: 0.5882352941176471, Validation Loss: 2.315340757369995, Validation Accuracy: 0.5\n",
      "Epoch 4574/10000, Training Loss: 1.1170028448104858, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8163645267486572, Validation Accuracy: 0.5\n",
      "Epoch 4575/10000, Training Loss: 1.3303446769714355, Training Accuracy: 0.5318627450980392, Validation Loss: 0.8879923820495605, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4576/10000, Training Loss: 1.053417682647705, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1235198974609375, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4577/10000, Training Loss: 1.099488615989685, Training Accuracy: 0.5318627450980392, Validation Loss: 1.1421891450881958, Validation Accuracy: 0.5\n",
      "Epoch 4578/10000, Training Loss: 0.9747103452682495, Training Accuracy: 0.5686274509803921, Validation Loss: 1.846640944480896, Validation Accuracy: 0.25\n",
      "Epoch 4579/10000, Training Loss: 1.1752876043319702, Training Accuracy: 0.6102941176470589, Validation Loss: 0.4242191016674042, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4580/10000, Training Loss: 1.1647419929504395, Training Accuracy: 0.5563725490196079, Validation Loss: 1.0839323997497559, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4581/10000, Training Loss: 1.1485936641693115, Training Accuracy: 0.5784313725490197, Validation Loss: 3.0011684894561768, Validation Accuracy: 0.25\n",
      "Epoch 4582/10000, Training Loss: 1.1349685192108154, Training Accuracy: 0.6372549019607843, Validation Loss: 2.845231771469116, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4583/10000, Training Loss: 1.1937814950942993, Training Accuracy: 0.6200980392156863, Validation Loss: 3.0057260990142822, Validation Accuracy: 0.25\n",
      "Epoch 4584/10000, Training Loss: 1.5886929035186768, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0832526683807373, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4585/10000, Training Loss: 1.234617829322815, Training Accuracy: 0.5514705882352942, Validation Loss: 0.940385639667511, Validation Accuracy: 0.5\n",
      "Epoch 4586/10000, Training Loss: 1.445576548576355, Training Accuracy: 0.5196078431372549, Validation Loss: 1.2752110958099365, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4587/10000, Training Loss: 1.8227216005325317, Training Accuracy: 0.5245098039215687, Validation Loss: 3.0325307846069336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4588/10000, Training Loss: 1.1702994108200073, Training Accuracy: 0.6004901960784313, Validation Loss: 2.8910605907440186, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4589/10000, Training Loss: 1.6022472381591797, Training Accuracy: 0.5514705882352942, Validation Loss: 3.172271490097046, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4590/10000, Training Loss: 1.435899019241333, Training Accuracy: 0.5392156862745098, Validation Loss: 1.7970318794250488, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4591/10000, Training Loss: 1.5265508890151978, Training Accuracy: 0.5392156862745098, Validation Loss: 1.3788868188858032, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4592/10000, Training Loss: 1.0681825876235962, Training Accuracy: 0.5906862745098039, Validation Loss: 1.135549545288086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4593/10000, Training Loss: 1.0948506593704224, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9694302678108215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4594/10000, Training Loss: 1.3682727813720703, Training Accuracy: 0.5294117647058824, Validation Loss: 2.1314451694488525, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4595/10000, Training Loss: 1.1597874164581299, Training Accuracy: 0.6078431372549019, Validation Loss: 2.9437789916992188, Validation Accuracy: 0.5\n",
      "Epoch 4596/10000, Training Loss: 1.1791818141937256, Training Accuracy: 0.5441176470588235, Validation Loss: 1.9986079931259155, Validation Accuracy: 0.5\n",
      "Epoch 4597/10000, Training Loss: 1.50692617893219, Training Accuracy: 0.5661764705882353, Validation Loss: 0.5442179441452026, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4598/10000, Training Loss: 1.3861236572265625, Training Accuracy: 0.6078431372549019, Validation Loss: 4.320114612579346, Validation Accuracy: 0.25\n",
      "Epoch 4599/10000, Training Loss: 1.2717243432998657, Training Accuracy: 0.571078431372549, Validation Loss: 2.1067922115325928, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4600/10000, Training Loss: 0.9924262762069702, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1130927801132202, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4601/10000, Training Loss: 1.2134822607040405, Training Accuracy: 0.5514705882352942, Validation Loss: 1.5112224817276, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4602/10000, Training Loss: 0.8704848885536194, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6345721483230591, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4603/10000, Training Loss: 1.1598106622695923, Training Accuracy: 0.5024509803921569, Validation Loss: 1.5397372245788574, Validation Accuracy: 0.25\n",
      "Epoch 4604/10000, Training Loss: 1.3329614400863647, Training Accuracy: 0.5441176470588235, Validation Loss: 1.8119544982910156, Validation Accuracy: 0.5\n",
      "Epoch 4605/10000, Training Loss: 1.1163549423217773, Training Accuracy: 0.5490196078431373, Validation Loss: 1.675653100013733, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4606/10000, Training Loss: 1.4260361194610596, Training Accuracy: 0.5441176470588235, Validation Loss: 2.0233168601989746, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4607/10000, Training Loss: 1.2058062553405762, Training Accuracy: 0.5955882352941176, Validation Loss: 1.4379318952560425, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4608/10000, Training Loss: 1.0952767133712769, Training Accuracy: 0.6568627450980392, Validation Loss: 2.0608558654785156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4609/10000, Training Loss: 1.6800256967544556, Training Accuracy: 0.5122549019607843, Validation Loss: 0.4728921353816986, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4610/10000, Training Loss: 1.0088227987289429, Training Accuracy: 0.6421568627450981, Validation Loss: 2.0649971961975098, Validation Accuracy: 0.5\n",
      "Epoch 4611/10000, Training Loss: 1.1388665437698364, Training Accuracy: 0.6004901960784313, Validation Loss: 2.456983804702759, Validation Accuracy: 0.0\n",
      "Epoch 4612/10000, Training Loss: 1.1740427017211914, Training Accuracy: 0.6053921568627451, Validation Loss: 4.249083995819092, Validation Accuracy: 0.25\n",
      "Epoch 4613/10000, Training Loss: 1.4697567224502563, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9340330958366394, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4614/10000, Training Loss: 1.4701348543167114, Training Accuracy: 0.5686274509803921, Validation Loss: 0.728477954864502, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4615/10000, Training Loss: 1.204897403717041, Training Accuracy: 0.5857843137254902, Validation Loss: 1.9389029741287231, Validation Accuracy: 0.5\n",
      "Epoch 4616/10000, Training Loss: 1.6418033838272095, Training Accuracy: 0.5294117647058824, Validation Loss: 3.7860050201416016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4617/10000, Training Loss: 0.9635065197944641, Training Accuracy: 0.5392156862745098, Validation Loss: 2.8748579025268555, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4618/10000, Training Loss: 1.3122568130493164, Training Accuracy: 0.4877450980392157, Validation Loss: 1.4882582426071167, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4619/10000, Training Loss: 0.9245729446411133, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7076321244239807, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4620/10000, Training Loss: 1.2035248279571533, Training Accuracy: 0.5759803921568627, Validation Loss: 2.229517698287964, Validation Accuracy: 0.5\n",
      "Epoch 4621/10000, Training Loss: 1.152428388595581, Training Accuracy: 0.5661764705882353, Validation Loss: 2.1282002925872803, Validation Accuracy: 0.5\n",
      "Epoch 4622/10000, Training Loss: 1.1487621068954468, Training Accuracy: 0.6348039215686274, Validation Loss: 3.29801082611084, Validation Accuracy: 0.25\n",
      "Epoch 4623/10000, Training Loss: 1.2811213731765747, Training Accuracy: 0.5441176470588235, Validation Loss: 1.082682728767395, Validation Accuracy: 0.5\n",
      "Epoch 4624/10000, Training Loss: 1.270545482635498, Training Accuracy: 0.6225490196078431, Validation Loss: 2.1915338039398193, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4625/10000, Training Loss: 1.1371078491210938, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7561476826667786, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4626/10000, Training Loss: 1.1303067207336426, Training Accuracy: 0.5245098039215687, Validation Loss: 0.7441542744636536, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4627/10000, Training Loss: 1.3727909326553345, Training Accuracy: 0.5882352941176471, Validation Loss: 1.2043832540512085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4628/10000, Training Loss: 1.1589165925979614, Training Accuracy: 0.5490196078431373, Validation Loss: 1.7712138891220093, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4629/10000, Training Loss: 1.3755415678024292, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7539073824882507, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4630/10000, Training Loss: 1.0356978178024292, Training Accuracy: 0.5661764705882353, Validation Loss: 1.145548701286316, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4631/10000, Training Loss: 0.9557563662528992, Training Accuracy: 0.625, Validation Loss: 1.2685073614120483, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4632/10000, Training Loss: 1.3291069269180298, Training Accuracy: 0.5784313725490197, Validation Loss: 2.0853497982025146, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4633/10000, Training Loss: 1.0681694746017456, Training Accuracy: 0.5906862745098039, Validation Loss: 2.8100109100341797, Validation Accuracy: 0.25\n",
      "Epoch 4634/10000, Training Loss: 1.1679892539978027, Training Accuracy: 0.5392156862745098, Validation Loss: 0.37271344661712646, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4635/10000, Training Loss: 0.9706656336784363, Training Accuracy: 0.6421568627450981, Validation Loss: 1.1301642656326294, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4636/10000, Training Loss: 1.4516128301620483, Training Accuracy: 0.5269607843137255, Validation Loss: 1.3922289609909058, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4637/10000, Training Loss: 1.0651402473449707, Training Accuracy: 0.5294117647058824, Validation Loss: 0.8057733178138733, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4638/10000, Training Loss: 1.5372209548950195, Training Accuracy: 0.5563725490196079, Validation Loss: 2.3101065158843994, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4639/10000, Training Loss: 1.3002862930297852, Training Accuracy: 0.5980392156862745, Validation Loss: 2.353933095932007, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4640/10000, Training Loss: 1.0155655145645142, Training Accuracy: 0.5735294117647058, Validation Loss: 3.5474021434783936, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4641/10000, Training Loss: 1.0721383094787598, Training Accuracy: 0.4950980392156863, Validation Loss: 1.583193302154541, Validation Accuracy: 0.25\n",
      "Epoch 4642/10000, Training Loss: 1.20134437084198, Training Accuracy: 0.5514705882352942, Validation Loss: 1.8242014646530151, Validation Accuracy: 0.25\n",
      "Epoch 4643/10000, Training Loss: 0.9802486896514893, Training Accuracy: 0.5784313725490197, Validation Loss: 1.0823400020599365, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4644/10000, Training Loss: 1.143880844116211, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7691605091094971, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4645/10000, Training Loss: 1.111185073852539, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8101487755775452, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4646/10000, Training Loss: 1.005053997039795, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3578075170516968, Validation Accuracy: 0.5\n",
      "Epoch 4647/10000, Training Loss: 1.1380115747451782, Training Accuracy: 0.4632352941176471, Validation Loss: 1.8864449262619019, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4648/10000, Training Loss: 1.2545818090438843, Training Accuracy: 0.5833333333333334, Validation Loss: 2.6856257915496826, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4649/10000, Training Loss: 1.130089282989502, Training Accuracy: 0.5784313725490197, Validation Loss: 0.4586069881916046, Validation Accuracy: 0.75\n",
      "Epoch 4650/10000, Training Loss: 1.2422220706939697, Training Accuracy: 0.4852941176470588, Validation Loss: 1.313228726387024, Validation Accuracy: 0.5\n",
      "Epoch 4651/10000, Training Loss: 1.1543785333633423, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3762192726135254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4652/10000, Training Loss: 1.3217719793319702, Training Accuracy: 0.5441176470588235, Validation Loss: 2.8676979541778564, Validation Accuracy: 0.5\n",
      "Epoch 4653/10000, Training Loss: 1.128462791442871, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7414632439613342, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4654/10000, Training Loss: 1.1554230451583862, Training Accuracy: 0.571078431372549, Validation Loss: 1.4583806991577148, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4655/10000, Training Loss: 1.045914649963379, Training Accuracy: 0.5931372549019608, Validation Loss: 2.2769439220428467, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4656/10000, Training Loss: 1.1235737800598145, Training Accuracy: 0.6372549019607843, Validation Loss: 1.5293859243392944, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4657/10000, Training Loss: 1.4810439348220825, Training Accuracy: 0.5637254901960784, Validation Loss: 1.598177433013916, Validation Accuracy: 0.5\n",
      "Epoch 4658/10000, Training Loss: 1.0396219491958618, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0375810861587524, Validation Accuracy: 0.25\n",
      "Epoch 4659/10000, Training Loss: 1.3260880708694458, Training Accuracy: 0.5318627450980392, Validation Loss: 2.3821322917938232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4660/10000, Training Loss: 0.9944671988487244, Training Accuracy: 0.6274509803921569, Validation Loss: 1.7080484628677368, Validation Accuracy: 0.5\n",
      "Epoch 4661/10000, Training Loss: 0.9216780066490173, Training Accuracy: 0.5833333333333334, Validation Loss: 1.4996623992919922, Validation Accuracy: 0.5\n",
      "Epoch 4662/10000, Training Loss: 1.0518943071365356, Training Accuracy: 0.5294117647058824, Validation Loss: 2.121119976043701, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4663/10000, Training Loss: 1.1483408212661743, Training Accuracy: 0.5073529411764706, Validation Loss: 1.076789379119873, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4664/10000, Training Loss: 1.0834569931030273, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8883572220802307, Validation Accuracy: 0.5\n",
      "Epoch 4665/10000, Training Loss: 1.3992897272109985, Training Accuracy: 0.571078431372549, Validation Loss: 2.3948140144348145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4666/10000, Training Loss: 1.5253095626831055, Training Accuracy: 0.5784313725490197, Validation Loss: 3.5675175189971924, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4667/10000, Training Loss: 0.896511435508728, Training Accuracy: 0.6715686274509803, Validation Loss: 1.2845207452774048, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4668/10000, Training Loss: 1.0400688648223877, Training Accuracy: 0.6200980392156863, Validation Loss: 2.0493736267089844, Validation Accuracy: 0.5\n",
      "Epoch 4669/10000, Training Loss: 1.8097480535507202, Training Accuracy: 0.5661764705882353, Validation Loss: 1.085890293121338, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4670/10000, Training Loss: 1.1419082880020142, Training Accuracy: 0.5857843137254902, Validation Loss: 2.181128740310669, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4671/10000, Training Loss: 1.2607094049453735, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1276540756225586, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4672/10000, Training Loss: 0.9706245064735413, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0147535800933838, Validation Accuracy: 0.75\n",
      "Epoch 4673/10000, Training Loss: 1.2712197303771973, Training Accuracy: 0.5563725490196079, Validation Loss: 1.5691226720809937, Validation Accuracy: 0.5\n",
      "Epoch 4674/10000, Training Loss: 1.3298068046569824, Training Accuracy: 0.5171568627450981, Validation Loss: 1.2708501815795898, Validation Accuracy: 0.5\n",
      "Epoch 4675/10000, Training Loss: 1.497431993484497, Training Accuracy: 0.5269607843137255, Validation Loss: 1.241940975189209, Validation Accuracy: 0.5\n",
      "Epoch 4676/10000, Training Loss: 1.1145200729370117, Training Accuracy: 0.5661764705882353, Validation Loss: 1.8656772375106812, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4677/10000, Training Loss: 1.0393695831298828, Training Accuracy: 0.6593137254901961, Validation Loss: 1.2517112493515015, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4678/10000, Training Loss: 1.104702115058899, Training Accuracy: 0.5441176470588235, Validation Loss: 1.362824559211731, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4679/10000, Training Loss: 1.0971040725708008, Training Accuracy: 0.5392156862745098, Validation Loss: 1.0774861574172974, Validation Accuracy: 0.5\n",
      "Epoch 4680/10000, Training Loss: 1.230454444885254, Training Accuracy: 0.5147058823529411, Validation Loss: 1.1901752948760986, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4681/10000, Training Loss: 1.202470302581787, Training Accuracy: 0.553921568627451, Validation Loss: 1.9034680128097534, Validation Accuracy: 0.25\n",
      "Epoch 4682/10000, Training Loss: 0.9690076112747192, Training Accuracy: 0.571078431372549, Validation Loss: 1.0313869714736938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4683/10000, Training Loss: 1.1788562536239624, Training Accuracy: 0.5563725490196079, Validation Loss: 1.8650022745132446, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4684/10000, Training Loss: 1.0610995292663574, Training Accuracy: 0.5980392156862745, Validation Loss: 2.0901637077331543, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4685/10000, Training Loss: 1.1423085927963257, Training Accuracy: 0.5465686274509803, Validation Loss: 1.4649271965026855, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4686/10000, Training Loss: 1.1933304071426392, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9228580594062805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4687/10000, Training Loss: 1.4410895109176636, Training Accuracy: 0.5759803921568627, Validation Loss: 1.254170298576355, Validation Accuracy: 0.5\n",
      "Epoch 4688/10000, Training Loss: 1.1858792304992676, Training Accuracy: 0.5857843137254902, Validation Loss: 0.5979307889938354, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4689/10000, Training Loss: 0.9516081213951111, Training Accuracy: 0.6274509803921569, Validation Loss: 2.0412137508392334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4690/10000, Training Loss: 1.1094437837600708, Training Accuracy: 0.5759803921568627, Validation Loss: 2.2211601734161377, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4691/10000, Training Loss: 1.3180999755859375, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8098850250244141, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4692/10000, Training Loss: 1.3333523273468018, Training Accuracy: 0.5, Validation Loss: 1.2413349151611328, Validation Accuracy: 0.5\n",
      "Epoch 4693/10000, Training Loss: 1.0818490982055664, Training Accuracy: 0.6200980392156863, Validation Loss: 1.4706288576126099, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4694/10000, Training Loss: 0.9779345393180847, Training Accuracy: 0.5147058823529411, Validation Loss: 0.6912174224853516, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4695/10000, Training Loss: 1.058060646057129, Training Accuracy: 0.5269607843137255, Validation Loss: 1.5033540725708008, Validation Accuracy: 0.25\n",
      "Epoch 4696/10000, Training Loss: 1.0696464776992798, Training Accuracy: 0.5882352941176471, Validation Loss: 1.3985471725463867, Validation Accuracy: 0.5\n",
      "Epoch 4697/10000, Training Loss: 0.994620680809021, Training Accuracy: 0.6004901960784313, Validation Loss: 2.636169672012329, Validation Accuracy: 0.5\n",
      "Epoch 4698/10000, Training Loss: 0.976611852645874, Training Accuracy: 0.625, Validation Loss: 2.015793561935425, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4699/10000, Training Loss: 1.0665109157562256, Training Accuracy: 0.6274509803921569, Validation Loss: 2.688901662826538, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4700/10000, Training Loss: 1.004319190979004, Training Accuracy: 0.5637254901960784, Validation Loss: 1.442611575126648, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4701/10000, Training Loss: 1.0265311002731323, Training Accuracy: 0.5661764705882353, Validation Loss: 1.2676273584365845, Validation Accuracy: 0.5\n",
      "Epoch 4702/10000, Training Loss: 1.1019669771194458, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9851529002189636, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4703/10000, Training Loss: 0.9640371203422546, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8672542572021484, Validation Accuracy: 0.5\n",
      "Epoch 4704/10000, Training Loss: 1.019004225730896, Training Accuracy: 0.5955882352941176, Validation Loss: 1.079250693321228, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4705/10000, Training Loss: 1.2959250211715698, Training Accuracy: 0.5441176470588235, Validation Loss: 1.077844500541687, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4706/10000, Training Loss: 1.1219955682754517, Training Accuracy: 0.5955882352941176, Validation Loss: 1.3485199213027954, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4707/10000, Training Loss: 1.191226601600647, Training Accuracy: 0.5686274509803921, Validation Loss: 3.846254348754883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4708/10000, Training Loss: 1.2716556787490845, Training Accuracy: 0.5465686274509803, Validation Loss: 2.099607229232788, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4709/10000, Training Loss: 1.3758893013000488, Training Accuracy: 0.5122549019607843, Validation Loss: 1.6308749914169312, Validation Accuracy: 0.5\n",
      "Epoch 4710/10000, Training Loss: 0.9545854926109314, Training Accuracy: 0.6274509803921569, Validation Loss: 1.5248597860336304, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4711/10000, Training Loss: 1.1043099164962769, Training Accuracy: 0.5661764705882353, Validation Loss: 1.8180917501449585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4712/10000, Training Loss: 1.2575513124465942, Training Accuracy: 0.5735294117647058, Validation Loss: 1.3153338432312012, Validation Accuracy: 0.5\n",
      "Epoch 4713/10000, Training Loss: 0.9299195408821106, Training Accuracy: 0.5612745098039216, Validation Loss: 1.1187360286712646, Validation Accuracy: 0.5\n",
      "Epoch 4714/10000, Training Loss: 1.0997453927993774, Training Accuracy: 0.6127450980392157, Validation Loss: 1.7704633474349976, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4715/10000, Training Loss: 1.0159053802490234, Training Accuracy: 0.5637254901960784, Validation Loss: 1.4906082153320312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4716/10000, Training Loss: 1.7846204042434692, Training Accuracy: 0.5122549019607843, Validation Loss: 1.682355523109436, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4717/10000, Training Loss: 0.9134204387664795, Training Accuracy: 0.6348039215686274, Validation Loss: 0.992372989654541, Validation Accuracy: 0.5\n",
      "Epoch 4718/10000, Training Loss: 1.0726330280303955, Training Accuracy: 0.5490196078431373, Validation Loss: 2.406751871109009, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4719/10000, Training Loss: 0.9966063499450684, Training Accuracy: 0.5980392156862745, Validation Loss: 1.9472020864486694, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4720/10000, Training Loss: 1.1705036163330078, Training Accuracy: 0.5833333333333334, Validation Loss: 1.4859861135482788, Validation Accuracy: 0.25\n",
      "Epoch 4721/10000, Training Loss: 1.3034143447875977, Training Accuracy: 0.5588235294117647, Validation Loss: 3.122196912765503, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4722/10000, Training Loss: 1.0526785850524902, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7791621088981628, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4723/10000, Training Loss: 1.0737675428390503, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7274831533432007, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4724/10000, Training Loss: 1.15445876121521, Training Accuracy: 0.6053921568627451, Validation Loss: 1.5939222574234009, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4725/10000, Training Loss: 0.7845736742019653, Training Accuracy: 0.6274509803921569, Validation Loss: 1.5574756860733032, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4726/10000, Training Loss: 0.8946424126625061, Training Accuracy: 0.6544117647058824, Validation Loss: 1.0310200452804565, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4727/10000, Training Loss: 1.3307338953018188, Training Accuracy: 0.49754901960784315, Validation Loss: 1.6520261764526367, Validation Accuracy: 0.25\n",
      "Epoch 4728/10000, Training Loss: 1.1352591514587402, Training Accuracy: 0.5955882352941176, Validation Loss: 1.2536625862121582, Validation Accuracy: 0.5\n",
      "Epoch 4729/10000, Training Loss: 0.9850320219993591, Training Accuracy: 0.5588235294117647, Validation Loss: 1.5868372917175293, Validation Accuracy: 0.25\n",
      "Epoch 4730/10000, Training Loss: 1.2053873538970947, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0911614894866943, Validation Accuracy: 0.75\n",
      "Epoch 4731/10000, Training Loss: 1.0952229499816895, Training Accuracy: 0.5833333333333334, Validation Loss: 1.6291524171829224, Validation Accuracy: 0.5\n",
      "Epoch 4732/10000, Training Loss: 0.9908720254898071, Training Accuracy: 0.5931372549019608, Validation Loss: 1.2083646059036255, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4733/10000, Training Loss: 0.9370870590209961, Training Accuracy: 0.5833333333333334, Validation Loss: 1.4855581521987915, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4734/10000, Training Loss: 0.8108351230621338, Training Accuracy: 0.6593137254901961, Validation Loss: 1.4365524053573608, Validation Accuracy: 0.5\n",
      "Epoch 4735/10000, Training Loss: 1.124532699584961, Training Accuracy: 0.6053921568627451, Validation Loss: 2.046983242034912, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4736/10000, Training Loss: 0.9615883827209473, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2075263261795044, Validation Accuracy: 0.5\n",
      "Epoch 4737/10000, Training Loss: 1.2594810724258423, Training Accuracy: 0.5049019607843137, Validation Loss: 0.9376392364501953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4738/10000, Training Loss: 0.974126398563385, Training Accuracy: 0.6127450980392157, Validation Loss: 2.3517096042633057, Validation Accuracy: 0.25\n",
      "Epoch 4739/10000, Training Loss: 0.9846435785293579, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9075384140014648, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4740/10000, Training Loss: 1.1049761772155762, Training Accuracy: 0.6200980392156863, Validation Loss: 2.785856008529663, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4741/10000, Training Loss: 0.8708933591842651, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9168219566345215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4742/10000, Training Loss: 1.028141736984253, Training Accuracy: 0.5980392156862745, Validation Loss: 1.605221152305603, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4743/10000, Training Loss: 1.1196295022964478, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9852766990661621, Validation Accuracy: 0.5\n",
      "Epoch 4744/10000, Training Loss: 1.0891504287719727, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0339775085449219, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4745/10000, Training Loss: 1.43971586227417, Training Accuracy: 0.5490196078431373, Validation Loss: 1.5431596040725708, Validation Accuracy: 0.25\n",
      "Epoch 4746/10000, Training Loss: 0.9412589073181152, Training Accuracy: 0.5906862745098039, Validation Loss: 1.6607483625411987, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4747/10000, Training Loss: 1.225027084350586, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1176248788833618, Validation Accuracy: 0.5\n",
      "Epoch 4748/10000, Training Loss: 1.2100192308425903, Training Accuracy: 0.6397058823529411, Validation Loss: 1.8004069328308105, Validation Accuracy: 0.5\n",
      "Epoch 4749/10000, Training Loss: 1.407808780670166, Training Accuracy: 0.6078431372549019, Validation Loss: 2.0844004154205322, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4750/10000, Training Loss: 1.283598780632019, Training Accuracy: 0.6299019607843137, Validation Loss: 2.3126137256622314, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4751/10000, Training Loss: 1.329540491104126, Training Accuracy: 0.5784313725490197, Validation Loss: 1.1631417274475098, Validation Accuracy: 0.5\n",
      "Epoch 4752/10000, Training Loss: 0.982269287109375, Training Accuracy: 0.5122549019607843, Validation Loss: 0.4049149751663208, Validation Accuracy: 0.75\n",
      "Epoch 4753/10000, Training Loss: 1.1345661878585815, Training Accuracy: 0.625, Validation Loss: 1.366726279258728, Validation Accuracy: 0.5\n",
      "Epoch 4754/10000, Training Loss: 1.1844342947006226, Training Accuracy: 0.5514705882352942, Validation Loss: 0.9155856966972351, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4755/10000, Training Loss: 1.0654007196426392, Training Accuracy: 0.6323529411764706, Validation Loss: 1.402553677558899, Validation Accuracy: 0.5\n",
      "Epoch 4756/10000, Training Loss: 1.6425458192825317, Training Accuracy: 0.553921568627451, Validation Loss: 1.3239554166793823, Validation Accuracy: 0.5\n",
      "Epoch 4757/10000, Training Loss: 0.9985139966011047, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9446277022361755, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4758/10000, Training Loss: 1.0949307680130005, Training Accuracy: 0.5122549019607843, Validation Loss: 3.201995849609375, Validation Accuracy: 0.25\n",
      "Epoch 4759/10000, Training Loss: 1.1139116287231445, Training Accuracy: 0.6348039215686274, Validation Loss: 1.6987754106521606, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4760/10000, Training Loss: 1.280535340309143, Training Accuracy: 0.5588235294117647, Validation Loss: 1.3539276123046875, Validation Accuracy: 0.5\n",
      "Epoch 4761/10000, Training Loss: 1.145288348197937, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1197527647018433, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4762/10000, Training Loss: 0.988206148147583, Training Accuracy: 0.5857843137254902, Validation Loss: 2.106388807296753, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4763/10000, Training Loss: 1.172952651977539, Training Accuracy: 0.571078431372549, Validation Loss: 0.9088373780250549, Validation Accuracy: 0.75\n",
      "Epoch 4764/10000, Training Loss: 1.0241012573242188, Training Accuracy: 0.5441176470588235, Validation Loss: 0.5152403116226196, Validation Accuracy: 0.75\n",
      "Epoch 4765/10000, Training Loss: 0.9115199446678162, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7805449366569519, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4766/10000, Training Loss: 1.317084789276123, Training Accuracy: 0.5441176470588235, Validation Loss: 1.3074220418930054, Validation Accuracy: 0.5\n",
      "Epoch 4767/10000, Training Loss: 1.041486382484436, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8644571900367737, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4768/10000, Training Loss: 1.0602002143859863, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0784715414047241, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4769/10000, Training Loss: 0.8207847476005554, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2618564367294312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4770/10000, Training Loss: 0.7955818772315979, Training Accuracy: 0.5931372549019608, Validation Loss: 1.190565824508667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4771/10000, Training Loss: 1.1626315116882324, Training Accuracy: 0.5808823529411765, Validation Loss: 1.3629928827285767, Validation Accuracy: 0.5\n",
      "Epoch 4772/10000, Training Loss: 1.1648902893066406, Training Accuracy: 0.5980392156862745, Validation Loss: 1.2790734767913818, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4773/10000, Training Loss: 1.065156102180481, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1876775026321411, Validation Accuracy: 0.5\n",
      "Epoch 4774/10000, Training Loss: 1.3465430736541748, Training Accuracy: 0.5220588235294118, Validation Loss: 1.8625074625015259, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4775/10000, Training Loss: 1.2589590549468994, Training Accuracy: 0.4950980392156863, Validation Loss: 1.6737403869628906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4776/10000, Training Loss: 1.2493929862976074, Training Accuracy: 0.5245098039215687, Validation Loss: 1.362655758857727, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4777/10000, Training Loss: 0.9138813614845276, Training Accuracy: 0.6151960784313726, Validation Loss: 1.652894139289856, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4778/10000, Training Loss: 1.2781219482421875, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1790072917938232, Validation Accuracy: 0.5\n",
      "Epoch 4779/10000, Training Loss: 1.0725902318954468, Training Accuracy: 0.5784313725490197, Validation Loss: 0.704552412033081, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4780/10000, Training Loss: 1.1317687034606934, Training Accuracy: 0.571078431372549, Validation Loss: 1.877776026725769, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4781/10000, Training Loss: 1.2376788854599, Training Accuracy: 0.5735294117647058, Validation Loss: 1.3088830709457397, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4782/10000, Training Loss: 1.3354068994522095, Training Accuracy: 0.5612745098039216, Validation Loss: 1.9223603010177612, Validation Accuracy: 0.5\n",
      "Epoch 4783/10000, Training Loss: 1.0759434700012207, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6909543871879578, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4784/10000, Training Loss: 1.0592447519302368, Training Accuracy: 0.5514705882352942, Validation Loss: 2.6340901851654053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4785/10000, Training Loss: 1.6630922555923462, Training Accuracy: 0.4877450980392157, Validation Loss: 1.6420921087265015, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4786/10000, Training Loss: 0.9258326292037964, Training Accuracy: 0.5931372549019608, Validation Loss: 1.3765010833740234, Validation Accuracy: 0.25\n",
      "Epoch 4787/10000, Training Loss: 1.3250527381896973, Training Accuracy: 0.5245098039215687, Validation Loss: 2.7052810192108154, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4788/10000, Training Loss: 1.1203380823135376, Training Accuracy: 0.4877450980392157, Validation Loss: 0.6581970453262329, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4789/10000, Training Loss: 1.1802111864089966, Training Accuracy: 0.5784313725490197, Validation Loss: 1.7661267518997192, Validation Accuracy: 0.5\n",
      "Epoch 4790/10000, Training Loss: 0.9175295233726501, Training Accuracy: 0.6004901960784313, Validation Loss: 1.4385308027267456, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4791/10000, Training Loss: 1.085536003112793, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7379014492034912, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4792/10000, Training Loss: 1.2097220420837402, Training Accuracy: 0.5269607843137255, Validation Loss: 1.1911118030548096, Validation Accuracy: 0.5\n",
      "Epoch 4793/10000, Training Loss: 1.6983377933502197, Training Accuracy: 0.553921568627451, Validation Loss: 3.2384092807769775, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4794/10000, Training Loss: 0.8904387354850769, Training Accuracy: 0.6078431372549019, Validation Loss: 1.6571882963180542, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4795/10000, Training Loss: 1.0758519172668457, Training Accuracy: 0.6200980392156863, Validation Loss: 1.316733717918396, Validation Accuracy: 0.75\n",
      "Epoch 4796/10000, Training Loss: 0.9932411313056946, Training Accuracy: 0.5416666666666666, Validation Loss: 1.9298229217529297, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4797/10000, Training Loss: 0.9592819809913635, Training Accuracy: 0.5588235294117647, Validation Loss: 1.2251697778701782, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4798/10000, Training Loss: 0.9289868474006653, Training Accuracy: 0.5514705882352942, Validation Loss: 1.328818917274475, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4799/10000, Training Loss: 0.883263111114502, Training Accuracy: 0.5563725490196079, Validation Loss: 1.829839825630188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4800/10000, Training Loss: 0.8737890124320984, Training Accuracy: 0.6053921568627451, Validation Loss: 1.559364914894104, Validation Accuracy: 0.25\n",
      "Epoch 4801/10000, Training Loss: 0.994564414024353, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0894622802734375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4802/10000, Training Loss: 1.0646620988845825, Training Accuracy: 0.5196078431372549, Validation Loss: 1.253230333328247, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4803/10000, Training Loss: 1.040303111076355, Training Accuracy: 0.5024509803921569, Validation Loss: 1.3313775062561035, Validation Accuracy: 0.25\n",
      "Epoch 4804/10000, Training Loss: 1.2435530424118042, Training Accuracy: 0.5980392156862745, Validation Loss: 1.6435686349868774, Validation Accuracy: 0.5\n",
      "Epoch 4805/10000, Training Loss: 0.9402158260345459, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9784908294677734, Validation Accuracy: 0.5\n",
      "Epoch 4806/10000, Training Loss: 1.2646089792251587, Training Accuracy: 0.571078431372549, Validation Loss: 1.8220800161361694, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4807/10000, Training Loss: 0.9708949327468872, Training Accuracy: 0.571078431372549, Validation Loss: 1.5254443883895874, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4808/10000, Training Loss: 1.018999457359314, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9972813725471497, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4809/10000, Training Loss: 1.1634737253189087, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6896993517875671, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4810/10000, Training Loss: 1.2709994316101074, Training Accuracy: 0.5514705882352942, Validation Loss: 1.2352122068405151, Validation Accuracy: 0.5\n",
      "Epoch 4811/10000, Training Loss: 0.913062572479248, Training Accuracy: 0.5612745098039216, Validation Loss: 1.603969931602478, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4812/10000, Training Loss: 0.8997583389282227, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0370222330093384, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4813/10000, Training Loss: 0.9421736598014832, Training Accuracy: 0.625, Validation Loss: 1.6187306642532349, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4814/10000, Training Loss: 1.1518759727478027, Training Accuracy: 0.5612745098039216, Validation Loss: 1.3355098962783813, Validation Accuracy: 0.25\n",
      "Epoch 4815/10000, Training Loss: 1.1971803903579712, Training Accuracy: 0.5661764705882353, Validation Loss: 1.7660986185073853, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4816/10000, Training Loss: 1.0994850397109985, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9513533711433411, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4817/10000, Training Loss: 0.7796969413757324, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9727265238761902, Validation Accuracy: 0.5\n",
      "Epoch 4818/10000, Training Loss: 1.1174687147140503, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1676859855651855, Validation Accuracy: 0.5\n",
      "Epoch 4819/10000, Training Loss: 0.9491216540336609, Training Accuracy: 0.5686274509803921, Validation Loss: 1.2627490758895874, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4820/10000, Training Loss: 1.1608175039291382, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8799411654472351, Validation Accuracy: 0.5\n",
      "Epoch 4821/10000, Training Loss: 0.9052560329437256, Training Accuracy: 0.6151960784313726, Validation Loss: 1.2010517120361328, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4822/10000, Training Loss: 1.4813166856765747, Training Accuracy: 0.5514705882352942, Validation Loss: 2.1098828315734863, Validation Accuracy: 0.5\n",
      "Epoch 4823/10000, Training Loss: 1.40543532371521, Training Accuracy: 0.5196078431372549, Validation Loss: 1.5386720895767212, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4824/10000, Training Loss: 1.271243691444397, Training Accuracy: 0.5294117647058824, Validation Loss: 2.138484001159668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4825/10000, Training Loss: 0.8813356161117554, Training Accuracy: 0.5955882352941176, Validation Loss: 1.5282849073410034, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4826/10000, Training Loss: 0.9426639080047607, Training Accuracy: 0.5588235294117647, Validation Loss: 1.4898828268051147, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4827/10000, Training Loss: 0.9542486071586609, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0934144258499146, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4828/10000, Training Loss: 1.18989896774292, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1576131582260132, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4829/10000, Training Loss: 0.8207021951675415, Training Accuracy: 0.6176470588235294, Validation Loss: 1.0850847959518433, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4830/10000, Training Loss: 1.3144245147705078, Training Accuracy: 0.5220588235294118, Validation Loss: 2.6981496810913086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4831/10000, Training Loss: 1.2399020195007324, Training Accuracy: 0.4632352941176471, Validation Loss: 0.9055646061897278, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4832/10000, Training Loss: 1.1206927299499512, Training Accuracy: 0.553921568627451, Validation Loss: 1.3607534170150757, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4833/10000, Training Loss: 1.046811580657959, Training Accuracy: 0.5441176470588235, Validation Loss: 0.8277764916419983, Validation Accuracy: 0.5\n",
      "Epoch 4834/10000, Training Loss: 0.9420924186706543, Training Accuracy: 0.6323529411764706, Validation Loss: 1.400099754333496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4835/10000, Training Loss: 1.531038761138916, Training Accuracy: 0.5490196078431373, Validation Loss: 1.74767005443573, Validation Accuracy: 0.25\n",
      "Epoch 4836/10000, Training Loss: 1.0713144540786743, Training Accuracy: 0.5759803921568627, Validation Loss: 1.2696613073349, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4837/10000, Training Loss: 0.9065655469894409, Training Accuracy: 0.553921568627451, Validation Loss: 0.9216094613075256, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4838/10000, Training Loss: 0.805124819278717, Training Accuracy: 0.5955882352941176, Validation Loss: 1.4326958656311035, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4839/10000, Training Loss: 1.2209805250167847, Training Accuracy: 0.5024509803921569, Validation Loss: 1.2353650331497192, Validation Accuracy: 0.5\n",
      "Epoch 4840/10000, Training Loss: 0.877727210521698, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8582582473754883, Validation Accuracy: 0.75\n",
      "Epoch 4841/10000, Training Loss: 1.0836714506149292, Training Accuracy: 0.5661764705882353, Validation Loss: 1.2013335227966309, Validation Accuracy: 0.5\n",
      "Epoch 4842/10000, Training Loss: 1.0679163932800293, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0318289995193481, Validation Accuracy: 0.5\n",
      "Epoch 4843/10000, Training Loss: 0.8351930379867554, Training Accuracy: 0.5784313725490197, Validation Loss: 1.4798874855041504, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4844/10000, Training Loss: 0.9948247075080872, Training Accuracy: 0.5857843137254902, Validation Loss: 1.36054265499115, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4845/10000, Training Loss: 1.04084050655365, Training Accuracy: 0.553921568627451, Validation Loss: 1.0965474843978882, Validation Accuracy: 0.5\n",
      "Epoch 4846/10000, Training Loss: 1.3254144191741943, Training Accuracy: 0.5294117647058824, Validation Loss: 1.1596583127975464, Validation Accuracy: 0.75\n",
      "Epoch 4847/10000, Training Loss: 1.1336606740951538, Training Accuracy: 0.5759803921568627, Validation Loss: 1.7850360870361328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4848/10000, Training Loss: 0.8517274856567383, Training Accuracy: 0.5980392156862745, Validation Loss: 1.8834227323532104, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4849/10000, Training Loss: 1.0132290124893188, Training Accuracy: 0.5514705882352942, Validation Loss: 1.232054591178894, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4850/10000, Training Loss: 1.1114658117294312, Training Accuracy: 0.5563725490196079, Validation Loss: 2.8851544857025146, Validation Accuracy: 0.5\n",
      "Epoch 4851/10000, Training Loss: 0.9136706590652466, Training Accuracy: 0.5294117647058824, Validation Loss: 0.9874582290649414, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4852/10000, Training Loss: 0.9551402926445007, Training Accuracy: 0.5416666666666666, Validation Loss: 1.8418813943862915, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4853/10000, Training Loss: 1.2124123573303223, Training Accuracy: 0.5245098039215687, Validation Loss: 0.6760594248771667, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4854/10000, Training Loss: 1.32089364528656, Training Accuracy: 0.6127450980392157, Validation Loss: 1.2431385517120361, Validation Accuracy: 0.5\n",
      "Epoch 4855/10000, Training Loss: 0.8234193325042725, Training Accuracy: 0.6102941176470589, Validation Loss: 1.215718150138855, Validation Accuracy: 0.5\n",
      "Epoch 4856/10000, Training Loss: 1.125473976135254, Training Accuracy: 0.5490196078431373, Validation Loss: 1.4480829238891602, Validation Accuracy: 0.5\n",
      "Epoch 4857/10000, Training Loss: 1.249530553817749, Training Accuracy: 0.6102941176470589, Validation Loss: 2.3461289405822754, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4858/10000, Training Loss: 1.068099856376648, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3286055326461792, Validation Accuracy: 0.5\n",
      "Epoch 4859/10000, Training Loss: 1.0547547340393066, Training Accuracy: 0.49264705882352944, Validation Loss: 1.8042854070663452, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 4860/10000, Training Loss: 1.003874659538269, Training Accuracy: 0.5343137254901961, Validation Loss: 1.6885719299316406, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4861/10000, Training Loss: 0.9546279311180115, Training Accuracy: 0.5955882352941176, Validation Loss: 1.5527915954589844, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4862/10000, Training Loss: 1.1177594661712646, Training Accuracy: 0.5563725490196079, Validation Loss: 1.9605790376663208, Validation Accuracy: 0.25\n",
      "Epoch 4863/10000, Training Loss: 0.9414321780204773, Training Accuracy: 0.5980392156862745, Validation Loss: 1.4935178756713867, Validation Accuracy: 0.5\n",
      "Epoch 4864/10000, Training Loss: 1.0187231302261353, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1292507648468018, Validation Accuracy: 0.5\n",
      "Epoch 4865/10000, Training Loss: 1.146428108215332, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3381849527359009, Validation Accuracy: 0.5\n",
      "Epoch 4866/10000, Training Loss: 0.9112285375595093, Training Accuracy: 0.5882352941176471, Validation Loss: 1.4211245775222778, Validation Accuracy: 0.5\n",
      "Epoch 4867/10000, Training Loss: 1.4358478784561157, Training Accuracy: 0.5588235294117647, Validation Loss: 3.5919625759124756, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4868/10000, Training Loss: 1.0847257375717163, Training Accuracy: 0.46078431372549017, Validation Loss: 1.6747384071350098, Validation Accuracy: 0.25\n",
      "Epoch 4869/10000, Training Loss: 0.9272372126579285, Training Accuracy: 0.6053921568627451, Validation Loss: 0.833890438079834, Validation Accuracy: 0.5\n",
      "Epoch 4870/10000, Training Loss: 1.1663851737976074, Training Accuracy: 0.5220588235294118, Validation Loss: 0.7274366021156311, Validation Accuracy: 0.5\n",
      "Epoch 4871/10000, Training Loss: 0.9390510320663452, Training Accuracy: 0.5931372549019608, Validation Loss: 1.2988358736038208, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4872/10000, Training Loss: 1.1660480499267578, Training Accuracy: 0.6004901960784313, Validation Loss: 1.9187370538711548, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4873/10000, Training Loss: 1.0059016942977905, Training Accuracy: 0.5882352941176471, Validation Loss: 1.8168390989303589, Validation Accuracy: 0.5\n",
      "Epoch 4874/10000, Training Loss: 1.1235783100128174, Training Accuracy: 0.5465686274509803, Validation Loss: 1.1758371591567993, Validation Accuracy: 0.5\n",
      "Epoch 4875/10000, Training Loss: 1.1878960132598877, Training Accuracy: 0.6421568627450981, Validation Loss: 1.581352710723877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4876/10000, Training Loss: 1.1763272285461426, Training Accuracy: 0.5686274509803921, Validation Loss: 2.2589073181152344, Validation Accuracy: 0.5\n",
      "Epoch 4877/10000, Training Loss: 0.9877641797065735, Training Accuracy: 0.571078431372549, Validation Loss: 1.3852237462997437, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4878/10000, Training Loss: 0.8904392123222351, Training Accuracy: 0.5882352941176471, Validation Loss: 1.7199220657348633, Validation Accuracy: 0.25\n",
      "Epoch 4879/10000, Training Loss: 0.8028578758239746, Training Accuracy: 0.5490196078431373, Validation Loss: 1.0226176977157593, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4880/10000, Training Loss: 0.9359451532363892, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1564505100250244, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4881/10000, Training Loss: 1.167062520980835, Training Accuracy: 0.5171568627450981, Validation Loss: 1.396729588508606, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4882/10000, Training Loss: 1.1217881441116333, Training Accuracy: 0.5441176470588235, Validation Loss: 0.550962507724762, Validation Accuracy: 0.5\n",
      "Epoch 4883/10000, Training Loss: 1.0170484781265259, Training Accuracy: 0.571078431372549, Validation Loss: 0.9227617383003235, Validation Accuracy: 0.5\n",
      "Epoch 4884/10000, Training Loss: 1.0769877433776855, Training Accuracy: 0.553921568627451, Validation Loss: 1.3035504817962646, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4885/10000, Training Loss: 1.0342196226119995, Training Accuracy: 0.5563725490196079, Validation Loss: 1.246569275856018, Validation Accuracy: 0.75\n",
      "Epoch 4886/10000, Training Loss: 1.2134342193603516, Training Accuracy: 0.5441176470588235, Validation Loss: 1.6326755285263062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4887/10000, Training Loss: 1.0445446968078613, Training Accuracy: 0.5416666666666666, Validation Loss: 1.0967793464660645, Validation Accuracy: 0.75\n",
      "Epoch 4888/10000, Training Loss: 0.857533872127533, Training Accuracy: 0.6029411764705882, Validation Loss: 1.2681931257247925, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4889/10000, Training Loss: 0.9874194860458374, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8040351271629333, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4890/10000, Training Loss: 1.8721520900726318, Training Accuracy: 0.5416666666666666, Validation Loss: 2.4233763217926025, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4891/10000, Training Loss: 0.7419670224189758, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9658073782920837, Validation Accuracy: 0.5\n",
      "Epoch 4892/10000, Training Loss: 0.8327394127845764, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0375617742538452, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4893/10000, Training Loss: 0.8616241216659546, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9669711589813232, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4894/10000, Training Loss: 1.045534372329712, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9965665340423584, Validation Accuracy: 0.75\n",
      "Epoch 4895/10000, Training Loss: 0.9226183891296387, Training Accuracy: 0.5833333333333334, Validation Loss: 1.016241192817688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4896/10000, Training Loss: 1.0648576021194458, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9867952466011047, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4897/10000, Training Loss: 1.1960548162460327, Training Accuracy: 0.571078431372549, Validation Loss: 1.8593212366104126, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4898/10000, Training Loss: 1.1218578815460205, Training Accuracy: 0.5, Validation Loss: 0.8647215962409973, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4899/10000, Training Loss: 1.2718863487243652, Training Accuracy: 0.5196078431372549, Validation Loss: 1.7315715551376343, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4900/10000, Training Loss: 0.8881606459617615, Training Accuracy: 0.6151960784313726, Validation Loss: 0.5299716591835022, Validation Accuracy: 0.75\n",
      "Epoch 4901/10000, Training Loss: 1.11875319480896, Training Accuracy: 0.6053921568627451, Validation Loss: 1.9859997034072876, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4902/10000, Training Loss: 1.0023449659347534, Training Accuracy: 0.6078431372549019, Validation Loss: 1.329227328300476, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4903/10000, Training Loss: 1.024041771888733, Training Accuracy: 0.5588235294117647, Validation Loss: 1.4180469512939453, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4904/10000, Training Loss: 0.9156908988952637, Training Accuracy: 0.5735294117647058, Validation Loss: 0.698922336101532, Validation Accuracy: 0.75\n",
      "Epoch 4905/10000, Training Loss: 1.206459403038025, Training Accuracy: 0.5416666666666666, Validation Loss: 1.2343801259994507, Validation Accuracy: 0.5\n",
      "Epoch 4906/10000, Training Loss: 1.2343416213989258, Training Accuracy: 0.5269607843137255, Validation Loss: 1.214941382408142, Validation Accuracy: 0.5\n",
      "Epoch 4907/10000, Training Loss: 1.027707815170288, Training Accuracy: 0.5563725490196079, Validation Loss: 0.6626026630401611, Validation Accuracy: 0.75\n",
      "Epoch 4908/10000, Training Loss: 1.1067146062850952, Training Accuracy: 0.5441176470588235, Validation Loss: 1.4742035865783691, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4909/10000, Training Loss: 0.9405072331428528, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1026333570480347, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4910/10000, Training Loss: 0.9495862126350403, Training Accuracy: 0.5637254901960784, Validation Loss: 0.764737606048584, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4911/10000, Training Loss: 1.0268011093139648, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0332773923873901, Validation Accuracy: 0.5\n",
      "Epoch 4912/10000, Training Loss: 1.0759698152542114, Training Accuracy: 0.5955882352941176, Validation Loss: 0.789799690246582, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4913/10000, Training Loss: 0.8416237831115723, Training Accuracy: 0.5906862745098039, Validation Loss: 1.520391821861267, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4914/10000, Training Loss: 1.1844470500946045, Training Accuracy: 0.5318627450980392, Validation Loss: 0.9253129959106445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4915/10000, Training Loss: 1.2058303356170654, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9796900749206543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4916/10000, Training Loss: 0.9978734254837036, Training Accuracy: 0.5686274509803921, Validation Loss: 1.100340723991394, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4917/10000, Training Loss: 1.314131736755371, Training Accuracy: 0.5245098039215687, Validation Loss: 1.506839394569397, Validation Accuracy: 0.5\n",
      "Epoch 4918/10000, Training Loss: 1.292662262916565, Training Accuracy: 0.6004901960784313, Validation Loss: 1.6995445489883423, Validation Accuracy: 0.5\n",
      "Epoch 4919/10000, Training Loss: 1.444604516029358, Training Accuracy: 0.5171568627450981, Validation Loss: 1.0188298225402832, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4920/10000, Training Loss: 0.9106166362762451, Training Accuracy: 0.5318627450980392, Validation Loss: 0.922466516494751, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4921/10000, Training Loss: 0.8523457050323486, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7728268504142761, Validation Accuracy: 0.75\n",
      "Epoch 4922/10000, Training Loss: 1.008589744567871, Training Accuracy: 0.5220588235294118, Validation Loss: 0.45024463534355164, Validation Accuracy: 0.75\n",
      "Epoch 4923/10000, Training Loss: 1.0386875867843628, Training Accuracy: 0.6102941176470589, Validation Loss: 1.8108676671981812, Validation Accuracy: 0.5\n",
      "Epoch 4924/10000, Training Loss: 1.3539246320724487, Training Accuracy: 0.5686274509803921, Validation Loss: 0.756359338760376, Validation Accuracy: 0.75\n",
      "Epoch 4925/10000, Training Loss: 1.1612039804458618, Training Accuracy: 0.6004901960784313, Validation Loss: 1.8876113891601562, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4926/10000, Training Loss: 1.0890060663223267, Training Accuracy: 0.47058823529411764, Validation Loss: 0.9025424122810364, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4927/10000, Training Loss: 0.9859382510185242, Training Accuracy: 0.5931372549019608, Validation Loss: 1.2347172498703003, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4928/10000, Training Loss: 0.8784355521202087, Training Accuracy: 0.5735294117647058, Validation Loss: 1.395801067352295, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4929/10000, Training Loss: 1.0231597423553467, Training Accuracy: 0.5367647058823529, Validation Loss: 0.8965928554534912, Validation Accuracy: 0.5\n",
      "Epoch 4930/10000, Training Loss: 0.8766748905181885, Training Accuracy: 0.6151960784313726, Validation Loss: 0.928450882434845, Validation Accuracy: 0.5\n",
      "Epoch 4931/10000, Training Loss: 1.1114107370376587, Training Accuracy: 0.5392156862745098, Validation Loss: 1.4855499267578125, Validation Accuracy: 0.25\n",
      "Epoch 4932/10000, Training Loss: 0.8717424273490906, Training Accuracy: 0.6200980392156863, Validation Loss: 1.1060740947723389, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4933/10000, Training Loss: 1.1906280517578125, Training Accuracy: 0.5759803921568627, Validation Loss: 2.397165060043335, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4934/10000, Training Loss: 1.646634578704834, Training Accuracy: 0.5514705882352942, Validation Loss: 1.7760082483291626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4935/10000, Training Loss: 1.114669919013977, Training Accuracy: 0.5490196078431373, Validation Loss: 1.1670846939086914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4936/10000, Training Loss: 1.3891757726669312, Training Accuracy: 0.5490196078431373, Validation Loss: 1.1954131126403809, Validation Accuracy: 0.5\n",
      "Epoch 4937/10000, Training Loss: 1.0534441471099854, Training Accuracy: 0.5318627450980392, Validation Loss: 1.0714036226272583, Validation Accuracy: 0.5\n",
      "Epoch 4938/10000, Training Loss: 0.9082922339439392, Training Accuracy: 0.5171568627450981, Validation Loss: 1.2183479070663452, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4939/10000, Training Loss: 0.9087503552436829, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8115888237953186, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4940/10000, Training Loss: 0.7870875597000122, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8246939182281494, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4941/10000, Training Loss: 0.8280931115150452, Training Accuracy: 0.6029411764705882, Validation Loss: 1.368232250213623, Validation Accuracy: 0.5\n",
      "Epoch 4942/10000, Training Loss: 0.9035112261772156, Training Accuracy: 0.5612745098039216, Validation Loss: 1.6304101943969727, Validation Accuracy: 0.25\n",
      "Epoch 4943/10000, Training Loss: 1.1857796907424927, Training Accuracy: 0.5735294117647058, Validation Loss: 2.746358633041382, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4944/10000, Training Loss: 1.1153818368911743, Training Accuracy: 0.5588235294117647, Validation Loss: 1.6316677331924438, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4945/10000, Training Loss: 1.1306005716323853, Training Accuracy: 0.5514705882352942, Validation Loss: 1.3611488342285156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4946/10000, Training Loss: 1.0218719244003296, Training Accuracy: 0.4950980392156863, Validation Loss: 0.7587546706199646, Validation Accuracy: 0.5\n",
      "Epoch 4947/10000, Training Loss: 0.9830851554870605, Training Accuracy: 0.49019607843137253, Validation Loss: 1.07168447971344, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4948/10000, Training Loss: 1.1219842433929443, Training Accuracy: 0.5857843137254902, Validation Loss: 2.139786958694458, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4949/10000, Training Loss: 0.8985998034477234, Training Accuracy: 0.571078431372549, Validation Loss: 1.191253423690796, Validation Accuracy: 0.25\n",
      "Epoch 4950/10000, Training Loss: 1.1373542547225952, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1836929321289062, Validation Accuracy: 0.5\n",
      "Epoch 4951/10000, Training Loss: 0.916408360004425, Training Accuracy: 0.5906862745098039, Validation Loss: 0.785301685333252, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4952/10000, Training Loss: 1.3015917539596558, Training Accuracy: 0.6053921568627451, Validation Loss: 1.994494915008545, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4953/10000, Training Loss: 0.8988209366798401, Training Accuracy: 0.5808823529411765, Validation Loss: 1.2085577249526978, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4954/10000, Training Loss: 1.0142948627471924, Training Accuracy: 0.4950980392156863, Validation Loss: 1.4937440156936646, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4955/10000, Training Loss: 0.9445571899414062, Training Accuracy: 0.5857843137254902, Validation Loss: 1.9381159543991089, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4956/10000, Training Loss: 1.0468840599060059, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8619418144226074, Validation Accuracy: 0.5\n",
      "Epoch 4957/10000, Training Loss: 1.0634682178497314, Training Accuracy: 0.5661764705882353, Validation Loss: 1.7280598878860474, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4958/10000, Training Loss: 0.8956202864646912, Training Accuracy: 0.5906862745098039, Validation Loss: 1.5116766691207886, Validation Accuracy: 0.5\n",
      "Epoch 4959/10000, Training Loss: 1.4118266105651855, Training Accuracy: 0.5906862745098039, Validation Loss: 2.276201009750366, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4960/10000, Training Loss: 0.8674172163009644, Training Accuracy: 0.5171568627450981, Validation Loss: 0.8261095881462097, Validation Accuracy: 0.5\n",
      "Epoch 4961/10000, Training Loss: 1.0854183435440063, Training Accuracy: 0.5906862745098039, Validation Loss: 2.302499771118164, Validation Accuracy: 0.5\n",
      "Epoch 4962/10000, Training Loss: 1.0201927423477173, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9647729992866516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4963/10000, Training Loss: 0.930758535861969, Training Accuracy: 0.571078431372549, Validation Loss: 0.6130353212356567, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 4964/10000, Training Loss: 1.1105190515518188, Training Accuracy: 0.5637254901960784, Validation Loss: 1.6837596893310547, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4965/10000, Training Loss: 0.9810779690742493, Training Accuracy: 0.5857843137254902, Validation Loss: 1.7972356081008911, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4966/10000, Training Loss: 0.9801149368286133, Training Accuracy: 0.5980392156862745, Validation Loss: 1.7458561658859253, Validation Accuracy: 0.25\n",
      "Epoch 4967/10000, Training Loss: 1.1661241054534912, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1247334480285645, Validation Accuracy: 0.5\n",
      "Epoch 4968/10000, Training Loss: 1.3614442348480225, Training Accuracy: 0.5514705882352942, Validation Loss: 2.3463776111602783, Validation Accuracy: 0.5\n",
      "Epoch 4969/10000, Training Loss: 1.3495312929153442, Training Accuracy: 0.553921568627451, Validation Loss: 1.0367511510849, Validation Accuracy: 0.5\n",
      "Epoch 4970/10000, Training Loss: 0.9507390856742859, Training Accuracy: 0.5906862745098039, Validation Loss: 1.1361197233200073, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4971/10000, Training Loss: 0.9292254447937012, Training Accuracy: 0.6078431372549019, Validation Loss: 0.978883683681488, Validation Accuracy: 0.5\n",
      "Epoch 4972/10000, Training Loss: 0.9543644785881042, Training Accuracy: 0.6348039215686274, Validation Loss: 1.442301630973816, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4973/10000, Training Loss: 0.9724920392036438, Training Accuracy: 0.571078431372549, Validation Loss: 1.211312174797058, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4974/10000, Training Loss: 0.7920470833778381, Training Accuracy: 0.6691176470588235, Validation Loss: 1.7781583070755005, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4975/10000, Training Loss: 0.9166985154151917, Training Accuracy: 0.5882352941176471, Validation Loss: 2.032668352127075, Validation Accuracy: 0.5\n",
      "Epoch 4976/10000, Training Loss: 0.881382167339325, Training Accuracy: 0.6102941176470589, Validation Loss: 1.3550645112991333, Validation Accuracy: 0.75\n",
      "Epoch 4977/10000, Training Loss: 0.7959506511688232, Training Accuracy: 0.6102941176470589, Validation Loss: 1.5409611463546753, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4978/10000, Training Loss: 1.193863034248352, Training Accuracy: 0.6053921568627451, Validation Loss: 0.863619327545166, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4979/10000, Training Loss: 0.7510254979133606, Training Accuracy: 0.5906862745098039, Validation Loss: 1.1177154779434204, Validation Accuracy: 0.5\n",
      "Epoch 4980/10000, Training Loss: 0.7781040668487549, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6837565898895264, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4981/10000, Training Loss: 0.9222712516784668, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7351942658424377, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4982/10000, Training Loss: 0.9464023113250732, Training Accuracy: 0.571078431372549, Validation Loss: 0.7829330563545227, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4983/10000, Training Loss: 1.1881192922592163, Training Accuracy: 0.5171568627450981, Validation Loss: 1.54188871383667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4984/10000, Training Loss: 0.9343948364257812, Training Accuracy: 0.6421568627450981, Validation Loss: 1.2493488788604736, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4985/10000, Training Loss: 0.9618732333183289, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0471101999282837, Validation Accuracy: 0.5\n",
      "Epoch 4986/10000, Training Loss: 0.8601596355438232, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9236800074577332, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4987/10000, Training Loss: 1.1786463260650635, Training Accuracy: 0.49019607843137253, Validation Loss: 0.8691636919975281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4988/10000, Training Loss: 0.9250320196151733, Training Accuracy: 0.6225490196078431, Validation Loss: 2.407447576522827, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4989/10000, Training Loss: 1.0779393911361694, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9566519856452942, Validation Accuracy: 0.5\n",
      "Epoch 4990/10000, Training Loss: 0.9577454328536987, Training Accuracy: 0.6127450980392157, Validation Loss: 0.42938220500946045, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 4991/10000, Training Loss: 0.9706814289093018, Training Accuracy: 0.553921568627451, Validation Loss: 1.041037917137146, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 4992/10000, Training Loss: 0.8955162167549133, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7602746486663818, Validation Accuracy: 0.75\n",
      "Epoch 4993/10000, Training Loss: 1.1132235527038574, Training Accuracy: 0.5931372549019608, Validation Loss: 1.694630742073059, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4994/10000, Training Loss: 1.136412262916565, Training Accuracy: 0.5269607843137255, Validation Loss: 1.0018140077590942, Validation Accuracy: 0.5\n",
      "Epoch 4995/10000, Training Loss: 0.8144014477729797, Training Accuracy: 0.6004901960784313, Validation Loss: 2.6340768337249756, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 4996/10000, Training Loss: 0.8908737301826477, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7637196779251099, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 4997/10000, Training Loss: 1.057725191116333, Training Accuracy: 0.5686274509803921, Validation Loss: 1.5668448209762573, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 4998/10000, Training Loss: 0.9552474617958069, Training Accuracy: 0.6078431372549019, Validation Loss: 1.5413349866867065, Validation Accuracy: 0.5\n",
      "Epoch 4999/10000, Training Loss: 1.0917397737503052, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9479069113731384, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5000/10000, Training Loss: 0.8067330718040466, Training Accuracy: 0.6053921568627451, Validation Loss: 1.828314185142517, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5001/10000, Training Loss: 1.1805189847946167, Training Accuracy: 0.5906862745098039, Validation Loss: 1.4007450342178345, Validation Accuracy: 0.5\n",
      "Epoch 5002/10000, Training Loss: 0.8088551759719849, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7788346409797668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5003/10000, Training Loss: 1.070055365562439, Training Accuracy: 0.5637254901960784, Validation Loss: 1.3742345571517944, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5004/10000, Training Loss: 0.9580873847007751, Training Accuracy: 0.5343137254901961, Validation Loss: 1.552552580833435, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5005/10000, Training Loss: 0.8823639154434204, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9853615760803223, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5006/10000, Training Loss: 0.9358388185501099, Training Accuracy: 0.5588235294117647, Validation Loss: 0.608298122882843, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5007/10000, Training Loss: 1.0419294834136963, Training Accuracy: 0.5857843137254902, Validation Loss: 2.2844769954681396, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5008/10000, Training Loss: 0.9903029799461365, Training Accuracy: 0.5612745098039216, Validation Loss: 1.3099931478500366, Validation Accuracy: 0.75\n",
      "Epoch 5009/10000, Training Loss: 0.9769474864006042, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6121726632118225, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5010/10000, Training Loss: 0.846997082233429, Training Accuracy: 0.5759803921568627, Validation Loss: 1.4371556043624878, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5011/10000, Training Loss: 0.9163618087768555, Training Accuracy: 0.5147058823529411, Validation Loss: 0.6131146550178528, Validation Accuracy: 0.75\n",
      "Epoch 5012/10000, Training Loss: 0.8570931553840637, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0880478620529175, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5013/10000, Training Loss: 0.9298307299613953, Training Accuracy: 0.6151960784313726, Validation Loss: 1.390879511833191, Validation Accuracy: 0.5\n",
      "Epoch 5014/10000, Training Loss: 0.8827662467956543, Training Accuracy: 0.5980392156862745, Validation Loss: 1.3062869310379028, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5015/10000, Training Loss: 0.9461044669151306, Training Accuracy: 0.5416666666666666, Validation Loss: 1.2446684837341309, Validation Accuracy: 0.25\n",
      "Epoch 5016/10000, Training Loss: 0.8713736534118652, Training Accuracy: 0.5367647058823529, Validation Loss: 1.5899945497512817, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5017/10000, Training Loss: 1.1074517965316772, Training Accuracy: 0.5073529411764706, Validation Loss: 1.1455004215240479, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5018/10000, Training Loss: 0.939629077911377, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7089981436729431, Validation Accuracy: 0.5\n",
      "Epoch 5019/10000, Training Loss: 0.8589665293693542, Training Accuracy: 0.5906862745098039, Validation Loss: 1.7446876764297485, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5020/10000, Training Loss: 1.0349035263061523, Training Accuracy: 0.5343137254901961, Validation Loss: 0.935920238494873, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5021/10000, Training Loss: 0.9387397170066833, Training Accuracy: 0.5857843137254902, Validation Loss: 1.3043192625045776, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5022/10000, Training Loss: 0.9202601313591003, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6492894887924194, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5023/10000, Training Loss: 1.0193448066711426, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8760395050048828, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5024/10000, Training Loss: 0.7901912927627563, Training Accuracy: 0.5833333333333334, Validation Loss: 1.3911446332931519, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5025/10000, Training Loss: 0.8143270015716553, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6612557768821716, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5026/10000, Training Loss: 1.0222523212432861, Training Accuracy: 0.5294117647058824, Validation Loss: 1.136802077293396, Validation Accuracy: 0.5\n",
      "Epoch 5027/10000, Training Loss: 0.9223548769950867, Training Accuracy: 0.5073529411764706, Validation Loss: 0.7810407280921936, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5028/10000, Training Loss: 0.8748605847358704, Training Accuracy: 0.6151960784313726, Validation Loss: 1.3679324388504028, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5029/10000, Training Loss: 0.7433351874351501, Training Accuracy: 0.6053921568627451, Validation Loss: 1.258379340171814, Validation Accuracy: 0.25\n",
      "Epoch 5030/10000, Training Loss: 0.982124924659729, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7355895638465881, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5031/10000, Training Loss: 0.8726655840873718, Training Accuracy: 0.5833333333333334, Validation Loss: 1.107103943824768, Validation Accuracy: 0.5\n",
      "Epoch 5032/10000, Training Loss: 1.1435314416885376, Training Accuracy: 0.5637254901960784, Validation Loss: 2.1254236698150635, Validation Accuracy: 0.5\n",
      "Epoch 5033/10000, Training Loss: 0.9771810173988342, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9996132850646973, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5034/10000, Training Loss: 0.9555380344390869, Training Accuracy: 0.5122549019607843, Validation Loss: 1.49044668674469, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5035/10000, Training Loss: 0.9970291256904602, Training Accuracy: 0.5245098039215687, Validation Loss: 0.8758139610290527, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5036/10000, Training Loss: 0.8913717269897461, Training Accuracy: 0.5980392156862745, Validation Loss: 1.058251976966858, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5037/10000, Training Loss: 1.0496944189071655, Training Accuracy: 0.5735294117647058, Validation Loss: 1.2321268320083618, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5038/10000, Training Loss: 1.0776222944259644, Training Accuracy: 0.5514705882352942, Validation Loss: 1.4182487726211548, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5039/10000, Training Loss: 0.8942465782165527, Training Accuracy: 0.5637254901960784, Validation Loss: 1.2047127485275269, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5040/10000, Training Loss: 0.8961142897605896, Training Accuracy: 0.5416666666666666, Validation Loss: 2.3615922927856445, Validation Accuracy: 0.25\n",
      "Epoch 5041/10000, Training Loss: 0.8494081497192383, Training Accuracy: 0.5392156862745098, Validation Loss: 1.3757003545761108, Validation Accuracy: 0.5\n",
      "Epoch 5042/10000, Training Loss: 1.24460768699646, Training Accuracy: 0.5220588235294118, Validation Loss: 1.2386175394058228, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5043/10000, Training Loss: 0.7994186282157898, Training Accuracy: 0.5563725490196079, Validation Loss: 1.0261460542678833, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5044/10000, Training Loss: 0.8314985632896423, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7593986392021179, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5045/10000, Training Loss: 0.86642986536026, Training Accuracy: 0.5980392156862745, Validation Loss: 2.985778570175171, Validation Accuracy: 0.75\n",
      "Epoch 5046/10000, Training Loss: 0.7923683524131775, Training Accuracy: 0.6127450980392157, Validation Loss: 1.180486798286438, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5047/10000, Training Loss: 0.899311900138855, Training Accuracy: 0.553921568627451, Validation Loss: 0.841806948184967, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5048/10000, Training Loss: 1.0626815557479858, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9585793018341064, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5049/10000, Training Loss: 0.8074841499328613, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9196370244026184, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5050/10000, Training Loss: 1.207631230354309, Training Accuracy: 0.5269607843137255, Validation Loss: 1.5235910415649414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5051/10000, Training Loss: 0.8401956558227539, Training Accuracy: 0.6176470588235294, Validation Loss: 1.258995532989502, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5052/10000, Training Loss: 0.8160397410392761, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0679221153259277, Validation Accuracy: 0.5\n",
      "Epoch 5053/10000, Training Loss: 0.7445154190063477, Training Accuracy: 0.6544117647058824, Validation Loss: 1.7148308753967285, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5054/10000, Training Loss: 0.9052466750144958, Training Accuracy: 0.5465686274509803, Validation Loss: 0.9166404604911804, Validation Accuracy: 0.5\n",
      "Epoch 5055/10000, Training Loss: 0.9041898846626282, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3411130905151367, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5056/10000, Training Loss: 0.7781037092208862, Training Accuracy: 0.5269607843137255, Validation Loss: 0.8570826053619385, Validation Accuracy: 0.75\n",
      "Epoch 5057/10000, Training Loss: 0.8717675805091858, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0931018590927124, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5058/10000, Training Loss: 0.7700523138046265, Training Accuracy: 0.5808823529411765, Validation Loss: 1.0561151504516602, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5059/10000, Training Loss: 1.041961669921875, Training Accuracy: 0.5955882352941176, Validation Loss: 2.0999252796173096, Validation Accuracy: 0.25\n",
      "Epoch 5060/10000, Training Loss: 1.0225437879562378, Training Accuracy: 0.5294117647058824, Validation Loss: 1.288637399673462, Validation Accuracy: 0.5\n",
      "Epoch 5061/10000, Training Loss: 0.7838952541351318, Training Accuracy: 0.5882352941176471, Validation Loss: 2.402580976486206, Validation Accuracy: 0.25\n",
      "Epoch 5062/10000, Training Loss: 1.103318214416504, Training Accuracy: 0.5196078431372549, Validation Loss: 0.6209591031074524, Validation Accuracy: 0.5\n",
      "Epoch 5063/10000, Training Loss: 1.0385329723358154, Training Accuracy: 0.5441176470588235, Validation Loss: 1.1288644075393677, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5064/10000, Training Loss: 0.7169526815414429, Training Accuracy: 0.6666666666666666, Validation Loss: 1.222490906715393, Validation Accuracy: 0.5\n",
      "Epoch 5065/10000, Training Loss: 0.9596549272537231, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0911107063293457, Validation Accuracy: 0.5\n",
      "Epoch 5066/10000, Training Loss: 0.7696352005004883, Training Accuracy: 0.6029411764705882, Validation Loss: 1.3783732652664185, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5067/10000, Training Loss: 1.1918931007385254, Training Accuracy: 0.571078431372549, Validation Loss: 2.073552131652832, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5068/10000, Training Loss: 0.9606236219406128, Training Accuracy: 0.5294117647058824, Validation Loss: 1.0612443685531616, Validation Accuracy: 0.5\n",
      "Epoch 5069/10000, Training Loss: 1.0272088050842285, Training Accuracy: 0.5465686274509803, Validation Loss: 2.205911159515381, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5070/10000, Training Loss: 0.6905030608177185, Training Accuracy: 0.6838235294117647, Validation Loss: 0.5167565941810608, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5071/10000, Training Loss: 0.9398821592330933, Training Accuracy: 0.5490196078431373, Validation Loss: 1.079694390296936, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5072/10000, Training Loss: 0.8794415593147278, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0010250806808472, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5073/10000, Training Loss: 1.1508923768997192, Training Accuracy: 0.5171568627450981, Validation Loss: 1.147779107093811, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5074/10000, Training Loss: 1.087436318397522, Training Accuracy: 0.5857843137254902, Validation Loss: 2.6253108978271484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5075/10000, Training Loss: 0.744199275970459, Training Accuracy: 0.5906862745098039, Validation Loss: 1.331664800643921, Validation Accuracy: 0.5\n",
      "Epoch 5076/10000, Training Loss: 0.8914773464202881, Training Accuracy: 0.5931372549019608, Validation Loss: 1.116745114326477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5077/10000, Training Loss: 1.0766209363937378, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3026119470596313, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5078/10000, Training Loss: 1.0620512962341309, Training Accuracy: 0.5367647058823529, Validation Loss: 0.7601392269134521, Validation Accuracy: 0.5\n",
      "Epoch 5079/10000, Training Loss: 0.9244420528411865, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7659206986427307, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5080/10000, Training Loss: 0.938640832901001, Training Accuracy: 0.5563725490196079, Validation Loss: 1.5833325386047363, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5081/10000, Training Loss: 1.0905243158340454, Training Accuracy: 0.5220588235294118, Validation Loss: 1.1118806600570679, Validation Accuracy: 0.5\n",
      "Epoch 5082/10000, Training Loss: 0.8792173266410828, Training Accuracy: 0.6617647058823529, Validation Loss: 1.885780930519104, Validation Accuracy: 0.5\n",
      "Epoch 5083/10000, Training Loss: 0.8273530006408691, Training Accuracy: 0.5882352941176471, Validation Loss: 1.3970180749893188, Validation Accuracy: 0.5\n",
      "Epoch 5084/10000, Training Loss: 1.0064971446990967, Training Accuracy: 0.5465686274509803, Validation Loss: 1.1963553428649902, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5085/10000, Training Loss: 0.9300158619880676, Training Accuracy: 0.5563725490196079, Validation Loss: 2.049595832824707, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5086/10000, Training Loss: 1.0370694398880005, Training Accuracy: 0.5318627450980392, Validation Loss: 1.2156881093978882, Validation Accuracy: 0.5\n",
      "Epoch 5087/10000, Training Loss: 0.9286935925483704, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7503926753997803, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5088/10000, Training Loss: 1.1205146312713623, Training Accuracy: 0.5906862745098039, Validation Loss: 1.525256633758545, Validation Accuracy: 0.5\n",
      "Epoch 5089/10000, Training Loss: 0.8537362217903137, Training Accuracy: 0.571078431372549, Validation Loss: 1.0290817022323608, Validation Accuracy: 0.5\n",
      "Epoch 5090/10000, Training Loss: 0.901056170463562, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8221065402030945, Validation Accuracy: 0.5\n",
      "Epoch 5091/10000, Training Loss: 0.9140690565109253, Training Accuracy: 0.5637254901960784, Validation Loss: 1.5683809518814087, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5092/10000, Training Loss: 0.9632619023323059, Training Accuracy: 0.5955882352941176, Validation Loss: 1.5149997472763062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5093/10000, Training Loss: 0.9391950964927673, Training Accuracy: 0.5833333333333334, Validation Loss: 1.0287971496582031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5094/10000, Training Loss: 0.9009523391723633, Training Accuracy: 0.6176470588235294, Validation Loss: 1.6517530679702759, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5095/10000, Training Loss: 0.9534196257591248, Training Accuracy: 0.6397058823529411, Validation Loss: 2.273946523666382, Validation Accuracy: 0.5\n",
      "Epoch 5096/10000, Training Loss: 0.9009343385696411, Training Accuracy: 0.5661764705882353, Validation Loss: 1.2484769821166992, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5097/10000, Training Loss: 0.8707372546195984, Training Accuracy: 0.5735294117647058, Validation Loss: 0.907067060470581, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5098/10000, Training Loss: 0.8889321684837341, Training Accuracy: 0.625, Validation Loss: 0.82919842004776, Validation Accuracy: 0.5\n",
      "Epoch 5099/10000, Training Loss: 0.9961209297180176, Training Accuracy: 0.6617647058823529, Validation Loss: 2.1140124797821045, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5100/10000, Training Loss: 0.750312328338623, Training Accuracy: 0.5882352941176471, Validation Loss: 1.2539470195770264, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5101/10000, Training Loss: 0.8195313215255737, Training Accuracy: 0.5612745098039216, Validation Loss: 1.349786400794983, Validation Accuracy: 0.25\n",
      "Epoch 5102/10000, Training Loss: 0.745245635509491, Training Accuracy: 0.6299019607843137, Validation Loss: 1.463412880897522, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5103/10000, Training Loss: 1.184688925743103, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8918167948722839, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5104/10000, Training Loss: 0.8878224492073059, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9088988900184631, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5105/10000, Training Loss: 1.157145619392395, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8935582637786865, Validation Accuracy: 0.5\n",
      "Epoch 5106/10000, Training Loss: 0.8355602025985718, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0058196783065796, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5107/10000, Training Loss: 0.8082812428474426, Training Accuracy: 0.5661764705882353, Validation Loss: 0.627186119556427, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5108/10000, Training Loss: 1.0443421602249146, Training Accuracy: 0.625, Validation Loss: 1.0248295068740845, Validation Accuracy: 0.5\n",
      "Epoch 5109/10000, Training Loss: 0.8171179294586182, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2387995719909668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5110/10000, Training Loss: 0.8227623105049133, Training Accuracy: 0.5661764705882353, Validation Loss: 1.5016164779663086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5111/10000, Training Loss: 0.8635512590408325, Training Accuracy: 0.5612745098039216, Validation Loss: 1.32024347782135, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5112/10000, Training Loss: 0.9101423621177673, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7923965454101562, Validation Accuracy: 0.5\n",
      "Epoch 5113/10000, Training Loss: 0.8836804032325745, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8480591177940369, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5114/10000, Training Loss: 1.0768202543258667, Training Accuracy: 0.5563725490196079, Validation Loss: 1.666438102722168, Validation Accuracy: 0.5\n",
      "Epoch 5115/10000, Training Loss: 1.1206454038619995, Training Accuracy: 0.5661764705882353, Validation Loss: 2.547970771789551, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5116/10000, Training Loss: 0.765652596950531, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1904383897781372, Validation Accuracy: 0.5\n",
      "Epoch 5117/10000, Training Loss: 0.9398980140686035, Training Accuracy: 0.6470588235294118, Validation Loss: 1.77120840549469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5118/10000, Training Loss: 0.8089597821235657, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0911020040512085, Validation Accuracy: 0.5\n",
      "Epoch 5119/10000, Training Loss: 0.8170114159584045, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9585568308830261, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5120/10000, Training Loss: 0.9400870203971863, Training Accuracy: 0.5147058823529411, Validation Loss: 0.9896907806396484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5121/10000, Training Loss: 1.096957802772522, Training Accuracy: 0.5147058823529411, Validation Loss: 0.7620660662651062, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5122/10000, Training Loss: 0.7724827527999878, Training Accuracy: 0.6323529411764706, Validation Loss: 1.26983642578125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5123/10000, Training Loss: 0.9734075665473938, Training Accuracy: 0.5955882352941176, Validation Loss: 1.3901728391647339, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5124/10000, Training Loss: 0.9667170643806458, Training Accuracy: 0.5490196078431373, Validation Loss: 0.665299654006958, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5125/10000, Training Loss: 1.0730339288711548, Training Accuracy: 0.6029411764705882, Validation Loss: 1.5741969347000122, Validation Accuracy: 0.5\n",
      "Epoch 5126/10000, Training Loss: 0.930930495262146, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7990930080413818, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5127/10000, Training Loss: 0.8367951512336731, Training Accuracy: 0.5416666666666666, Validation Loss: 1.3010696172714233, Validation Accuracy: 0.5\n",
      "Epoch 5128/10000, Training Loss: 0.8008567094802856, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8958813548088074, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5129/10000, Training Loss: 1.014574408531189, Training Accuracy: 0.5318627450980392, Validation Loss: 0.6769840121269226, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5130/10000, Training Loss: 0.8228586316108704, Training Accuracy: 0.5808823529411765, Validation Loss: 0.5746736526489258, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5131/10000, Training Loss: 0.866093635559082, Training Accuracy: 0.6004901960784313, Validation Loss: 2.083749532699585, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5132/10000, Training Loss: 0.7640790939331055, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1460882425308228, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5133/10000, Training Loss: 0.8503212332725525, Training Accuracy: 0.5514705882352942, Validation Loss: 0.9366865754127502, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5134/10000, Training Loss: 0.8801271319389343, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9478299617767334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5135/10000, Training Loss: 1.0051746368408203, Training Accuracy: 0.5245098039215687, Validation Loss: 1.074328064918518, Validation Accuracy: 0.5\n",
      "Epoch 5136/10000, Training Loss: 0.8149164915084839, Training Accuracy: 0.6200980392156863, Validation Loss: 2.4453933238983154, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5137/10000, Training Loss: 0.8608298897743225, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8334736824035645, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5138/10000, Training Loss: 0.9430030584335327, Training Accuracy: 0.5343137254901961, Validation Loss: 1.204351544380188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5139/10000, Training Loss: 0.770622730255127, Training Accuracy: 0.6151960784313726, Validation Loss: 1.8989280462265015, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5140/10000, Training Loss: 1.2275885343551636, Training Accuracy: 0.5612745098039216, Validation Loss: 1.5148593187332153, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5141/10000, Training Loss: 1.153992772102356, Training Accuracy: 0.553921568627451, Validation Loss: 0.7897793650627136, Validation Accuracy: 0.75\n",
      "Epoch 5142/10000, Training Loss: 0.9302946925163269, Training Accuracy: 0.6299019607843137, Validation Loss: 1.2262318134307861, Validation Accuracy: 0.5\n",
      "Epoch 5143/10000, Training Loss: 0.7968040108680725, Training Accuracy: 0.5906862745098039, Validation Loss: 1.239028811454773, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5144/10000, Training Loss: 0.9808628559112549, Training Accuracy: 0.6151960784313726, Validation Loss: 1.1798646450042725, Validation Accuracy: 0.5\n",
      "Epoch 5145/10000, Training Loss: 0.9187590479850769, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0917284488677979, Validation Accuracy: 0.5\n",
      "Epoch 5146/10000, Training Loss: 0.8351030349731445, Training Accuracy: 0.6151960784313726, Validation Loss: 1.055145263671875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5147/10000, Training Loss: 0.9078292846679688, Training Accuracy: 0.6151960784313726, Validation Loss: 1.1368695497512817, Validation Accuracy: 0.5\n",
      "Epoch 5148/10000, Training Loss: 0.9491764307022095, Training Accuracy: 0.571078431372549, Validation Loss: 1.4242606163024902, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5149/10000, Training Loss: 0.949787437915802, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1673649549484253, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5150/10000, Training Loss: 0.7858795523643494, Training Accuracy: 0.6200980392156863, Validation Loss: 0.711268424987793, Validation Accuracy: 0.5\n",
      "Epoch 5151/10000, Training Loss: 0.773590087890625, Training Accuracy: 0.6446078431372549, Validation Loss: 1.2872862815856934, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5152/10000, Training Loss: 0.9236644506454468, Training Accuracy: 0.6029411764705882, Validation Loss: 0.75457364320755, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5153/10000, Training Loss: 0.8583961725234985, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1022166013717651, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5154/10000, Training Loss: 0.9985911250114441, Training Accuracy: 0.5318627450980392, Validation Loss: 1.7319849729537964, Validation Accuracy: 0.25\n",
      "Epoch 5155/10000, Training Loss: 0.9575821161270142, Training Accuracy: 0.5882352941176471, Validation Loss: 1.283225178718567, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5156/10000, Training Loss: 0.9712454676628113, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0129376649856567, Validation Accuracy: 0.5\n",
      "Epoch 5157/10000, Training Loss: 1.0696730613708496, Training Accuracy: 0.571078431372549, Validation Loss: 2.0432450771331787, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5158/10000, Training Loss: 0.8584756255149841, Training Accuracy: 0.4852941176470588, Validation Loss: 1.24777090549469, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5159/10000, Training Loss: 0.9735491275787354, Training Accuracy: 0.5416666666666666, Validation Loss: 1.377463459968567, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5160/10000, Training Loss: 0.8044636845588684, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3023558855056763, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5161/10000, Training Loss: 0.8879807591438293, Training Accuracy: 0.5735294117647058, Validation Loss: 0.931104838848114, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5162/10000, Training Loss: 0.9979186654090881, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7127942442893982, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5163/10000, Training Loss: 0.9687901735305786, Training Accuracy: 0.6617647058823529, Validation Loss: 1.6751805543899536, Validation Accuracy: 0.25\n",
      "Epoch 5164/10000, Training Loss: 0.96634840965271, Training Accuracy: 0.5661764705882353, Validation Loss: 1.08346688747406, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5165/10000, Training Loss: 1.0220946073532104, Training Accuracy: 0.5563725490196079, Validation Loss: 1.1466710567474365, Validation Accuracy: 0.5\n",
      "Epoch 5166/10000, Training Loss: 0.9295758008956909, Training Accuracy: 0.5563725490196079, Validation Loss: 1.0035595893859863, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5167/10000, Training Loss: 1.0353752374649048, Training Accuracy: 0.5514705882352942, Validation Loss: 1.2972160577774048, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5168/10000, Training Loss: 0.9008170962333679, Training Accuracy: 0.5857843137254902, Validation Loss: 1.3269540071487427, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5169/10000, Training Loss: 0.8563796877861023, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9978597164154053, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5170/10000, Training Loss: 0.8909475803375244, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7277213931083679, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5171/10000, Training Loss: 0.7404336333274841, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8433240056037903, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5172/10000, Training Loss: 0.8844018578529358, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0790306329727173, Validation Accuracy: 0.75\n",
      "Epoch 5173/10000, Training Loss: 0.8989560008049011, Training Accuracy: 0.5735294117647058, Validation Loss: 1.3657360076904297, Validation Accuracy: 0.5\n",
      "Epoch 5174/10000, Training Loss: 0.8594706058502197, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9622688293457031, Validation Accuracy: 0.5\n",
      "Epoch 5175/10000, Training Loss: 0.896582305431366, Training Accuracy: 0.5612745098039216, Validation Loss: 1.473484992980957, Validation Accuracy: 0.25\n",
      "Epoch 5176/10000, Training Loss: 0.919762909412384, Training Accuracy: 0.6004901960784313, Validation Loss: 1.5732802152633667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5177/10000, Training Loss: 0.8874459266662598, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0912820100784302, Validation Accuracy: 0.5\n",
      "Epoch 5178/10000, Training Loss: 0.870012640953064, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0942076444625854, Validation Accuracy: 0.25\n",
      "Epoch 5179/10000, Training Loss: 0.851090133190155, Training Accuracy: 0.5857843137254902, Validation Loss: 1.5562790632247925, Validation Accuracy: 0.5\n",
      "Epoch 5180/10000, Training Loss: 0.8486860394477844, Training Accuracy: 0.6127450980392157, Validation Loss: 1.3054149150848389, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5181/10000, Training Loss: 0.7600009441375732, Training Accuracy: 0.6397058823529411, Validation Loss: 2.1401383876800537, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5182/10000, Training Loss: 0.8507343530654907, Training Accuracy: 0.6078431372549019, Validation Loss: 1.609505295753479, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5183/10000, Training Loss: 0.9599089026451111, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1927367448806763, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5184/10000, Training Loss: 0.9559944272041321, Training Accuracy: 0.5098039215686274, Validation Loss: 1.1366922855377197, Validation Accuracy: 0.5\n",
      "Epoch 5185/10000, Training Loss: 0.8855373859405518, Training Accuracy: 0.5637254901960784, Validation Loss: 1.2430028915405273, Validation Accuracy: 0.5\n",
      "Epoch 5186/10000, Training Loss: 0.7743636965751648, Training Accuracy: 0.5931372549019608, Validation Loss: 1.2914061546325684, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5187/10000, Training Loss: 0.918010950088501, Training Accuracy: 0.6102941176470589, Validation Loss: 1.3342499732971191, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5188/10000, Training Loss: 0.8183799386024475, Training Accuracy: 0.6102941176470589, Validation Loss: 1.069144606590271, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5189/10000, Training Loss: 0.8530683517456055, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9776919484138489, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5190/10000, Training Loss: 0.8311640620231628, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9779858589172363, Validation Accuracy: 0.5\n",
      "Epoch 5191/10000, Training Loss: 0.8147730231285095, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1139987707138062, Validation Accuracy: 0.5\n",
      "Epoch 5192/10000, Training Loss: 0.8694025874137878, Training Accuracy: 0.6151960784313726, Validation Loss: 1.4096364974975586, Validation Accuracy: 0.25\n",
      "Epoch 5193/10000, Training Loss: 0.7992277145385742, Training Accuracy: 0.5882352941176471, Validation Loss: 2.4619123935699463, Validation Accuracy: 0.25\n",
      "Epoch 5194/10000, Training Loss: 0.9034038782119751, Training Accuracy: 0.4803921568627451, Validation Loss: 1.4321485757827759, Validation Accuracy: 0.25\n",
      "Epoch 5195/10000, Training Loss: 0.8816957473754883, Training Accuracy: 0.5833333333333334, Validation Loss: 1.708088755607605, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5196/10000, Training Loss: 0.9759585857391357, Training Accuracy: 0.6151960784313726, Validation Loss: 2.168543815612793, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5197/10000, Training Loss: 0.8068478107452393, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1907095909118652, Validation Accuracy: 0.5\n",
      "Epoch 5198/10000, Training Loss: 0.8288915753364563, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8015468120574951, Validation Accuracy: 0.5\n",
      "Epoch 5199/10000, Training Loss: 0.8459265232086182, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1375609636306763, Validation Accuracy: 0.25\n",
      "Epoch 5200/10000, Training Loss: 0.788608193397522, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9373396039009094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5201/10000, Training Loss: 1.032223105430603, Training Accuracy: 0.5196078431372549, Validation Loss: 1.123767375946045, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5202/10000, Training Loss: 0.888991117477417, Training Accuracy: 0.6127450980392157, Validation Loss: 1.9857290983200073, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5203/10000, Training Loss: 1.0067561864852905, Training Accuracy: 0.553921568627451, Validation Loss: 1.1910239458084106, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5204/10000, Training Loss: 0.7126350998878479, Training Accuracy: 0.6397058823529411, Validation Loss: 1.2527238130569458, Validation Accuracy: 0.5\n",
      "Epoch 5205/10000, Training Loss: 1.2913824319839478, Training Accuracy: 0.5955882352941176, Validation Loss: 2.0102765560150146, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5206/10000, Training Loss: 0.8768582940101624, Training Accuracy: 0.553921568627451, Validation Loss: 1.7927179336547852, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5207/10000, Training Loss: 0.7966859340667725, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8866483569145203, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5208/10000, Training Loss: 0.9245120882987976, Training Accuracy: 0.5465686274509803, Validation Loss: 1.1287397146224976, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5209/10000, Training Loss: 0.8525645136833191, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8637006878852844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5210/10000, Training Loss: 0.807482898235321, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8785335421562195, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5211/10000, Training Loss: 0.846406102180481, Training Accuracy: 0.6519607843137255, Validation Loss: 1.0505452156066895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5212/10000, Training Loss: 0.8689810633659363, Training Accuracy: 0.5294117647058824, Validation Loss: 0.9987743496894836, Validation Accuracy: 0.5\n",
      "Epoch 5213/10000, Training Loss: 0.9027186632156372, Training Accuracy: 0.5441176470588235, Validation Loss: 1.2804204225540161, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5214/10000, Training Loss: 0.9623911380767822, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8621439337730408, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5215/10000, Training Loss: 0.8923643231391907, Training Accuracy: 0.5122549019607843, Validation Loss: 0.9582998752593994, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5216/10000, Training Loss: 0.8996507525444031, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7205249667167664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5217/10000, Training Loss: 0.8281913995742798, Training Accuracy: 0.625, Validation Loss: 1.0141829252243042, Validation Accuracy: 0.5\n",
      "Epoch 5218/10000, Training Loss: 0.9686018228530884, Training Accuracy: 0.5049019607843137, Validation Loss: 1.5554604530334473, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5219/10000, Training Loss: 0.7990120053291321, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7504981160163879, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5220/10000, Training Loss: 1.1348891258239746, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9678996205329895, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5221/10000, Training Loss: 0.8770418167114258, Training Accuracy: 0.5857843137254902, Validation Loss: 0.745037317276001, Validation Accuracy: 0.5\n",
      "Epoch 5222/10000, Training Loss: 0.8795993328094482, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1773018836975098, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5223/10000, Training Loss: 0.8653203845024109, Training Accuracy: 0.5784313725490197, Validation Loss: 1.2721930742263794, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5224/10000, Training Loss: 0.7705820798873901, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0606650114059448, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5225/10000, Training Loss: 0.8874301314353943, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7374951243400574, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5226/10000, Training Loss: 1.0252712965011597, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9912135004997253, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5227/10000, Training Loss: 0.9643363356590271, Training Accuracy: 0.5465686274509803, Validation Loss: 1.3949719667434692, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5228/10000, Training Loss: 1.0282937288284302, Training Accuracy: 0.5367647058823529, Validation Loss: 1.101519227027893, Validation Accuracy: 0.5\n",
      "Epoch 5229/10000, Training Loss: 0.7849162220954895, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0283194780349731, Validation Accuracy: 0.5\n",
      "Epoch 5230/10000, Training Loss: 0.8488329648971558, Training Accuracy: 0.6078431372549019, Validation Loss: 1.8874460458755493, Validation Accuracy: 0.5\n",
      "Epoch 5231/10000, Training Loss: 1.2545005083084106, Training Accuracy: 0.5637254901960784, Validation Loss: 1.6372852325439453, Validation Accuracy: 0.5\n",
      "Epoch 5232/10000, Training Loss: 1.021087884902954, Training Accuracy: 0.553921568627451, Validation Loss: 1.087368130683899, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5233/10000, Training Loss: 1.020909070968628, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9557662606239319, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5234/10000, Training Loss: 0.9173880219459534, Training Accuracy: 0.5, Validation Loss: 0.45004770159721375, Validation Accuracy: 0.75\n",
      "Epoch 5235/10000, Training Loss: 0.7986288666725159, Training Accuracy: 0.5980392156862745, Validation Loss: 1.522584319114685, Validation Accuracy: 0.25\n",
      "Epoch 5236/10000, Training Loss: 0.7906227111816406, Training Accuracy: 0.6102941176470589, Validation Loss: 1.2164559364318848, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5237/10000, Training Loss: 0.8469032645225525, Training Accuracy: 0.6029411764705882, Validation Loss: 1.2592005729675293, Validation Accuracy: 0.5\n",
      "Epoch 5238/10000, Training Loss: 1.0119929313659668, Training Accuracy: 0.6495098039215687, Validation Loss: 1.4369069337844849, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5239/10000, Training Loss: 0.8551174998283386, Training Accuracy: 0.5931372549019608, Validation Loss: 1.5999072790145874, Validation Accuracy: 0.5\n",
      "Epoch 5240/10000, Training Loss: 1.0418012142181396, Training Accuracy: 0.5833333333333334, Validation Loss: 1.083818793296814, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5241/10000, Training Loss: 0.711690366268158, Training Accuracy: 0.6348039215686274, Validation Loss: 1.351493000984192, Validation Accuracy: 0.5\n",
      "Epoch 5242/10000, Training Loss: 0.8480859398841858, Training Accuracy: 0.5318627450980392, Validation Loss: 0.9874584674835205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5243/10000, Training Loss: 0.9691543579101562, Training Accuracy: 0.5661764705882353, Validation Loss: 2.320528268814087, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5244/10000, Training Loss: 0.7231988310813904, Training Accuracy: 0.6200980392156863, Validation Loss: 0.929263174533844, Validation Accuracy: 0.5\n",
      "Epoch 5245/10000, Training Loss: 0.8135733604431152, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0915166139602661, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5246/10000, Training Loss: 0.8380076885223389, Training Accuracy: 0.6127450980392157, Validation Loss: 1.9764410257339478, Validation Accuracy: 0.25\n",
      "Epoch 5247/10000, Training Loss: 1.0530948638916016, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9730387330055237, Validation Accuracy: 0.5\n",
      "Epoch 5248/10000, Training Loss: 0.8873018622398376, Training Accuracy: 0.6004901960784313, Validation Loss: 1.1719242334365845, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5249/10000, Training Loss: 0.7980665564537048, Training Accuracy: 0.6176470588235294, Validation Loss: 1.9313030242919922, Validation Accuracy: 0.25\n",
      "Epoch 5250/10000, Training Loss: 0.8183053731918335, Training Accuracy: 0.678921568627451, Validation Loss: 1.2403215169906616, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5251/10000, Training Loss: 0.966951847076416, Training Accuracy: 0.553921568627451, Validation Loss: 0.948969841003418, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5252/10000, Training Loss: 1.1885192394256592, Training Accuracy: 0.4852941176470588, Validation Loss: 0.9948382377624512, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5253/10000, Training Loss: 1.1003808975219727, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1226192712783813, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5254/10000, Training Loss: 0.7731407880783081, Training Accuracy: 0.5980392156862745, Validation Loss: 1.5745841264724731, Validation Accuracy: 0.5\n",
      "Epoch 5255/10000, Training Loss: 0.8574826717376709, Training Accuracy: 0.6102941176470589, Validation Loss: 1.101213812828064, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5256/10000, Training Loss: 0.8349326848983765, Training Accuracy: 0.5514705882352942, Validation Loss: 0.789866030216217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5257/10000, Training Loss: 0.9176120162010193, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0282078981399536, Validation Accuracy: 0.75\n",
      "Epoch 5258/10000, Training Loss: 0.8525904417037964, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8013514876365662, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5259/10000, Training Loss: 0.8250579833984375, Training Accuracy: 0.5465686274509803, Validation Loss: 1.1242867708206177, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5260/10000, Training Loss: 0.9449535608291626, Training Accuracy: 0.5049019607843137, Validation Loss: 0.5138333439826965, Validation Accuracy: 0.75\n",
      "Epoch 5261/10000, Training Loss: 0.8205003142356873, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0566247701644897, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5262/10000, Training Loss: 0.930056095123291, Training Accuracy: 0.553921568627451, Validation Loss: 1.0173259973526, Validation Accuracy: 0.25\n",
      "Epoch 5263/10000, Training Loss: 0.7864010334014893, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9822483658790588, Validation Accuracy: 0.5\n",
      "Epoch 5264/10000, Training Loss: 0.866327702999115, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7488632202148438, Validation Accuracy: 0.5\n",
      "Epoch 5265/10000, Training Loss: 0.7826883792877197, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0576380491256714, Validation Accuracy: 0.5\n",
      "Epoch 5266/10000, Training Loss: 0.9700627326965332, Training Accuracy: 0.5833333333333334, Validation Loss: 1.452100157737732, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5267/10000, Training Loss: 0.7815356254577637, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1037541627883911, Validation Accuracy: 0.5\n",
      "Epoch 5268/10000, Training Loss: 0.8345864415168762, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9342045783996582, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5269/10000, Training Loss: 0.8758319020271301, Training Accuracy: 0.5612745098039216, Validation Loss: 1.467405915260315, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5270/10000, Training Loss: 0.9088590145111084, Training Accuracy: 0.5392156862745098, Validation Loss: 1.04729163646698, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5271/10000, Training Loss: 0.7265933156013489, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8397643566131592, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5272/10000, Training Loss: 0.9057227373123169, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7814531326293945, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5273/10000, Training Loss: 0.8097352981567383, Training Accuracy: 0.5686274509803921, Validation Loss: 1.6606049537658691, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5274/10000, Training Loss: 1.1515591144561768, Training Accuracy: 0.5612745098039216, Validation Loss: 1.2931469678878784, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5275/10000, Training Loss: 0.7235180139541626, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7239447236061096, Validation Accuracy: 0.75\n",
      "Epoch 5276/10000, Training Loss: 0.7618486285209656, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9387164115905762, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5277/10000, Training Loss: 0.9006660580635071, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9488700032234192, Validation Accuracy: 0.25\n",
      "Epoch 5278/10000, Training Loss: 0.7492527961730957, Training Accuracy: 0.6004901960784313, Validation Loss: 0.797250509262085, Validation Accuracy: 0.5\n",
      "Epoch 5279/10000, Training Loss: 0.7992677092552185, Training Accuracy: 0.6666666666666666, Validation Loss: 0.5917381644248962, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5280/10000, Training Loss: 1.0381948947906494, Training Accuracy: 0.571078431372549, Validation Loss: 1.1362708806991577, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5281/10000, Training Loss: 0.8028773665428162, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9232645630836487, Validation Accuracy: 0.5\n",
      "Epoch 5282/10000, Training Loss: 0.7588752508163452, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7898340821266174, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5283/10000, Training Loss: 0.8657169938087463, Training Accuracy: 0.5906862745098039, Validation Loss: 1.315210223197937, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5284/10000, Training Loss: 0.8914936780929565, Training Accuracy: 0.5588235294117647, Validation Loss: 1.8155879974365234, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5285/10000, Training Loss: 0.9684641361236572, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7522923350334167, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5286/10000, Training Loss: 0.8151348233222961, Training Accuracy: 0.6274509803921569, Validation Loss: 1.3580561876296997, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5287/10000, Training Loss: 0.8815898299217224, Training Accuracy: 0.5588235294117647, Validation Loss: 0.5234821438789368, Validation Accuracy: 0.75\n",
      "Epoch 5288/10000, Training Loss: 1.0107591152191162, Training Accuracy: 0.5318627450980392, Validation Loss: 2.059983968734741, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5289/10000, Training Loss: 0.9902998805046082, Training Accuracy: 0.5367647058823529, Validation Loss: 1.1730848550796509, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5290/10000, Training Loss: 0.9219300746917725, Training Accuracy: 0.6397058823529411, Validation Loss: 1.6254029273986816, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5291/10000, Training Loss: 0.806861937046051, Training Accuracy: 0.6053921568627451, Validation Loss: 1.4089747667312622, Validation Accuracy: 0.25\n",
      "Epoch 5292/10000, Training Loss: 0.9130191206932068, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8265132904052734, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5293/10000, Training Loss: 0.7831578254699707, Training Accuracy: 0.5931372549019608, Validation Loss: 1.831417441368103, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5294/10000, Training Loss: 0.794323205947876, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8637543320655823, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5295/10000, Training Loss: 0.7758270502090454, Training Accuracy: 0.6323529411764706, Validation Loss: 1.9583948850631714, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5296/10000, Training Loss: 0.8593595027923584, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7883350253105164, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5297/10000, Training Loss: 0.8149434924125671, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0933146476745605, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5298/10000, Training Loss: 0.7935611605644226, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7055993676185608, Validation Accuracy: 0.75\n",
      "Epoch 5299/10000, Training Loss: 0.8435973525047302, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9659742712974548, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5300/10000, Training Loss: 0.6780929565429688, Training Accuracy: 0.6740196078431373, Validation Loss: 0.835923433303833, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5301/10000, Training Loss: 0.7720444798469543, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6202589273452759, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5302/10000, Training Loss: 0.8738982081413269, Training Accuracy: 0.5686274509803921, Validation Loss: 1.449663519859314, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5303/10000, Training Loss: 1.0796337127685547, Training Accuracy: 0.553921568627451, Validation Loss: 1.014550805091858, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5304/10000, Training Loss: 0.8339105248451233, Training Accuracy: 0.5882352941176471, Validation Loss: 0.850016176700592, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5305/10000, Training Loss: 0.7702258229255676, Training Accuracy: 0.6568627450980392, Validation Loss: 1.3150110244750977, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5306/10000, Training Loss: 0.9196749925613403, Training Accuracy: 0.5686274509803921, Validation Loss: 1.4182748794555664, Validation Accuracy: 0.5\n",
      "Epoch 5307/10000, Training Loss: 0.862194836139679, Training Accuracy: 0.6102941176470589, Validation Loss: 1.3715847730636597, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5308/10000, Training Loss: 0.8588369488716125, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0684453248977661, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5309/10000, Training Loss: 0.7572409510612488, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8612857460975647, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5310/10000, Training Loss: 0.8424437046051025, Training Accuracy: 0.5171568627450981, Validation Loss: 0.6064935326576233, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5311/10000, Training Loss: 0.8401201367378235, Training Accuracy: 0.5563725490196079, Validation Loss: 0.5676753520965576, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5312/10000, Training Loss: 0.9452667832374573, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8055159449577332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5313/10000, Training Loss: 0.8035762310028076, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1907126903533936, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5314/10000, Training Loss: 0.951336145401001, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9130753874778748, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5315/10000, Training Loss: 0.7949739098548889, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7215831875801086, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5316/10000, Training Loss: 0.8975964188575745, Training Accuracy: 0.6029411764705882, Validation Loss: 0.934179961681366, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5317/10000, Training Loss: 0.7848140597343445, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0241444110870361, Validation Accuracy: 0.5\n",
      "Epoch 5318/10000, Training Loss: 0.7065478563308716, Training Accuracy: 0.6519607843137255, Validation Loss: 1.0532885789871216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5319/10000, Training Loss: 0.8698034882545471, Training Accuracy: 0.5514705882352942, Validation Loss: 1.414634108543396, Validation Accuracy: 0.5\n",
      "Epoch 5320/10000, Training Loss: 0.8614590167999268, Training Accuracy: 0.6078431372549019, Validation Loss: 1.3066067695617676, Validation Accuracy: 0.5\n",
      "Epoch 5321/10000, Training Loss: 0.8824656009674072, Training Accuracy: 0.5367647058823529, Validation Loss: 1.2237526178359985, Validation Accuracy: 0.5\n",
      "Epoch 5322/10000, Training Loss: 1.065222144126892, Training Accuracy: 0.49019607843137253, Validation Loss: 1.2166858911514282, Validation Accuracy: 0.5\n",
      "Epoch 5323/10000, Training Loss: 0.6948351263999939, Training Accuracy: 0.6127450980392157, Validation Loss: 1.4189467430114746, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5324/10000, Training Loss: 0.8233604431152344, Training Accuracy: 0.6642156862745098, Validation Loss: 1.183066487312317, Validation Accuracy: 0.25\n",
      "Epoch 5325/10000, Training Loss: 0.9367566108703613, Training Accuracy: 0.6029411764705882, Validation Loss: 1.5385761260986328, Validation Accuracy: 0.5\n",
      "Epoch 5326/10000, Training Loss: 0.8390001654624939, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1341534852981567, Validation Accuracy: 0.5\n",
      "Epoch 5327/10000, Training Loss: 0.9030323624610901, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7607032656669617, Validation Accuracy: 0.5\n",
      "Epoch 5328/10000, Training Loss: 0.9132831692695618, Training Accuracy: 0.571078431372549, Validation Loss: 0.6099022030830383, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5329/10000, Training Loss: 0.7462545037269592, Training Accuracy: 0.6299019607843137, Validation Loss: 0.4236304461956024, Validation Accuracy: 0.75\n",
      "Epoch 5330/10000, Training Loss: 0.7936751246452332, Training Accuracy: 0.625, Validation Loss: 1.2764467000961304, Validation Accuracy: 0.25\n",
      "Epoch 5331/10000, Training Loss: 0.7695321440696716, Training Accuracy: 0.5122549019607843, Validation Loss: 0.969052255153656, Validation Accuracy: 0.5\n",
      "Epoch 5332/10000, Training Loss: 0.7783334255218506, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8834193348884583, Validation Accuracy: 0.5\n",
      "Epoch 5333/10000, Training Loss: 0.914268970489502, Training Accuracy: 0.5392156862745098, Validation Loss: 0.757847011089325, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5334/10000, Training Loss: 0.909925103187561, Training Accuracy: 0.5343137254901961, Validation Loss: 0.8032962679862976, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5335/10000, Training Loss: 0.8197113275527954, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9304838180541992, Validation Accuracy: 0.75\n",
      "Epoch 5336/10000, Training Loss: 1.0001707077026367, Training Accuracy: 0.5245098039215687, Validation Loss: 1.9831362962722778, Validation Accuracy: 0.5\n",
      "Epoch 5337/10000, Training Loss: 0.8752180933952332, Training Accuracy: 0.5955882352941176, Validation Loss: 0.5615785717964172, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5338/10000, Training Loss: 0.7422088384628296, Training Accuracy: 0.6078431372549019, Validation Loss: 0.5576910376548767, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5339/10000, Training Loss: 0.7683302164077759, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7097582817077637, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5340/10000, Training Loss: 0.852348804473877, Training Accuracy: 0.5490196078431373, Validation Loss: 2.141205072402954, Validation Accuracy: 0.25\n",
      "Epoch 5341/10000, Training Loss: 0.892744779586792, Training Accuracy: 0.5122549019607843, Validation Loss: 0.8731999397277832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5342/10000, Training Loss: 0.9244560599327087, Training Accuracy: 0.5343137254901961, Validation Loss: 1.524049162864685, Validation Accuracy: 0.5\n",
      "Epoch 5343/10000, Training Loss: 0.8168700933456421, Training Accuracy: 0.6127450980392157, Validation Loss: 1.687921166419983, Validation Accuracy: 0.25\n",
      "Epoch 5344/10000, Training Loss: 0.8036754131317139, Training Accuracy: 0.6004901960784313, Validation Loss: 1.2049609422683716, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5345/10000, Training Loss: 0.8007305860519409, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8889188766479492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5346/10000, Training Loss: 0.9563097357749939, Training Accuracy: 0.5686274509803921, Validation Loss: 1.5219244956970215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5347/10000, Training Loss: 0.8416281938552856, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9338162541389465, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5348/10000, Training Loss: 0.7838425040245056, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9954641461372375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5349/10000, Training Loss: 0.8693724274635315, Training Accuracy: 0.5392156862745098, Validation Loss: 1.3688374757766724, Validation Accuracy: 0.25\n",
      "Epoch 5350/10000, Training Loss: 0.7035796046257019, Training Accuracy: 0.625, Validation Loss: 0.6636462211608887, Validation Accuracy: 0.75\n",
      "Epoch 5351/10000, Training Loss: 0.8512383103370667, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7522422671318054, Validation Accuracy: 0.5\n",
      "Epoch 5352/10000, Training Loss: 0.987041711807251, Training Accuracy: 0.5343137254901961, Validation Loss: 0.48735156655311584, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5353/10000, Training Loss: 0.7579278945922852, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7534986138343811, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5354/10000, Training Loss: 0.935449481010437, Training Accuracy: 0.5661764705882353, Validation Loss: 1.401956558227539, Validation Accuracy: 0.5\n",
      "Epoch 5355/10000, Training Loss: 0.9624584317207336, Training Accuracy: 0.5759803921568627, Validation Loss: 1.2152372598648071, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5356/10000, Training Loss: 0.9187369346618652, Training Accuracy: 0.5857843137254902, Validation Loss: 0.801260232925415, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5357/10000, Training Loss: 0.8546665906906128, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9291461110115051, Validation Accuracy: 0.5\n",
      "Epoch 5358/10000, Training Loss: 0.7788177132606506, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6023696064949036, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5359/10000, Training Loss: 0.712241530418396, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9352898597717285, Validation Accuracy: 0.5\n",
      "Epoch 5360/10000, Training Loss: 0.7990822196006775, Training Accuracy: 0.6200980392156863, Validation Loss: 0.808194100856781, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5361/10000, Training Loss: 0.8338223695755005, Training Accuracy: 0.6691176470588235, Validation Loss: 1.2297195196151733, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5362/10000, Training Loss: 0.8120495676994324, Training Accuracy: 0.5343137254901961, Validation Loss: 0.6672158241271973, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5363/10000, Training Loss: 0.7044668197631836, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8046280741691589, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5364/10000, Training Loss: 0.898988664150238, Training Accuracy: 0.5441176470588235, Validation Loss: 0.5419513583183289, Validation Accuracy: 0.75\n",
      "Epoch 5365/10000, Training Loss: 0.8408379554748535, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9304259419441223, Validation Accuracy: 0.5\n",
      "Epoch 5366/10000, Training Loss: 0.795879065990448, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6857776045799255, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5367/10000, Training Loss: 0.8337730765342712, Training Accuracy: 0.571078431372549, Validation Loss: 0.62672358751297, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5368/10000, Training Loss: 1.1006121635437012, Training Accuracy: 0.5441176470588235, Validation Loss: 1.3220022916793823, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5369/10000, Training Loss: 0.7918922305107117, Training Accuracy: 0.5661764705882353, Validation Loss: 1.153700828552246, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5370/10000, Training Loss: 0.8978643417358398, Training Accuracy: 0.5588235294117647, Validation Loss: 1.8895105123519897, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5371/10000, Training Loss: 0.6882691979408264, Training Accuracy: 0.6740196078431373, Validation Loss: 1.4326568841934204, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5372/10000, Training Loss: 0.9272795915603638, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9494612812995911, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5373/10000, Training Loss: 0.7624212503433228, Training Accuracy: 0.5661764705882353, Validation Loss: 1.018715500831604, Validation Accuracy: 0.5\n",
      "Epoch 5374/10000, Training Loss: 0.9418255090713501, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1914992332458496, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5375/10000, Training Loss: 0.9024789929389954, Training Accuracy: 0.5906862745098039, Validation Loss: 1.2374852895736694, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5376/10000, Training Loss: 0.7626546025276184, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7292645573616028, Validation Accuracy: 0.5\n",
      "Epoch 5377/10000, Training Loss: 0.8848088383674622, Training Accuracy: 0.5416666666666666, Validation Loss: 1.6856597661972046, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5378/10000, Training Loss: 0.9140625, Training Accuracy: 0.5122549019607843, Validation Loss: 0.832737922668457, Validation Accuracy: 0.5\n",
      "Epoch 5379/10000, Training Loss: 0.7491101026535034, Training Accuracy: 0.6225490196078431, Validation Loss: 1.3060909509658813, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5380/10000, Training Loss: 0.914672315120697, Training Accuracy: 0.5759803921568627, Validation Loss: 2.1438684463500977, Validation Accuracy: 0.25\n",
      "Epoch 5381/10000, Training Loss: 0.8981817364692688, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7532599568367004, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5382/10000, Training Loss: 0.8654961585998535, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9381701350212097, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5383/10000, Training Loss: 0.7641209363937378, Training Accuracy: 0.571078431372549, Validation Loss: 1.1629225015640259, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5384/10000, Training Loss: 0.9206289649009705, Training Accuracy: 0.5661764705882353, Validation Loss: 1.5402954816818237, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5385/10000, Training Loss: 0.727874755859375, Training Accuracy: 0.625, Validation Loss: 1.0539659261703491, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5386/10000, Training Loss: 0.9189320802688599, Training Accuracy: 0.553921568627451, Validation Loss: 1.1971354484558105, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5387/10000, Training Loss: 1.1126619577407837, Training Accuracy: 0.5196078431372549, Validation Loss: 1.8454903364181519, Validation Accuracy: 0.5\n",
      "Epoch 5388/10000, Training Loss: 0.8724731206893921, Training Accuracy: 0.5784313725490197, Validation Loss: 0.973999559879303, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5389/10000, Training Loss: 0.8416290283203125, Training Accuracy: 0.571078431372549, Validation Loss: 0.6339201927185059, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5390/10000, Training Loss: 0.7633575797080994, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9692152142524719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5391/10000, Training Loss: 0.8505114912986755, Training Accuracy: 0.5367647058823529, Validation Loss: 0.8382924199104309, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5392/10000, Training Loss: 1.0131887197494507, Training Accuracy: 0.5220588235294118, Validation Loss: 0.63025963306427, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5393/10000, Training Loss: 0.7739854454994202, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9187006950378418, Validation Accuracy: 0.5\n",
      "Epoch 5394/10000, Training Loss: 1.012174367904663, Training Accuracy: 0.49754901960784315, Validation Loss: 0.833347499370575, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5395/10000, Training Loss: 0.8184077143669128, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0280801057815552, Validation Accuracy: 0.5\n",
      "Epoch 5396/10000, Training Loss: 0.828921914100647, Training Accuracy: 0.6372549019607843, Validation Loss: 0.891295850276947, Validation Accuracy: 0.5\n",
      "Epoch 5397/10000, Training Loss: 0.9581946730613708, Training Accuracy: 0.5906862745098039, Validation Loss: 1.378638744354248, Validation Accuracy: 0.5\n",
      "Epoch 5398/10000, Training Loss: 0.8203690648078918, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7420219779014587, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5399/10000, Training Loss: 0.8781784772872925, Training Accuracy: 0.5269607843137255, Validation Loss: 1.5723519325256348, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5400/10000, Training Loss: 0.8888488411903381, Training Accuracy: 0.4950980392156863, Validation Loss: 0.8699672818183899, Validation Accuracy: 0.5\n",
      "Epoch 5401/10000, Training Loss: 0.8280255794525146, Training Accuracy: 0.571078431372549, Validation Loss: 1.5277042388916016, Validation Accuracy: 0.25\n",
      "Epoch 5402/10000, Training Loss: 0.8860294222831726, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7848899364471436, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5403/10000, Training Loss: 1.0831775665283203, Training Accuracy: 0.5269607843137255, Validation Loss: 1.8856525421142578, Validation Accuracy: 0.5\n",
      "Epoch 5404/10000, Training Loss: 0.8490974307060242, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7538228034973145, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5405/10000, Training Loss: 0.8527309894561768, Training Accuracy: 0.5514705882352942, Validation Loss: 1.1351484060287476, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5406/10000, Training Loss: 0.8377674221992493, Training Accuracy: 0.553921568627451, Validation Loss: 1.1852096319198608, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5407/10000, Training Loss: 0.7322800755500793, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8131473660469055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5408/10000, Training Loss: 1.1451669931411743, Training Accuracy: 0.5514705882352942, Validation Loss: 1.637306571006775, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5409/10000, Training Loss: 0.7468695044517517, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3449888229370117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5410/10000, Training Loss: 0.7172610759735107, Training Accuracy: 0.5882352941176471, Validation Loss: 1.4182204008102417, Validation Accuracy: 0.25\n",
      "Epoch 5411/10000, Training Loss: 0.9077829718589783, Training Accuracy: 0.5637254901960784, Validation Loss: 1.2606717348098755, Validation Accuracy: 0.5\n",
      "Epoch 5412/10000, Training Loss: 0.8516499996185303, Training Accuracy: 0.5759803921568627, Validation Loss: 1.16791832447052, Validation Accuracy: 0.5\n",
      "Epoch 5413/10000, Training Loss: 0.8039263486862183, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8726314902305603, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5414/10000, Training Loss: 0.8908677101135254, Training Accuracy: 0.625, Validation Loss: 0.8933960795402527, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5415/10000, Training Loss: 0.7807183861732483, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9794557690620422, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5416/10000, Training Loss: 0.7246964573860168, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1265935897827148, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5417/10000, Training Loss: 0.7849469780921936, Training Accuracy: 0.5931372549019608, Validation Loss: 1.8534499406814575, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5418/10000, Training Loss: 0.9684175848960876, Training Accuracy: 0.5514705882352942, Validation Loss: 0.93967604637146, Validation Accuracy: 0.5\n",
      "Epoch 5419/10000, Training Loss: 0.8280912637710571, Training Accuracy: 0.5661764705882353, Validation Loss: 1.229535460472107, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5420/10000, Training Loss: 0.7719822525978088, Training Accuracy: 0.5980392156862745, Validation Loss: 1.2051351070404053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5421/10000, Training Loss: 0.6885930299758911, Training Accuracy: 0.6593137254901961, Validation Loss: 1.196749210357666, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5422/10000, Training Loss: 0.7989826798439026, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8651609420776367, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5423/10000, Training Loss: 0.8932340145111084, Training Accuracy: 0.5490196078431373, Validation Loss: 0.999981164932251, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5424/10000, Training Loss: 0.9678043127059937, Training Accuracy: 0.5318627450980392, Validation Loss: 1.0733262300491333, Validation Accuracy: 0.5\n",
      "Epoch 5425/10000, Training Loss: 1.014555811882019, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0766195058822632, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5426/10000, Training Loss: 0.9414379596710205, Training Accuracy: 0.5588235294117647, Validation Loss: 0.988987147808075, Validation Accuracy: 0.5\n",
      "Epoch 5427/10000, Training Loss: 1.0537025928497314, Training Accuracy: 0.5294117647058824, Validation Loss: 0.8716394305229187, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5428/10000, Training Loss: 0.8248117566108704, Training Accuracy: 0.5955882352941176, Validation Loss: 1.3790124654769897, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5429/10000, Training Loss: 0.8974263668060303, Training Accuracy: 0.6225490196078431, Validation Loss: 1.321968674659729, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5430/10000, Training Loss: 0.7699872255325317, Training Accuracy: 0.5563725490196079, Validation Loss: 0.6630778908729553, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5431/10000, Training Loss: 0.8248880505561829, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1073614358901978, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5432/10000, Training Loss: 0.899800717830658, Training Accuracy: 0.6176470588235294, Validation Loss: 1.5667637586593628, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5433/10000, Training Loss: 0.7773388624191284, Training Accuracy: 0.5612745098039216, Validation Loss: 1.1167670488357544, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5434/10000, Training Loss: 0.841046929359436, Training Accuracy: 0.5416666666666666, Validation Loss: 0.5522384643554688, Validation Accuracy: 0.75\n",
      "Epoch 5435/10000, Training Loss: 0.824027419090271, Training Accuracy: 0.6225490196078431, Validation Loss: 1.6986440420150757, Validation Accuracy: 0.25\n",
      "Epoch 5436/10000, Training Loss: 0.9211643934249878, Training Accuracy: 0.625, Validation Loss: 1.8272193670272827, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5437/10000, Training Loss: 0.8591084480285645, Training Accuracy: 0.5269607843137255, Validation Loss: 1.0578008890151978, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5438/10000, Training Loss: 0.8040217757225037, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9907569885253906, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5439/10000, Training Loss: 0.694734513759613, Training Accuracy: 0.6519607843137255, Validation Loss: 1.2147259712219238, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5440/10000, Training Loss: 0.9153718948364258, Training Accuracy: 0.6078431372549019, Validation Loss: 1.093878984451294, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5441/10000, Training Loss: 0.7620609402656555, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9739931225776672, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5442/10000, Training Loss: 0.7337138652801514, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9118692278862, Validation Accuracy: 0.5\n",
      "Epoch 5443/10000, Training Loss: 0.841636061668396, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0535591840744019, Validation Accuracy: 0.25\n",
      "Epoch 5444/10000, Training Loss: 0.748508095741272, Training Accuracy: 0.6078431372549019, Validation Loss: 1.4151172637939453, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5445/10000, Training Loss: 0.9404008984565735, Training Accuracy: 0.5514705882352942, Validation Loss: 1.8305811882019043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5446/10000, Training Loss: 0.932762622833252, Training Accuracy: 0.6200980392156863, Validation Loss: 1.5231748819351196, Validation Accuracy: 0.5\n",
      "Epoch 5447/10000, Training Loss: 0.754582405090332, Training Accuracy: 0.571078431372549, Validation Loss: 0.9776358008384705, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5448/10000, Training Loss: 0.8104869723320007, Training Accuracy: 0.5441176470588235, Validation Loss: 1.1854125261306763, Validation Accuracy: 0.5\n",
      "Epoch 5449/10000, Training Loss: 0.8341955542564392, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1800999641418457, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5450/10000, Training Loss: 0.7738718390464783, Training Accuracy: 0.5563725490196079, Validation Loss: 1.4564580917358398, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5451/10000, Training Loss: 0.801680326461792, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8209354281425476, Validation Accuracy: 0.5\n",
      "Epoch 5452/10000, Training Loss: 0.8066891431808472, Training Accuracy: 0.5612745098039216, Validation Loss: 1.134265422821045, Validation Accuracy: 0.25\n",
      "Epoch 5453/10000, Training Loss: 0.769338071346283, Training Accuracy: 0.5612745098039216, Validation Loss: 1.3620437383651733, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5454/10000, Training Loss: 0.7241801619529724, Training Accuracy: 0.6274509803921569, Validation Loss: 1.2614420652389526, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5455/10000, Training Loss: 0.8512890338897705, Training Accuracy: 0.5612745098039216, Validation Loss: 1.4474021196365356, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5456/10000, Training Loss: 0.774263322353363, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1240448951721191, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5457/10000, Training Loss: 0.8024436831474304, Training Accuracy: 0.5980392156862745, Validation Loss: 0.621908962726593, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5458/10000, Training Loss: 0.881530225276947, Training Accuracy: 0.47794117647058826, Validation Loss: 0.7292067408561707, Validation Accuracy: 0.5\n",
      "Epoch 5459/10000, Training Loss: 0.7687384486198425, Training Accuracy: 0.6151960784313726, Validation Loss: 0.847934901714325, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5460/10000, Training Loss: 0.8083505630493164, Training Accuracy: 0.5514705882352942, Validation Loss: 1.0014876127243042, Validation Accuracy: 0.5\n",
      "Epoch 5461/10000, Training Loss: 0.769279956817627, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8148773312568665, Validation Accuracy: 0.5\n",
      "Epoch 5462/10000, Training Loss: 0.7532947063446045, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0277153253555298, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5463/10000, Training Loss: 0.8124862909317017, Training Accuracy: 0.5612745098039216, Validation Loss: 1.6457643508911133, Validation Accuracy: 0.25\n",
      "Epoch 5464/10000, Training Loss: 0.6985378861427307, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9391710162162781, Validation Accuracy: 0.5\n",
      "Epoch 5465/10000, Training Loss: 0.7732519507408142, Training Accuracy: 0.5882352941176471, Validation Loss: 1.5596246719360352, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5466/10000, Training Loss: 0.7983537316322327, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8370497226715088, Validation Accuracy: 0.5\n",
      "Epoch 5467/10000, Training Loss: 0.7375760674476624, Training Accuracy: 0.5269607843137255, Validation Loss: 1.4961332082748413, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5468/10000, Training Loss: 0.755504310131073, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0149167776107788, Validation Accuracy: 0.5\n",
      "Epoch 5469/10000, Training Loss: 0.7714216709136963, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8159084320068359, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5470/10000, Training Loss: 0.7752869725227356, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8599107265472412, Validation Accuracy: 0.5\n",
      "Epoch 5471/10000, Training Loss: 0.7528958320617676, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6736472249031067, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5472/10000, Training Loss: 0.775154709815979, Training Accuracy: 0.5784313725490197, Validation Loss: 1.1101160049438477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5473/10000, Training Loss: 0.7923102974891663, Training Accuracy: 0.6078431372549019, Validation Loss: 1.2933286428451538, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5474/10000, Training Loss: 0.8334859013557434, Training Accuracy: 0.6666666666666666, Validation Loss: 2.555250883102417, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5475/10000, Training Loss: 0.8173588514328003, Training Accuracy: 0.5563725490196079, Validation Loss: 0.6139276027679443, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5476/10000, Training Loss: 0.8280416131019592, Training Accuracy: 0.571078431372549, Validation Loss: 0.8471863865852356, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5477/10000, Training Loss: 0.7451392412185669, Training Accuracy: 0.5906862745098039, Validation Loss: 1.1005727052688599, Validation Accuracy: 0.5\n",
      "Epoch 5478/10000, Training Loss: 0.7222996950149536, Training Accuracy: 0.6004901960784313, Validation Loss: 1.1139861345291138, Validation Accuracy: 0.25\n",
      "Epoch 5479/10000, Training Loss: 0.8816797733306885, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1840072870254517, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5480/10000, Training Loss: 0.825860321521759, Training Accuracy: 0.5735294117647058, Validation Loss: 1.151187539100647, Validation Accuracy: 0.5\n",
      "Epoch 5481/10000, Training Loss: 0.7716694474220276, Training Accuracy: 0.6029411764705882, Validation Loss: 1.094282865524292, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5482/10000, Training Loss: 0.7770030498504639, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0637431144714355, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5483/10000, Training Loss: 0.7908559441566467, Training Accuracy: 0.5367647058823529, Validation Loss: 1.23778235912323, Validation Accuracy: 0.25\n",
      "Epoch 5484/10000, Training Loss: 0.8002667427062988, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8277602195739746, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5485/10000, Training Loss: 0.813224732875824, Training Accuracy: 0.553921568627451, Validation Loss: 1.173153281211853, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5486/10000, Training Loss: 0.7865971326828003, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1586511135101318, Validation Accuracy: 0.5\n",
      "Epoch 5487/10000, Training Loss: 0.7878482341766357, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8543478846549988, Validation Accuracy: 0.5\n",
      "Epoch 5488/10000, Training Loss: 0.8422598838806152, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9046674370765686, Validation Accuracy: 0.25\n",
      "Epoch 5489/10000, Training Loss: 0.7278971672058105, Training Accuracy: 0.5906862745098039, Validation Loss: 0.854649007320404, Validation Accuracy: 0.5\n",
      "Epoch 5490/10000, Training Loss: 0.754810631275177, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8196976780891418, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5491/10000, Training Loss: 0.8090888261795044, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8026986122131348, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5492/10000, Training Loss: 0.7620245814323425, Training Accuracy: 0.6029411764705882, Validation Loss: 0.4990158975124359, Validation Accuracy: 0.75\n",
      "Epoch 5493/10000, Training Loss: 0.8777421712875366, Training Accuracy: 0.5416666666666666, Validation Loss: 0.875002384185791, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5494/10000, Training Loss: 0.7700611352920532, Training Accuracy: 0.571078431372549, Validation Loss: 1.5057530403137207, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 5495/10000, Training Loss: 0.885301947593689, Training Accuracy: 0.5171568627450981, Validation Loss: 1.050285816192627, Validation Accuracy: 0.5\n",
      "Epoch 5496/10000, Training Loss: 0.8054691553115845, Training Accuracy: 0.5759803921568627, Validation Loss: 1.904772400856018, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5497/10000, Training Loss: 0.935265839099884, Training Accuracy: 0.5955882352941176, Validation Loss: 1.2593437433242798, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5498/10000, Training Loss: 0.9581826329231262, Training Accuracy: 0.5367647058823529, Validation Loss: 2.5065715312957764, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5499/10000, Training Loss: 0.8388671278953552, Training Accuracy: 0.5808823529411765, Validation Loss: 1.0334056615829468, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5500/10000, Training Loss: 0.9486509561538696, Training Accuracy: 0.5612745098039216, Validation Loss: 2.0960352420806885, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5501/10000, Training Loss: 0.7694623470306396, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0693210363388062, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5502/10000, Training Loss: 0.7702466249465942, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8787806630134583, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5503/10000, Training Loss: 0.7902257442474365, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9502268433570862, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5504/10000, Training Loss: 0.8112711906433105, Training Accuracy: 0.5980392156862745, Validation Loss: 2.1736180782318115, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5505/10000, Training Loss: 0.7280413508415222, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7098081111907959, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5506/10000, Training Loss: 0.6967953443527222, Training Accuracy: 0.6225490196078431, Validation Loss: 0.965574324131012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5507/10000, Training Loss: 1.2242989540100098, Training Accuracy: 0.5122549019607843, Validation Loss: 1.235396385192871, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5508/10000, Training Loss: 0.7934489250183105, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7025222778320312, Validation Accuracy: 0.5\n",
      "Epoch 5509/10000, Training Loss: 0.7116445899009705, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0653636455535889, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5510/10000, Training Loss: 0.7233303189277649, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1470346450805664, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5511/10000, Training Loss: 0.84322589635849, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3004027605056763, Validation Accuracy: 0.5\n",
      "Epoch 5512/10000, Training Loss: 0.8854988217353821, Training Accuracy: 0.5784313725490197, Validation Loss: 1.4928665161132812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5513/10000, Training Loss: 0.7521440982818604, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7540838122367859, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5514/10000, Training Loss: 0.9330238699913025, Training Accuracy: 0.5220588235294118, Validation Loss: 1.116703748703003, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5515/10000, Training Loss: 0.743975043296814, Training Accuracy: 0.5784313725490197, Validation Loss: 0.532281756401062, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5516/10000, Training Loss: 0.8146581649780273, Training Accuracy: 0.5637254901960784, Validation Loss: 1.2651444673538208, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5517/10000, Training Loss: 0.9511968493461609, Training Accuracy: 0.6029411764705882, Validation Loss: 2.961261749267578, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5518/10000, Training Loss: 0.7032570838928223, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8644548058509827, Validation Accuracy: 0.5\n",
      "Epoch 5519/10000, Training Loss: 0.7480937242507935, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0608755350112915, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5520/10000, Training Loss: 0.9213418960571289, Training Accuracy: 0.5980392156862745, Validation Loss: 2.7172253131866455, Validation Accuracy: 0.25\n",
      "Epoch 5521/10000, Training Loss: 0.8846575617790222, Training Accuracy: 0.5049019607843137, Validation Loss: 1.78374183177948, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5522/10000, Training Loss: 0.793316125869751, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0509275197982788, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5523/10000, Training Loss: 0.7380767464637756, Training Accuracy: 0.6102941176470589, Validation Loss: 1.162382960319519, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5524/10000, Training Loss: 0.7368829250335693, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9927169680595398, Validation Accuracy: 0.25\n",
      "Epoch 5525/10000, Training Loss: 0.758841872215271, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1230435371398926, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5526/10000, Training Loss: 0.9505444765090942, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0554583072662354, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5527/10000, Training Loss: 0.8402018547058105, Training Accuracy: 0.5661764705882353, Validation Loss: 1.3246146440505981, Validation Accuracy: 0.25\n",
      "Epoch 5528/10000, Training Loss: 0.8952279090881348, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6419810652732849, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5529/10000, Training Loss: 0.6996665596961975, Training Accuracy: 0.6568627450980392, Validation Loss: 1.377726674079895, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5530/10000, Training Loss: 0.8674144148826599, Training Accuracy: 0.5833333333333334, Validation Loss: 2.6827232837677, Validation Accuracy: 0.5\n",
      "Epoch 5531/10000, Training Loss: 0.7221603989601135, Training Accuracy: 0.5735294117647058, Validation Loss: 1.10000741481781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5532/10000, Training Loss: 0.7073525190353394, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7494490146636963, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5533/10000, Training Loss: 0.7820581197738647, Training Accuracy: 0.6274509803921569, Validation Loss: 1.1705225706100464, Validation Accuracy: 0.5\n",
      "Epoch 5534/10000, Training Loss: 0.6914380192756653, Training Accuracy: 0.6299019607843137, Validation Loss: 1.2178481817245483, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5535/10000, Training Loss: 0.7713419795036316, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0470151901245117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5536/10000, Training Loss: 0.9637251496315002, Training Accuracy: 0.571078431372549, Validation Loss: 0.654325008392334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5537/10000, Training Loss: 0.9098652601242065, Training Accuracy: 0.6127450980392157, Validation Loss: 1.2438985109329224, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5538/10000, Training Loss: 0.8163952827453613, Training Accuracy: 0.5171568627450981, Validation Loss: 0.7365304827690125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5539/10000, Training Loss: 0.9477729201316833, Training Accuracy: 0.5857843137254902, Validation Loss: 1.3366069793701172, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5540/10000, Training Loss: 0.7018952965736389, Training Accuracy: 0.6053921568627451, Validation Loss: 1.134830117225647, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5541/10000, Training Loss: 0.6941856741905212, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7179200053215027, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5542/10000, Training Loss: 0.7269431948661804, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7066357135772705, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5543/10000, Training Loss: 0.8809800744056702, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8249964714050293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5544/10000, Training Loss: 0.7457014918327332, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7600610852241516, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5545/10000, Training Loss: 0.8482892513275146, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9377779960632324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5546/10000, Training Loss: 0.773961067199707, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9435250759124756, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5547/10000, Training Loss: 0.9228788614273071, Training Accuracy: 0.5465686274509803, Validation Loss: 1.1765750646591187, Validation Accuracy: 0.5\n",
      "Epoch 5548/10000, Training Loss: 0.7223451137542725, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3133156299591064, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5549/10000, Training Loss: 0.8760526776313782, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7067378163337708, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5550/10000, Training Loss: 0.7171921133995056, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9239183068275452, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5551/10000, Training Loss: 0.8026399612426758, Training Accuracy: 0.5392156862745098, Validation Loss: 1.2524603605270386, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5552/10000, Training Loss: 0.8584405779838562, Training Accuracy: 0.571078431372549, Validation Loss: 0.9639304280281067, Validation Accuracy: 0.5\n",
      "Epoch 5553/10000, Training Loss: 0.8365871906280518, Training Accuracy: 0.5122549019607843, Validation Loss: 0.739417552947998, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5554/10000, Training Loss: 0.7336884140968323, Training Accuracy: 0.5833333333333334, Validation Loss: 0.5955985188484192, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5555/10000, Training Loss: 0.8052513003349304, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6112586259841919, Validation Accuracy: 0.75\n",
      "Epoch 5556/10000, Training Loss: 0.8790538907051086, Training Accuracy: 0.4583333333333333, Validation Loss: 1.0302340984344482, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5557/10000, Training Loss: 0.7330920100212097, Training Accuracy: 0.5980392156862745, Validation Loss: 0.955938994884491, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5558/10000, Training Loss: 0.725086510181427, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9716847538948059, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5559/10000, Training Loss: 0.65323805809021, Training Accuracy: 0.6544117647058824, Validation Loss: 1.0679199695587158, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5560/10000, Training Loss: 0.7575889229774475, Training Accuracy: 0.5269607843137255, Validation Loss: 0.7512595057487488, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5561/10000, Training Loss: 0.7430773973464966, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7482144832611084, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5562/10000, Training Loss: 0.7717171311378479, Training Accuracy: 0.6029411764705882, Validation Loss: 1.2826780080795288, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5563/10000, Training Loss: 0.774117112159729, Training Accuracy: 0.6151960784313726, Validation Loss: 1.302966833114624, Validation Accuracy: 0.5\n",
      "Epoch 5564/10000, Training Loss: 0.7692037224769592, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9107052683830261, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5565/10000, Training Loss: 0.7989570498466492, Training Accuracy: 0.6225490196078431, Validation Loss: 2.231558322906494, Validation Accuracy: 0.25\n",
      "Epoch 5566/10000, Training Loss: 0.8229966163635254, Training Accuracy: 0.553921568627451, Validation Loss: 1.3331462144851685, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5567/10000, Training Loss: 0.8038446307182312, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9039412140846252, Validation Accuracy: 0.5\n",
      "Epoch 5568/10000, Training Loss: 0.754986047744751, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0046712160110474, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5569/10000, Training Loss: 0.8071293830871582, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0697200298309326, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5570/10000, Training Loss: 0.7979313731193542, Training Accuracy: 0.5882352941176471, Validation Loss: 0.960507869720459, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5571/10000, Training Loss: 0.8994983434677124, Training Accuracy: 0.5465686274509803, Validation Loss: 1.2173875570297241, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5572/10000, Training Loss: 0.8506696820259094, Training Accuracy: 0.5563725490196079, Validation Loss: 1.1818071603775024, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5573/10000, Training Loss: 0.8252190947532654, Training Accuracy: 0.6274509803921569, Validation Loss: 1.4350584745407104, Validation Accuracy: 0.5\n",
      "Epoch 5574/10000, Training Loss: 0.7969406247138977, Training Accuracy: 0.6176470588235294, Validation Loss: 1.7453235387802124, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5575/10000, Training Loss: 0.7406175136566162, Training Accuracy: 0.6176470588235294, Validation Loss: 1.280401349067688, Validation Accuracy: 0.25\n",
      "Epoch 5576/10000, Training Loss: 0.6925826072692871, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0375808477401733, Validation Accuracy: 0.25\n",
      "Epoch 5577/10000, Training Loss: 0.7575678825378418, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7871084213256836, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5578/10000, Training Loss: 0.7647976875305176, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7361637949943542, Validation Accuracy: 0.5\n",
      "Epoch 5579/10000, Training Loss: 0.7765199542045593, Training Accuracy: 0.5637254901960784, Validation Loss: 0.5851725935935974, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5580/10000, Training Loss: 0.7656006813049316, Training Accuracy: 0.553921568627451, Validation Loss: 0.618239164352417, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5581/10000, Training Loss: 0.705041766166687, Training Accuracy: 0.6421568627450981, Validation Loss: 1.093924880027771, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5582/10000, Training Loss: 0.8067544102668762, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9562807679176331, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5583/10000, Training Loss: 0.6882354617118835, Training Accuracy: 0.625, Validation Loss: 0.8549051284790039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5584/10000, Training Loss: 0.7231296300888062, Training Accuracy: 0.6323529411764706, Validation Loss: 1.239927887916565, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5585/10000, Training Loss: 0.8936923742294312, Training Accuracy: 0.5245098039215687, Validation Loss: 0.954636812210083, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5586/10000, Training Loss: 0.8141775727272034, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9197368621826172, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5587/10000, Training Loss: 0.7623928189277649, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7504283785820007, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5588/10000, Training Loss: 0.7715625166893005, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1879955530166626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5589/10000, Training Loss: 0.8368400931358337, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3873891830444336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5590/10000, Training Loss: 0.7593844532966614, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8591567873954773, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5591/10000, Training Loss: 0.908681333065033, Training Accuracy: 0.5465686274509803, Validation Loss: 1.3215928077697754, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5592/10000, Training Loss: 0.8324317932128906, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8650757670402527, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5593/10000, Training Loss: 0.6824081540107727, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9548017978668213, Validation Accuracy: 0.5\n",
      "Epoch 5594/10000, Training Loss: 0.8035908341407776, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6521250605583191, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5595/10000, Training Loss: 0.7678524851799011, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6647732853889465, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5596/10000, Training Loss: 0.8160333037376404, Training Accuracy: 0.5759803921568627, Validation Loss: 1.1312549114227295, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5597/10000, Training Loss: 0.8438470363616943, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9951351284980774, Validation Accuracy: 0.5\n",
      "Epoch 5598/10000, Training Loss: 0.7122990489006042, Training Accuracy: 0.5759803921568627, Validation Loss: 0.5684864521026611, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5599/10000, Training Loss: 0.7428133487701416, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0172098875045776, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5600/10000, Training Loss: 0.7077553868293762, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9022438526153564, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5601/10000, Training Loss: 0.7616206407546997, Training Accuracy: 0.625, Validation Loss: 0.7178089618682861, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5602/10000, Training Loss: 0.9624883532524109, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0544682741165161, Validation Accuracy: 0.5\n",
      "Epoch 5603/10000, Training Loss: 0.8126397728919983, Training Accuracy: 0.5808823529411765, Validation Loss: 1.4242132902145386, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5604/10000, Training Loss: 1.1562854051589966, Training Accuracy: 0.5392156862745098, Validation Loss: 0.7441167831420898, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5605/10000, Training Loss: 0.7441449761390686, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8864416480064392, Validation Accuracy: 0.5\n",
      "Epoch 5606/10000, Training Loss: 0.7828590273857117, Training Accuracy: 0.6274509803921569, Validation Loss: 1.336621880531311, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5607/10000, Training Loss: 0.7346963286399841, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8910431861877441, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5608/10000, Training Loss: 0.7496959567070007, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9372382164001465, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5609/10000, Training Loss: 0.7313046455383301, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6756963729858398, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5610/10000, Training Loss: 0.7292856574058533, Training Accuracy: 0.5906862745098039, Validation Loss: 0.699883759021759, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5611/10000, Training Loss: 0.776374340057373, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7944650650024414, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5612/10000, Training Loss: 0.7704411149024963, Training Accuracy: 0.5318627450980392, Validation Loss: 1.0766681432724, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5613/10000, Training Loss: 0.7608017921447754, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0337287187576294, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5614/10000, Training Loss: 0.7343762516975403, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0570930242538452, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5615/10000, Training Loss: 0.7620065212249756, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0677071809768677, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5616/10000, Training Loss: 0.7406601905822754, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7903071045875549, Validation Accuracy: 0.5\n",
      "Epoch 5617/10000, Training Loss: 0.7699787020683289, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1297184228897095, Validation Accuracy: 0.5\n",
      "Epoch 5618/10000, Training Loss: 0.6979223489761353, Training Accuracy: 0.6176470588235294, Validation Loss: 1.578688144683838, Validation Accuracy: 0.5\n",
      "Epoch 5619/10000, Training Loss: 0.8525938987731934, Training Accuracy: 0.5, Validation Loss: 1.3413934707641602, Validation Accuracy: 0.75\n",
      "Epoch 5620/10000, Training Loss: 0.7565747499465942, Training Accuracy: 0.5661764705882353, Validation Loss: 1.614256501197815, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5621/10000, Training Loss: 1.0370672941207886, Training Accuracy: 0.5367647058823529, Validation Loss: 0.693260669708252, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5622/10000, Training Loss: 0.7773404121398926, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9201746582984924, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5623/10000, Training Loss: 0.7355363368988037, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8205727934837341, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5624/10000, Training Loss: 0.8060937523841858, Training Accuracy: 0.5147058823529411, Validation Loss: 1.2243759632110596, Validation Accuracy: 0.25\n",
      "Epoch 5625/10000, Training Loss: 0.7898594737052917, Training Accuracy: 0.6053921568627451, Validation Loss: 1.3868235349655151, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5626/10000, Training Loss: 0.802379846572876, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0371555089950562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5627/10000, Training Loss: 0.7998722195625305, Training Accuracy: 0.5637254901960784, Validation Loss: 1.3231197595596313, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5628/10000, Training Loss: 0.6883037686347961, Training Accuracy: 0.6642156862745098, Validation Loss: 1.343129277229309, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5629/10000, Training Loss: 0.8059302568435669, Training Accuracy: 0.5955882352941176, Validation Loss: 2.286233901977539, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5630/10000, Training Loss: 0.8086329698562622, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7797015309333801, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5631/10000, Training Loss: 0.9092307686805725, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9064469933509827, Validation Accuracy: 0.5\n",
      "Epoch 5632/10000, Training Loss: 0.6730082035064697, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8501014113426208, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5633/10000, Training Loss: 0.8365411162376404, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8256149888038635, Validation Accuracy: 0.5\n",
      "Epoch 5634/10000, Training Loss: 0.812404453754425, Training Accuracy: 0.5588235294117647, Validation Loss: 0.9830109477043152, Validation Accuracy: 0.5\n",
      "Epoch 5635/10000, Training Loss: 0.8577083349227905, Training Accuracy: 0.6274509803921569, Validation Loss: 1.250073790550232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5636/10000, Training Loss: 0.728792667388916, Training Accuracy: 0.6200980392156863, Validation Loss: 1.9415544271469116, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5637/10000, Training Loss: 0.7523730397224426, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8368304371833801, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5638/10000, Training Loss: 0.7493407130241394, Training Accuracy: 0.6348039215686274, Validation Loss: 1.1597338914871216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5639/10000, Training Loss: 0.8425031304359436, Training Accuracy: 0.5784313725490197, Validation Loss: 1.3765076398849487, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5640/10000, Training Loss: 0.7435057163238525, Training Accuracy: 0.6029411764705882, Validation Loss: 1.1141101121902466, Validation Accuracy: 0.5\n",
      "Epoch 5641/10000, Training Loss: 0.8048735857009888, Training Accuracy: 0.5686274509803921, Validation Loss: 1.24239981174469, Validation Accuracy: 0.5\n",
      "Epoch 5642/10000, Training Loss: 0.9118766188621521, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0660654306411743, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5643/10000, Training Loss: 0.8485876321792603, Training Accuracy: 0.5563725490196079, Validation Loss: 0.970902144908905, Validation Accuracy: 0.5\n",
      "Epoch 5644/10000, Training Loss: 0.8547695875167847, Training Accuracy: 0.5465686274509803, Validation Loss: 1.0833817720413208, Validation Accuracy: 0.5\n",
      "Epoch 5645/10000, Training Loss: 0.7462934851646423, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9321457743644714, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5646/10000, Training Loss: 0.7177495956420898, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7997642159461975, Validation Accuracy: 0.5\n",
      "Epoch 5647/10000, Training Loss: 0.7246006727218628, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7710933089256287, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5648/10000, Training Loss: 0.6926574110984802, Training Accuracy: 0.6397058823529411, Validation Loss: 1.5120677947998047, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 5649/10000, Training Loss: 0.7034979462623596, Training Accuracy: 0.571078431372549, Validation Loss: 1.1776541471481323, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5650/10000, Training Loss: 0.8571510910987854, Training Accuracy: 0.5367647058823529, Validation Loss: 0.7828097343444824, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5651/10000, Training Loss: 0.8284392952919006, Training Accuracy: 0.5367647058823529, Validation Loss: 1.322519063949585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5652/10000, Training Loss: 0.7931509613990784, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8662249445915222, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5653/10000, Training Loss: 0.728582501411438, Training Accuracy: 0.553921568627451, Validation Loss: 0.7499173283576965, Validation Accuracy: 0.5\n",
      "Epoch 5654/10000, Training Loss: 0.677212119102478, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7412312030792236, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5655/10000, Training Loss: 0.7696008086204529, Training Accuracy: 0.5955882352941176, Validation Loss: 1.4824514389038086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5656/10000, Training Loss: 0.7959039807319641, Training Accuracy: 0.5882352941176471, Validation Loss: 1.408591389656067, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5657/10000, Training Loss: 0.8558980822563171, Training Accuracy: 0.5196078431372549, Validation Loss: 1.40652334690094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5658/10000, Training Loss: 0.8281921744346619, Training Accuracy: 0.5367647058823529, Validation Loss: 1.420977234840393, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5659/10000, Training Loss: 0.8466380834579468, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9453228116035461, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5660/10000, Training Loss: 0.6474782228469849, Training Accuracy: 0.6593137254901961, Validation Loss: 1.8562618494033813, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5661/10000, Training Loss: 0.8558769822120667, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7112632393836975, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5662/10000, Training Loss: 0.8137741088867188, Training Accuracy: 0.5808823529411765, Validation Loss: 1.149392008781433, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5663/10000, Training Loss: 0.828843891620636, Training Accuracy: 0.571078431372549, Validation Loss: 0.9881636500358582, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5664/10000, Training Loss: 0.8679518699645996, Training Accuracy: 0.5367647058823529, Validation Loss: 0.9316244721412659, Validation Accuracy: 0.25\n",
      "Epoch 5665/10000, Training Loss: 0.7362188696861267, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8261874318122864, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5666/10000, Training Loss: 0.7257000207901001, Training Accuracy: 0.5441176470588235, Validation Loss: 1.116194725036621, Validation Accuracy: 0.5\n",
      "Epoch 5667/10000, Training Loss: 0.8169383406639099, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7190880179405212, Validation Accuracy: 0.5\n",
      "Epoch 5668/10000, Training Loss: 0.8198603987693787, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9325149655342102, Validation Accuracy: 0.25\n",
      "Epoch 5669/10000, Training Loss: 0.6902726292610168, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7333868145942688, Validation Accuracy: 0.5\n",
      "Epoch 5670/10000, Training Loss: 0.8513109087944031, Training Accuracy: 0.5416666666666666, Validation Loss: 0.9205126166343689, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5671/10000, Training Loss: 0.7509583234786987, Training Accuracy: 0.553921568627451, Validation Loss: 0.866173505783081, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5672/10000, Training Loss: 0.9723962545394897, Training Accuracy: 0.5490196078431373, Validation Loss: 1.2422398328781128, Validation Accuracy: 0.5\n",
      "Epoch 5673/10000, Training Loss: 0.7955562472343445, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9140878319740295, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5674/10000, Training Loss: 0.7053108215332031, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7717875838279724, Validation Accuracy: 0.5\n",
      "Epoch 5675/10000, Training Loss: 0.7388064861297607, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8985101580619812, Validation Accuracy: 0.5\n",
      "Epoch 5676/10000, Training Loss: 0.6922122240066528, Training Accuracy: 0.5661764705882353, Validation Loss: 1.4697953462600708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5677/10000, Training Loss: 0.7154809832572937, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9372019171714783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5678/10000, Training Loss: 0.8805039525032043, Training Accuracy: 0.625, Validation Loss: 0.959783136844635, Validation Accuracy: 0.5\n",
      "Epoch 5679/10000, Training Loss: 0.7346734404563904, Training Accuracy: 0.571078431372549, Validation Loss: 0.6742154955863953, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5680/10000, Training Loss: 0.784765362739563, Training Accuracy: 0.625, Validation Loss: 1.202621340751648, Validation Accuracy: 0.5\n",
      "Epoch 5681/10000, Training Loss: 0.9543614983558655, Training Accuracy: 0.5024509803921569, Validation Loss: 0.7708592414855957, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5682/10000, Training Loss: 0.730251669883728, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8742617964744568, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5683/10000, Training Loss: 0.8290519714355469, Training Accuracy: 0.5784313725490197, Validation Loss: 1.0902763605117798, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5684/10000, Training Loss: 0.8602918982505798, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6615433096885681, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5685/10000, Training Loss: 1.0015358924865723, Training Accuracy: 0.5196078431372549, Validation Loss: 1.197107195854187, Validation Accuracy: 0.5\n",
      "Epoch 5686/10000, Training Loss: 0.6940617561340332, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0551352500915527, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5687/10000, Training Loss: 0.7681183218955994, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9281592965126038, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5688/10000, Training Loss: 0.7896969318389893, Training Accuracy: 0.5784313725490197, Validation Loss: 0.946709394454956, Validation Accuracy: 0.5\n",
      "Epoch 5689/10000, Training Loss: 0.8011949062347412, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7701641917228699, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5690/10000, Training Loss: 0.7130319476127625, Training Accuracy: 0.6372549019607843, Validation Loss: 1.2123602628707886, Validation Accuracy: 0.75\n",
      "Epoch 5691/10000, Training Loss: 0.7782231569290161, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8570530414581299, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5692/10000, Training Loss: 0.8779757618904114, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9667110443115234, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5693/10000, Training Loss: 0.8593776822090149, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8227505087852478, Validation Accuracy: 0.5\n",
      "Epoch 5694/10000, Training Loss: 0.7118303179740906, Training Accuracy: 0.5490196078431373, Validation Loss: 1.0035814046859741, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5695/10000, Training Loss: 0.8393457531929016, Training Accuracy: 0.5808823529411765, Validation Loss: 1.191001296043396, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5696/10000, Training Loss: 0.7296354174613953, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9790646433830261, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5697/10000, Training Loss: 1.1014633178710938, Training Accuracy: 0.5147058823529411, Validation Loss: 0.9225229620933533, Validation Accuracy: 0.5\n",
      "Epoch 5698/10000, Training Loss: 0.9314315915107727, Training Accuracy: 0.5245098039215687, Validation Loss: 1.4183472394943237, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5699/10000, Training Loss: 0.6621745228767395, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8947670459747314, Validation Accuracy: 0.5\n",
      "Epoch 5700/10000, Training Loss: 0.7581247091293335, Training Accuracy: 0.5612745098039216, Validation Loss: 1.4533281326293945, Validation Accuracy: 0.5\n",
      "Epoch 5701/10000, Training Loss: 0.7132805585861206, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7392958998680115, Validation Accuracy: 0.5\n",
      "Epoch 5702/10000, Training Loss: 0.6928754448890686, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7896725535392761, Validation Accuracy: 0.5\n",
      "Epoch 5703/10000, Training Loss: 0.7678875923156738, Training Accuracy: 0.5759803921568627, Validation Loss: 1.290891408920288, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5704/10000, Training Loss: 0.7559276819229126, Training Accuracy: 0.5759803921568627, Validation Loss: 1.413018822669983, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5705/10000, Training Loss: 0.6847845911979675, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7751877307891846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5706/10000, Training Loss: 0.7658121585845947, Training Accuracy: 0.5490196078431373, Validation Loss: 1.175622820854187, Validation Accuracy: 0.25\n",
      "Epoch 5707/10000, Training Loss: 0.6856700778007507, Training Accuracy: 0.6446078431372549, Validation Loss: 1.2603545188903809, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5708/10000, Training Loss: 0.8189489841461182, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7006030082702637, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5709/10000, Training Loss: 0.7974714636802673, Training Accuracy: 0.5392156862745098, Validation Loss: 0.9269173741340637, Validation Accuracy: 0.5\n",
      "Epoch 5710/10000, Training Loss: 0.8738980293273926, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6918623447418213, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5711/10000, Training Loss: 0.7700441479682922, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8476848602294922, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5712/10000, Training Loss: 0.7835376262664795, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8935284614562988, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5713/10000, Training Loss: 0.7899471521377563, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8873338103294373, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5714/10000, Training Loss: 0.7240479588508606, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0892693996429443, Validation Accuracy: 0.5\n",
      "Epoch 5715/10000, Training Loss: 0.728379487991333, Training Accuracy: 0.6004901960784313, Validation Loss: 1.6700600385665894, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5716/10000, Training Loss: 0.9667626023292542, Training Accuracy: 0.5220588235294118, Validation Loss: 0.72428959608078, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5717/10000, Training Loss: 0.7733750343322754, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2482346296310425, Validation Accuracy: 0.25\n",
      "Epoch 5718/10000, Training Loss: 0.7403814196586609, Training Accuracy: 0.6029411764705882, Validation Loss: 1.1151946783065796, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5719/10000, Training Loss: 0.7223930954933167, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7519496083259583, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5720/10000, Training Loss: 0.6679654121398926, Training Accuracy: 0.6740196078431373, Validation Loss: 1.042304277420044, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5721/10000, Training Loss: 0.7158339023590088, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8562290072441101, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5722/10000, Training Loss: 0.7056849598884583, Training Accuracy: 0.5931372549019608, Validation Loss: 1.15308678150177, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5723/10000, Training Loss: 0.6388972997665405, Training Accuracy: 0.6593137254901961, Validation Loss: 0.945854127407074, Validation Accuracy: 0.5\n",
      "Epoch 5724/10000, Training Loss: 0.7179937362670898, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0152500867843628, Validation Accuracy: 0.25\n",
      "Epoch 5725/10000, Training Loss: 0.7297478318214417, Training Accuracy: 0.6348039215686274, Validation Loss: 0.5141273736953735, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5726/10000, Training Loss: 0.8409639000892639, Training Accuracy: 0.5147058823529411, Validation Loss: 1.0216134786605835, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5727/10000, Training Loss: 0.8304225206375122, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6836704611778259, Validation Accuracy: 0.5\n",
      "Epoch 5728/10000, Training Loss: 0.7146516442298889, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7724277377128601, Validation Accuracy: 0.5\n",
      "Epoch 5729/10000, Training Loss: 0.7098198533058167, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9168720841407776, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5730/10000, Training Loss: 0.880886435508728, Training Accuracy: 0.5882352941176471, Validation Loss: 1.0261412858963013, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5731/10000, Training Loss: 0.9127290844917297, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9184558987617493, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5732/10000, Training Loss: 0.8050166368484497, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3145358562469482, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5733/10000, Training Loss: 0.7169907689094543, Training Accuracy: 0.6029411764705882, Validation Loss: 0.851466715335846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5734/10000, Training Loss: 0.8170165419578552, Training Accuracy: 0.5465686274509803, Validation Loss: 1.5512033700942993, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5735/10000, Training Loss: 0.7759431004524231, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0029489994049072, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5736/10000, Training Loss: 0.8564069867134094, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8083653450012207, Validation Accuracy: 0.5\n",
      "Epoch 5737/10000, Training Loss: 0.693185567855835, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8294059634208679, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5738/10000, Training Loss: 0.8573549389839172, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6625195145606995, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5739/10000, Training Loss: 0.8002660274505615, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7434036135673523, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5740/10000, Training Loss: 0.7812666296958923, Training Accuracy: 0.6127450980392157, Validation Loss: 1.3070441484451294, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5741/10000, Training Loss: 0.7263544797897339, Training Accuracy: 0.6176470588235294, Validation Loss: 1.225892186164856, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5742/10000, Training Loss: 0.7927278876304626, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6568682193756104, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5743/10000, Training Loss: 0.6857640743255615, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8978257775306702, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5744/10000, Training Loss: 0.7433478236198425, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8023435473442078, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5745/10000, Training Loss: 0.812989354133606, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6809918880462646, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5746/10000, Training Loss: 0.6785308122634888, Training Accuracy: 0.6617647058823529, Validation Loss: 1.3359025716781616, Validation Accuracy: 0.25\n",
      "Epoch 5747/10000, Training Loss: 0.7579197883605957, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6628074645996094, Validation Accuracy: 0.5\n",
      "Epoch 5748/10000, Training Loss: 0.668178915977478, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8960198760032654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5749/10000, Training Loss: 0.7472237944602966, Training Accuracy: 0.5514705882352942, Validation Loss: 1.5656766891479492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5750/10000, Training Loss: 0.7576617002487183, Training Accuracy: 0.5588235294117647, Validation Loss: 1.029354214668274, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5751/10000, Training Loss: 0.6943734884262085, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9519557356834412, Validation Accuracy: 0.5\n",
      "Epoch 5752/10000, Training Loss: 0.8483230471611023, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7451677918434143, Validation Accuracy: 0.5\n",
      "Epoch 5753/10000, Training Loss: 0.6771966814994812, Training Accuracy: 0.5980392156862745, Validation Loss: 0.69331294298172, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5754/10000, Training Loss: 0.7362885475158691, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7517829537391663, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5755/10000, Training Loss: 0.7223695516586304, Training Accuracy: 0.5735294117647058, Validation Loss: 0.3760594129562378, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5756/10000, Training Loss: 0.7512294054031372, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8077101707458496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5757/10000, Training Loss: 0.7014952301979065, Training Accuracy: 0.6225490196078431, Validation Loss: 1.3056750297546387, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5758/10000, Training Loss: 0.7824906706809998, Training Accuracy: 0.6078431372549019, Validation Loss: 1.350734829902649, Validation Accuracy: 0.5\n",
      "Epoch 5759/10000, Training Loss: 0.7562340497970581, Training Accuracy: 0.6299019607843137, Validation Loss: 1.4346171617507935, Validation Accuracy: 0.25\n",
      "Epoch 5760/10000, Training Loss: 0.6696209907531738, Training Accuracy: 0.6127450980392157, Validation Loss: 0.748866081237793, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5761/10000, Training Loss: 0.7146698236465454, Training Accuracy: 0.6421568627450981, Validation Loss: 1.2866973876953125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5762/10000, Training Loss: 0.8122338652610779, Training Accuracy: 0.553921568627451, Validation Loss: 0.7931655049324036, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5763/10000, Training Loss: 0.7566390633583069, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9025816321372986, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5764/10000, Training Loss: 0.7267556190490723, Training Accuracy: 0.5980392156862745, Validation Loss: 1.3244112730026245, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5765/10000, Training Loss: 0.9493091106414795, Training Accuracy: 0.5245098039215687, Validation Loss: 1.3044289350509644, Validation Accuracy: 0.25\n",
      "Epoch 5766/10000, Training Loss: 0.7119272351264954, Training Accuracy: 0.6151960784313726, Validation Loss: 1.203414797782898, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 5767/10000, Training Loss: 0.7615757584571838, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8403090834617615, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5768/10000, Training Loss: 0.7408338785171509, Training Accuracy: 0.5245098039215687, Validation Loss: 1.0250614881515503, Validation Accuracy: 0.25\n",
      "Epoch 5769/10000, Training Loss: 0.7543507218360901, Training Accuracy: 0.6495098039215687, Validation Loss: 0.4632021486759186, Validation Accuracy: 0.75\n",
      "Epoch 5770/10000, Training Loss: 0.746893584728241, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8900890350341797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5771/10000, Training Loss: 0.6945513486862183, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0125057697296143, Validation Accuracy: 0.25\n",
      "Epoch 5772/10000, Training Loss: 0.9105335474014282, Training Accuracy: 0.5318627450980392, Validation Loss: 1.0921574831008911, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5773/10000, Training Loss: 0.6532037854194641, Training Accuracy: 0.6691176470588235, Validation Loss: 1.1126413345336914, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5774/10000, Training Loss: 0.7187771797180176, Training Accuracy: 0.571078431372549, Validation Loss: 0.8171173930168152, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5775/10000, Training Loss: 0.867007851600647, Training Accuracy: 0.5318627450980392, Validation Loss: 0.8364498615264893, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5776/10000, Training Loss: 0.7592673301696777, Training Accuracy: 0.5808823529411765, Validation Loss: 1.034531831741333, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5777/10000, Training Loss: 0.802736222743988, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7794784903526306, Validation Accuracy: 0.5\n",
      "Epoch 5778/10000, Training Loss: 0.6866931319236755, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0803385972976685, Validation Accuracy: 0.5\n",
      "Epoch 5779/10000, Training Loss: 0.8200526237487793, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6429280638694763, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5780/10000, Training Loss: 0.7371318936347961, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2024120092391968, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5781/10000, Training Loss: 0.6698333024978638, Training Accuracy: 0.625, Validation Loss: 0.7189667820930481, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5782/10000, Training Loss: 0.7540983557701111, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7843215465545654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5783/10000, Training Loss: 0.7531812787055969, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6821978688240051, Validation Accuracy: 0.75\n",
      "Epoch 5784/10000, Training Loss: 0.936227560043335, Training Accuracy: 0.5245098039215687, Validation Loss: 0.7748308777809143, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5785/10000, Training Loss: 0.7764725089073181, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1523762941360474, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5786/10000, Training Loss: 0.7348315715789795, Training Accuracy: 0.6323529411764706, Validation Loss: 1.207053780555725, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5787/10000, Training Loss: 0.6711761355400085, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8875999450683594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5788/10000, Training Loss: 0.6798245906829834, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1128919124603271, Validation Accuracy: 0.25\n",
      "Epoch 5789/10000, Training Loss: 0.7480359673500061, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8973450660705566, Validation Accuracy: 0.5\n",
      "Epoch 5790/10000, Training Loss: 0.6919190883636475, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0760751962661743, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5791/10000, Training Loss: 0.7136781811714172, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7375546097755432, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5792/10000, Training Loss: 0.7390758991241455, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8549301624298096, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5793/10000, Training Loss: 0.7528437972068787, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8552801609039307, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5794/10000, Training Loss: 0.8132115602493286, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6755433082580566, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5795/10000, Training Loss: 0.7575346231460571, Training Accuracy: 0.5759803921568627, Validation Loss: 1.05818510055542, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5796/10000, Training Loss: 0.7767207026481628, Training Accuracy: 0.5245098039215687, Validation Loss: 1.0098294019699097, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5797/10000, Training Loss: 0.8844462633132935, Training Accuracy: 0.5784313725490197, Validation Loss: 0.5607045888900757, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5798/10000, Training Loss: 0.7565045356750488, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7221571803092957, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5799/10000, Training Loss: 0.7744244337081909, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7118098139762878, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5800/10000, Training Loss: 0.9121565818786621, Training Accuracy: 0.5465686274509803, Validation Loss: 1.2398582696914673, Validation Accuracy: 0.5\n",
      "Epoch 5801/10000, Training Loss: 0.6972107291221619, Training Accuracy: 0.678921568627451, Validation Loss: 0.654136598110199, Validation Accuracy: 0.75\n",
      "Epoch 5802/10000, Training Loss: 0.6811681985855103, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6874421238899231, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5803/10000, Training Loss: 0.8088998794555664, Training Accuracy: 0.5955882352941176, Validation Loss: 1.3888139724731445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5804/10000, Training Loss: 0.752856969833374, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7936131954193115, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5805/10000, Training Loss: 0.7422882318496704, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8898599743843079, Validation Accuracy: 0.25\n",
      "Epoch 5806/10000, Training Loss: 0.686205267906189, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7650289535522461, Validation Accuracy: 0.5\n",
      "Epoch 5807/10000, Training Loss: 0.733113169670105, Training Accuracy: 0.6127450980392157, Validation Loss: 1.23918879032135, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5808/10000, Training Loss: 0.7279456853866577, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7928693294525146, Validation Accuracy: 0.5\n",
      "Epoch 5809/10000, Training Loss: 0.735511839389801, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0711129903793335, Validation Accuracy: 0.5\n",
      "Epoch 5810/10000, Training Loss: 0.784250020980835, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1138895750045776, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5811/10000, Training Loss: 0.7057802677154541, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7510053515434265, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5812/10000, Training Loss: 0.8368016481399536, Training Accuracy: 0.5318627450980392, Validation Loss: 0.9202938079833984, Validation Accuracy: 0.25\n",
      "Epoch 5813/10000, Training Loss: 0.7976704835891724, Training Accuracy: 0.5269607843137255, Validation Loss: 0.5140549540519714, Validation Accuracy: 0.75\n",
      "Epoch 5814/10000, Training Loss: 0.706403374671936, Training Accuracy: 0.5808823529411765, Validation Loss: 0.941445529460907, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5815/10000, Training Loss: 0.9030189514160156, Training Accuracy: 0.5024509803921569, Validation Loss: 0.8209450840950012, Validation Accuracy: 0.5\n",
      "Epoch 5816/10000, Training Loss: 0.7432053685188293, Training Accuracy: 0.5931372549019608, Validation Loss: 0.5873748064041138, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5817/10000, Training Loss: 0.7050632238388062, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9110278487205505, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5818/10000, Training Loss: 0.6769895553588867, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0590192079544067, Validation Accuracy: 0.5\n",
      "Epoch 5819/10000, Training Loss: 0.7355989217758179, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7327519059181213, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5820/10000, Training Loss: 0.8038241267204285, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9864374995231628, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5821/10000, Training Loss: 0.7507972717285156, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8692958950996399, Validation Accuracy: 0.5\n",
      "Epoch 5822/10000, Training Loss: 0.7262279391288757, Training Accuracy: 0.6495098039215687, Validation Loss: 1.1932563781738281, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5823/10000, Training Loss: 0.7574083805084229, Training Accuracy: 0.553921568627451, Validation Loss: 1.0482720136642456, Validation Accuracy: 0.5\n",
      "Epoch 5824/10000, Training Loss: 0.7905420064926147, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7975574135780334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5825/10000, Training Loss: 0.7760388851165771, Training Accuracy: 0.5171568627450981, Validation Loss: 0.7684423923492432, Validation Accuracy: 0.5\n",
      "Epoch 5826/10000, Training Loss: 0.7693650722503662, Training Accuracy: 0.49754901960784315, Validation Loss: 0.5919107794761658, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5827/10000, Training Loss: 0.7935521006584167, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7289503216743469, Validation Accuracy: 0.5\n",
      "Epoch 5828/10000, Training Loss: 0.7391239404678345, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8139466643333435, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5829/10000, Training Loss: 0.8254013061523438, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9926133155822754, Validation Accuracy: 0.5\n",
      "Epoch 5830/10000, Training Loss: 0.7331669926643372, Training Accuracy: 0.625, Validation Loss: 0.728476345539093, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5831/10000, Training Loss: 0.8754422664642334, Training Accuracy: 0.5318627450980392, Validation Loss: 0.9928755760192871, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5832/10000, Training Loss: 0.7258355617523193, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7758075594902039, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5833/10000, Training Loss: 0.7536687850952148, Training Accuracy: 0.571078431372549, Validation Loss: 1.056053638458252, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5834/10000, Training Loss: 0.8078892827033997, Training Accuracy: 0.5245098039215687, Validation Loss: 0.9174103140830994, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5835/10000, Training Loss: 0.7490044236183167, Training Accuracy: 0.5588235294117647, Validation Loss: 1.2994301319122314, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5836/10000, Training Loss: 0.7728280425071716, Training Accuracy: 0.6053921568627451, Validation Loss: 1.3743244409561157, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5837/10000, Training Loss: 0.7294159531593323, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7663840651512146, Validation Accuracy: 0.5\n",
      "Epoch 5838/10000, Training Loss: 0.6926941871643066, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8729208111763, Validation Accuracy: 0.5\n",
      "Epoch 5839/10000, Training Loss: 0.7297891974449158, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0630604028701782, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5840/10000, Training Loss: 0.7629485726356506, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9232015013694763, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5841/10000, Training Loss: 0.7566431760787964, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9228181838989258, Validation Accuracy: 0.5\n",
      "Epoch 5842/10000, Training Loss: 0.784843385219574, Training Accuracy: 0.5906862745098039, Validation Loss: 0.974006712436676, Validation Accuracy: 0.5\n",
      "Epoch 5843/10000, Training Loss: 0.6833745241165161, Training Accuracy: 0.6127450980392157, Validation Loss: 1.029353380203247, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5844/10000, Training Loss: 0.7724289894104004, Training Accuracy: 0.5857843137254902, Validation Loss: 1.4754986763000488, Validation Accuracy: 0.5\n",
      "Epoch 5845/10000, Training Loss: 0.6814965009689331, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7786796689033508, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5846/10000, Training Loss: 0.7268996238708496, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7082118988037109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5847/10000, Training Loss: 0.7688985466957092, Training Accuracy: 0.5490196078431373, Validation Loss: 0.8975319862365723, Validation Accuracy: 0.25\n",
      "Epoch 5848/10000, Training Loss: 0.698492705821991, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9912639260292053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5849/10000, Training Loss: 0.6544039845466614, Training Accuracy: 0.696078431372549, Validation Loss: 1.1212025880813599, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5850/10000, Training Loss: 0.6580827236175537, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8270928263664246, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5851/10000, Training Loss: 0.7370394468307495, Training Accuracy: 0.5245098039215687, Validation Loss: 0.6936861872673035, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5852/10000, Training Loss: 0.84828120470047, Training Accuracy: 0.5906862745098039, Validation Loss: 1.259171962738037, Validation Accuracy: 0.5\n",
      "Epoch 5853/10000, Training Loss: 0.8227061629295349, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9299710392951965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5854/10000, Training Loss: 0.7567188739776611, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7656502723693848, Validation Accuracy: 0.5\n",
      "Epoch 5855/10000, Training Loss: 0.8533347845077515, Training Accuracy: 0.5367647058823529, Validation Loss: 0.900824248790741, Validation Accuracy: 0.5\n",
      "Epoch 5856/10000, Training Loss: 0.7421737909317017, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8230016827583313, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5857/10000, Training Loss: 0.6479753851890564, Training Accuracy: 0.6421568627450981, Validation Loss: 1.212167739868164, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5858/10000, Training Loss: 0.8222503662109375, Training Accuracy: 0.625, Validation Loss: 0.7388853430747986, Validation Accuracy: 0.5\n",
      "Epoch 5859/10000, Training Loss: 0.7333239912986755, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8180446624755859, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5860/10000, Training Loss: 0.7660558223724365, Training Accuracy: 0.5196078431372549, Validation Loss: 0.6503967046737671, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5861/10000, Training Loss: 0.67342209815979, Training Accuracy: 0.6495098039215687, Validation Loss: 0.860811710357666, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5862/10000, Training Loss: 0.8603538870811462, Training Accuracy: 0.553921568627451, Validation Loss: 1.1842352151870728, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5863/10000, Training Loss: 0.8400238156318665, Training Accuracy: 0.5122549019607843, Validation Loss: 1.58242666721344, Validation Accuracy: 0.5\n",
      "Epoch 5864/10000, Training Loss: 0.6925389766693115, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9564176201820374, Validation Accuracy: 0.5\n",
      "Epoch 5865/10000, Training Loss: 0.6594969034194946, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1628788709640503, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5866/10000, Training Loss: 0.6925210356712341, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6239657998085022, Validation Accuracy: 0.75\n",
      "Epoch 5867/10000, Training Loss: 0.7192261815071106, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8327825665473938, Validation Accuracy: 0.25\n",
      "Epoch 5868/10000, Training Loss: 0.7751315832138062, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8395664691925049, Validation Accuracy: 0.5\n",
      "Epoch 5869/10000, Training Loss: 0.92984938621521, Training Accuracy: 0.5049019607843137, Validation Loss: 0.8485975861549377, Validation Accuracy: 0.5\n",
      "Epoch 5870/10000, Training Loss: 0.7427515983581543, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8400848507881165, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5871/10000, Training Loss: 0.7400879859924316, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7348305583000183, Validation Accuracy: 0.5\n",
      "Epoch 5872/10000, Training Loss: 0.7367105484008789, Training Accuracy: 0.571078431372549, Validation Loss: 0.903847873210907, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5873/10000, Training Loss: 0.6633048057556152, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9464133381843567, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5874/10000, Training Loss: 0.7381035089492798, Training Accuracy: 0.5833333333333334, Validation Loss: 0.637182354927063, Validation Accuracy: 0.75\n",
      "Epoch 5875/10000, Training Loss: 0.939332127571106, Training Accuracy: 0.5392156862745098, Validation Loss: 1.5044711828231812, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5876/10000, Training Loss: 0.7252762913703918, Training Accuracy: 0.6029411764705882, Validation Loss: 0.688612699508667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5877/10000, Training Loss: 0.7213670611381531, Training Accuracy: 0.5686274509803921, Validation Loss: 0.842923641204834, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5878/10000, Training Loss: 0.7741681933403015, Training Accuracy: 0.5882352941176471, Validation Loss: 1.0196624994277954, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5879/10000, Training Loss: 0.7066507339477539, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7501606941223145, Validation Accuracy: 0.5\n",
      "Epoch 5880/10000, Training Loss: 0.8123615384101868, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0828698873519897, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5881/10000, Training Loss: 0.6901041865348816, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8678906559944153, Validation Accuracy: 0.5\n",
      "Epoch 5882/10000, Training Loss: 0.7753437161445618, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8784060478210449, Validation Accuracy: 0.75\n",
      "Epoch 5883/10000, Training Loss: 0.7842706441879272, Training Accuracy: 0.5220588235294118, Validation Loss: 0.8471498489379883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5884/10000, Training Loss: 0.6755965948104858, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0337584018707275, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5885/10000, Training Loss: 0.6943590044975281, Training Accuracy: 0.6225490196078431, Validation Loss: 0.976900577545166, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5886/10000, Training Loss: 0.7442219853401184, Training Accuracy: 0.6323529411764706, Validation Loss: 1.4207204580307007, Validation Accuracy: 0.5\n",
      "Epoch 5887/10000, Training Loss: 0.7227012515068054, Training Accuracy: 0.5269607843137255, Validation Loss: 1.164401888847351, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5888/10000, Training Loss: 0.7396380305290222, Training Accuracy: 0.5196078431372549, Validation Loss: 0.8621928691864014, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5889/10000, Training Loss: 0.7499127984046936, Training Accuracy: 0.5220588235294118, Validation Loss: 0.9424996376037598, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5890/10000, Training Loss: 0.7335035800933838, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8929576277732849, Validation Accuracy: 0.5\n",
      "Epoch 5891/10000, Training Loss: 0.682321310043335, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7593436241149902, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5892/10000, Training Loss: 0.8716956377029419, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9547863006591797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5893/10000, Training Loss: 0.6984152793884277, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1952303647994995, Validation Accuracy: 0.5\n",
      "Epoch 5894/10000, Training Loss: 0.7089511752128601, Training Accuracy: 0.5980392156862745, Validation Loss: 1.3736387491226196, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5895/10000, Training Loss: 0.6817140579223633, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7987537384033203, Validation Accuracy: 0.5\n",
      "Epoch 5896/10000, Training Loss: 0.7686366438865662, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8581368327140808, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5897/10000, Training Loss: 0.6892682909965515, Training Accuracy: 0.6470588235294118, Validation Loss: 1.1863056421279907, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5898/10000, Training Loss: 0.802237868309021, Training Accuracy: 0.46078431372549017, Validation Loss: 1.1357200145721436, Validation Accuracy: 0.25\n",
      "Epoch 5899/10000, Training Loss: 0.7172079682350159, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7212295532226562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5900/10000, Training Loss: 0.7073121666908264, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2745506763458252, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5901/10000, Training Loss: 0.7766473889350891, Training Accuracy: 0.5343137254901961, Validation Loss: 0.8778902888298035, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5902/10000, Training Loss: 0.6779518723487854, Training Accuracy: 0.6078431372549019, Validation Loss: 1.3142284154891968, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 5903/10000, Training Loss: 0.7465397715568542, Training Accuracy: 0.6274509803921569, Validation Loss: 1.281777024269104, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5904/10000, Training Loss: 0.7129033207893372, Training Accuracy: 0.6127450980392157, Validation Loss: 0.5278117060661316, Validation Accuracy: 0.75\n",
      "Epoch 5905/10000, Training Loss: 0.7400636672973633, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7954884171485901, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5906/10000, Training Loss: 0.7732992768287659, Training Accuracy: 0.5882352941176471, Validation Loss: 1.0497716665267944, Validation Accuracy: 0.5\n",
      "Epoch 5907/10000, Training Loss: 0.790833592414856, Training Accuracy: 0.5147058823529411, Validation Loss: 0.8879036903381348, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5908/10000, Training Loss: 0.7310687899589539, Training Accuracy: 0.6225490196078431, Validation Loss: 1.2303495407104492, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5909/10000, Training Loss: 0.8243948221206665, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9333165287971497, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5910/10000, Training Loss: 0.7521617412567139, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9475302696228027, Validation Accuracy: 0.5\n",
      "Epoch 5911/10000, Training Loss: 0.7996727228164673, Training Accuracy: 0.5147058823529411, Validation Loss: 1.1731730699539185, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5912/10000, Training Loss: 0.7206571102142334, Training Accuracy: 0.571078431372549, Validation Loss: 0.9071481823921204, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5913/10000, Training Loss: 0.6995494961738586, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7342617511749268, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5914/10000, Training Loss: 0.6623086929321289, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6508565545082092, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5915/10000, Training Loss: 0.7697857022285461, Training Accuracy: 0.5612745098039216, Validation Loss: 1.0714952945709229, Validation Accuracy: 0.5\n",
      "Epoch 5916/10000, Training Loss: 0.7221177816390991, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6201189160346985, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5917/10000, Training Loss: 0.6970458626747131, Training Accuracy: 0.6666666666666666, Validation Loss: 2.2027652263641357, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 5918/10000, Training Loss: 0.7900070548057556, Training Accuracy: 0.5, Validation Loss: 0.8228488564491272, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5919/10000, Training Loss: 0.9080909490585327, Training Accuracy: 0.5441176470588235, Validation Loss: 0.740907609462738, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5920/10000, Training Loss: 0.733441174030304, Training Accuracy: 0.5637254901960784, Validation Loss: 0.937561571598053, Validation Accuracy: 0.75\n",
      "Epoch 5921/10000, Training Loss: 0.7761353254318237, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8158600926399231, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5922/10000, Training Loss: 0.734017014503479, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9267446994781494, Validation Accuracy: 0.5\n",
      "Epoch 5923/10000, Training Loss: 0.8096826076507568, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6925734877586365, Validation Accuracy: 0.5\n",
      "Epoch 5924/10000, Training Loss: 0.76888507604599, Training Accuracy: 0.553921568627451, Validation Loss: 0.6035811305046082, Validation Accuracy: 0.75\n",
      "Epoch 5925/10000, Training Loss: 0.6698457598686218, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9302629828453064, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5926/10000, Training Loss: 0.8468313813209534, Training Accuracy: 0.5220588235294118, Validation Loss: 0.9540577530860901, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5927/10000, Training Loss: 0.6741462349891663, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9246887564659119, Validation Accuracy: 0.5\n",
      "Epoch 5928/10000, Training Loss: 0.7124090194702148, Training Accuracy: 0.6127450980392157, Validation Loss: 1.3107861280441284, Validation Accuracy: 0.5\n",
      "Epoch 5929/10000, Training Loss: 0.7270306348800659, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6031981110572815, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5930/10000, Training Loss: 0.806433379650116, Training Accuracy: 0.5073529411764706, Validation Loss: 0.752685010433197, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5931/10000, Training Loss: 0.7273140549659729, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0350619554519653, Validation Accuracy: 0.5\n",
      "Epoch 5932/10000, Training Loss: 0.6538618206977844, Training Accuracy: 0.6593137254901961, Validation Loss: 1.0478659868240356, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5933/10000, Training Loss: 0.621027946472168, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7362980842590332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5934/10000, Training Loss: 0.70191490650177, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7569518685340881, Validation Accuracy: 0.5\n",
      "Epoch 5935/10000, Training Loss: 0.8091955780982971, Training Accuracy: 0.5490196078431373, Validation Loss: 0.8114137649536133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5936/10000, Training Loss: 0.6330574750900269, Training Accuracy: 0.6838235294117647, Validation Loss: 0.8917601704597473, Validation Accuracy: 0.5\n",
      "Epoch 5937/10000, Training Loss: 0.6844716668128967, Training Accuracy: 0.6397058823529411, Validation Loss: 0.65402752161026, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5938/10000, Training Loss: 0.8299352526664734, Training Accuracy: 0.5759803921568627, Validation Loss: 0.985914945602417, Validation Accuracy: 0.5\n",
      "Epoch 5939/10000, Training Loss: 0.6678870916366577, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9481087327003479, Validation Accuracy: 0.25\n",
      "Epoch 5940/10000, Training Loss: 0.7633541226387024, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9286949038505554, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5941/10000, Training Loss: 0.7187616229057312, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7981939315795898, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5942/10000, Training Loss: 0.6968069076538086, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6142532825469971, Validation Accuracy: 0.5\n",
      "Epoch 5943/10000, Training Loss: 0.7790573835372925, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1938976049423218, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5944/10000, Training Loss: 0.8894820213317871, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9242050647735596, Validation Accuracy: 0.25\n",
      "Epoch 5945/10000, Training Loss: 0.7595633864402771, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9383603930473328, Validation Accuracy: 0.5\n",
      "Epoch 5946/10000, Training Loss: 0.7684311270713806, Training Accuracy: 0.571078431372549, Validation Loss: 1.123355746269226, Validation Accuracy: 0.25\n",
      "Epoch 5947/10000, Training Loss: 0.7453785538673401, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9766383171081543, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5948/10000, Training Loss: 0.8451892137527466, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8889704346656799, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5949/10000, Training Loss: 0.8168774843215942, Training Accuracy: 0.6004901960784313, Validation Loss: 1.498276710510254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5950/10000, Training Loss: 0.7183367609977722, Training Accuracy: 0.6053921568627451, Validation Loss: 1.1171581745147705, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 5951/10000, Training Loss: 0.8789781332015991, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2758413553237915, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5952/10000, Training Loss: 0.695570170879364, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9901377558708191, Validation Accuracy: 0.25\n",
      "Epoch 5953/10000, Training Loss: 0.662975549697876, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8571681380271912, Validation Accuracy: 0.5\n",
      "Epoch 5954/10000, Training Loss: 0.7782513499259949, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9326962828636169, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5955/10000, Training Loss: 0.6922355890274048, Training Accuracy: 0.6200980392156863, Validation Loss: 1.120501160621643, Validation Accuracy: 0.5\n",
      "Epoch 5956/10000, Training Loss: 0.6685136556625366, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9011576175689697, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5957/10000, Training Loss: 0.6797832250595093, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9405731558799744, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5958/10000, Training Loss: 0.7649127840995789, Training Accuracy: 0.5122549019607843, Validation Loss: 0.664844274520874, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5959/10000, Training Loss: 0.723608136177063, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8806503415107727, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5960/10000, Training Loss: 0.861860990524292, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9660964012145996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5961/10000, Training Loss: 0.7300952076911926, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8790351748466492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5962/10000, Training Loss: 0.6805323362350464, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8396217823028564, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5963/10000, Training Loss: 0.7285235524177551, Training Accuracy: 0.5955882352941176, Validation Loss: 0.5700402855873108, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 5964/10000, Training Loss: 0.7353568077087402, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6258595585823059, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5965/10000, Training Loss: 0.7294795513153076, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8482949733734131, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5966/10000, Training Loss: 0.7236249446868896, Training Accuracy: 0.6176470588235294, Validation Loss: 1.2463401556015015, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5967/10000, Training Loss: 0.7836145162582397, Training Accuracy: 0.6053921568627451, Validation Loss: 1.19282865524292, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5968/10000, Training Loss: 0.7196779251098633, Training Accuracy: 0.5441176470588235, Validation Loss: 0.8711631298065186, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5969/10000, Training Loss: 0.7865095138549805, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8868263363838196, Validation Accuracy: 0.75\n",
      "Epoch 5970/10000, Training Loss: 0.7062973380088806, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7208716869354248, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5971/10000, Training Loss: 0.727392852306366, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6809613108634949, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5972/10000, Training Loss: 0.687391996383667, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8120965361595154, Validation Accuracy: 0.5\n",
      "Epoch 5973/10000, Training Loss: 0.7423377633094788, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7972010970115662, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5974/10000, Training Loss: 0.679865837097168, Training Accuracy: 0.6813725490196079, Validation Loss: 1.5574407577514648, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5975/10000, Training Loss: 0.7406153082847595, Training Accuracy: 0.6715686274509803, Validation Loss: 1.3539305925369263, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5976/10000, Training Loss: 0.7080674171447754, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7546636462211609, Validation Accuracy: 0.5\n",
      "Epoch 5977/10000, Training Loss: 0.7286769151687622, Training Accuracy: 0.5882352941176471, Validation Loss: 1.3007220029830933, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5978/10000, Training Loss: 0.8491852879524231, Training Accuracy: 0.553921568627451, Validation Loss: 0.8508499264717102, Validation Accuracy: 0.5\n",
      "Epoch 5979/10000, Training Loss: 0.6939149498939514, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7029457092285156, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5980/10000, Training Loss: 0.7742326259613037, Training Accuracy: 0.5269607843137255, Validation Loss: 0.699310302734375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5981/10000, Training Loss: 0.6926047205924988, Training Accuracy: 0.6519607843137255, Validation Loss: 1.2286986112594604, Validation Accuracy: 0.25\n",
      "Epoch 5982/10000, Training Loss: 0.7421420216560364, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0871859788894653, Validation Accuracy: 0.25\n",
      "Epoch 5983/10000, Training Loss: 0.784527063369751, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6036957502365112, Validation Accuracy: 0.25\n",
      "Epoch 5984/10000, Training Loss: 0.7434178590774536, Training Accuracy: 0.5759803921568627, Validation Loss: 1.3819066286087036, Validation Accuracy: 0.5\n",
      "Epoch 5985/10000, Training Loss: 0.6761952042579651, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0378423929214478, Validation Accuracy: 0.5\n",
      "Epoch 5986/10000, Training Loss: 0.7802106738090515, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0642309188842773, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5987/10000, Training Loss: 0.7454349994659424, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8512943387031555, Validation Accuracy: 0.5\n",
      "Epoch 5988/10000, Training Loss: 0.7840375900268555, Training Accuracy: 0.5392156862745098, Validation Loss: 1.1701394319534302, Validation Accuracy: 0.5\n",
      "Epoch 5989/10000, Training Loss: 0.7365464568138123, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7318245768547058, Validation Accuracy: 0.5\n",
      "Epoch 5990/10000, Training Loss: 0.7440882921218872, Training Accuracy: 0.5612745098039216, Validation Loss: 1.233212947845459, Validation Accuracy: 0.25\n",
      "Epoch 5991/10000, Training Loss: 0.7047460079193115, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6314169764518738, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5992/10000, Training Loss: 0.7060150504112244, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9307944178581238, Validation Accuracy: 0.5\n",
      "Epoch 5993/10000, Training Loss: 0.7196998000144958, Training Accuracy: 0.6200980392156863, Validation Loss: 1.3116306066513062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5994/10000, Training Loss: 0.8210267424583435, Training Accuracy: 0.5563725490196079, Validation Loss: 1.3373064994812012, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 5995/10000, Training Loss: 0.7139729261398315, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8839669227600098, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5996/10000, Training Loss: 0.7564785480499268, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6231465935707092, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 5997/10000, Training Loss: 0.9451619386672974, Training Accuracy: 0.4877450980392157, Validation Loss: 0.6862954497337341, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 5998/10000, Training Loss: 0.6906694173812866, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7425708770751953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 5999/10000, Training Loss: 0.7173811793327332, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7789017558097839, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6000/10000, Training Loss: 0.79996657371521, Training Accuracy: 0.5294117647058824, Validation Loss: 0.6926218867301941, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6001/10000, Training Loss: 0.7008289098739624, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8428625464439392, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6002/10000, Training Loss: 0.7550650835037231, Training Accuracy: 0.5196078431372549, Validation Loss: 0.8979983329772949, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6003/10000, Training Loss: 0.8502289056777954, Training Accuracy: 0.571078431372549, Validation Loss: 0.9536025524139404, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6004/10000, Training Loss: 0.6712983250617981, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1294254064559937, Validation Accuracy: 0.25\n",
      "Epoch 6005/10000, Training Loss: 0.7850828766822815, Training Accuracy: 0.5294117647058824, Validation Loss: 0.9212596416473389, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6006/10000, Training Loss: 0.6735197901725769, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8299283385276794, Validation Accuracy: 0.5\n",
      "Epoch 6007/10000, Training Loss: 0.6870989799499512, Training Accuracy: 0.6078431372549019, Validation Loss: 1.1791831254959106, Validation Accuracy: 0.25\n",
      "Epoch 6008/10000, Training Loss: 0.7493861317634583, Training Accuracy: 0.5392156862745098, Validation Loss: 0.7897337079048157, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6009/10000, Training Loss: 0.655788779258728, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8488308787345886, Validation Accuracy: 0.5\n",
      "Epoch 6010/10000, Training Loss: 0.6886302828788757, Training Accuracy: 0.6348039215686274, Validation Loss: 0.685945987701416, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6011/10000, Training Loss: 0.8191651105880737, Training Accuracy: 0.5882352941176471, Validation Loss: 0.848336398601532, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6012/10000, Training Loss: 0.6782323122024536, Training Accuracy: 0.6053921568627451, Validation Loss: 0.631337583065033, Validation Accuracy: 0.5\n",
      "Epoch 6013/10000, Training Loss: 0.7535256147384644, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7353366017341614, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6014/10000, Training Loss: 0.7219346165657043, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0333528518676758, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6015/10000, Training Loss: 0.7022985816001892, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0856088399887085, Validation Accuracy: 0.5\n",
      "Epoch 6016/10000, Training Loss: 0.6867501735687256, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8963542580604553, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6017/10000, Training Loss: 0.7006193995475769, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0846022367477417, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6018/10000, Training Loss: 0.7389361262321472, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6723087430000305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6019/10000, Training Loss: 0.6745170950889587, Training Accuracy: 0.625, Validation Loss: 1.0933847427368164, Validation Accuracy: 0.5\n",
      "Epoch 6020/10000, Training Loss: 0.7490512728691101, Training Accuracy: 0.5637254901960784, Validation Loss: 0.790241003036499, Validation Accuracy: 0.5\n",
      "Epoch 6021/10000, Training Loss: 0.7644445300102234, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8419435024261475, Validation Accuracy: 0.5\n",
      "Epoch 6022/10000, Training Loss: 0.6769422888755798, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7630073428153992, Validation Accuracy: 0.5\n",
      "Epoch 6023/10000, Training Loss: 0.7071173191070557, Training Accuracy: 0.5759803921568627, Validation Loss: 0.5159013271331787, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6024/10000, Training Loss: 0.725066065788269, Training Accuracy: 0.6372549019607843, Validation Loss: 1.1496213674545288, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6025/10000, Training Loss: 0.706539511680603, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7520161271095276, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6026/10000, Training Loss: 0.6803385615348816, Training Accuracy: 0.5980392156862745, Validation Loss: 1.719119906425476, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6027/10000, Training Loss: 0.7054471969604492, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9168073534965515, Validation Accuracy: 0.5\n",
      "Epoch 6028/10000, Training Loss: 0.6885586977005005, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6488803625106812, Validation Accuracy: 0.75\n",
      "Epoch 6029/10000, Training Loss: 0.7015060186386108, Training Accuracy: 0.5392156862745098, Validation Loss: 1.0309510231018066, Validation Accuracy: 0.25\n",
      "Epoch 6030/10000, Training Loss: 0.6698676943778992, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8193852305412292, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6031/10000, Training Loss: 0.6994675397872925, Training Accuracy: 0.6544117647058824, Validation Loss: 1.385370135307312, Validation Accuracy: 0.25\n",
      "Epoch 6032/10000, Training Loss: 0.721782386302948, Training Accuracy: 0.6029411764705882, Validation Loss: 0.876843273639679, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6033/10000, Training Loss: 0.7007942199707031, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6721871495246887, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6034/10000, Training Loss: 0.6824008822441101, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8176661133766174, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6035/10000, Training Loss: 0.6873403191566467, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8503234386444092, Validation Accuracy: 0.5\n",
      "Epoch 6036/10000, Training Loss: 0.8081380128860474, Training Accuracy: 0.5122549019607843, Validation Loss: 0.9363110065460205, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6037/10000, Training Loss: 0.6784390211105347, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8831112384796143, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6038/10000, Training Loss: 0.7563176155090332, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8575570583343506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6039/10000, Training Loss: 0.7425190210342407, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1861518621444702, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6040/10000, Training Loss: 0.675260066986084, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7928152084350586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6041/10000, Training Loss: 0.7294548749923706, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8208145499229431, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6042/10000, Training Loss: 0.6296572685241699, Training Accuracy: 0.6274509803921569, Validation Loss: 1.645246148109436, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6043/10000, Training Loss: 0.7618741989135742, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8669225573539734, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6044/10000, Training Loss: 0.6890761256217957, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8981818556785583, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6045/10000, Training Loss: 0.7180963158607483, Training Accuracy: 0.5931372549019608, Validation Loss: 0.687248945236206, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6046/10000, Training Loss: 0.6684643030166626, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6079915761947632, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6047/10000, Training Loss: 0.6774078011512756, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1432764530181885, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6048/10000, Training Loss: 0.6453097462654114, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6458213329315186, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6049/10000, Training Loss: 0.648013174533844, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6036736965179443, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6050/10000, Training Loss: 0.7339437007904053, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6486709713935852, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6051/10000, Training Loss: 0.7979531288146973, Training Accuracy: 0.5294117647058824, Validation Loss: 0.8997153639793396, Validation Accuracy: 0.5\n",
      "Epoch 6052/10000, Training Loss: 0.7075276970863342, Training Accuracy: 0.5588235294117647, Validation Loss: 1.022802710533142, Validation Accuracy: 0.25\n",
      "Epoch 6053/10000, Training Loss: 0.8817811608314514, Training Accuracy: 0.5220588235294118, Validation Loss: 1.2108830213546753, Validation Accuracy: 0.25\n",
      "Epoch 6054/10000, Training Loss: 0.7626097202301025, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9952784180641174, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6055/10000, Training Loss: 0.7784854173660278, Training Accuracy: 0.5294117647058824, Validation Loss: 0.6838536262512207, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6056/10000, Training Loss: 0.6623735427856445, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6165062189102173, Validation Accuracy: 0.75\n",
      "Epoch 6057/10000, Training Loss: 0.6266592144966125, Training Accuracy: 0.6862745098039216, Validation Loss: 1.707523226737976, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6058/10000, Training Loss: 0.7357347011566162, Training Accuracy: 0.5588235294117647, Validation Loss: 0.6907162666320801, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6059/10000, Training Loss: 0.7442107796669006, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9055073857307434, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6060/10000, Training Loss: 0.7032718062400818, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9567155838012695, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6061/10000, Training Loss: 0.7106847763061523, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6090602278709412, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6062/10000, Training Loss: 0.6826497316360474, Training Accuracy: 0.6078431372549019, Validation Loss: 1.1862188577651978, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6063/10000, Training Loss: 0.7660151720046997, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0626236200332642, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6064/10000, Training Loss: 0.7343317866325378, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8274364471435547, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6065/10000, Training Loss: 0.8377454876899719, Training Accuracy: 0.4950980392156863, Validation Loss: 0.9454655647277832, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6066/10000, Training Loss: 0.7331234812736511, Training Accuracy: 0.5784313725490197, Validation Loss: 0.923225462436676, Validation Accuracy: 0.5\n",
      "Epoch 6067/10000, Training Loss: 0.6947939395904541, Training Accuracy: 0.5784313725490197, Validation Loss: 0.595167338848114, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6068/10000, Training Loss: 0.701602578163147, Training Accuracy: 0.5294117647058824, Validation Loss: 0.6111692786216736, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6069/10000, Training Loss: 0.6521415114402771, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8153142333030701, Validation Accuracy: 0.5\n",
      "Epoch 6070/10000, Training Loss: 0.6242910027503967, Training Accuracy: 0.6323529411764706, Validation Loss: 1.001611590385437, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6071/10000, Training Loss: 0.6444438695907593, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8107402324676514, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6072/10000, Training Loss: 0.7325023412704468, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8146221041679382, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6073/10000, Training Loss: 0.7495747804641724, Training Accuracy: 0.5392156862745098, Validation Loss: 2.5412018299102783, Validation Accuracy: 0.25\n",
      "Epoch 6074/10000, Training Loss: 0.7416574358940125, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9936169981956482, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6075/10000, Training Loss: 0.6692782640457153, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7401767373085022, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6076/10000, Training Loss: 0.6891329884529114, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8232272267341614, Validation Accuracy: 0.5\n",
      "Epoch 6077/10000, Training Loss: 0.7411789894104004, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9336838126182556, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6078/10000, Training Loss: 0.7283987402915955, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6499255299568176, Validation Accuracy: 0.5\n",
      "Epoch 6079/10000, Training Loss: 0.633704662322998, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9990077614784241, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6080/10000, Training Loss: 0.7031473517417908, Training Accuracy: 0.5661764705882353, Validation Loss: 0.928946316242218, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6081/10000, Training Loss: 0.7704654932022095, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8353106379508972, Validation Accuracy: 0.5\n",
      "Epoch 6082/10000, Training Loss: 0.7080157399177551, Training Accuracy: 0.5784313725490197, Validation Loss: 0.5944845080375671, Validation Accuracy: 0.5\n",
      "Epoch 6083/10000, Training Loss: 0.6382240056991577, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0144766569137573, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6084/10000, Training Loss: 0.7565101385116577, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8700473308563232, Validation Accuracy: 0.5\n",
      "Epoch 6085/10000, Training Loss: 0.7951657176017761, Training Accuracy: 0.5441176470588235, Validation Loss: 2.0786631107330322, Validation Accuracy: 0.5\n",
      "Epoch 6086/10000, Training Loss: 0.7723655104637146, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7186091542243958, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6087/10000, Training Loss: 0.6816120743751526, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9540197849273682, Validation Accuracy: 0.5\n",
      "Epoch 6088/10000, Training Loss: 0.7461714148521423, Training Accuracy: 0.5588235294117647, Validation Loss: 0.5054534077644348, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6089/10000, Training Loss: 0.7869929671287537, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6959152221679688, Validation Accuracy: 0.5\n",
      "Epoch 6090/10000, Training Loss: 0.6816133260726929, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0524919033050537, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 6091/10000, Training Loss: 0.7000709176063538, Training Accuracy: 0.5392156862745098, Validation Loss: 0.9164137244224548, Validation Accuracy: 0.25\n",
      "Epoch 6092/10000, Training Loss: 0.7775676250457764, Training Accuracy: 0.5245098039215687, Validation Loss: 1.364186406135559, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6093/10000, Training Loss: 0.694005012512207, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8301439881324768, Validation Accuracy: 0.5\n",
      "Epoch 6094/10000, Training Loss: 0.7544903755187988, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7035725116729736, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6095/10000, Training Loss: 0.6939421892166138, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7138494849205017, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6096/10000, Training Loss: 0.6873561143875122, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7010164856910706, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6097/10000, Training Loss: 0.6407930254936218, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6923985481262207, Validation Accuracy: 0.5\n",
      "Epoch 6098/10000, Training Loss: 0.6914118528366089, Training Accuracy: 0.553921568627451, Validation Loss: 0.5534418225288391, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6099/10000, Training Loss: 0.6978642344474792, Training Accuracy: 0.5661764705882353, Validation Loss: 0.686450183391571, Validation Accuracy: 0.75\n",
      "Epoch 6100/10000, Training Loss: 0.7576329708099365, Training Accuracy: 0.5269607843137255, Validation Loss: 0.5975921154022217, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6101/10000, Training Loss: 0.6597261428833008, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7297560572624207, Validation Accuracy: 0.5\n",
      "Epoch 6102/10000, Training Loss: 0.8223325610160828, Training Accuracy: 0.553921568627451, Validation Loss: 1.3388515710830688, Validation Accuracy: 0.25\n",
      "Epoch 6103/10000, Training Loss: 0.7096179127693176, Training Accuracy: 0.5441176470588235, Validation Loss: 0.9346068501472473, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6104/10000, Training Loss: 0.6520345211029053, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7477735877037048, Validation Accuracy: 0.5\n",
      "Epoch 6105/10000, Training Loss: 0.6788849830627441, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7044662833213806, Validation Accuracy: 0.5\n",
      "Epoch 6106/10000, Training Loss: 0.7265763282775879, Training Accuracy: 0.5490196078431373, Validation Loss: 0.690838098526001, Validation Accuracy: 0.5\n",
      "Epoch 6107/10000, Training Loss: 0.6833081841468811, Training Accuracy: 0.6029411764705882, Validation Loss: 1.1385663747787476, Validation Accuracy: 0.5\n",
      "Epoch 6108/10000, Training Loss: 0.7251849174499512, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6621472239494324, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6109/10000, Training Loss: 0.6786215305328369, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6105219721794128, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6110/10000, Training Loss: 0.6667945981025696, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0011893510818481, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6111/10000, Training Loss: 0.6961186528205872, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6937150955200195, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6112/10000, Training Loss: 0.677400529384613, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9139122366905212, Validation Accuracy: 0.5\n",
      "Epoch 6113/10000, Training Loss: 0.7484580874443054, Training Accuracy: 0.5367647058823529, Validation Loss: 0.5445079207420349, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6114/10000, Training Loss: 0.7901729345321655, Training Accuracy: 0.6053921568627451, Validation Loss: 1.3247114419937134, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6115/10000, Training Loss: 0.7161774635314941, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0061194896697998, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6116/10000, Training Loss: 0.7779983878135681, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7873684763908386, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6117/10000, Training Loss: 0.7190940976142883, Training Accuracy: 0.5906862745098039, Validation Loss: 0.628191351890564, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6118/10000, Training Loss: 0.7164896130561829, Training Accuracy: 0.625, Validation Loss: 0.8297517895698547, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6119/10000, Training Loss: 0.7541054487228394, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8931165337562561, Validation Accuracy: 0.5\n",
      "Epoch 6120/10000, Training Loss: 0.6702881455421448, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6540437340736389, Validation Accuracy: 0.75\n",
      "Epoch 6121/10000, Training Loss: 0.7111608982086182, Training Accuracy: 0.5588235294117647, Validation Loss: 0.9395978450775146, Validation Accuracy: 0.5\n",
      "Epoch 6122/10000, Training Loss: 0.6559613347053528, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6588223576545715, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6123/10000, Training Loss: 0.68001788854599, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7773950695991516, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6124/10000, Training Loss: 0.7292230725288391, Training Accuracy: 0.5784313725490197, Validation Loss: 1.2850183248519897, Validation Accuracy: 0.25\n",
      "Epoch 6125/10000, Training Loss: 0.7232571840286255, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8423154354095459, Validation Accuracy: 0.5\n",
      "Epoch 6126/10000, Training Loss: 0.6875750422477722, Training Accuracy: 0.678921568627451, Validation Loss: 1.0641275644302368, Validation Accuracy: 0.5\n",
      "Epoch 6127/10000, Training Loss: 0.7216261029243469, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6762135624885559, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6128/10000, Training Loss: 0.702744722366333, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7592975497245789, Validation Accuracy: 0.5\n",
      "Epoch 6129/10000, Training Loss: 0.7142355442047119, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6401077508926392, Validation Accuracy: 0.5\n",
      "Epoch 6130/10000, Training Loss: 0.689454972743988, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7570202946662903, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6131/10000, Training Loss: 0.7240104079246521, Training Accuracy: 0.5490196078431373, Validation Loss: 0.8146927356719971, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6132/10000, Training Loss: 0.7047288417816162, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8123204112052917, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6133/10000, Training Loss: 0.6980909705162048, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7989592552185059, Validation Accuracy: 0.5\n",
      "Epoch 6134/10000, Training Loss: 0.6315113306045532, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8813027739524841, Validation Accuracy: 0.5\n",
      "Epoch 6135/10000, Training Loss: 0.7142210602760315, Training Accuracy: 0.6274509803921569, Validation Loss: 0.5373315215110779, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6136/10000, Training Loss: 0.7751023769378662, Training Accuracy: 0.5686274509803921, Validation Loss: 1.05663001537323, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6137/10000, Training Loss: 0.7414113879203796, Training Accuracy: 0.5612745098039216, Validation Loss: 1.0480340719223022, Validation Accuracy: 0.5\n",
      "Epoch 6138/10000, Training Loss: 0.7494298219680786, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9007853865623474, Validation Accuracy: 0.5\n",
      "Epoch 6139/10000, Training Loss: 0.7041721940040588, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9156262278556824, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6140/10000, Training Loss: 0.6952029466629028, Training Accuracy: 0.6151960784313726, Validation Loss: 1.5883684158325195, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6141/10000, Training Loss: 0.6953985095024109, Training Accuracy: 0.5735294117647058, Validation Loss: 0.5961101651191711, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6142/10000, Training Loss: 0.7235480546951294, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8921976685523987, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6143/10000, Training Loss: 0.7205591201782227, Training Accuracy: 0.571078431372549, Validation Loss: 0.8671414852142334, Validation Accuracy: 0.5\n",
      "Epoch 6144/10000, Training Loss: 0.7018097639083862, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7608437538146973, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6145/10000, Training Loss: 0.6960877776145935, Training Accuracy: 0.5490196078431373, Validation Loss: 1.0244005918502808, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6146/10000, Training Loss: 0.6550213098526001, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0904278755187988, Validation Accuracy: 0.25\n",
      "Epoch 6147/10000, Training Loss: 0.710692286491394, Training Accuracy: 0.5245098039215687, Validation Loss: 1.0718015432357788, Validation Accuracy: 0.5\n",
      "Epoch 6148/10000, Training Loss: 0.7166524529457092, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0478934049606323, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6149/10000, Training Loss: 0.8693715333938599, Training Accuracy: 0.5220588235294118, Validation Loss: 0.752476692199707, Validation Accuracy: 0.5\n",
      "Epoch 6150/10000, Training Loss: 0.7122350931167603, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8316516876220703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6151/10000, Training Loss: 0.7417138814926147, Training Accuracy: 0.6372549019607843, Validation Loss: 1.1119128465652466, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6152/10000, Training Loss: 0.7108476161956787, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7165107727050781, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6153/10000, Training Loss: 0.7871241569519043, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8125007748603821, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6154/10000, Training Loss: 0.6177041530609131, Training Accuracy: 0.678921568627451, Validation Loss: 0.8089749217033386, Validation Accuracy: 0.5\n",
      "Epoch 6155/10000, Training Loss: 0.7195989489555359, Training Accuracy: 0.625, Validation Loss: 1.3621753454208374, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6156/10000, Training Loss: 0.7274035215377808, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8561124205589294, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6157/10000, Training Loss: 0.754732608795166, Training Accuracy: 0.5514705882352942, Validation Loss: 1.2013064622879028, Validation Accuracy: 0.25\n",
      "Epoch 6158/10000, Training Loss: 0.7189950942993164, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9482672810554504, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6159/10000, Training Loss: 0.7312586307525635, Training Accuracy: 0.49754901960784315, Validation Loss: 0.7781382203102112, Validation Accuracy: 0.5\n",
      "Epoch 6160/10000, Training Loss: 0.6844778656959534, Training Accuracy: 0.5588235294117647, Validation Loss: 0.875600278377533, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6161/10000, Training Loss: 0.7061173915863037, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9456622004508972, Validation Accuracy: 0.25\n",
      "Epoch 6162/10000, Training Loss: 0.6737489104270935, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7613134384155273, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6163/10000, Training Loss: 0.776908278465271, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6664748787879944, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6164/10000, Training Loss: 0.7183453440666199, Training Accuracy: 0.6200980392156863, Validation Loss: 1.09328293800354, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6165/10000, Training Loss: 0.6221670508384705, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8676335215568542, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6166/10000, Training Loss: 0.711814284324646, Training Accuracy: 0.553921568627451, Validation Loss: 0.6613442897796631, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6167/10000, Training Loss: 0.6691041588783264, Training Accuracy: 0.5686274509803921, Validation Loss: 1.2900604009628296, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6168/10000, Training Loss: 0.693071722984314, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6359585523605347, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6169/10000, Training Loss: 0.6731089949607849, Training Accuracy: 0.5686274509803921, Validation Loss: 0.5663341879844666, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6170/10000, Training Loss: 0.6884492635726929, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0142885446548462, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6171/10000, Training Loss: 0.6937799453735352, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7803726196289062, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6172/10000, Training Loss: 0.771831750869751, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9216415882110596, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6173/10000, Training Loss: 0.6771973371505737, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7346946597099304, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6174/10000, Training Loss: 0.6405104994773865, Training Accuracy: 0.6470588235294118, Validation Loss: 0.739715039730072, Validation Accuracy: 0.5\n",
      "Epoch 6175/10000, Training Loss: 0.8052181005477905, Training Accuracy: 0.47794117647058826, Validation Loss: 0.9446815848350525, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6176/10000, Training Loss: 0.7068821787834167, Training Accuracy: 0.5808823529411765, Validation Loss: 1.0414899587631226, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6177/10000, Training Loss: 0.7876928448677063, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0125336647033691, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6178/10000, Training Loss: 0.7662301659584045, Training Accuracy: 0.5343137254901961, Validation Loss: 0.8547152876853943, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6179/10000, Training Loss: 0.7442614436149597, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8114454746246338, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6180/10000, Training Loss: 0.7756949067115784, Training Accuracy: 0.5343137254901961, Validation Loss: 0.8875297904014587, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6181/10000, Training Loss: 0.6657611727714539, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9254403114318848, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6182/10000, Training Loss: 0.6793568730354309, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9672064781188965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6183/10000, Training Loss: 0.7095360159873962, Training Accuracy: 0.5122549019607843, Validation Loss: 0.8008823394775391, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6184/10000, Training Loss: 0.7553939819335938, Training Accuracy: 0.5637254901960784, Validation Loss: 0.5917791724205017, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6185/10000, Training Loss: 0.6945536732673645, Training Accuracy: 0.6200980392156863, Validation Loss: 1.3564029932022095, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6186/10000, Training Loss: 0.7220554947853088, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7945497035980225, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6187/10000, Training Loss: 0.7192854881286621, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9137818217277527, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6188/10000, Training Loss: 0.6636838912963867, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9017185568809509, Validation Accuracy: 0.75\n",
      "Epoch 6189/10000, Training Loss: 0.7933816313743591, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7345669269561768, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6190/10000, Training Loss: 0.7428218126296997, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7750998139381409, Validation Accuracy: 0.5\n",
      "Epoch 6191/10000, Training Loss: 0.8207545280456543, Training Accuracy: 0.5931372549019608, Validation Loss: 1.195874571800232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6192/10000, Training Loss: 0.6681596636772156, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7811477184295654, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6193/10000, Training Loss: 0.7196263074874878, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7635071873664856, Validation Accuracy: 0.5\n",
      "Epoch 6194/10000, Training Loss: 0.7264120578765869, Training Accuracy: 0.5098039215686274, Validation Loss: 0.7609308362007141, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6195/10000, Training Loss: 0.7336093783378601, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6264581084251404, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6196/10000, Training Loss: 0.7559337019920349, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7966877818107605, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6197/10000, Training Loss: 0.6411992311477661, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7768551707267761, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6198/10000, Training Loss: 0.7237482070922852, Training Accuracy: 0.5367647058823529, Validation Loss: 0.7206920981407166, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6199/10000, Training Loss: 0.6726620197296143, Training Accuracy: 0.6323529411764706, Validation Loss: 0.787475049495697, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6200/10000, Training Loss: 0.6973267197608948, Training Accuracy: 0.5269607843137255, Validation Loss: 0.7230052947998047, Validation Accuracy: 0.5\n",
      "Epoch 6201/10000, Training Loss: 0.7797037959098816, Training Accuracy: 0.5416666666666666, Validation Loss: 1.0847123861312866, Validation Accuracy: 0.25\n",
      "Epoch 6202/10000, Training Loss: 0.75417560338974, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9023509621620178, Validation Accuracy: 0.25\n",
      "Epoch 6203/10000, Training Loss: 0.6682469248771667, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9598074555397034, Validation Accuracy: 0.5\n",
      "Epoch 6204/10000, Training Loss: 0.727323591709137, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8882076740264893, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6205/10000, Training Loss: 0.7175372242927551, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9712872505187988, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6206/10000, Training Loss: 0.712394118309021, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8336586356163025, Validation Accuracy: 0.75\n",
      "Epoch 6207/10000, Training Loss: 0.7168984413146973, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8770197033882141, Validation Accuracy: 0.5\n",
      "Epoch 6208/10000, Training Loss: 0.6490811109542847, Training Accuracy: 0.6470588235294118, Validation Loss: 1.09442138671875, Validation Accuracy: 0.5\n",
      "Epoch 6209/10000, Training Loss: 0.775162935256958, Training Accuracy: 0.5122549019607843, Validation Loss: 0.6523329615592957, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6210/10000, Training Loss: 0.6676272749900818, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7051234841346741, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6211/10000, Training Loss: 0.72974693775177, Training Accuracy: 0.5196078431372549, Validation Loss: 0.9555007815361023, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6212/10000, Training Loss: 0.6735387444496155, Training Accuracy: 0.5294117647058824, Validation Loss: 0.7570275664329529, Validation Accuracy: 0.25\n",
      "Epoch 6213/10000, Training Loss: 0.7184242606163025, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7724363803863525, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6214/10000, Training Loss: 0.6831632256507874, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8542394638061523, Validation Accuracy: 0.5\n",
      "Epoch 6215/10000, Training Loss: 0.704205334186554, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6259951591491699, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6216/10000, Training Loss: 0.631646990776062, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9857147336006165, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6217/10000, Training Loss: 0.7639848589897156, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9621925950050354, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6218/10000, Training Loss: 0.6796814203262329, Training Accuracy: 0.553921568627451, Validation Loss: 0.6844590306282043, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6219/10000, Training Loss: 0.7222946286201477, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7050784230232239, Validation Accuracy: 0.5\n",
      "Epoch 6220/10000, Training Loss: 0.6465848088264465, Training Accuracy: 0.6176470588235294, Validation Loss: 0.715385913848877, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6221/10000, Training Loss: 0.6323138475418091, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0642012357711792, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6222/10000, Training Loss: 0.6185449957847595, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0525785684585571, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6223/10000, Training Loss: 0.6637876629829407, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9660061001777649, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6224/10000, Training Loss: 0.6747629046440125, Training Accuracy: 0.5980392156862745, Validation Loss: 0.829268217086792, Validation Accuracy: 0.5\n",
      "Epoch 6225/10000, Training Loss: 0.7819228768348694, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8741629123687744, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6226/10000, Training Loss: 0.6478861570358276, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1421713829040527, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6227/10000, Training Loss: 0.6876951456069946, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1323117017745972, Validation Accuracy: 0.25\n",
      "Epoch 6228/10000, Training Loss: 0.7336130142211914, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9401093125343323, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6229/10000, Training Loss: 0.706041693687439, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8513180613517761, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6230/10000, Training Loss: 0.7737720012664795, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7999023795127869, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6231/10000, Training Loss: 0.7517655491828918, Training Accuracy: 0.5784313725490197, Validation Loss: 0.5598986744880676, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6232/10000, Training Loss: 0.6592665910720825, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8607697486877441, Validation Accuracy: 0.5\n",
      "Epoch 6233/10000, Training Loss: 0.685482919216156, Training Accuracy: 0.5906862745098039, Validation Loss: 1.2432094812393188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6234/10000, Training Loss: 0.6765156388282776, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7366644740104675, Validation Accuracy: 0.5\n",
      "Epoch 6235/10000, Training Loss: 0.7255642414093018, Training Accuracy: 0.5735294117647058, Validation Loss: 0.926048219203949, Validation Accuracy: 0.5\n",
      "Epoch 6236/10000, Training Loss: 0.6944658756256104, Training Accuracy: 0.5906862745098039, Validation Loss: 1.3039586544036865, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6237/10000, Training Loss: 0.6664994359016418, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9172235131263733, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6238/10000, Training Loss: 0.7226201891899109, Training Accuracy: 0.5318627450980392, Validation Loss: 0.8871954083442688, Validation Accuracy: 0.5\n",
      "Epoch 6239/10000, Training Loss: 0.6402144432067871, Training Accuracy: 0.625, Validation Loss: 0.7444880604743958, Validation Accuracy: 0.5\n",
      "Epoch 6240/10000, Training Loss: 0.7129100561141968, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0679582357406616, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6241/10000, Training Loss: 0.7636788487434387, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7005966305732727, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6242/10000, Training Loss: 0.6536218523979187, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8021480441093445, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6243/10000, Training Loss: 0.6226590275764465, Training Accuracy: 0.6813725490196079, Validation Loss: 1.0302919149398804, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6244/10000, Training Loss: 0.7086407542228699, Training Accuracy: 0.571078431372549, Validation Loss: 0.735156774520874, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6245/10000, Training Loss: 0.7159934639930725, Training Accuracy: 0.5171568627450981, Validation Loss: 0.7046132683753967, Validation Accuracy: 0.5\n",
      "Epoch 6246/10000, Training Loss: 0.6792107224464417, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7906398177146912, Validation Accuracy: 0.5\n",
      "Epoch 6247/10000, Training Loss: 0.7521620392799377, Training Accuracy: 0.5122549019607843, Validation Loss: 0.8522722125053406, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6248/10000, Training Loss: 0.7232835292816162, Training Accuracy: 0.5514705882352942, Validation Loss: 1.0324078798294067, Validation Accuracy: 0.5\n",
      "Epoch 6249/10000, Training Loss: 0.7200716733932495, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9227030873298645, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6250/10000, Training Loss: 0.6560014486312866, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9044803977012634, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6251/10000, Training Loss: 0.7179567813873291, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9292581081390381, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6252/10000, Training Loss: 0.7424653172492981, Training Accuracy: 0.571078431372549, Validation Loss: 1.0419957637786865, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6253/10000, Training Loss: 0.7110191583633423, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7230165600776672, Validation Accuracy: 0.75\n",
      "Epoch 6254/10000, Training Loss: 0.6666165590286255, Training Accuracy: 0.5784313725490197, Validation Loss: 1.121599793434143, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6255/10000, Training Loss: 0.7058437466621399, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7773520946502686, Validation Accuracy: 0.25\n",
      "Epoch 6256/10000, Training Loss: 0.637100875377655, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9109060168266296, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6257/10000, Training Loss: 0.672818124294281, Training Accuracy: 0.6274509803921569, Validation Loss: 0.879661500453949, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6258/10000, Training Loss: 0.7346335649490356, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9223101139068604, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6259/10000, Training Loss: 0.769940972328186, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7175186276435852, Validation Accuracy: 0.5\n",
      "Epoch 6260/10000, Training Loss: 0.6643726229667664, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7963352799415588, Validation Accuracy: 0.5\n",
      "Epoch 6261/10000, Training Loss: 0.7153259515762329, Training Accuracy: 0.5980392156862745, Validation Loss: 0.807553768157959, Validation Accuracy: 0.25\n",
      "Epoch 6262/10000, Training Loss: 0.7124364972114563, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6040787100791931, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6263/10000, Training Loss: 0.7005159258842468, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9654156565666199, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6264/10000, Training Loss: 0.7104538083076477, Training Accuracy: 0.5808823529411765, Validation Loss: 1.2872692346572876, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6265/10000, Training Loss: 0.6683740019798279, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8856420516967773, Validation Accuracy: 0.5\n",
      "Epoch 6266/10000, Training Loss: 0.6886993646621704, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7490012645721436, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6267/10000, Training Loss: 0.7122235894203186, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7020835876464844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6268/10000, Training Loss: 0.7291256785392761, Training Accuracy: 0.6519607843137255, Validation Loss: 1.4460158348083496, Validation Accuracy: 0.25\n",
      "Epoch 6269/10000, Training Loss: 0.6459094285964966, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7311487793922424, Validation Accuracy: 0.5\n",
      "Epoch 6270/10000, Training Loss: 0.6058268547058105, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6493903994560242, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6271/10000, Training Loss: 0.6902111172676086, Training Accuracy: 0.6299019607843137, Validation Loss: 1.399733066558838, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6272/10000, Training Loss: 0.676743745803833, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7883191108703613, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6273/10000, Training Loss: 0.7116298079490662, Training Accuracy: 0.5367647058823529, Validation Loss: 0.5391779541969299, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6274/10000, Training Loss: 0.6881956458091736, Training Accuracy: 0.6127450980392157, Validation Loss: 0.680863618850708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6275/10000, Training Loss: 0.7008059024810791, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6646848320960999, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6276/10000, Training Loss: 0.7639037370681763, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8343920707702637, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6277/10000, Training Loss: 0.6598012447357178, Training Accuracy: 0.6740196078431373, Validation Loss: 0.853749692440033, Validation Accuracy: 0.5\n",
      "Epoch 6278/10000, Training Loss: 0.662598192691803, Training Accuracy: 0.5955882352941176, Validation Loss: 0.688447892665863, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6279/10000, Training Loss: 0.7105413675308228, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1243317127227783, Validation Accuracy: 0.5\n",
      "Epoch 6280/10000, Training Loss: 0.6528638005256653, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7362815737724304, Validation Accuracy: 0.5\n",
      "Epoch 6281/10000, Training Loss: 0.7008161544799805, Training Accuracy: 0.5661764705882353, Validation Loss: 0.712742805480957, Validation Accuracy: 0.5\n",
      "Epoch 6282/10000, Training Loss: 0.6890842914581299, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9798205494880676, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6283/10000, Training Loss: 0.7697672843933105, Training Accuracy: 0.5147058823529411, Validation Loss: 0.6449446082115173, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6284/10000, Training Loss: 0.6530857682228088, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9099302887916565, Validation Accuracy: 0.5\n",
      "Epoch 6285/10000, Training Loss: 0.6777573227882385, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8626019954681396, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6286/10000, Training Loss: 0.7244011163711548, Training Accuracy: 0.5122549019607843, Validation Loss: 0.8931750655174255, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6287/10000, Training Loss: 0.6576693058013916, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8790772557258606, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6288/10000, Training Loss: 0.7129746079444885, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8463096618652344, Validation Accuracy: 0.5\n",
      "Epoch 6289/10000, Training Loss: 0.67974454164505, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6384536027908325, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6290/10000, Training Loss: 0.6421748399734497, Training Accuracy: 0.6593137254901961, Validation Loss: 1.026664137840271, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6291/10000, Training Loss: 0.7356270551681519, Training Accuracy: 0.571078431372549, Validation Loss: 0.7621287703514099, Validation Accuracy: 0.5\n",
      "Epoch 6292/10000, Training Loss: 0.6534103751182556, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7461768984794617, Validation Accuracy: 0.5\n",
      "Epoch 6293/10000, Training Loss: 0.7878789901733398, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0651766061782837, Validation Accuracy: 0.5\n",
      "Epoch 6294/10000, Training Loss: 0.6706790328025818, Training Accuracy: 0.6593137254901961, Validation Loss: 1.491485595703125, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6295/10000, Training Loss: 0.6945783495903015, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7258674502372742, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6296/10000, Training Loss: 0.7249539494514465, Training Accuracy: 0.5759803921568627, Validation Loss: 0.9141060709953308, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6297/10000, Training Loss: 0.6856414079666138, Training Accuracy: 0.5833333333333334, Validation Loss: 0.5597939491271973, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6298/10000, Training Loss: 0.6556991338729858, Training Accuracy: 0.5980392156862745, Validation Loss: 0.933336079120636, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6299/10000, Training Loss: 0.7196954488754272, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8341218829154968, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6300/10000, Training Loss: 0.67333984375, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0856876373291016, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6301/10000, Training Loss: 0.7263932824134827, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7576878070831299, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6302/10000, Training Loss: 0.6569616198539734, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6972053647041321, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6303/10000, Training Loss: 0.7075626850128174, Training Accuracy: 0.553921568627451, Validation Loss: 0.7504162192344666, Validation Accuracy: 0.5\n",
      "Epoch 6304/10000, Training Loss: 0.6558867692947388, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7498014569282532, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6305/10000, Training Loss: 0.6582034230232239, Training Accuracy: 0.6397058823529411, Validation Loss: 1.048177719116211, Validation Accuracy: 0.75\n",
      "Epoch 6306/10000, Training Loss: 0.7025076150894165, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9533879160881042, Validation Accuracy: 0.5\n",
      "Epoch 6307/10000, Training Loss: 0.6662675738334656, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8921210169792175, Validation Accuracy: 0.5\n",
      "Epoch 6308/10000, Training Loss: 0.6317258477210999, Training Accuracy: 0.7009803921568627, Validation Loss: 1.5259909629821777, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6309/10000, Training Loss: 0.6933425664901733, Training Accuracy: 0.6078431372549019, Validation Loss: 0.885850191116333, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6310/10000, Training Loss: 0.7136976718902588, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7491975426673889, Validation Accuracy: 0.5\n",
      "Epoch 6311/10000, Training Loss: 0.6519666314125061, Training Accuracy: 0.6421568627450981, Validation Loss: 1.1305269002914429, Validation Accuracy: 0.25\n",
      "Epoch 6312/10000, Training Loss: 0.6490746140480042, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7780892848968506, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6313/10000, Training Loss: 0.7028183341026306, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7091069221496582, Validation Accuracy: 0.5\n",
      "Epoch 6314/10000, Training Loss: 0.6544114947319031, Training Accuracy: 0.6348039215686274, Validation Loss: 1.2516158819198608, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6315/10000, Training Loss: 0.697737991809845, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8293759822845459, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6316/10000, Training Loss: 0.6494181156158447, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9080514311790466, Validation Accuracy: 0.25\n",
      "Epoch 6317/10000, Training Loss: 0.7350040674209595, Training Accuracy: 0.5367647058823529, Validation Loss: 0.7608845233917236, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6318/10000, Training Loss: 0.6905023455619812, Training Accuracy: 0.5808823529411765, Validation Loss: 1.410521149635315, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6319/10000, Training Loss: 0.694598376750946, Training Accuracy: 0.5269607843137255, Validation Loss: 0.6028072834014893, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6320/10000, Training Loss: 0.700308084487915, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6354959011077881, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6321/10000, Training Loss: 0.8024136424064636, Training Accuracy: 0.571078431372549, Validation Loss: 0.9561520218849182, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6322/10000, Training Loss: 0.6623638868331909, Training Accuracy: 0.6053921568627451, Validation Loss: 1.075513243675232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6323/10000, Training Loss: 0.7067726850509644, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1361339092254639, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6324/10000, Training Loss: 0.705858051776886, Training Accuracy: 0.6151960784313726, Validation Loss: 1.1309863328933716, Validation Accuracy: 0.5\n",
      "Epoch 6325/10000, Training Loss: 0.6251068115234375, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9435873031616211, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6326/10000, Training Loss: 0.6772611737251282, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9447765946388245, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6327/10000, Training Loss: 0.6380752325057983, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8544543385505676, Validation Accuracy: 0.5\n",
      "Epoch 6328/10000, Training Loss: 0.7473478317260742, Training Accuracy: 0.553921568627451, Validation Loss: 0.7896512150764465, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6329/10000, Training Loss: 0.6055665016174316, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7448654174804688, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6330/10000, Training Loss: 0.649441123008728, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7138280868530273, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6331/10000, Training Loss: 0.662827730178833, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8716523051261902, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6332/10000, Training Loss: 0.6901640295982361, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8811256885528564, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6333/10000, Training Loss: 0.6321331262588501, Training Accuracy: 0.6936274509803921, Validation Loss: 1.2517398595809937, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6334/10000, Training Loss: 0.6641205549240112, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7641347050666809, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6335/10000, Training Loss: 0.6622995734214783, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7242062091827393, Validation Accuracy: 0.5\n",
      "Epoch 6336/10000, Training Loss: 0.7115358710289001, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8334386348724365, Validation Accuracy: 0.5\n",
      "Epoch 6337/10000, Training Loss: 0.6732741594314575, Training Accuracy: 0.5906862745098039, Validation Loss: 0.754176914691925, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6338/10000, Training Loss: 0.7291890978813171, Training Accuracy: 0.5759803921568627, Validation Loss: 1.118123173713684, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6339/10000, Training Loss: 0.6254922747612, Training Accuracy: 0.6642156862745098, Validation Loss: 0.856860339641571, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6340/10000, Training Loss: 0.6636508703231812, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7309942841529846, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6341/10000, Training Loss: 0.7136816382408142, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8040497899055481, Validation Accuracy: 0.5\n",
      "Epoch 6342/10000, Training Loss: 0.6724292039871216, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8014556765556335, Validation Accuracy: 0.5\n",
      "Epoch 6343/10000, Training Loss: 0.6834224462509155, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8093566298484802, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6344/10000, Training Loss: 0.6713388562202454, Training Accuracy: 0.6323529411764706, Validation Loss: 1.043010950088501, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6345/10000, Training Loss: 0.646936297416687, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8181338906288147, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6346/10000, Training Loss: 0.6693955063819885, Training Accuracy: 0.6348039215686274, Validation Loss: 1.2917684316635132, Validation Accuracy: 0.25\n",
      "Epoch 6347/10000, Training Loss: 0.73407381772995, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1050244569778442, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6348/10000, Training Loss: 0.6452730894088745, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6346383094787598, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6349/10000, Training Loss: 0.7460876107215881, Training Accuracy: 0.6004901960784313, Validation Loss: 1.2135305404663086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6350/10000, Training Loss: 0.6366494297981262, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9174358248710632, Validation Accuracy: 0.5\n",
      "Epoch 6351/10000, Training Loss: 0.7617630362510681, Training Accuracy: 0.5269607843137255, Validation Loss: 0.9346075057983398, Validation Accuracy: 0.5\n",
      "Epoch 6352/10000, Training Loss: 0.7335935831069946, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7339879870414734, Validation Accuracy: 0.5\n",
      "Epoch 6353/10000, Training Loss: 0.7658356428146362, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8310413360595703, Validation Accuracy: 0.5\n",
      "Epoch 6354/10000, Training Loss: 0.6931001543998718, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6902573108673096, Validation Accuracy: 0.5\n",
      "Epoch 6355/10000, Training Loss: 0.6605538129806519, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7183555960655212, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6356/10000, Training Loss: 0.7382462620735168, Training Accuracy: 0.5735294117647058, Validation Loss: 1.1793209314346313, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6357/10000, Training Loss: 0.6660977602005005, Training Accuracy: 0.6029411764705882, Validation Loss: 1.3848053216934204, Validation Accuracy: 0.25\n",
      "Epoch 6358/10000, Training Loss: 0.7506836652755737, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8792073726654053, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6359/10000, Training Loss: 0.641579270362854, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7227445244789124, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6360/10000, Training Loss: 0.6626330614089966, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9862916469573975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6361/10000, Training Loss: 0.6234838962554932, Training Accuracy: 0.6691176470588235, Validation Loss: 1.0212637186050415, Validation Accuracy: 0.5\n",
      "Epoch 6362/10000, Training Loss: 0.681694507598877, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7123109698295593, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6363/10000, Training Loss: 0.6741652488708496, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9279220104217529, Validation Accuracy: 0.25\n",
      "Epoch 6364/10000, Training Loss: 0.6615428328514099, Training Accuracy: 0.6862745098039216, Validation Loss: 0.815451443195343, Validation Accuracy: 0.5\n",
      "Epoch 6365/10000, Training Loss: 0.7206140160560608, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0926074981689453, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6366/10000, Training Loss: 0.6705768704414368, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8000656962394714, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6367/10000, Training Loss: 0.7151369452476501, Training Accuracy: 0.49754901960784315, Validation Loss: 0.9187455773353577, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6368/10000, Training Loss: 0.6508991718292236, Training Accuracy: 0.6568627450980392, Validation Loss: 0.876570463180542, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6369/10000, Training Loss: 0.689024806022644, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8286113739013672, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6370/10000, Training Loss: 0.702888011932373, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6884884238243103, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6371/10000, Training Loss: 0.7091879844665527, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8386252522468567, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6372/10000, Training Loss: 0.6851763725280762, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9346513152122498, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6373/10000, Training Loss: 0.682468056678772, Training Accuracy: 0.6397058823529411, Validation Loss: 1.480402946472168, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6374/10000, Training Loss: 0.7290351986885071, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6495068669319153, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6375/10000, Training Loss: 0.691088855266571, Training Accuracy: 0.5857843137254902, Validation Loss: 0.68095463514328, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6376/10000, Training Loss: 0.6774271726608276, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9412081837654114, Validation Accuracy: 0.5\n",
      "Epoch 6377/10000, Training Loss: 0.654371976852417, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6804950833320618, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6378/10000, Training Loss: 0.6961042881011963, Training Accuracy: 0.5686274509803921, Validation Loss: 1.1739039421081543, Validation Accuracy: 0.25\n",
      "Epoch 6379/10000, Training Loss: 0.7325853109359741, Training Accuracy: 0.5637254901960784, Validation Loss: 0.9073728919029236, Validation Accuracy: 0.5\n",
      "Epoch 6380/10000, Training Loss: 0.7447793483734131, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8293898701667786, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6381/10000, Training Loss: 0.7095409631729126, Training Accuracy: 0.553921568627451, Validation Loss: 0.7762608528137207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6382/10000, Training Loss: 0.6967650651931763, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7398034930229187, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6383/10000, Training Loss: 0.6998754739761353, Training Accuracy: 0.5343137254901961, Validation Loss: 0.6789088249206543, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6384/10000, Training Loss: 0.6428044438362122, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7170462608337402, Validation Accuracy: 0.5\n",
      "Epoch 6385/10000, Training Loss: 0.67289799451828, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8532761931419373, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6386/10000, Training Loss: 0.6637970209121704, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9928993582725525, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6387/10000, Training Loss: 0.680576503276825, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0169564485549927, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6388/10000, Training Loss: 0.6495203971862793, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0286369323730469, Validation Accuracy: 0.5\n",
      "Epoch 6389/10000, Training Loss: 0.6790022253990173, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7245261073112488, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6390/10000, Training Loss: 0.6276487708091736, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7540378570556641, Validation Accuracy: 0.5\n",
      "Epoch 6391/10000, Training Loss: 0.6245303153991699, Training Accuracy: 0.6666666666666666, Validation Loss: 1.5352519750595093, Validation Accuracy: 0.25\n",
      "Epoch 6392/10000, Training Loss: 0.6754875183105469, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9516099095344543, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6393/10000, Training Loss: 0.6959964036941528, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9196207523345947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6394/10000, Training Loss: 0.6944270133972168, Training Accuracy: 0.625, Validation Loss: 0.8609976172447205, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6395/10000, Training Loss: 0.7224344611167908, Training Accuracy: 0.5490196078431373, Validation Loss: 1.2692760229110718, Validation Accuracy: 0.25\n",
      "Epoch 6396/10000, Training Loss: 0.6939547657966614, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7051225304603577, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6397/10000, Training Loss: 0.6958447694778442, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7619075775146484, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6398/10000, Training Loss: 0.6475387215614319, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9251996874809265, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6399/10000, Training Loss: 0.6836363077163696, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9027581214904785, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6400/10000, Training Loss: 0.6592214703559875, Training Accuracy: 0.6397058823529411, Validation Loss: 1.3640927076339722, Validation Accuracy: 0.25\n",
      "Epoch 6401/10000, Training Loss: 0.6653135418891907, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6871897578239441, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6402/10000, Training Loss: 0.6822284460067749, Training Accuracy: 0.6053921568627451, Validation Loss: 1.005577802658081, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6403/10000, Training Loss: 0.6313082575798035, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0709254741668701, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6404/10000, Training Loss: 0.6416829228401184, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6568728089332581, Validation Accuracy: 0.75\n",
      "Epoch 6405/10000, Training Loss: 0.6785141229629517, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7174201607704163, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6406/10000, Training Loss: 0.6938180923461914, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9205427765846252, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6407/10000, Training Loss: 0.7367985248565674, Training Accuracy: 0.5294117647058824, Validation Loss: 0.5803807377815247, Validation Accuracy: 0.75\n",
      "Epoch 6408/10000, Training Loss: 0.6521008014678955, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8919095993041992, Validation Accuracy: 0.5\n",
      "Epoch 6409/10000, Training Loss: 0.6722869873046875, Training Accuracy: 0.6225490196078431, Validation Loss: 0.60489821434021, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6410/10000, Training Loss: 0.7185760736465454, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6706903576850891, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6411/10000, Training Loss: 0.7268601059913635, Training Accuracy: 0.5392156862745098, Validation Loss: 0.798433780670166, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6412/10000, Training Loss: 0.7191106677055359, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7939162254333496, Validation Accuracy: 0.5\n",
      "Epoch 6413/10000, Training Loss: 0.664870023727417, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9374843239784241, Validation Accuracy: 0.5\n",
      "Epoch 6414/10000, Training Loss: 0.7300892472267151, Training Accuracy: 0.5612745098039216, Validation Loss: 0.5831162929534912, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6415/10000, Training Loss: 0.6546569466590881, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8978573679924011, Validation Accuracy: 0.5\n",
      "Epoch 6416/10000, Training Loss: 0.7870385646820068, Training Accuracy: 0.5441176470588235, Validation Loss: 0.7085431218147278, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6417/10000, Training Loss: 0.6452925205230713, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1287580728530884, Validation Accuracy: 0.5\n",
      "Epoch 6418/10000, Training Loss: 0.6953195929527283, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7097978591918945, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6419/10000, Training Loss: 0.6337286233901978, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9092505574226379, Validation Accuracy: 0.5\n",
      "Epoch 6420/10000, Training Loss: 0.6946149468421936, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6655596494674683, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6421/10000, Training Loss: 0.6275092959403992, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0273796319961548, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6422/10000, Training Loss: 0.7056361436843872, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7277042865753174, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6423/10000, Training Loss: 0.7206321954727173, Training Accuracy: 0.5686274509803921, Validation Loss: 0.564156174659729, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6424/10000, Training Loss: 0.6739036440849304, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0030032396316528, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6425/10000, Training Loss: 0.7058792114257812, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8120046257972717, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6426/10000, Training Loss: 0.651450514793396, Training Accuracy: 0.6225490196078431, Validation Loss: 1.174006462097168, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6427/10000, Training Loss: 0.6604280471801758, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9894230365753174, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6428/10000, Training Loss: 0.7047938704490662, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0360857248306274, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6429/10000, Training Loss: 0.652382493019104, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7330904006958008, Validation Accuracy: 0.5\n",
      "Epoch 6430/10000, Training Loss: 0.7207673192024231, Training Accuracy: 0.5955882352941176, Validation Loss: 0.910845935344696, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6431/10000, Training Loss: 0.7517468333244324, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6276984214782715, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6432/10000, Training Loss: 0.7163544297218323, Training Accuracy: 0.5563725490196079, Validation Loss: 0.965343177318573, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6433/10000, Training Loss: 0.6928504705429077, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8910388350486755, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6434/10000, Training Loss: 0.7216847538948059, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6611495614051819, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6435/10000, Training Loss: 0.7383586168289185, Training Accuracy: 0.5490196078431373, Validation Loss: 0.7104044556617737, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6436/10000, Training Loss: 0.7119729518890381, Training Accuracy: 0.5416666666666666, Validation Loss: 0.5841338038444519, Validation Accuracy: 0.75\n",
      "Epoch 6437/10000, Training Loss: 0.6224361658096313, Training Accuracy: 0.6593137254901961, Validation Loss: 0.823944091796875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6438/10000, Training Loss: 0.8080306649208069, Training Accuracy: 0.5367647058823529, Validation Loss: 1.1179170608520508, Validation Accuracy: 0.5\n",
      "Epoch 6439/10000, Training Loss: 0.6866350173950195, Training Accuracy: 0.5906862745098039, Validation Loss: 1.0131468772888184, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6440/10000, Training Loss: 0.7215046882629395, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7575991749763489, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6441/10000, Training Loss: 0.6519909501075745, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9901134371757507, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6442/10000, Training Loss: 0.7256929874420166, Training Accuracy: 0.625, Validation Loss: 1.3099011182785034, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6443/10000, Training Loss: 0.7407673597335815, Training Accuracy: 0.5367647058823529, Validation Loss: 1.120848298072815, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6444/10000, Training Loss: 0.7247563004493713, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6985676884651184, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6445/10000, Training Loss: 0.6497335433959961, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9809804558753967, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6446/10000, Training Loss: 0.6220870018005371, Training Accuracy: 0.6495098039215687, Validation Loss: 0.5702393651008606, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6447/10000, Training Loss: 0.6970419883728027, Training Accuracy: 0.6200980392156863, Validation Loss: 1.169127106666565, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6448/10000, Training Loss: 0.7059258818626404, Training Accuracy: 0.571078431372549, Validation Loss: 0.7150722146034241, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6449/10000, Training Loss: 0.6046136021614075, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0352870225906372, Validation Accuracy: 0.5\n",
      "Epoch 6450/10000, Training Loss: 0.7388453483581543, Training Accuracy: 0.5955882352941176, Validation Loss: 1.194250464439392, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6451/10000, Training Loss: 0.6887767314910889, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7079126834869385, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6452/10000, Training Loss: 0.6738383769989014, Training Accuracy: 0.625, Validation Loss: 0.765265941619873, Validation Accuracy: 0.5\n",
      "Epoch 6453/10000, Training Loss: 0.6154757738113403, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9323818683624268, Validation Accuracy: 0.5\n",
      "Epoch 6454/10000, Training Loss: 0.6817080974578857, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0238686800003052, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6455/10000, Training Loss: 0.6872822642326355, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7064387798309326, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6456/10000, Training Loss: 0.659887969493866, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8718569278717041, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6457/10000, Training Loss: 0.6392863988876343, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0230389833450317, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6458/10000, Training Loss: 0.6854867935180664, Training Accuracy: 0.5906862745098039, Validation Loss: 0.929555356502533, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6459/10000, Training Loss: 0.6424439549446106, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7091491222381592, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6460/10000, Training Loss: 0.7426356077194214, Training Accuracy: 0.5759803921568627, Validation Loss: 0.5742889046669006, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6461/10000, Training Loss: 0.673979640007019, Training Accuracy: 0.6053921568627451, Validation Loss: 1.4257116317749023, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6462/10000, Training Loss: 0.6686122417449951, Training Accuracy: 0.6299019607843137, Validation Loss: 0.752508819103241, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6463/10000, Training Loss: 0.661319375038147, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0109282732009888, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6464/10000, Training Loss: 0.668387770652771, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0071759223937988, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6465/10000, Training Loss: 0.6507973670959473, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7205265164375305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6466/10000, Training Loss: 0.6640900373458862, Training Accuracy: 0.625, Validation Loss: 0.8202283382415771, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6467/10000, Training Loss: 0.7953755855560303, Training Accuracy: 0.5, Validation Loss: 1.0029253959655762, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6468/10000, Training Loss: 0.6478720903396606, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7303142547607422, Validation Accuracy: 0.5\n",
      "Epoch 6469/10000, Training Loss: 0.6851779818534851, Training Accuracy: 0.571078431372549, Validation Loss: 0.8492133021354675, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6470/10000, Training Loss: 0.648358941078186, Training Accuracy: 0.6568627450980392, Validation Loss: 1.109200119972229, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 6471/10000, Training Loss: 0.7026899456977844, Training Accuracy: 0.6004901960784313, Validation Loss: 0.788102388381958, Validation Accuracy: 0.5\n",
      "Epoch 6472/10000, Training Loss: 0.7454960942268372, Training Accuracy: 0.5588235294117647, Validation Loss: 0.6314237713813782, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6473/10000, Training Loss: 0.6945644617080688, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7496979832649231, Validation Accuracy: 0.5\n",
      "Epoch 6474/10000, Training Loss: 0.6650171279907227, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8816741108894348, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6475/10000, Training Loss: 0.710415780544281, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7537625432014465, Validation Accuracy: 0.5\n",
      "Epoch 6476/10000, Training Loss: 0.6561412215232849, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7134936451911926, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6477/10000, Training Loss: 0.7844871282577515, Training Accuracy: 0.5661764705882353, Validation Loss: 1.107509732246399, Validation Accuracy: 0.25\n",
      "Epoch 6478/10000, Training Loss: 0.6254965662956238, Training Accuracy: 0.6617647058823529, Validation Loss: 1.2178716659545898, Validation Accuracy: 0.25\n",
      "Epoch 6479/10000, Training Loss: 0.673740029335022, Training Accuracy: 0.6102941176470589, Validation Loss: 0.5788728594779968, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6480/10000, Training Loss: 0.7201904654502869, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6985711455345154, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6481/10000, Training Loss: 0.670667827129364, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6747970581054688, Validation Accuracy: 0.5\n",
      "Epoch 6482/10000, Training Loss: 0.6290076971054077, Training Accuracy: 0.6495098039215687, Validation Loss: 0.560674786567688, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6483/10000, Training Loss: 0.6467705368995667, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8795759677886963, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6484/10000, Training Loss: 0.6271200180053711, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7344246506690979, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6485/10000, Training Loss: 0.6575824618339539, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9866693615913391, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6486/10000, Training Loss: 0.7067124843597412, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9282342791557312, Validation Accuracy: 0.5\n",
      "Epoch 6487/10000, Training Loss: 0.6483801007270813, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8373710513114929, Validation Accuracy: 0.5\n",
      "Epoch 6488/10000, Training Loss: 0.726988673210144, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7864895462989807, Validation Accuracy: 0.5\n",
      "Epoch 6489/10000, Training Loss: 0.767729640007019, Training Accuracy: 0.553921568627451, Validation Loss: 0.5565357804298401, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6490/10000, Training Loss: 0.6357290744781494, Training Accuracy: 0.6691176470588235, Validation Loss: 1.1490364074707031, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6491/10000, Training Loss: 0.7042616009712219, Training Accuracy: 0.6274509803921569, Validation Loss: 0.732689380645752, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6492/10000, Training Loss: 0.7093384861946106, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7903090119361877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6493/10000, Training Loss: 0.6600025296211243, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7656619548797607, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6494/10000, Training Loss: 0.6770950555801392, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8492314219474792, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6495/10000, Training Loss: 0.8013631105422974, Training Accuracy: 0.5686274509803921, Validation Loss: 1.4183136224746704, Validation Accuracy: 0.5\n",
      "Epoch 6496/10000, Training Loss: 0.700779139995575, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8313689827919006, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6497/10000, Training Loss: 0.6602961421012878, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7900349497795105, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6498/10000, Training Loss: 0.7621052265167236, Training Accuracy: 0.5196078431372549, Validation Loss: 0.7015111446380615, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6499/10000, Training Loss: 0.6908109188079834, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6744746565818787, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6500/10000, Training Loss: 0.6350076794624329, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9292463660240173, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6501/10000, Training Loss: 0.6296325922012329, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8686623573303223, Validation Accuracy: 0.5\n",
      "Epoch 6502/10000, Training Loss: 0.656395435333252, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9924540519714355, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6503/10000, Training Loss: 0.6841152906417847, Training Accuracy: 0.571078431372549, Validation Loss: 0.899341344833374, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6504/10000, Training Loss: 0.7017117738723755, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0434542894363403, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6505/10000, Training Loss: 0.763940155506134, Training Accuracy: 0.6642156862745098, Validation Loss: 0.847943127155304, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6506/10000, Training Loss: 0.6786011457443237, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7977614402770996, Validation Accuracy: 0.75\n",
      "Epoch 6507/10000, Training Loss: 0.6620286107063293, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9237639307975769, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6508/10000, Training Loss: 0.6376128792762756, Training Accuracy: 0.6200980392156863, Validation Loss: 0.709083616733551, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6509/10000, Training Loss: 0.729823112487793, Training Accuracy: 0.5931372549019608, Validation Loss: 1.0336552858352661, Validation Accuracy: 0.5\n",
      "Epoch 6510/10000, Training Loss: 0.6401321291923523, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7171465754508972, Validation Accuracy: 0.5\n",
      "Epoch 6511/10000, Training Loss: 0.6824081540107727, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8290719985961914, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6512/10000, Training Loss: 0.6804400682449341, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7368704676628113, Validation Accuracy: 0.5\n",
      "Epoch 6513/10000, Training Loss: 0.6827207803726196, Training Accuracy: 0.6372549019607843, Validation Loss: 1.321797490119934, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6514/10000, Training Loss: 0.683435320854187, Training Accuracy: 0.6029411764705882, Validation Loss: 1.063340663909912, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6515/10000, Training Loss: 0.6318680047988892, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8614928126335144, Validation Accuracy: 0.5\n",
      "Epoch 6516/10000, Training Loss: 0.7458296418190002, Training Accuracy: 0.5686274509803921, Validation Loss: 1.3038556575775146, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6517/10000, Training Loss: 0.6395941972732544, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9117593765258789, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6518/10000, Training Loss: 0.6404803991317749, Training Accuracy: 0.6151960784313726, Validation Loss: 1.3802911043167114, Validation Accuracy: 0.5\n",
      "Epoch 6519/10000, Training Loss: 0.7134628891944885, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8287789225578308, Validation Accuracy: 0.5\n",
      "Epoch 6520/10000, Training Loss: 0.6825718879699707, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8960707187652588, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6521/10000, Training Loss: 0.6859461665153503, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6846274733543396, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6522/10000, Training Loss: 0.6842837333679199, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6199091076850891, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6523/10000, Training Loss: 0.6763907670974731, Training Accuracy: 0.6078431372549019, Validation Loss: 1.1177432537078857, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6524/10000, Training Loss: 0.6627432703971863, Training Accuracy: 0.6666666666666666, Validation Loss: 1.189780354499817, Validation Accuracy: 0.5\n",
      "Epoch 6525/10000, Training Loss: 0.7310659885406494, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6596918702125549, Validation Accuracy: 0.75\n",
      "Epoch 6526/10000, Training Loss: 0.6513330340385437, Training Accuracy: 0.6225490196078431, Validation Loss: 1.1046315431594849, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6527/10000, Training Loss: 0.7297441363334656, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7163805365562439, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6528/10000, Training Loss: 0.7108368873596191, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7326640486717224, Validation Accuracy: 0.5\n",
      "Epoch 6529/10000, Training Loss: 0.683333694934845, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6211917996406555, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6530/10000, Training Loss: 0.6517788767814636, Training Accuracy: 0.625, Validation Loss: 1.0150867700576782, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6531/10000, Training Loss: 0.6460362672805786, Training Accuracy: 0.6323529411764706, Validation Loss: 1.293743371963501, Validation Accuracy: 0.5\n",
      "Epoch 6532/10000, Training Loss: 0.6472968459129333, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8722290396690369, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6533/10000, Training Loss: 0.6844136714935303, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7448115944862366, Validation Accuracy: 0.5\n",
      "Epoch 6534/10000, Training Loss: 0.7099740505218506, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0620862245559692, Validation Accuracy: 0.25\n",
      "Epoch 6535/10000, Training Loss: 0.70929354429245, Training Accuracy: 0.5318627450980392, Validation Loss: 1.0986491441726685, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6536/10000, Training Loss: 0.7015764117240906, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9149887561798096, Validation Accuracy: 0.25\n",
      "Epoch 6537/10000, Training Loss: 0.7398769855499268, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8177943825721741, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6538/10000, Training Loss: 0.7291008234024048, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0086394548416138, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6539/10000, Training Loss: 0.6578361392021179, Training Accuracy: 0.6176470588235294, Validation Loss: 1.5342302322387695, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 6540/10000, Training Loss: 0.6637476086616516, Training Accuracy: 0.6274509803921569, Validation Loss: 0.893549382686615, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6541/10000, Training Loss: 0.709787130355835, Training Accuracy: 0.5906862745098039, Validation Loss: 0.5400363802909851, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6542/10000, Training Loss: 0.6521591544151306, Training Accuracy: 0.6053921568627451, Validation Loss: 0.884993314743042, Validation Accuracy: 0.25\n",
      "Epoch 6543/10000, Training Loss: 0.6652583479881287, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7525520324707031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6544/10000, Training Loss: 0.6610490679740906, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8209607005119324, Validation Accuracy: 0.5\n",
      "Epoch 6545/10000, Training Loss: 0.6730087399482727, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9111128449440002, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6546/10000, Training Loss: 0.6902700662612915, Training Accuracy: 0.6446078431372549, Validation Loss: 0.814943253993988, Validation Accuracy: 0.5\n",
      "Epoch 6547/10000, Training Loss: 0.725521445274353, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6974199414253235, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6548/10000, Training Loss: 0.6857762336730957, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7486922740936279, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6549/10000, Training Loss: 0.660696268081665, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6834366321563721, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6550/10000, Training Loss: 0.7059136033058167, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7351393699645996, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6551/10000, Training Loss: 0.6915899515151978, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9050381183624268, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6552/10000, Training Loss: 0.7057490348815918, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7346863150596619, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6553/10000, Training Loss: 0.6558290123939514, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7452146410942078, Validation Accuracy: 0.5\n",
      "Epoch 6554/10000, Training Loss: 0.7022522687911987, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1136759519577026, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6555/10000, Training Loss: 0.6467147469520569, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6508496403694153, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6556/10000, Training Loss: 0.6495348811149597, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8465204238891602, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6557/10000, Training Loss: 0.660700798034668, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7199435234069824, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6558/10000, Training Loss: 0.6912052035331726, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9042118191719055, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6559/10000, Training Loss: 0.634735107421875, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9366273880004883, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6560/10000, Training Loss: 0.6817262768745422, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7036500573158264, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6561/10000, Training Loss: 0.5935761332511902, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0265856981277466, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6562/10000, Training Loss: 0.6589244604110718, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8738596439361572, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6563/10000, Training Loss: 0.691571056842804, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6061351895332336, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6564/10000, Training Loss: 0.7081381678581238, Training Accuracy: 0.5269607843137255, Validation Loss: 0.6272799372673035, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6565/10000, Training Loss: 0.6685776114463806, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8836601376533508, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6566/10000, Training Loss: 0.6538112759590149, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6942610740661621, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6567/10000, Training Loss: 0.6330540776252747, Training Accuracy: 0.5808823529411765, Validation Loss: 0.66693514585495, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6568/10000, Training Loss: 0.7280402779579163, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8370819687843323, Validation Accuracy: 0.5\n",
      "Epoch 6569/10000, Training Loss: 0.6756129264831543, Training Accuracy: 0.5955882352941176, Validation Loss: 1.161400556564331, Validation Accuracy: 0.25\n",
      "Epoch 6570/10000, Training Loss: 0.726565957069397, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6246194243431091, Validation Accuracy: 0.75\n",
      "Epoch 6571/10000, Training Loss: 0.6415169835090637, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0236507654190063, Validation Accuracy: 0.5\n",
      "Epoch 6572/10000, Training Loss: 0.687036395072937, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8008410930633545, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6573/10000, Training Loss: 0.6569564938545227, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9306378364562988, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6574/10000, Training Loss: 0.657927393913269, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8518388867378235, Validation Accuracy: 0.5\n",
      "Epoch 6575/10000, Training Loss: 0.6492534875869751, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8539161086082458, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6576/10000, Training Loss: 0.7329850792884827, Training Accuracy: 0.5073529411764706, Validation Loss: 0.7107443809509277, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6577/10000, Training Loss: 0.7447916865348816, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1608927249908447, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6578/10000, Training Loss: 0.6481741070747375, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9364688992500305, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6579/10000, Training Loss: 0.6444563865661621, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8430250287055969, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6580/10000, Training Loss: 0.6213128566741943, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7566401362419128, Validation Accuracy: 0.75\n",
      "Epoch 6581/10000, Training Loss: 0.6871705651283264, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9343862533569336, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6582/10000, Training Loss: 0.7710347175598145, Training Accuracy: 0.5049019607843137, Validation Loss: 0.7273814678192139, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6583/10000, Training Loss: 0.6831330060958862, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1011769771575928, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6584/10000, Training Loss: 0.6674272418022156, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1535159349441528, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6585/10000, Training Loss: 0.6358992457389832, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7984326481819153, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6586/10000, Training Loss: 0.6352476477622986, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8424970507621765, Validation Accuracy: 0.25\n",
      "Epoch 6587/10000, Training Loss: 0.6614285707473755, Training Accuracy: 0.678921568627451, Validation Loss: 0.7076637148857117, Validation Accuracy: 0.5\n",
      "Epoch 6588/10000, Training Loss: 0.6338304877281189, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7330043315887451, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6589/10000, Training Loss: 0.6832087635993958, Training Accuracy: 0.5514705882352942, Validation Loss: 1.0436385869979858, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6590/10000, Training Loss: 0.6608371138572693, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9820134043693542, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6591/10000, Training Loss: 0.6864377856254578, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7073450684547424, Validation Accuracy: 0.25\n",
      "Epoch 6592/10000, Training Loss: 0.7302083969116211, Training Accuracy: 0.5171568627450981, Validation Loss: 0.8320868015289307, Validation Accuracy: 0.25\n",
      "Epoch 6593/10000, Training Loss: 0.7023241519927979, Training Accuracy: 0.5612745098039216, Validation Loss: 1.0925347805023193, Validation Accuracy: 0.5\n",
      "Epoch 6594/10000, Training Loss: 0.6418771743774414, Training Accuracy: 0.6740196078431373, Validation Loss: 0.9761330485343933, Validation Accuracy: 0.5\n",
      "Epoch 6595/10000, Training Loss: 0.7402011752128601, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9545211791992188, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6596/10000, Training Loss: 0.6619327068328857, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0573211908340454, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 6597/10000, Training Loss: 0.7493069767951965, Training Accuracy: 0.5441176470588235, Validation Loss: 1.0479973554611206, Validation Accuracy: 0.5\n",
      "Epoch 6598/10000, Training Loss: 0.6633858680725098, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8467037081718445, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6599/10000, Training Loss: 0.6743403673171997, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7212329506874084, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6600/10000, Training Loss: 0.6732972264289856, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7886446118354797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6601/10000, Training Loss: 0.7470076084136963, Training Accuracy: 0.5735294117647058, Validation Loss: 0.5132152438163757, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6602/10000, Training Loss: 0.7035862803459167, Training Accuracy: 0.5514705882352942, Validation Loss: 0.6985108852386475, Validation Accuracy: 0.5\n",
      "Epoch 6603/10000, Training Loss: 0.6621431708335876, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6647654175758362, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6604/10000, Training Loss: 0.6510689854621887, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0922681093215942, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6605/10000, Training Loss: 0.6615855693817139, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7776823043823242, Validation Accuracy: 0.5\n",
      "Epoch 6606/10000, Training Loss: 0.6871879696846008, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7331944108009338, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6607/10000, Training Loss: 0.7493938207626343, Training Accuracy: 0.5147058823529411, Validation Loss: 0.8242311477661133, Validation Accuracy: 0.5\n",
      "Epoch 6608/10000, Training Loss: 0.704340398311615, Training Accuracy: 0.5563725490196079, Validation Loss: 0.5526081919670105, Validation Accuracy: 0.75\n",
      "Epoch 6609/10000, Training Loss: 0.6884663701057434, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8789887428283691, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6610/10000, Training Loss: 0.7197697758674622, Training Accuracy: 0.5759803921568627, Validation Loss: 1.172889232635498, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6611/10000, Training Loss: 0.6890442967414856, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6710917353630066, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6612/10000, Training Loss: 0.6578571200370789, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8331761360168457, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6613/10000, Training Loss: 0.6691054701805115, Training Accuracy: 0.6568627450980392, Validation Loss: 0.831143856048584, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6614/10000, Training Loss: 0.6706802248954773, Training Accuracy: 0.6004901960784313, Validation Loss: 0.877526581287384, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6615/10000, Training Loss: 0.6769677996635437, Training Accuracy: 0.6200980392156863, Validation Loss: 0.590366780757904, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6616/10000, Training Loss: 0.6089546084403992, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9466691613197327, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6617/10000, Training Loss: 0.7245550751686096, Training Accuracy: 0.5122549019607843, Validation Loss: 0.7627593874931335, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6618/10000, Training Loss: 0.6672304272651672, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8280957341194153, Validation Accuracy: 0.5\n",
      "Epoch 6619/10000, Training Loss: 0.7213514447212219, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7729234099388123, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6620/10000, Training Loss: 0.6919230818748474, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9569880962371826, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6621/10000, Training Loss: 0.6548858284950256, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7258196473121643, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6622/10000, Training Loss: 0.6967349052429199, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6596123576164246, Validation Accuracy: 0.5\n",
      "Epoch 6623/10000, Training Loss: 0.652296245098114, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9690213799476624, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6624/10000, Training Loss: 0.6813435554504395, Training Accuracy: 0.5882352941176471, Validation Loss: 1.001228928565979, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6625/10000, Training Loss: 0.67929607629776, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6324703693389893, Validation Accuracy: 0.5\n",
      "Epoch 6626/10000, Training Loss: 0.6846544742584229, Training Accuracy: 0.5661764705882353, Validation Loss: 0.513858437538147, Validation Accuracy: 1.0\n",
      "Epoch 6627/10000, Training Loss: 0.6196020245552063, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1468149423599243, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6628/10000, Training Loss: 0.6607011556625366, Training Accuracy: 0.6078431372549019, Validation Loss: 1.167392611503601, Validation Accuracy: 0.25\n",
      "Epoch 6629/10000, Training Loss: 0.6920337080955505, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9272140860557556, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6630/10000, Training Loss: 0.6584759950637817, Training Accuracy: 0.6053921568627451, Validation Loss: 1.3323712348937988, Validation Accuracy: 0.25\n",
      "Epoch 6631/10000, Training Loss: 0.6452828049659729, Training Accuracy: 0.6397058823529411, Validation Loss: 0.756420910358429, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6632/10000, Training Loss: 0.6801760792732239, Training Accuracy: 0.5784313725490197, Validation Loss: 1.17708420753479, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6633/10000, Training Loss: 0.6403579115867615, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8522248268127441, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6634/10000, Training Loss: 0.6781846880912781, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8473766446113586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6635/10000, Training Loss: 0.6829503178596497, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0097304582595825, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6636/10000, Training Loss: 0.6329183578491211, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7284119725227356, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6637/10000, Training Loss: 0.6924117803573608, Training Accuracy: 0.5392156862745098, Validation Loss: 0.9631478786468506, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6638/10000, Training Loss: 0.6939957737922668, Training Accuracy: 0.5514705882352942, Validation Loss: 0.944552481174469, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 6639/10000, Training Loss: 0.6715644598007202, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8221504092216492, Validation Accuracy: 0.5\n",
      "Epoch 6640/10000, Training Loss: 0.8276323676109314, Training Accuracy: 0.5269607843137255, Validation Loss: 0.7178800106048584, Validation Accuracy: 0.5\n",
      "Epoch 6641/10000, Training Loss: 0.7698089480400085, Training Accuracy: 0.5931372549019608, Validation Loss: 0.737091064453125, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6642/10000, Training Loss: 0.6635533571243286, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6931018829345703, Validation Accuracy: 0.5\n",
      "Epoch 6643/10000, Training Loss: 0.7590911984443665, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9905765056610107, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6644/10000, Training Loss: 0.652020275592804, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6814916133880615, Validation Accuracy: 0.5\n",
      "Epoch 6645/10000, Training Loss: 0.6989185810089111, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6956458687782288, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6646/10000, Training Loss: 0.6508287191390991, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7921130061149597, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6647/10000, Training Loss: 0.6556467413902283, Training Accuracy: 0.625, Validation Loss: 0.7986461520195007, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6648/10000, Training Loss: 0.7500501871109009, Training Accuracy: 0.5147058823529411, Validation Loss: 0.8149605393409729, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6649/10000, Training Loss: 0.684626042842865, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8993259072303772, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6650/10000, Training Loss: 0.7335612177848816, Training Accuracy: 0.5367647058823529, Validation Loss: 0.6922674179077148, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6651/10000, Training Loss: 0.6732304096221924, Training Accuracy: 0.5514705882352942, Validation Loss: 0.6909060478210449, Validation Accuracy: 0.5\n",
      "Epoch 6652/10000, Training Loss: 0.6837619543075562, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7876198887825012, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6653/10000, Training Loss: 0.7047459483146667, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1309971809387207, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6654/10000, Training Loss: 0.7040565609931946, Training Accuracy: 0.5906862745098039, Validation Loss: 1.1391264200210571, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6655/10000, Training Loss: 0.6662976741790771, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7918996810913086, Validation Accuracy: 0.5\n",
      "Epoch 6656/10000, Training Loss: 0.6614601016044617, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8679134249687195, Validation Accuracy: 0.5\n",
      "Epoch 6657/10000, Training Loss: 0.6795724630355835, Training Accuracy: 0.6348039215686274, Validation Loss: 1.080678105354309, Validation Accuracy: 0.25\n",
      "Epoch 6658/10000, Training Loss: 0.6716060042381287, Training Accuracy: 0.5931372549019608, Validation Loss: 0.750011146068573, Validation Accuracy: 0.5\n",
      "Epoch 6659/10000, Training Loss: 0.66396164894104, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0717250108718872, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6660/10000, Training Loss: 0.6289373636245728, Training Accuracy: 0.6397058823529411, Validation Loss: 1.4253783226013184, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6661/10000, Training Loss: 0.6902424693107605, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9003114104270935, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6662/10000, Training Loss: 0.6402450799942017, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8828005194664001, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6663/10000, Training Loss: 0.6792027950286865, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8670665621757507, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6664/10000, Training Loss: 0.6505415439605713, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7062597870826721, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6665/10000, Training Loss: 0.6957122087478638, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8059806823730469, Validation Accuracy: 0.5\n",
      "Epoch 6666/10000, Training Loss: 0.6798825860023499, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7823057174682617, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6667/10000, Training Loss: 0.6682495474815369, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8689817786216736, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6668/10000, Training Loss: 0.637880265712738, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7304475903511047, Validation Accuracy: 0.5\n",
      "Epoch 6669/10000, Training Loss: 0.6742221713066101, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7158001065254211, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6670/10000, Training Loss: 0.7334500551223755, Training Accuracy: 0.5147058823529411, Validation Loss: 0.7402904033660889, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6671/10000, Training Loss: 0.7162305116653442, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6192607879638672, Validation Accuracy: 0.5\n",
      "Epoch 6672/10000, Training Loss: 0.6804598569869995, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6034204363822937, Validation Accuracy: 0.5\n",
      "Epoch 6673/10000, Training Loss: 0.7274017930030823, Training Accuracy: 0.5465686274509803, Validation Loss: 0.5229806900024414, Validation Accuracy: 0.75\n",
      "Epoch 6674/10000, Training Loss: 0.6616154313087463, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9072103500366211, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6675/10000, Training Loss: 0.6658057570457458, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7256669402122498, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6676/10000, Training Loss: 0.7048428654670715, Training Accuracy: 0.5367647058823529, Validation Loss: 0.6947124004364014, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6677/10000, Training Loss: 0.6766189932823181, Training Accuracy: 0.5612745098039216, Validation Loss: 0.9665055871009827, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6678/10000, Training Loss: 0.7100293040275574, Training Accuracy: 0.5490196078431373, Validation Loss: 0.7549066543579102, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6679/10000, Training Loss: 0.6410055756568909, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8650751113891602, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6680/10000, Training Loss: 0.6610339879989624, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9286666512489319, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6681/10000, Training Loss: 0.6918214559555054, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9496117234230042, Validation Accuracy: 0.5\n",
      "Epoch 6682/10000, Training Loss: 0.6108753085136414, Training Accuracy: 0.6740196078431373, Validation Loss: 0.723503589630127, Validation Accuracy: 0.5\n",
      "Epoch 6683/10000, Training Loss: 0.6931459307670593, Training Accuracy: 0.625, Validation Loss: 0.9932842254638672, Validation Accuracy: 0.5\n",
      "Epoch 6684/10000, Training Loss: 0.6206801533699036, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0680042505264282, Validation Accuracy: 0.25\n",
      "Epoch 6685/10000, Training Loss: 0.7696808576583862, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7254101634025574, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6686/10000, Training Loss: 0.6095409989356995, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8239636421203613, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6687/10000, Training Loss: 0.6735325455665588, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6648721098899841, Validation Accuracy: 0.5\n",
      "Epoch 6688/10000, Training Loss: 0.6460773348808289, Training Accuracy: 0.6274509803921569, Validation Loss: 0.625848114490509, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6689/10000, Training Loss: 0.7276522517204285, Training Accuracy: 0.5759803921568627, Validation Loss: 1.0064036846160889, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6690/10000, Training Loss: 0.6572461724281311, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8010227680206299, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6691/10000, Training Loss: 0.6284003853797913, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1592365503311157, Validation Accuracy: 0.5\n",
      "Epoch 6692/10000, Training Loss: 0.6743010878562927, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7900033593177795, Validation Accuracy: 0.5\n",
      "Epoch 6693/10000, Training Loss: 0.6772968173027039, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7644749283790588, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6694/10000, Training Loss: 0.6428622603416443, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7229753136634827, Validation Accuracy: 0.5\n",
      "Epoch 6695/10000, Training Loss: 0.6752322912216187, Training Accuracy: 0.553921568627451, Validation Loss: 0.9149764180183411, Validation Accuracy: 0.5\n",
      "Epoch 6696/10000, Training Loss: 0.6625722050666809, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6893461346626282, Validation Accuracy: 0.5\n",
      "Epoch 6697/10000, Training Loss: 0.6661474108695984, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9186603426933289, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6698/10000, Training Loss: 0.6735536456108093, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1119881868362427, Validation Accuracy: 0.5\n",
      "Epoch 6699/10000, Training Loss: 0.6961489915847778, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8128497004508972, Validation Accuracy: 0.25\n",
      "Epoch 6700/10000, Training Loss: 0.621487021446228, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8471251130104065, Validation Accuracy: 0.75\n",
      "Epoch 6701/10000, Training Loss: 0.6308477520942688, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8088403344154358, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6702/10000, Training Loss: 0.6403353810310364, Training Accuracy: 0.6102941176470589, Validation Loss: 1.1452066898345947, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6703/10000, Training Loss: 0.661717414855957, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7431290149688721, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6704/10000, Training Loss: 0.6906977891921997, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8234860301017761, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6705/10000, Training Loss: 0.7024263143539429, Training Accuracy: 0.5098039215686274, Validation Loss: 0.8229432702064514, Validation Accuracy: 0.5\n",
      "Epoch 6706/10000, Training Loss: 0.6517519354820251, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8713827133178711, Validation Accuracy: 0.5\n",
      "Epoch 6707/10000, Training Loss: 0.7258359789848328, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9327331185340881, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6708/10000, Training Loss: 0.6951008439064026, Training Accuracy: 0.5955882352941176, Validation Loss: 0.5617464184761047, Validation Accuracy: 0.75\n",
      "Epoch 6709/10000, Training Loss: 0.6590421795845032, Training Accuracy: 0.6274509803921569, Validation Loss: 0.5740737318992615, Validation Accuracy: 0.75\n",
      "Epoch 6710/10000, Training Loss: 0.696053683757782, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6731310486793518, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6711/10000, Training Loss: 0.6594717502593994, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7757918834686279, Validation Accuracy: 0.5\n",
      "Epoch 6712/10000, Training Loss: 0.7248004078865051, Training Accuracy: 0.5343137254901961, Validation Loss: 0.7964470982551575, Validation Accuracy: 0.5\n",
      "Epoch 6713/10000, Training Loss: 0.7187605500221252, Training Accuracy: 0.5612745098039216, Validation Loss: 0.5801159143447876, Validation Accuracy: 0.5\n",
      "Epoch 6714/10000, Training Loss: 0.6992117166519165, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6726233959197998, Validation Accuracy: 0.75\n",
      "Epoch 6715/10000, Training Loss: 0.6290530562400818, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9993461966514587, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6716/10000, Training Loss: 0.6706244349479675, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7040672898292542, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6717/10000, Training Loss: 0.7613353133201599, Training Accuracy: 0.5441176470588235, Validation Loss: 1.2545745372772217, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6718/10000, Training Loss: 0.6687572002410889, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0249429941177368, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6719/10000, Training Loss: 0.7185225486755371, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9370244145393372, Validation Accuracy: 0.25\n",
      "Epoch 6720/10000, Training Loss: 0.6538475751876831, Training Accuracy: 0.6151960784313726, Validation Loss: 1.6109057664871216, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6721/10000, Training Loss: 0.6465222239494324, Training Accuracy: 0.6568627450980392, Validation Loss: 1.1967064142227173, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6722/10000, Training Loss: 0.6987317204475403, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7722516059875488, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6723/10000, Training Loss: 0.7206112146377563, Training Accuracy: 0.6004901960784313, Validation Loss: 1.098069667816162, Validation Accuracy: 0.5\n",
      "Epoch 6724/10000, Training Loss: 0.6321288347244263, Training Accuracy: 0.6813725490196079, Validation Loss: 1.000961422920227, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6725/10000, Training Loss: 0.6961476802825928, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8366147875785828, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6726/10000, Training Loss: 0.6495722532272339, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7938093543052673, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6727/10000, Training Loss: 0.6850155591964722, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8092507719993591, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6728/10000, Training Loss: 0.6897371411323547, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8158512711524963, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6729/10000, Training Loss: 0.6855912804603577, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9128859639167786, Validation Accuracy: 0.25\n",
      "Epoch 6730/10000, Training Loss: 0.7130230069160461, Training Accuracy: 0.571078431372549, Validation Loss: 0.650005578994751, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6731/10000, Training Loss: 0.6914308071136475, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7595986723899841, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6732/10000, Training Loss: 0.6550402045249939, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7458558678627014, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6733/10000, Training Loss: 0.6238574981689453, Training Accuracy: 0.6372549019607843, Validation Loss: 1.1257294416427612, Validation Accuracy: 0.5\n",
      "Epoch 6734/10000, Training Loss: 0.6738477945327759, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8020070195198059, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6735/10000, Training Loss: 0.729850709438324, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6463901400566101, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6736/10000, Training Loss: 0.7000845074653625, Training Accuracy: 0.5686274509803921, Validation Loss: 0.711793839931488, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6737/10000, Training Loss: 0.6493635177612305, Training Accuracy: 0.5980392156862745, Validation Loss: 0.803885281085968, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6738/10000, Training Loss: 0.6802987456321716, Training Accuracy: 0.553921568627451, Validation Loss: 0.7679540514945984, Validation Accuracy: 0.5\n",
      "Epoch 6739/10000, Training Loss: 0.6890413761138916, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8990982174873352, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6740/10000, Training Loss: 0.6687228679656982, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0133100748062134, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6741/10000, Training Loss: 0.6384565234184265, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0237394571304321, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6742/10000, Training Loss: 0.6405413746833801, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9214487075805664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6743/10000, Training Loss: 0.6374682188034058, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6779119968414307, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6744/10000, Training Loss: 0.6744992136955261, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7259067893028259, Validation Accuracy: 0.5\n",
      "Epoch 6745/10000, Training Loss: 0.6352307796478271, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8503474593162537, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6746/10000, Training Loss: 0.6859217882156372, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8978635668754578, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6747/10000, Training Loss: 0.6651373505592346, Training Accuracy: 0.6348039215686274, Validation Loss: 0.69536954164505, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6748/10000, Training Loss: 0.6606930494308472, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7952418923377991, Validation Accuracy: 0.5\n",
      "Epoch 6749/10000, Training Loss: 0.6393201947212219, Training Accuracy: 0.6225490196078431, Validation Loss: 1.1754343509674072, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6750/10000, Training Loss: 0.733549177646637, Training Accuracy: 0.5563725490196079, Validation Loss: 1.2980501651763916, Validation Accuracy: 0.5\n",
      "Epoch 6751/10000, Training Loss: 0.6629994511604309, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0477808713912964, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6752/10000, Training Loss: 0.63018798828125, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6877040863037109, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6753/10000, Training Loss: 0.6707543134689331, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8131476044654846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6754/10000, Training Loss: 0.6879991292953491, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0175576210021973, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6755/10000, Training Loss: 0.755488395690918, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7100815773010254, Validation Accuracy: 0.5\n",
      "Epoch 6756/10000, Training Loss: 0.6956565976142883, Training Accuracy: 0.5686274509803921, Validation Loss: 1.0483192205429077, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6757/10000, Training Loss: 0.6670799255371094, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6738994717597961, Validation Accuracy: 0.5\n",
      "Epoch 6758/10000, Training Loss: 0.6821720600128174, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8204249739646912, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6759/10000, Training Loss: 0.6678345799446106, Training Accuracy: 0.5416666666666666, Validation Loss: 0.6447808742523193, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6760/10000, Training Loss: 0.6250537037849426, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7534732222557068, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6761/10000, Training Loss: 0.6580361723899841, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6601389646530151, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6762/10000, Training Loss: 0.6561782956123352, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7666904330253601, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6763/10000, Training Loss: 0.6598246097564697, Training Accuracy: 0.5857843137254902, Validation Loss: 1.059286117553711, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6764/10000, Training Loss: 0.6710270047187805, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7300985455513, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6765/10000, Training Loss: 0.7043174505233765, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9117252230644226, Validation Accuracy: 0.5\n",
      "Epoch 6766/10000, Training Loss: 0.6567129492759705, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9007845520973206, Validation Accuracy: 0.5\n",
      "Epoch 6767/10000, Training Loss: 0.7107781767845154, Training Accuracy: 0.5563725490196079, Validation Loss: 0.5368322730064392, Validation Accuracy: 0.75\n",
      "Epoch 6768/10000, Training Loss: 0.6655414700508118, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6443600058555603, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6769/10000, Training Loss: 0.6531583666801453, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7280416488647461, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6770/10000, Training Loss: 0.6081439852714539, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9236530661582947, Validation Accuracy: 0.5\n",
      "Epoch 6771/10000, Training Loss: 0.6624255180358887, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8407390117645264, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6772/10000, Training Loss: 0.7157625555992126, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9167478680610657, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6773/10000, Training Loss: 0.6667044162750244, Training Accuracy: 0.6372549019607843, Validation Loss: 0.742424726486206, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6774/10000, Training Loss: 0.6847942471504211, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7869201302528381, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6775/10000, Training Loss: 0.6940488815307617, Training Accuracy: 0.5392156862745098, Validation Loss: 0.8927856087684631, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6776/10000, Training Loss: 0.6974008083343506, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9036169648170471, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6777/10000, Training Loss: 0.6433582901954651, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6818366646766663, Validation Accuracy: 0.75\n",
      "Epoch 6778/10000, Training Loss: 0.651015043258667, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8931903839111328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6779/10000, Training Loss: 0.6411942839622498, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7470051646232605, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6780/10000, Training Loss: 0.6636678576469421, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6720280647277832, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6781/10000, Training Loss: 0.7296956181526184, Training Accuracy: 0.553921568627451, Validation Loss: 0.8426502346992493, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6782/10000, Training Loss: 0.6972838640213013, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8774372935295105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6783/10000, Training Loss: 0.6383441090583801, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7018551826477051, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6784/10000, Training Loss: 0.612381637096405, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7180898785591125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6785/10000, Training Loss: 0.6836036443710327, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8477795124053955, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6786/10000, Training Loss: 0.6491198539733887, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9699296951293945, Validation Accuracy: 0.5\n",
      "Epoch 6787/10000, Training Loss: 0.6111614108085632, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7449450492858887, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6788/10000, Training Loss: 0.6648068428039551, Training Accuracy: 0.6421568627450981, Validation Loss: 1.0863181352615356, Validation Accuracy: 0.5\n",
      "Epoch 6789/10000, Training Loss: 0.6965238451957703, Training Accuracy: 0.5612745098039216, Validation Loss: 0.705387532711029, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6790/10000, Training Loss: 0.6190564632415771, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6780549883842468, Validation Accuracy: 0.5\n",
      "Epoch 6791/10000, Training Loss: 0.6782205104827881, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7168712615966797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6792/10000, Training Loss: 0.7037539482116699, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7328024506568909, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6793/10000, Training Loss: 0.6733380556106567, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7815434336662292, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6794/10000, Training Loss: 0.6566171646118164, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6227472424507141, Validation Accuracy: 0.5\n",
      "Epoch 6795/10000, Training Loss: 0.6800290942192078, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0876199007034302, Validation Accuracy: 0.25\n",
      "Epoch 6796/10000, Training Loss: 0.667512059211731, Training Accuracy: 0.5514705882352942, Validation Loss: 0.6436893343925476, Validation Accuracy: 0.5\n",
      "Epoch 6797/10000, Training Loss: 0.6520995497703552, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9211304187774658, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6798/10000, Training Loss: 0.6612783670425415, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6731142401695251, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6799/10000, Training Loss: 0.6750779747962952, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9864006042480469, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6800/10000, Training Loss: 0.7312889099121094, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8590326905250549, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6801/10000, Training Loss: 0.6527961492538452, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8295496106147766, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6802/10000, Training Loss: 0.6477752327919006, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6615902781486511, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6803/10000, Training Loss: 0.637092649936676, Training Accuracy: 0.6446078431372549, Validation Loss: 1.4319254159927368, Validation Accuracy: 0.25\n",
      "Epoch 6804/10000, Training Loss: 0.6541867256164551, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7325565218925476, Validation Accuracy: 0.75\n",
      "Epoch 6805/10000, Training Loss: 0.6623002886772156, Training Accuracy: 0.6666666666666666, Validation Loss: 1.083620548248291, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6806/10000, Training Loss: 0.6605717539787292, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6215881705284119, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6807/10000, Training Loss: 0.6175100803375244, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9245416522026062, Validation Accuracy: 0.25\n",
      "Epoch 6808/10000, Training Loss: 0.660226583480835, Training Accuracy: 0.6323529411764706, Validation Loss: 1.121573805809021, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6809/10000, Training Loss: 0.6255849599838257, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6473830342292786, Validation Accuracy: 0.5\n",
      "Epoch 6810/10000, Training Loss: 0.6838860511779785, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9323484897613525, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6811/10000, Training Loss: 0.6828370690345764, Training Accuracy: 0.6102941176470589, Validation Loss: 0.5775406360626221, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6812/10000, Training Loss: 0.6813997626304626, Training Accuracy: 0.5735294117647058, Validation Loss: 1.2614784240722656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6813/10000, Training Loss: 0.6415155529975891, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0091646909713745, Validation Accuracy: 0.5\n",
      "Epoch 6814/10000, Training Loss: 0.6736600995063782, Training Accuracy: 0.5661764705882353, Validation Loss: 0.808760941028595, Validation Accuracy: 0.5\n",
      "Epoch 6815/10000, Training Loss: 0.6720480918884277, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8533568382263184, Validation Accuracy: 0.5\n",
      "Epoch 6816/10000, Training Loss: 0.6866002678871155, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8540692329406738, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6817/10000, Training Loss: 0.6317299604415894, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9496285319328308, Validation Accuracy: 0.5\n",
      "Epoch 6818/10000, Training Loss: 0.6189337968826294, Training Accuracy: 0.7058823529411765, Validation Loss: 0.5900638699531555, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6819/10000, Training Loss: 0.6291539669036865, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8951037526130676, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6820/10000, Training Loss: 0.648959755897522, Training Accuracy: 0.5882352941176471, Validation Loss: 1.1443438529968262, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6821/10000, Training Loss: 0.6463323831558228, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9405338168144226, Validation Accuracy: 0.25\n",
      "Epoch 6822/10000, Training Loss: 0.6426004767417908, Training Accuracy: 0.6029411764705882, Validation Loss: 0.839212954044342, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6823/10000, Training Loss: 0.6492524147033691, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8818881511688232, Validation Accuracy: 0.75\n",
      "Epoch 6824/10000, Training Loss: 0.6541650295257568, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8790025115013123, Validation Accuracy: 0.5\n",
      "Epoch 6825/10000, Training Loss: 0.6606712937355042, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7876954674720764, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6826/10000, Training Loss: 0.6774049401283264, Training Accuracy: 0.6127450980392157, Validation Loss: 0.790808379650116, Validation Accuracy: 0.25\n",
      "Epoch 6827/10000, Training Loss: 0.6634576916694641, Training Accuracy: 0.6421568627450981, Validation Loss: 0.901597797870636, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6828/10000, Training Loss: 0.704758882522583, Training Accuracy: 0.5367647058823529, Validation Loss: 0.688714325428009, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6829/10000, Training Loss: 0.7248376607894897, Training Accuracy: 0.5073529411764706, Validation Loss: 0.7452839016914368, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6830/10000, Training Loss: 0.6596991419792175, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6971855163574219, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6831/10000, Training Loss: 0.6742870211601257, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9474859833717346, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6832/10000, Training Loss: 0.6975148320198059, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1010252237319946, Validation Accuracy: 0.5\n",
      "Epoch 6833/10000, Training Loss: 0.6628071665763855, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9644827842712402, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6834/10000, Training Loss: 0.6193367838859558, Training Accuracy: 0.6544117647058824, Validation Loss: 0.890582799911499, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6835/10000, Training Loss: 0.6519684195518494, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7997336983680725, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6836/10000, Training Loss: 0.6463373303413391, Training Accuracy: 0.6519607843137255, Validation Loss: 1.2072300910949707, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6837/10000, Training Loss: 0.6429632306098938, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7396411895751953, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6838/10000, Training Loss: 0.6529673933982849, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0326865911483765, Validation Accuracy: 0.25\n",
      "Epoch 6839/10000, Training Loss: 0.6632251143455505, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6621670722961426, Validation Accuracy: 0.5\n",
      "Epoch 6840/10000, Training Loss: 0.6258232593536377, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6846728324890137, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6841/10000, Training Loss: 0.6211408972740173, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6921203136444092, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6842/10000, Training Loss: 0.6621198654174805, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8121129870414734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6843/10000, Training Loss: 0.6409978866577148, Training Accuracy: 0.6078431372549019, Validation Loss: 0.935342013835907, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6844/10000, Training Loss: 0.6481344103813171, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6263822913169861, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6845/10000, Training Loss: 0.6797869801521301, Training Accuracy: 0.571078431372549, Validation Loss: 0.7320426106452942, Validation Accuracy: 0.5\n",
      "Epoch 6846/10000, Training Loss: 0.6915864944458008, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6653529405593872, Validation Accuracy: 0.5\n",
      "Epoch 6847/10000, Training Loss: 0.5906717777252197, Training Accuracy: 0.696078431372549, Validation Loss: 1.6253172159194946, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6848/10000, Training Loss: 0.6514226794242859, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0819038152694702, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6849/10000, Training Loss: 0.6563506722450256, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2238200902938843, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6850/10000, Training Loss: 0.7580186724662781, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7061670422554016, Validation Accuracy: 0.5\n",
      "Epoch 6851/10000, Training Loss: 0.6188077926635742, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7200062870979309, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6852/10000, Training Loss: 0.681928813457489, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9338603615760803, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6853/10000, Training Loss: 0.6779966950416565, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7375667095184326, Validation Accuracy: 0.5\n",
      "Epoch 6854/10000, Training Loss: 0.6704603433609009, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6697672009468079, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6855/10000, Training Loss: 0.6886551976203918, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7147769331932068, Validation Accuracy: 0.5\n",
      "Epoch 6856/10000, Training Loss: 0.6422533988952637, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8028045296669006, Validation Accuracy: 0.5\n",
      "Epoch 6857/10000, Training Loss: 0.6307190656661987, Training Accuracy: 0.678921568627451, Validation Loss: 0.7063297629356384, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6858/10000, Training Loss: 0.6987573504447937, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7295851707458496, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6859/10000, Training Loss: 0.6232044696807861, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7408709526062012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6860/10000, Training Loss: 0.6629360318183899, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6962606310844421, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6861/10000, Training Loss: 0.6700823903083801, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8357989192008972, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6862/10000, Training Loss: 0.6377174258232117, Training Accuracy: 0.6666666666666666, Validation Loss: 1.057207465171814, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6863/10000, Training Loss: 0.6879698038101196, Training Accuracy: 0.6053921568627451, Validation Loss: 0.884954035282135, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6864/10000, Training Loss: 0.6578723788261414, Training Accuracy: 0.6029411764705882, Validation Loss: 0.940218448638916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6865/10000, Training Loss: 0.7294675707817078, Training Accuracy: 0.5024509803921569, Validation Loss: 0.8411958813667297, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6866/10000, Training Loss: 0.6998080015182495, Training Accuracy: 0.5343137254901961, Validation Loss: 0.8622977137565613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6867/10000, Training Loss: 0.6360970139503479, Training Accuracy: 0.6911764705882353, Validation Loss: 0.8918748497962952, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6868/10000, Training Loss: 0.5919143557548523, Training Accuracy: 0.7352941176470589, Validation Loss: 1.0834068059921265, Validation Accuracy: 0.5\n",
      "Epoch 6869/10000, Training Loss: 0.6622259616851807, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8596816658973694, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6870/10000, Training Loss: 0.7360331416130066, Training Accuracy: 0.5171568627450981, Validation Loss: 0.7384480834007263, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6871/10000, Training Loss: 0.6131171584129333, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9737949371337891, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6872/10000, Training Loss: 0.6628119349479675, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7908074259757996, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6873/10000, Training Loss: 0.6681703925132751, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7672738432884216, Validation Accuracy: 0.5\n",
      "Epoch 6874/10000, Training Loss: 0.659873366355896, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9411700367927551, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6875/10000, Training Loss: 0.667630672454834, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8956697583198547, Validation Accuracy: 0.25\n",
      "Epoch 6876/10000, Training Loss: 0.6721728444099426, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6415676474571228, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6877/10000, Training Loss: 0.6230054497718811, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8220908045768738, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6878/10000, Training Loss: 0.6649566888809204, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9272734522819519, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6879/10000, Training Loss: 0.6567820906639099, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7875797748565674, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6880/10000, Training Loss: 0.6502265930175781, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6708188652992249, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6881/10000, Training Loss: 0.6210035681724548, Training Accuracy: 0.678921568627451, Validation Loss: 0.6788952946662903, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6882/10000, Training Loss: 0.7507357597351074, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9345299601554871, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6883/10000, Training Loss: 0.6581387519836426, Training Accuracy: 0.5784313725490197, Validation Loss: 0.5828633904457092, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6884/10000, Training Loss: 0.6499977707862854, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6288321018218994, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6885/10000, Training Loss: 0.616287350654602, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7727773785591125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6886/10000, Training Loss: 0.6709660291671753, Training Accuracy: 0.625, Validation Loss: 0.7145716547966003, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6887/10000, Training Loss: 0.6240116357803345, Training Accuracy: 0.6372549019607843, Validation Loss: 0.624172031879425, Validation Accuracy: 0.75\n",
      "Epoch 6888/10000, Training Loss: 0.6413354277610779, Training Accuracy: 0.6078431372549019, Validation Loss: 1.078577995300293, Validation Accuracy: 0.25\n",
      "Epoch 6889/10000, Training Loss: 0.704730749130249, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8689677715301514, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6890/10000, Training Loss: 0.6705309748649597, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7748663425445557, Validation Accuracy: 0.5\n",
      "Epoch 6891/10000, Training Loss: 0.6580325961112976, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7813234329223633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6892/10000, Training Loss: 0.6699766516685486, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7087347507476807, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6893/10000, Training Loss: 0.6693447232246399, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8304553031921387, Validation Accuracy: 0.5\n",
      "Epoch 6894/10000, Training Loss: 0.6470328569412231, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7337701320648193, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6895/10000, Training Loss: 0.658332347869873, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0347414016723633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6896/10000, Training Loss: 0.6234392523765564, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7256098389625549, Validation Accuracy: 0.5\n",
      "Epoch 6897/10000, Training Loss: 0.6802480220794678, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9201193451881409, Validation Accuracy: 0.5\n",
      "Epoch 6898/10000, Training Loss: 0.6985893249511719, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6811986565589905, Validation Accuracy: 0.5\n",
      "Epoch 6899/10000, Training Loss: 0.7102267146110535, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7572017312049866, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6900/10000, Training Loss: 0.7023846507072449, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7750846743583679, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6901/10000, Training Loss: 0.6773279905319214, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6990836262702942, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6902/10000, Training Loss: 0.6603485345840454, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7035215497016907, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6903/10000, Training Loss: 0.6651171445846558, Training Accuracy: 0.6323529411764706, Validation Loss: 0.5950067639350891, Validation Accuracy: 0.75\n",
      "Epoch 6904/10000, Training Loss: 0.6505364179611206, Training Accuracy: 0.625, Validation Loss: 0.7781972289085388, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6905/10000, Training Loss: 0.6858816742897034, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8619412779808044, Validation Accuracy: 0.5\n",
      "Epoch 6906/10000, Training Loss: 0.6777678728103638, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8362707495689392, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6907/10000, Training Loss: 0.6844428777694702, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0178130865097046, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6908/10000, Training Loss: 0.7038110494613647, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6226749420166016, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6909/10000, Training Loss: 0.6617477536201477, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8396611213684082, Validation Accuracy: 0.5\n",
      "Epoch 6910/10000, Training Loss: 0.6424355506896973, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7622110247612, Validation Accuracy: 0.5\n",
      "Epoch 6911/10000, Training Loss: 0.6380009651184082, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6764641404151917, Validation Accuracy: 0.5\n",
      "Epoch 6912/10000, Training Loss: 0.8422080278396606, Training Accuracy: 0.5637254901960784, Validation Loss: 1.1328915357589722, Validation Accuracy: 0.5\n",
      "Epoch 6913/10000, Training Loss: 0.6743557453155518, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9975555539131165, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6914/10000, Training Loss: 0.6590470671653748, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8491165637969971, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6915/10000, Training Loss: 0.6275320649147034, Training Accuracy: 0.6421568627450981, Validation Loss: 1.0456693172454834, Validation Accuracy: 0.5\n",
      "Epoch 6916/10000, Training Loss: 0.6093305349349976, Training Accuracy: 0.7107843137254902, Validation Loss: 0.6959980130195618, Validation Accuracy: 0.5\n",
      "Epoch 6917/10000, Training Loss: 0.6409388780593872, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7152884602546692, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6918/10000, Training Loss: 0.6865541338920593, Training Accuracy: 0.5490196078431373, Validation Loss: 0.7653233408927917, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6919/10000, Training Loss: 0.6874905824661255, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8674339652061462, Validation Accuracy: 0.5\n",
      "Epoch 6920/10000, Training Loss: 0.6224144101142883, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0624711513519287, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6921/10000, Training Loss: 0.6334609985351562, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8550403118133545, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6922/10000, Training Loss: 0.6913838386535645, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7938632965087891, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6923/10000, Training Loss: 0.6491730809211731, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6285939812660217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6924/10000, Training Loss: 0.7009299993515015, Training Accuracy: 0.5294117647058824, Validation Loss: 0.9859097003936768, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6925/10000, Training Loss: 0.664400041103363, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8833732604980469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6926/10000, Training Loss: 0.7037733197212219, Training Accuracy: 0.553921568627451, Validation Loss: 0.7827315926551819, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6927/10000, Training Loss: 0.679442822933197, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8861110806465149, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6928/10000, Training Loss: 0.6508451700210571, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7262976765632629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6929/10000, Training Loss: 0.7010476589202881, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7176058888435364, Validation Accuracy: 0.5\n",
      "Epoch 6930/10000, Training Loss: 0.7427207827568054, Training Accuracy: 0.5441176470588235, Validation Loss: 0.5436618328094482, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6931/10000, Training Loss: 0.6698996424674988, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7693647742271423, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6932/10000, Training Loss: 0.6949257254600525, Training Accuracy: 0.5906862745098039, Validation Loss: 0.897885799407959, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6933/10000, Training Loss: 0.621910572052002, Training Accuracy: 0.6446078431372549, Validation Loss: 1.221068024635315, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6934/10000, Training Loss: 0.6811776161193848, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8295750021934509, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6935/10000, Training Loss: 0.6434553265571594, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7723159790039062, Validation Accuracy: 0.5\n",
      "Epoch 6936/10000, Training Loss: 0.6703910827636719, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0621250867843628, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6937/10000, Training Loss: 0.6010227799415588, Training Accuracy: 0.6838235294117647, Validation Loss: 1.0644017457962036, Validation Accuracy: 0.5\n",
      "Epoch 6938/10000, Training Loss: 0.6514708399772644, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7187995910644531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6939/10000, Training Loss: 0.6448790431022644, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7934555411338806, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6940/10000, Training Loss: 0.6570018529891968, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7234591841697693, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6941/10000, Training Loss: 0.6688313484191895, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7297640442848206, Validation Accuracy: 0.5\n",
      "Epoch 6942/10000, Training Loss: 0.6357154250144958, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1376198530197144, Validation Accuracy: 0.5\n",
      "Epoch 6943/10000, Training Loss: 0.6649990677833557, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7591495513916016, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6944/10000, Training Loss: 0.6786726117134094, Training Accuracy: 0.5686274509803921, Validation Loss: 0.841644823551178, Validation Accuracy: 0.25\n",
      "Epoch 6945/10000, Training Loss: 0.6685954928398132, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6891923546791077, Validation Accuracy: 0.5\n",
      "Epoch 6946/10000, Training Loss: 0.6643268465995789, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7620366215705872, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6947/10000, Training Loss: 0.6302824020385742, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8200531005859375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6948/10000, Training Loss: 0.6589778661727905, Training Accuracy: 0.571078431372549, Validation Loss: 0.644491970539093, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6949/10000, Training Loss: 0.6819844245910645, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9715145230293274, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6950/10000, Training Loss: 0.6326923966407776, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8531954288482666, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6951/10000, Training Loss: 0.6642765998840332, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7131736278533936, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6952/10000, Training Loss: 0.6452289819717407, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7279877066612244, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6953/10000, Training Loss: 0.6613729596138, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7659109234809875, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6954/10000, Training Loss: 0.6544189453125, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8575090765953064, Validation Accuracy: 0.25\n",
      "Epoch 6955/10000, Training Loss: 0.6968663334846497, Training Accuracy: 0.5612745098039216, Validation Loss: 0.629628598690033, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6956/10000, Training Loss: 0.6726107001304626, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8580994606018066, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6957/10000, Training Loss: 0.6775340437889099, Training Accuracy: 0.5833333333333334, Validation Loss: 1.039322018623352, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6958/10000, Training Loss: 0.6733720302581787, Training Accuracy: 0.5955882352941176, Validation Loss: 0.5385406613349915, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6959/10000, Training Loss: 0.6916730403900146, Training Accuracy: 0.5416666666666666, Validation Loss: 0.9848005771636963, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6960/10000, Training Loss: 0.6457487344741821, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1633542776107788, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6961/10000, Training Loss: 0.7018157839775085, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7872676253318787, Validation Accuracy: 0.25\n",
      "Epoch 6962/10000, Training Loss: 0.6878330111503601, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8328225016593933, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6963/10000, Training Loss: 0.7155556678771973, Training Accuracy: 0.553921568627451, Validation Loss: 0.7140140533447266, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6964/10000, Training Loss: 0.6935486197471619, Training Accuracy: 0.5343137254901961, Validation Loss: 0.9692500233650208, Validation Accuracy: 0.25\n",
      "Epoch 6965/10000, Training Loss: 0.6574918627738953, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7098743319511414, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6966/10000, Training Loss: 0.7782152891159058, Training Accuracy: 0.4877450980392157, Validation Loss: 0.9496540427207947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6967/10000, Training Loss: 0.7467076182365417, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7224125862121582, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6968/10000, Training Loss: 0.6542863249778748, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7812859416007996, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6969/10000, Training Loss: 0.6808709502220154, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9169662594795227, Validation Accuracy: 0.5\n",
      "Epoch 6970/10000, Training Loss: 0.6597342491149902, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9717616438865662, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6971/10000, Training Loss: 0.7011380195617676, Training Accuracy: 0.6029411764705882, Validation Loss: 0.764129638671875, Validation Accuracy: 0.5\n",
      "Epoch 6972/10000, Training Loss: 0.670540988445282, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8430009484291077, Validation Accuracy: 0.25\n",
      "Epoch 6973/10000, Training Loss: 0.6436488628387451, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7470213770866394, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6974/10000, Training Loss: 0.6698873043060303, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7701549530029297, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6975/10000, Training Loss: 0.693872332572937, Training Accuracy: 0.5441176470588235, Validation Loss: 0.78694748878479, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6976/10000, Training Loss: 0.6300520300865173, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9139966368675232, Validation Accuracy: 0.5\n",
      "Epoch 6977/10000, Training Loss: 0.699397087097168, Training Accuracy: 0.5882352941176471, Validation Loss: 0.5663430094718933, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6978/10000, Training Loss: 0.6910929679870605, Training Accuracy: 0.5906862745098039, Validation Loss: 0.902383029460907, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6979/10000, Training Loss: 0.6695709228515625, Training Accuracy: 0.5857843137254902, Validation Loss: 0.5702559947967529, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6980/10000, Training Loss: 0.7119795680046082, Training Accuracy: 0.6764705882352942, Validation Loss: 1.4456524848937988, Validation Accuracy: 0.25\n",
      "Epoch 6981/10000, Training Loss: 0.6511664986610413, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6438674330711365, Validation Accuracy: 0.5\n",
      "Epoch 6982/10000, Training Loss: 0.6787065863609314, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7073707580566406, Validation Accuracy: 0.5\n",
      "Epoch 6983/10000, Training Loss: 0.649100661277771, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7064380049705505, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6984/10000, Training Loss: 0.6591225266456604, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8309090733528137, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6985/10000, Training Loss: 0.695018470287323, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6355293393135071, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6986/10000, Training Loss: 0.6590664982795715, Training Accuracy: 0.6127450980392157, Validation Loss: 0.642909824848175, Validation Accuracy: 0.5\n",
      "Epoch 6987/10000, Training Loss: 0.7265778183937073, Training Accuracy: 0.5318627450980392, Validation Loss: 0.5960648059844971, Validation Accuracy: 0.75\n",
      "Epoch 6988/10000, Training Loss: 0.6471638679504395, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8872013688087463, Validation Accuracy: 0.5\n",
      "Epoch 6989/10000, Training Loss: 0.6593207716941833, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7747933268547058, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 6990/10000, Training Loss: 0.6473788619041443, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8030804991722107, Validation Accuracy: 0.25\n",
      "Epoch 6991/10000, Training Loss: 0.6999490261077881, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6632108092308044, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6992/10000, Training Loss: 0.6961974501609802, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6804240345954895, Validation Accuracy: 0.5\n",
      "Epoch 6993/10000, Training Loss: 0.6478320956230164, Training Accuracy: 0.6568627450980392, Validation Loss: 1.1700319051742554, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 6994/10000, Training Loss: 0.627996563911438, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6652975678443909, Validation Accuracy: 0.5\n",
      "Epoch 6995/10000, Training Loss: 0.6068189144134521, Training Accuracy: 0.6495098039215687, Validation Loss: 0.5690189599990845, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 6996/10000, Training Loss: 0.6931440830230713, Training Accuracy: 0.553921568627451, Validation Loss: 0.6538861989974976, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 6997/10000, Training Loss: 0.6470943689346313, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8189678192138672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 6998/10000, Training Loss: 0.6436010003089905, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6775462031364441, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 6999/10000, Training Loss: 0.6630635261535645, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9470956921577454, Validation Accuracy: 0.25\n",
      "Epoch 7000/10000, Training Loss: 0.6289478540420532, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9339707493782043, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7001/10000, Training Loss: 0.6273641586303711, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8246126174926758, Validation Accuracy: 0.5\n",
      "Epoch 7002/10000, Training Loss: 0.6668630242347717, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8134141564369202, Validation Accuracy: 0.25\n",
      "Epoch 7003/10000, Training Loss: 0.6885063052177429, Training Accuracy: 0.5735294117647058, Validation Loss: 1.0258032083511353, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7004/10000, Training Loss: 0.6891201734542847, Training Accuracy: 0.5686274509803921, Validation Loss: 1.1305536031723022, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7005/10000, Training Loss: 0.6595656275749207, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9216756820678711, Validation Accuracy: 0.5\n",
      "Epoch 7006/10000, Training Loss: 0.633478581905365, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9655917286872864, Validation Accuracy: 0.25\n",
      "Epoch 7007/10000, Training Loss: 0.6647946238517761, Training Accuracy: 0.5367647058823529, Validation Loss: 0.6285008788108826, Validation Accuracy: 0.75\n",
      "Epoch 7008/10000, Training Loss: 0.5842466354370117, Training Accuracy: 0.7132352941176471, Validation Loss: 1.019205927848816, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7009/10000, Training Loss: 0.7213281989097595, Training Accuracy: 0.5196078431372549, Validation Loss: 0.6765734553337097, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7010/10000, Training Loss: 0.6501119136810303, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9144951701164246, Validation Accuracy: 0.5\n",
      "Epoch 7011/10000, Training Loss: 0.6560713648796082, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7202902436256409, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7012/10000, Training Loss: 0.6404918432235718, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9648735523223877, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7013/10000, Training Loss: 0.666914165019989, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8639624714851379, Validation Accuracy: 0.25\n",
      "Epoch 7014/10000, Training Loss: 0.6458892822265625, Training Accuracy: 0.6568627450980392, Validation Loss: 0.808053195476532, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7015/10000, Training Loss: 0.6932408809661865, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8659074902534485, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7016/10000, Training Loss: 0.6913475394248962, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7941610217094421, Validation Accuracy: 0.5\n",
      "Epoch 7017/10000, Training Loss: 0.687086284160614, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7328246235847473, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7018/10000, Training Loss: 0.6962135434150696, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1593852043151855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7019/10000, Training Loss: 0.6864659786224365, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9037031531333923, Validation Accuracy: 0.25\n",
      "Epoch 7020/10000, Training Loss: 0.656055748462677, Training Accuracy: 0.6397058823529411, Validation Loss: 0.647606372833252, Validation Accuracy: 0.75\n",
      "Epoch 7021/10000, Training Loss: 0.6086645722389221, Training Accuracy: 0.6642156862745098, Validation Loss: 0.97804194688797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7022/10000, Training Loss: 0.7018277645111084, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6116334199905396, Validation Accuracy: 0.5\n",
      "Epoch 7023/10000, Training Loss: 0.6337556838989258, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7678213119506836, Validation Accuracy: 0.5\n",
      "Epoch 7024/10000, Training Loss: 0.662909209728241, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7104997038841248, Validation Accuracy: 0.75\n",
      "Epoch 7025/10000, Training Loss: 0.6475889682769775, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9238662123680115, Validation Accuracy: 0.5\n",
      "Epoch 7026/10000, Training Loss: 0.7295174598693848, Training Accuracy: 0.5490196078431373, Validation Loss: 1.0849924087524414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7027/10000, Training Loss: 0.6411837339401245, Training Accuracy: 0.6544117647058824, Validation Loss: 1.0706983804702759, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 7028/10000, Training Loss: 0.6444752812385559, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0115550756454468, Validation Accuracy: 0.5\n",
      "Epoch 7029/10000, Training Loss: 0.6439772248268127, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7758072018623352, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7030/10000, Training Loss: 0.6909616589546204, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7515678405761719, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7031/10000, Training Loss: 0.6932649612426758, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9390332698822021, Validation Accuracy: 0.5\n",
      "Epoch 7032/10000, Training Loss: 0.6689860224723816, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6836804747581482, Validation Accuracy: 0.5\n",
      "Epoch 7033/10000, Training Loss: 0.6760350465774536, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7679560780525208, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7034/10000, Training Loss: 0.607537567615509, Training Accuracy: 0.6887254901960784, Validation Loss: 0.9493429064750671, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7035/10000, Training Loss: 0.6685045957565308, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7302778363227844, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7036/10000, Training Loss: 0.6648589372634888, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6522037386894226, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7037/10000, Training Loss: 0.6911913752555847, Training Accuracy: 0.5637254901960784, Validation Loss: 0.6019194722175598, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7038/10000, Training Loss: 0.6648856997489929, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8952963948249817, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7039/10000, Training Loss: 0.6043047904968262, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9208201766014099, Validation Accuracy: 0.25\n",
      "Epoch 7040/10000, Training Loss: 0.6253248453140259, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6499364376068115, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7041/10000, Training Loss: 0.6545976400375366, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7892675399780273, Validation Accuracy: 0.5\n",
      "Epoch 7042/10000, Training Loss: 0.721111536026001, Training Accuracy: 0.5024509803921569, Validation Loss: 0.6900720596313477, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7043/10000, Training Loss: 0.629543125629425, Training Accuracy: 0.6470588235294118, Validation Loss: 0.671358585357666, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7044/10000, Training Loss: 0.651050865650177, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7396312355995178, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7045/10000, Training Loss: 0.647852897644043, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8658443093299866, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7046/10000, Training Loss: 0.6825396418571472, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8155887722969055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7047/10000, Training Loss: 0.6979438662528992, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7204602360725403, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7048/10000, Training Loss: 0.6335248947143555, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7795889377593994, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7049/10000, Training Loss: 0.6651585698127747, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8681668639183044, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7050/10000, Training Loss: 0.660062849521637, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7147948145866394, Validation Accuracy: 0.5\n",
      "Epoch 7051/10000, Training Loss: 0.6652001142501831, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8024575710296631, Validation Accuracy: 0.25\n",
      "Epoch 7052/10000, Training Loss: 0.6398489475250244, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8388726711273193, Validation Accuracy: 0.25\n",
      "Epoch 7053/10000, Training Loss: 0.627535879611969, Training Accuracy: 0.6593137254901961, Validation Loss: 0.801285982131958, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7054/10000, Training Loss: 0.7041907906532288, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7181290984153748, Validation Accuracy: 0.5\n",
      "Epoch 7055/10000, Training Loss: 0.6707317233085632, Training Accuracy: 0.5955882352941176, Validation Loss: 0.706915557384491, Validation Accuracy: 0.5\n",
      "Epoch 7056/10000, Training Loss: 0.6407855749130249, Training Accuracy: 0.5661764705882353, Validation Loss: 0.645491898059845, Validation Accuracy: 0.75\n",
      "Epoch 7057/10000, Training Loss: 0.6362082362174988, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9418142437934875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7058/10000, Training Loss: 0.6513205766677856, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9125483632087708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7059/10000, Training Loss: 0.6932478547096252, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6534457802772522, Validation Accuracy: 0.75\n",
      "Epoch 7060/10000, Training Loss: 0.6469022631645203, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7828289866447449, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7061/10000, Training Loss: 0.7014603018760681, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7776877880096436, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7062/10000, Training Loss: 0.6880599856376648, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7249755263328552, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7063/10000, Training Loss: 0.6141139268875122, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9488024115562439, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7064/10000, Training Loss: 0.6162434816360474, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8348525166511536, Validation Accuracy: 0.25\n",
      "Epoch 7065/10000, Training Loss: 0.6941554546356201, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1407057046890259, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7066/10000, Training Loss: 0.6265628933906555, Training Accuracy: 0.6397058823529411, Validation Loss: 0.732806921005249, Validation Accuracy: 0.5\n",
      "Epoch 7067/10000, Training Loss: 0.6813515424728394, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9112982749938965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7068/10000, Training Loss: 0.6648638844490051, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7545122504234314, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7069/10000, Training Loss: 0.687536358833313, Training Accuracy: 0.5416666666666666, Validation Loss: 0.6637679934501648, Validation Accuracy: 0.5\n",
      "Epoch 7070/10000, Training Loss: 0.6841375827789307, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9881467819213867, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 7071/10000, Training Loss: 0.6567845344543457, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7376553416252136, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7072/10000, Training Loss: 0.6032188534736633, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7599701285362244, Validation Accuracy: 0.5\n",
      "Epoch 7073/10000, Training Loss: 0.6265161633491516, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7190254330635071, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7074/10000, Training Loss: 0.6246207356452942, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7709119915962219, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7075/10000, Training Loss: 0.6724244952201843, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7843782305717468, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7076/10000, Training Loss: 0.7371612191200256, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7209806442260742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7077/10000, Training Loss: 0.6349009275436401, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6921865940093994, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7078/10000, Training Loss: 0.6517140865325928, Training Accuracy: 0.5759803921568627, Validation Loss: 0.577653169631958, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7079/10000, Training Loss: 0.6796694993972778, Training Accuracy: 0.5269607843137255, Validation Loss: 0.5348690152168274, Validation Accuracy: 0.75\n",
      "Epoch 7080/10000, Training Loss: 0.6512981653213501, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9431875348091125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7081/10000, Training Loss: 0.6798206567764282, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8343460559844971, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7082/10000, Training Loss: 0.6362963914871216, Training Accuracy: 0.6102941176470589, Validation Loss: 0.78177809715271, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7083/10000, Training Loss: 0.7044718265533447, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8292510509490967, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7084/10000, Training Loss: 0.6616899967193604, Training Accuracy: 0.6151960784313726, Validation Loss: 1.1530905961990356, Validation Accuracy: 0.25\n",
      "Epoch 7085/10000, Training Loss: 0.667900025844574, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7857866883277893, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7086/10000, Training Loss: 0.6619668006896973, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7333304286003113, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7087/10000, Training Loss: 0.6580809950828552, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8535206317901611, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7088/10000, Training Loss: 0.6551510095596313, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8027594089508057, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7089/10000, Training Loss: 0.6765918135643005, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7225301861763, Validation Accuracy: 0.5\n",
      "Epoch 7090/10000, Training Loss: 0.6838889122009277, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8412465453147888, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7091/10000, Training Loss: 0.6440725326538086, Training Accuracy: 0.625, Validation Loss: 0.650382936000824, Validation Accuracy: 0.5\n",
      "Epoch 7092/10000, Training Loss: 0.6184071898460388, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8106786608695984, Validation Accuracy: 0.5\n",
      "Epoch 7093/10000, Training Loss: 0.6879189610481262, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9457979798316956, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7094/10000, Training Loss: 0.705712616443634, Training Accuracy: 0.5882352941176471, Validation Loss: 0.591408908367157, Validation Accuracy: 0.75\n",
      "Epoch 7095/10000, Training Loss: 0.702074408531189, Training Accuracy: 0.5784313725490197, Validation Loss: 0.725553572177887, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7096/10000, Training Loss: 0.6567263007164001, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6877469420433044, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7097/10000, Training Loss: 0.6741447448730469, Training Accuracy: 0.553921568627451, Validation Loss: 0.617030918598175, Validation Accuracy: 0.5\n",
      "Epoch 7098/10000, Training Loss: 0.6637077927589417, Training Accuracy: 0.5833333333333334, Validation Loss: 0.712088406085968, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7099/10000, Training Loss: 0.6892325282096863, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7229415774345398, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7100/10000, Training Loss: 0.6614162921905518, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8947827219963074, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7101/10000, Training Loss: 0.6412920951843262, Training Accuracy: 0.6348039215686274, Validation Loss: 1.2616147994995117, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7102/10000, Training Loss: 0.6711372137069702, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6962592601776123, Validation Accuracy: 0.5\n",
      "Epoch 7103/10000, Training Loss: 0.6799564957618713, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6562355160713196, Validation Accuracy: 0.75\n",
      "Epoch 7104/10000, Training Loss: 0.6817715167999268, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0171712636947632, Validation Accuracy: 0.5\n",
      "Epoch 7105/10000, Training Loss: 0.6732355952262878, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7558299899101257, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7106/10000, Training Loss: 0.6607862114906311, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6391458511352539, Validation Accuracy: 0.5\n",
      "Epoch 7107/10000, Training Loss: 0.6337800621986389, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8570111393928528, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7108/10000, Training Loss: 0.6602334380149841, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6146027445793152, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7109/10000, Training Loss: 0.6393892765045166, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7474678158760071, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7110/10000, Training Loss: 0.6688814163208008, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7673099040985107, Validation Accuracy: 0.25\n",
      "Epoch 7111/10000, Training Loss: 0.660401463508606, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7636006474494934, Validation Accuracy: 0.5\n",
      "Epoch 7112/10000, Training Loss: 0.6648574471473694, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9639881253242493, Validation Accuracy: 0.25\n",
      "Epoch 7113/10000, Training Loss: 0.6592361330986023, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9298927187919617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7114/10000, Training Loss: 0.6638717651367188, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6257790923118591, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7115/10000, Training Loss: 0.6720239520072937, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8885753750801086, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7116/10000, Training Loss: 0.7069578170776367, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7237187027931213, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7117/10000, Training Loss: 0.6134933233261108, Training Accuracy: 0.678921568627451, Validation Loss: 0.651715099811554, Validation Accuracy: 0.5\n",
      "Epoch 7118/10000, Training Loss: 0.6715410947799683, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6690037250518799, Validation Accuracy: 0.5\n",
      "Epoch 7119/10000, Training Loss: 0.7301515936851501, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8186058402061462, Validation Accuracy: 0.5\n",
      "Epoch 7120/10000, Training Loss: 0.6712420582771301, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7699187397956848, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7121/10000, Training Loss: 0.6412966251373291, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0708636045455933, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7122/10000, Training Loss: 0.6632930040359497, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6921067833900452, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7123/10000, Training Loss: 0.6689584255218506, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6340527534484863, Validation Accuracy: 0.5\n",
      "Epoch 7124/10000, Training Loss: 0.6704023480415344, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7675278782844543, Validation Accuracy: 0.5\n",
      "Epoch 7125/10000, Training Loss: 0.6313967704772949, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7707891464233398, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7126/10000, Training Loss: 0.6398491859436035, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8084654211997986, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7127/10000, Training Loss: 0.6272661685943604, Training Accuracy: 0.6740196078431373, Validation Loss: 1.0434272289276123, Validation Accuracy: 0.5\n",
      "Epoch 7128/10000, Training Loss: 0.652908980846405, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7479667663574219, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7129/10000, Training Loss: 0.7058796882629395, Training Accuracy: 0.5637254901960784, Validation Loss: 1.234697699546814, Validation Accuracy: 0.25\n",
      "Epoch 7130/10000, Training Loss: 0.6947450041770935, Training Accuracy: 0.553921568627451, Validation Loss: 0.8333485126495361, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7131/10000, Training Loss: 0.692854642868042, Training Accuracy: 0.5441176470588235, Validation Loss: 0.8875142931938171, Validation Accuracy: 0.5\n",
      "Epoch 7132/10000, Training Loss: 0.6670085191726685, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7233597636222839, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7133/10000, Training Loss: 0.6988360285758972, Training Accuracy: 0.6200980392156863, Validation Loss: 0.855668842792511, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7134/10000, Training Loss: 0.7142626643180847, Training Accuracy: 0.6004901960784313, Validation Loss: 0.5697188973426819, Validation Accuracy: 0.75\n",
      "Epoch 7135/10000, Training Loss: 0.6667565107345581, Training Accuracy: 0.6078431372549019, Validation Loss: 0.850368320941925, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7136/10000, Training Loss: 0.7259970903396606, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0506749153137207, Validation Accuracy: 0.5\n",
      "Epoch 7137/10000, Training Loss: 0.7053917050361633, Training Accuracy: 0.5514705882352942, Validation Loss: 0.5531969666481018, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7138/10000, Training Loss: 0.6688302755355835, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9621696472167969, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7139/10000, Training Loss: 0.6830339431762695, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6203468441963196, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7140/10000, Training Loss: 0.643959105014801, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7356162071228027, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7141/10000, Training Loss: 0.6339084506034851, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9524548649787903, Validation Accuracy: 0.5\n",
      "Epoch 7142/10000, Training Loss: 0.6861781477928162, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6645823121070862, Validation Accuracy: 0.5\n",
      "Epoch 7143/10000, Training Loss: 0.6983950734138489, Training Accuracy: 0.5343137254901961, Validation Loss: 0.6858115792274475, Validation Accuracy: 0.5\n",
      "Epoch 7144/10000, Training Loss: 0.6676589846611023, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8738517761230469, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7145/10000, Training Loss: 0.6182458400726318, Training Accuracy: 0.678921568627451, Validation Loss: 0.8655470013618469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7146/10000, Training Loss: 0.6458041071891785, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7164255976676941, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7147/10000, Training Loss: 0.6597593426704407, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8675193786621094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7148/10000, Training Loss: 0.6687201857566833, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7834497094154358, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7149/10000, Training Loss: 0.6389579176902771, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1061409711837769, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7150/10000, Training Loss: 0.6857746839523315, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8044064044952393, Validation Accuracy: 0.5\n",
      "Epoch 7151/10000, Training Loss: 0.6572274565696716, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7560202479362488, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7152/10000, Training Loss: 0.6567797660827637, Training Accuracy: 0.6593137254901961, Validation Loss: 0.784094512462616, Validation Accuracy: 0.5\n",
      "Epoch 7153/10000, Training Loss: 0.6499754786491394, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8101289868354797, Validation Accuracy: 0.5\n",
      "Epoch 7154/10000, Training Loss: 0.6464233994483948, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7398662567138672, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7155/10000, Training Loss: 0.6368200778961182, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8724340796470642, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7156/10000, Training Loss: 0.6455032229423523, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8750961422920227, Validation Accuracy: 0.25\n",
      "Epoch 7157/10000, Training Loss: 0.7179291844367981, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7805569767951965, Validation Accuracy: 0.5\n",
      "Epoch 7158/10000, Training Loss: 0.6287034749984741, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7523459792137146, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7159/10000, Training Loss: 0.695661187171936, Training Accuracy: 0.5416666666666666, Validation Loss: 1.0458070039749146, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7160/10000, Training Loss: 0.6542232632637024, Training Accuracy: 0.678921568627451, Validation Loss: 0.700447142124176, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7161/10000, Training Loss: 0.6791765093803406, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7709416747093201, Validation Accuracy: 0.25\n",
      "Epoch 7162/10000, Training Loss: 0.6166642308235168, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8492644429206848, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7163/10000, Training Loss: 0.6700899004936218, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6764124035835266, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7164/10000, Training Loss: 0.6436169147491455, Training Accuracy: 0.6053921568627451, Validation Loss: 0.993070125579834, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7165/10000, Training Loss: 0.685861349105835, Training Accuracy: 0.6225490196078431, Validation Loss: 0.812858521938324, Validation Accuracy: 0.5\n",
      "Epoch 7166/10000, Training Loss: 0.7330002188682556, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8714439272880554, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7167/10000, Training Loss: 0.708844780921936, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9107803702354431, Validation Accuracy: 0.25\n",
      "Epoch 7168/10000, Training Loss: 0.672881543636322, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8510164618492126, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7169/10000, Training Loss: 0.6275681257247925, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7850213646888733, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7170/10000, Training Loss: 0.629542350769043, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7182573676109314, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7171/10000, Training Loss: 0.6175003051757812, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1740363836288452, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7172/10000, Training Loss: 0.6742721199989319, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7715975642204285, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7173/10000, Training Loss: 0.6142479181289673, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8053221106529236, Validation Accuracy: 0.5\n",
      "Epoch 7174/10000, Training Loss: 0.6134567260742188, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8794460296630859, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7175/10000, Training Loss: 0.6445838212966919, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8726964592933655, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7176/10000, Training Loss: 0.6168688535690308, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9516420364379883, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7177/10000, Training Loss: 0.6771997213363647, Training Accuracy: 0.6029411764705882, Validation Loss: 0.5129358172416687, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 7178/10000, Training Loss: 0.6111204028129578, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6304337978363037, Validation Accuracy: 0.5\n",
      "Epoch 7179/10000, Training Loss: 0.6641815304756165, Training Accuracy: 0.6421568627450981, Validation Loss: 1.0409692525863647, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7180/10000, Training Loss: 0.6948878765106201, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7352306246757507, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7181/10000, Training Loss: 0.6808269619941711, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8106507658958435, Validation Accuracy: 0.5\n",
      "Epoch 7182/10000, Training Loss: 0.7097001075744629, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1350244283676147, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7183/10000, Training Loss: 0.6509408950805664, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7746580243110657, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7184/10000, Training Loss: 0.6412881016731262, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6332893371582031, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7185/10000, Training Loss: 0.6641550064086914, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9800379872322083, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7186/10000, Training Loss: 0.659324049949646, Training Accuracy: 0.6127450980392157, Validation Loss: 0.567937970161438, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7187/10000, Training Loss: 0.6167747378349304, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0349763631820679, Validation Accuracy: 0.5\n",
      "Epoch 7188/10000, Training Loss: 0.6239368915557861, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9878013730049133, Validation Accuracy: 0.25\n",
      "Epoch 7189/10000, Training Loss: 0.6581207513809204, Training Accuracy: 0.6078431372549019, Validation Loss: 0.865591824054718, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7190/10000, Training Loss: 0.63362717628479, Training Accuracy: 0.6372549019607843, Validation Loss: 0.876439094543457, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7191/10000, Training Loss: 0.6516154408454895, Training Accuracy: 0.5808823529411765, Validation Loss: 0.648949921131134, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7192/10000, Training Loss: 0.6265352368354797, Training Accuracy: 0.6862745098039216, Validation Loss: 1.352005958557129, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7193/10000, Training Loss: 0.6669854521751404, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7563953995704651, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7194/10000, Training Loss: 0.6698781251907349, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7364359498023987, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7195/10000, Training Loss: 0.5980884432792664, Training Accuracy: 0.6936274509803921, Validation Loss: 1.1812231540679932, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7196/10000, Training Loss: 0.769598662853241, Training Accuracy: 0.5637254901960784, Validation Loss: 0.7724427580833435, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7197/10000, Training Loss: 0.695331335067749, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7464897632598877, Validation Accuracy: 0.5\n",
      "Epoch 7198/10000, Training Loss: 0.6901809573173523, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0351170301437378, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7199/10000, Training Loss: 0.6772419214248657, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7039499282836914, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7200/10000, Training Loss: 0.6654574275016785, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7149372696876526, Validation Accuracy: 0.5\n",
      "Epoch 7201/10000, Training Loss: 0.6611090302467346, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0018683671951294, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7202/10000, Training Loss: 0.659504234790802, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7630100250244141, Validation Accuracy: 0.5\n",
      "Epoch 7203/10000, Training Loss: 0.6561967730522156, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6594563126564026, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7204/10000, Training Loss: 0.6754180788993835, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7373235821723938, Validation Accuracy: 0.5\n",
      "Epoch 7205/10000, Training Loss: 0.6589590907096863, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8426408171653748, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7206/10000, Training Loss: 0.6553402543067932, Training Accuracy: 0.6151960784313726, Validation Loss: 0.756089985370636, Validation Accuracy: 0.5\n",
      "Epoch 7207/10000, Training Loss: 0.6718554496765137, Training Accuracy: 0.625, Validation Loss: 0.9442927837371826, Validation Accuracy: 0.25\n",
      "Epoch 7208/10000, Training Loss: 0.6787534356117249, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0506561994552612, Validation Accuracy: 0.5\n",
      "Epoch 7209/10000, Training Loss: 0.673973023891449, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7502375245094299, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7210/10000, Training Loss: 0.656522274017334, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0216890573501587, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7211/10000, Training Loss: 0.6960151791572571, Training Accuracy: 0.6053921568627451, Validation Loss: 0.743377149105072, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7212/10000, Training Loss: 0.5989583134651184, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0779527425765991, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7213/10000, Training Loss: 0.6586072444915771, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7679665684700012, Validation Accuracy: 0.5\n",
      "Epoch 7214/10000, Training Loss: 0.6899768710136414, Training Accuracy: 0.6127450980392157, Validation Loss: 0.770489513874054, Validation Accuracy: 0.5\n",
      "Epoch 7215/10000, Training Loss: 0.6591153740882874, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9801692962646484, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7216/10000, Training Loss: 0.591199517250061, Training Accuracy: 0.7107843137254902, Validation Loss: 0.9054250717163086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7217/10000, Training Loss: 0.6561285853385925, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6746568083763123, Validation Accuracy: 0.5\n",
      "Epoch 7218/10000, Training Loss: 0.7024121880531311, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8309833407402039, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7219/10000, Training Loss: 0.6555743217468262, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0830146074295044, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7220/10000, Training Loss: 0.6789963841438293, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7455694079399109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7221/10000, Training Loss: 0.6182616949081421, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8136126399040222, Validation Accuracy: 0.5\n",
      "Epoch 7222/10000, Training Loss: 0.6313276290893555, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8732044696807861, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7223/10000, Training Loss: 0.6284346580505371, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8140934109687805, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7224/10000, Training Loss: 0.6545337438583374, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7398295402526855, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7225/10000, Training Loss: 0.6271044611930847, Training Accuracy: 0.6568627450980392, Validation Loss: 0.801149845123291, Validation Accuracy: 0.5\n",
      "Epoch 7226/10000, Training Loss: 0.6841928362846375, Training Accuracy: 0.553921568627451, Validation Loss: 0.6885554790496826, Validation Accuracy: 0.5\n",
      "Epoch 7227/10000, Training Loss: 0.7231078147888184, Training Accuracy: 0.5514705882352942, Validation Loss: 0.8259535431861877, Validation Accuracy: 0.5\n",
      "Epoch 7228/10000, Training Loss: 0.648449182510376, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9909678101539612, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7229/10000, Training Loss: 0.6348366737365723, Training Accuracy: 0.6299019607843137, Validation Loss: 0.655149519443512, Validation Accuracy: 0.75\n",
      "Epoch 7230/10000, Training Loss: 0.6946640610694885, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6557952761650085, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7231/10000, Training Loss: 0.6880291104316711, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6355041861534119, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7232/10000, Training Loss: 0.6938198208808899, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7648809552192688, Validation Accuracy: 0.25\n",
      "Epoch 7233/10000, Training Loss: 0.6368696689605713, Training Accuracy: 0.6446078431372549, Validation Loss: 1.1954864263534546, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7234/10000, Training Loss: 0.6910718083381653, Training Accuracy: 0.5808823529411765, Validation Loss: 0.9282845854759216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7235/10000, Training Loss: 0.6634265780448914, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7524309754371643, Validation Accuracy: 0.5\n",
      "Epoch 7236/10000, Training Loss: 0.6540635228157043, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7771386504173279, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7237/10000, Training Loss: 0.6459521055221558, Training Accuracy: 0.625, Validation Loss: 0.652758777141571, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7238/10000, Training Loss: 0.67148357629776, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7528135180473328, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7239/10000, Training Loss: 0.6525515913963318, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7458546757698059, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7240/10000, Training Loss: 0.6548207402229309, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8914900422096252, Validation Accuracy: 0.5\n",
      "Epoch 7241/10000, Training Loss: 0.670001208782196, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9667269587516785, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7242/10000, Training Loss: 0.660772442817688, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8266469836235046, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7243/10000, Training Loss: 0.7006282210350037, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9169889092445374, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7244/10000, Training Loss: 0.6438083052635193, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8300237059593201, Validation Accuracy: 0.5\n",
      "Epoch 7245/10000, Training Loss: 0.7001864910125732, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0124322175979614, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7246/10000, Training Loss: 0.600376307964325, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7665998339653015, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7247/10000, Training Loss: 0.6054026484489441, Training Accuracy: 0.6519607843137255, Validation Loss: 1.1163029670715332, Validation Accuracy: 0.5\n",
      "Epoch 7248/10000, Training Loss: 0.6712052822113037, Training Accuracy: 0.5318627450980392, Validation Loss: 0.7156586647033691, Validation Accuracy: 0.5\n",
      "Epoch 7249/10000, Training Loss: 0.7008225917816162, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6906509399414062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7250/10000, Training Loss: 0.6405577063560486, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9212405681610107, Validation Accuracy: 0.5\n",
      "Epoch 7251/10000, Training Loss: 0.6484158039093018, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6806581020355225, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7252/10000, Training Loss: 0.641088604927063, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7555809617042542, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7253/10000, Training Loss: 0.6485452651977539, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6279901266098022, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7254/10000, Training Loss: 0.6894232630729675, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7045336365699768, Validation Accuracy: 0.5\n",
      "Epoch 7255/10000, Training Loss: 0.7026750445365906, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8315203785896301, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7256/10000, Training Loss: 0.7153347134590149, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9095098376274109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7257/10000, Training Loss: 0.7073987126350403, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8156270384788513, Validation Accuracy: 0.5\n",
      "Epoch 7258/10000, Training Loss: 0.6719772219657898, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7607898116111755, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7259/10000, Training Loss: 0.6215410828590393, Training Accuracy: 0.6838235294117647, Validation Loss: 0.722277820110321, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7260/10000, Training Loss: 0.6549075841903687, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6466994285583496, Validation Accuracy: 0.75\n",
      "Epoch 7261/10000, Training Loss: 0.6214317679405212, Training Accuracy: 0.6446078431372549, Validation Loss: 0.47823861241340637, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 7262/10000, Training Loss: 0.6851480007171631, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6337697505950928, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7263/10000, Training Loss: 0.6427046060562134, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7212007641792297, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7264/10000, Training Loss: 0.6629741191864014, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9479935169219971, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7265/10000, Training Loss: 0.666871190071106, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7992534041404724, Validation Accuracy: 0.5\n",
      "Epoch 7266/10000, Training Loss: 0.6759270429611206, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9096089005470276, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7267/10000, Training Loss: 0.6638039350509644, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7406490445137024, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7268/10000, Training Loss: 0.6555261015892029, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8354833722114563, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7269/10000, Training Loss: 0.7007524967193604, Training Accuracy: 0.571078431372549, Validation Loss: 0.6539385914802551, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7270/10000, Training Loss: 0.6533352732658386, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8101873993873596, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7271/10000, Training Loss: 0.6024118661880493, Training Accuracy: 0.6838235294117647, Validation Loss: 1.003543734550476, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7272/10000, Training Loss: 0.6752023696899414, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8880848288536072, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7273/10000, Training Loss: 0.6785527467727661, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8522577881813049, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7274/10000, Training Loss: 0.6433404684066772, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7028899788856506, Validation Accuracy: 0.5\n",
      "Epoch 7275/10000, Training Loss: 0.6502442955970764, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9105086326599121, Validation Accuracy: 0.5\n",
      "Epoch 7276/10000, Training Loss: 0.6683105230331421, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9003476500511169, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7277/10000, Training Loss: 0.6652140021324158, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8406478762626648, Validation Accuracy: 0.5\n",
      "Epoch 7278/10000, Training Loss: 0.72868812084198, Training Accuracy: 0.5024509803921569, Validation Loss: 0.6298109889030457, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7279/10000, Training Loss: 0.6682205200195312, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7858205437660217, Validation Accuracy: 0.5\n",
      "Epoch 7280/10000, Training Loss: 0.6331923007965088, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8114987015724182, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7281/10000, Training Loss: 0.659704327583313, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7332839965820312, Validation Accuracy: 0.5\n",
      "Epoch 7282/10000, Training Loss: 0.6703751683235168, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7324904799461365, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7283/10000, Training Loss: 0.6322165727615356, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8494138121604919, Validation Accuracy: 0.5\n",
      "Epoch 7284/10000, Training Loss: 0.7089688777923584, Training Accuracy: 0.5416666666666666, Validation Loss: 0.8095547556877136, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7285/10000, Training Loss: 0.6402783393859863, Training Accuracy: 0.6127450980392157, Validation Loss: 0.868215799331665, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7286/10000, Training Loss: 0.6320387721061707, Training Accuracy: 0.625, Validation Loss: 0.6500420570373535, Validation Accuracy: 0.5\n",
      "Epoch 7287/10000, Training Loss: 0.6236765384674072, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9231119155883789, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7288/10000, Training Loss: 0.663335919380188, Training Accuracy: 0.5906862745098039, Validation Loss: 0.838630199432373, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7289/10000, Training Loss: 0.7081964015960693, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7903118133544922, Validation Accuracy: 0.5\n",
      "Epoch 7290/10000, Training Loss: 0.673504650592804, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7250646948814392, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7291/10000, Training Loss: 0.6142092943191528, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6410960555076599, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7292/10000, Training Loss: 0.6637088656425476, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6964657306671143, Validation Accuracy: 0.5\n",
      "Epoch 7293/10000, Training Loss: 0.620762288570404, Training Accuracy: 0.6274509803921569, Validation Loss: 0.5651296973228455, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7294/10000, Training Loss: 0.6762465834617615, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7191941142082214, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7295/10000, Training Loss: 0.6603055596351624, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6844897270202637, Validation Accuracy: 0.5\n",
      "Epoch 7296/10000, Training Loss: 0.6528865694999695, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6874005794525146, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7297/10000, Training Loss: 0.6998605728149414, Training Accuracy: 0.5955882352941176, Validation Loss: 0.5792588591575623, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7298/10000, Training Loss: 0.6552775502204895, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8087372779846191, Validation Accuracy: 0.5\n",
      "Epoch 7299/10000, Training Loss: 0.6714069247245789, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7401711940765381, Validation Accuracy: 0.5\n",
      "Epoch 7300/10000, Training Loss: 0.6451677680015564, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8316340446472168, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7301/10000, Training Loss: 0.680109977722168, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6873505711555481, Validation Accuracy: 0.5\n",
      "Epoch 7302/10000, Training Loss: 0.6330317854881287, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8517406582832336, Validation Accuracy: 0.5\n",
      "Epoch 7303/10000, Training Loss: 0.6811940670013428, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7460545897483826, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7304/10000, Training Loss: 0.6530148386955261, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6402285099029541, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7305/10000, Training Loss: 0.6741793751716614, Training Accuracy: 0.5882352941176471, Validation Loss: 0.969120442867279, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7306/10000, Training Loss: 0.639493465423584, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6991259455680847, Validation Accuracy: 0.5\n",
      "Epoch 7307/10000, Training Loss: 0.6349416971206665, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7984132766723633, Validation Accuracy: 0.5\n",
      "Epoch 7308/10000, Training Loss: 0.628190279006958, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7501567006111145, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7309/10000, Training Loss: 0.7173409461975098, Training Accuracy: 0.5735294117647058, Validation Loss: 0.849503755569458, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7310/10000, Training Loss: 0.6550961136817932, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7104108929634094, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7311/10000, Training Loss: 0.6466116309165955, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8327650427818298, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7312/10000, Training Loss: 0.6553969979286194, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7287041544914246, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7313/10000, Training Loss: 0.6815638542175293, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6102258563041687, Validation Accuracy: 0.75\n",
      "Epoch 7314/10000, Training Loss: 0.6706178784370422, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7532332539558411, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7315/10000, Training Loss: 0.6808879375457764, Training Accuracy: 0.5392156862745098, Validation Loss: 0.7576640248298645, Validation Accuracy: 0.5\n",
      "Epoch 7316/10000, Training Loss: 0.661165714263916, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8025406002998352, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7317/10000, Training Loss: 0.6612191200256348, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6079832911491394, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7318/10000, Training Loss: 0.6232813000679016, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6208934783935547, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7319/10000, Training Loss: 0.6926174759864807, Training Accuracy: 0.5490196078431373, Validation Loss: 0.791053295135498, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7320/10000, Training Loss: 0.6409189701080322, Training Accuracy: 0.625, Validation Loss: 0.8680494427680969, Validation Accuracy: 0.25\n",
      "Epoch 7321/10000, Training Loss: 0.6491755247116089, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0746827125549316, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7322/10000, Training Loss: 0.6738046407699585, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7783544063568115, Validation Accuracy: 0.25\n",
      "Epoch 7323/10000, Training Loss: 0.6615582704544067, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6421446204185486, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7324/10000, Training Loss: 0.6105754971504211, Training Accuracy: 0.6936274509803921, Validation Loss: 0.8150200843811035, Validation Accuracy: 0.5\n",
      "Epoch 7325/10000, Training Loss: 0.6509951949119568, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7180726528167725, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7326/10000, Training Loss: 0.679429829120636, Training Accuracy: 0.6397058823529411, Validation Loss: 0.771068274974823, Validation Accuracy: 0.5\n",
      "Epoch 7327/10000, Training Loss: 0.6941795945167542, Training Accuracy: 0.5661764705882353, Validation Loss: 1.1074814796447754, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7328/10000, Training Loss: 0.65841144323349, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8047205805778503, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7329/10000, Training Loss: 0.6349661350250244, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9443798661231995, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7330/10000, Training Loss: 0.6915414333343506, Training Accuracy: 0.6053921568627451, Validation Loss: 0.5179968476295471, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7331/10000, Training Loss: 0.6422693729400635, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9990273118019104, Validation Accuracy: 0.25\n",
      "Epoch 7332/10000, Training Loss: 0.6743044257164001, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8510848879814148, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7333/10000, Training Loss: 0.6396940350532532, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8476760983467102, Validation Accuracy: 0.25\n",
      "Epoch 7334/10000, Training Loss: 0.6482476592063904, Training Accuracy: 0.6200980392156863, Validation Loss: 0.5449288487434387, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7335/10000, Training Loss: 0.6674685478210449, Training Accuracy: 0.5686274509803921, Validation Loss: 0.67606121301651, Validation Accuracy: 0.5\n",
      "Epoch 7336/10000, Training Loss: 0.6977193355560303, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9654389023780823, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7337/10000, Training Loss: 0.6461014747619629, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7569219470024109, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7338/10000, Training Loss: 0.6314395070075989, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0063396692276, Validation Accuracy: 0.5\n",
      "Epoch 7339/10000, Training Loss: 0.6486017107963562, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7178168892860413, Validation Accuracy: 0.5\n",
      "Epoch 7340/10000, Training Loss: 0.6256702542304993, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9498031735420227, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7341/10000, Training Loss: 0.6554682850837708, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7754657864570618, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7342/10000, Training Loss: 0.6777002811431885, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8261504769325256, Validation Accuracy: 0.5\n",
      "Epoch 7343/10000, Training Loss: 0.6414837837219238, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9513313174247742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7344/10000, Training Loss: 0.6042749881744385, Training Accuracy: 0.7107843137254902, Validation Loss: 0.6917746067047119, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7345/10000, Training Loss: 0.6440801620483398, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9222745895385742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7346/10000, Training Loss: 0.6735992431640625, Training Accuracy: 0.5833333333333334, Validation Loss: 0.519824743270874, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7347/10000, Training Loss: 0.6957249641418457, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9250814914703369, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7348/10000, Training Loss: 0.6168190240859985, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7657257914543152, Validation Accuracy: 0.5\n",
      "Epoch 7349/10000, Training Loss: 0.614615261554718, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9169595241546631, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7350/10000, Training Loss: 0.6271818280220032, Training Accuracy: 0.7132352941176471, Validation Loss: 1.4615225791931152, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7351/10000, Training Loss: 0.65488201379776, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6986344456672668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7352/10000, Training Loss: 0.6329538822174072, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9055271744728088, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7353/10000, Training Loss: 0.6244215369224548, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6452236771583557, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7354/10000, Training Loss: 0.6765664219856262, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8907732963562012, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7355/10000, Training Loss: 0.6829631328582764, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6079545617103577, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7356/10000, Training Loss: 0.6662779450416565, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6285918354988098, Validation Accuracy: 0.75\n",
      "Epoch 7357/10000, Training Loss: 0.6481846570968628, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8341240286827087, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7358/10000, Training Loss: 0.6817561388015747, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8963866233825684, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7359/10000, Training Loss: 0.6146112680435181, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8037645816802979, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7360/10000, Training Loss: 0.6441777348518372, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9174203276634216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7361/10000, Training Loss: 0.6926857233047485, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8215685486793518, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7362/10000, Training Loss: 0.663819432258606, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7001943588256836, Validation Accuracy: 0.5\n",
      "Epoch 7363/10000, Training Loss: 0.6709078550338745, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6307992935180664, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7364/10000, Training Loss: 0.6695473790168762, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8001265525817871, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7365/10000, Training Loss: 0.6591343879699707, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6261245608329773, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7366/10000, Training Loss: 0.6052988171577454, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7766421437263489, Validation Accuracy: 0.5\n",
      "Epoch 7367/10000, Training Loss: 0.6619377732276917, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8710604310035706, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7368/10000, Training Loss: 0.644696056842804, Training Accuracy: 0.6348039215686274, Validation Loss: 1.1534761190414429, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7369/10000, Training Loss: 0.6915703415870667, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7116889953613281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7370/10000, Training Loss: 0.6115265488624573, Training Accuracy: 0.6862745098039216, Validation Loss: 0.743567168712616, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7371/10000, Training Loss: 0.6886228919029236, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7528690695762634, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7372/10000, Training Loss: 0.6253774762153625, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9228391051292419, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7373/10000, Training Loss: 0.6838124394416809, Training Accuracy: 0.6544117647058824, Validation Loss: 0.890261709690094, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7374/10000, Training Loss: 0.6204147934913635, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0147796869277954, Validation Accuracy: 0.25\n",
      "Epoch 7375/10000, Training Loss: 0.6935551762580872, Training Accuracy: 0.5465686274509803, Validation Loss: 0.6679165363311768, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7376/10000, Training Loss: 0.6750643849372864, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6812534928321838, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7377/10000, Training Loss: 0.6789392828941345, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9802950024604797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7378/10000, Training Loss: 0.6555689573287964, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7400776743888855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7379/10000, Training Loss: 0.6500758528709412, Training Accuracy: 0.6372549019607843, Validation Loss: 0.5372982025146484, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7380/10000, Training Loss: 0.6324073076248169, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7240884900093079, Validation Accuracy: 0.25\n",
      "Epoch 7381/10000, Training Loss: 0.662398099899292, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9861977696418762, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7382/10000, Training Loss: 0.6398205757141113, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7586407661437988, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7383/10000, Training Loss: 0.6463302969932556, Training Accuracy: 0.6053921568627451, Validation Loss: 0.850180447101593, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7384/10000, Training Loss: 0.6996394395828247, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8322775959968567, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7385/10000, Training Loss: 0.6621093153953552, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7461960315704346, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7386/10000, Training Loss: 0.6735901236534119, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6917055249214172, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7387/10000, Training Loss: 0.642763078212738, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7736929059028625, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7388/10000, Training Loss: 0.7112172245979309, Training Accuracy: 0.5122549019607843, Validation Loss: 0.8341619372367859, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7389/10000, Training Loss: 0.6500889658927917, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6690180897712708, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7390/10000, Training Loss: 0.6571609377861023, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6978268623352051, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7391/10000, Training Loss: 0.6791355013847351, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7112992405891418, Validation Accuracy: 0.5\n",
      "Epoch 7392/10000, Training Loss: 0.6733284592628479, Training Accuracy: 0.5416666666666666, Validation Loss: 0.7546336650848389, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7393/10000, Training Loss: 0.6488442420959473, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8552064299583435, Validation Accuracy: 0.5\n",
      "Epoch 7394/10000, Training Loss: 0.6669021844863892, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6696794629096985, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7395/10000, Training Loss: 0.6983284950256348, Training Accuracy: 0.6078431372549019, Validation Loss: 1.062375545501709, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7396/10000, Training Loss: 0.6106886863708496, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8506907820701599, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7397/10000, Training Loss: 0.6260830760002136, Training Accuracy: 0.6519607843137255, Validation Loss: 0.5277519822120667, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7398/10000, Training Loss: 0.6652075052261353, Training Accuracy: 0.6078431372549019, Validation Loss: 0.695721447467804, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7399/10000, Training Loss: 0.6604762077331543, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7853855490684509, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7400/10000, Training Loss: 0.6558805704116821, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6829258799552917, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7401/10000, Training Loss: 0.6416204571723938, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8049161434173584, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7402/10000, Training Loss: 0.6590423583984375, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8592119216918945, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7403/10000, Training Loss: 0.6192002892494202, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0083518028259277, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7404/10000, Training Loss: 0.6371363401412964, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6864383816719055, Validation Accuracy: 0.5\n",
      "Epoch 7405/10000, Training Loss: 0.6332593560218811, Training Accuracy: 0.625, Validation Loss: 1.08147394657135, Validation Accuracy: 0.25\n",
      "Epoch 7406/10000, Training Loss: 0.6528679132461548, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7987304329872131, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7407/10000, Training Loss: 0.6039426326751709, Training Accuracy: 0.6740196078431373, Validation Loss: 1.271103024482727, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7408/10000, Training Loss: 0.6230571866035461, Training Accuracy: 0.6642156862745098, Validation Loss: 1.198024034500122, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7409/10000, Training Loss: 0.6567286849021912, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9249704480171204, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7410/10000, Training Loss: 0.6296310424804688, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8557250499725342, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7411/10000, Training Loss: 0.6556305289268494, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6740982532501221, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7412/10000, Training Loss: 0.6662631034851074, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7279122471809387, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7413/10000, Training Loss: 0.6565466523170471, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7570628523826599, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7414/10000, Training Loss: 0.6616389751434326, Training Accuracy: 0.571078431372549, Validation Loss: 0.7609943747520447, Validation Accuracy: 0.5\n",
      "Epoch 7415/10000, Training Loss: 0.6099311709403992, Training Accuracy: 0.7107843137254902, Validation Loss: 0.9212340712547302, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7416/10000, Training Loss: 0.6446180939674377, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0767613649368286, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7417/10000, Training Loss: 0.6931703090667725, Training Accuracy: 0.5661764705882353, Validation Loss: 0.6696373820304871, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7418/10000, Training Loss: 0.6300092935562134, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7782671451568604, Validation Accuracy: 0.5\n",
      "Epoch 7419/10000, Training Loss: 0.653632640838623, Training Accuracy: 0.6397058823529411, Validation Loss: 0.657768189907074, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7420/10000, Training Loss: 0.6713364720344543, Training Accuracy: 0.6299019607843137, Validation Loss: 1.115087628364563, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7421/10000, Training Loss: 0.630703866481781, Training Accuracy: 0.6225490196078431, Validation Loss: 1.1336060762405396, Validation Accuracy: 0.5\n",
      "Epoch 7422/10000, Training Loss: 0.6455132961273193, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8690117001533508, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7423/10000, Training Loss: 0.6642955541610718, Training Accuracy: 0.6421568627450981, Validation Loss: 1.4371968507766724, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7424/10000, Training Loss: 0.6603188514709473, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8046441674232483, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7425/10000, Training Loss: 0.6568732857704163, Training Accuracy: 0.5686274509803921, Validation Loss: 0.673011302947998, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7426/10000, Training Loss: 0.6734938025474548, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7358787059783936, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7427/10000, Training Loss: 0.6247889399528503, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6961986422538757, Validation Accuracy: 0.75\n",
      "Epoch 7428/10000, Training Loss: 0.6503462195396423, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6619153022766113, Validation Accuracy: 0.75\n",
      "Epoch 7429/10000, Training Loss: 0.6865324378013611, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8300833702087402, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7430/10000, Training Loss: 0.6542274355888367, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9037901759147644, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7431/10000, Training Loss: 0.6951655745506287, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7022140622138977, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7432/10000, Training Loss: 0.6246020197868347, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9179399609565735, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7433/10000, Training Loss: 0.6515349745750427, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7782792448997498, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7434/10000, Training Loss: 0.6514683365821838, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8594422340393066, Validation Accuracy: 0.5\n",
      "Epoch 7435/10000, Training Loss: 0.5986403226852417, Training Accuracy: 0.7107843137254902, Validation Loss: 0.7322621941566467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7436/10000, Training Loss: 0.6815602779388428, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7500552535057068, Validation Accuracy: 0.5\n",
      "Epoch 7437/10000, Training Loss: 0.6235747933387756, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9052813053131104, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7438/10000, Training Loss: 0.6838720440864563, Training Accuracy: 0.6078431372549019, Validation Loss: 0.934448778629303, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7439/10000, Training Loss: 0.6291190981864929, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0416613817214966, Validation Accuracy: 0.5\n",
      "Epoch 7440/10000, Training Loss: 0.6225724220275879, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6460254788398743, Validation Accuracy: 0.5\n",
      "Epoch 7441/10000, Training Loss: 0.6419404745101929, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7873042225837708, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7442/10000, Training Loss: 0.6376798748970032, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7874377369880676, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7443/10000, Training Loss: 0.6093288660049438, Training Accuracy: 0.696078431372549, Validation Loss: 0.7377062439918518, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7444/10000, Training Loss: 0.6440640687942505, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0293020009994507, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7445/10000, Training Loss: 0.6561941504478455, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7870133519172668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7446/10000, Training Loss: 0.6390359997749329, Training Accuracy: 0.6593137254901961, Validation Loss: 0.775937020778656, Validation Accuracy: 0.5\n",
      "Epoch 7447/10000, Training Loss: 0.6455821394920349, Training Accuracy: 0.6004901960784313, Validation Loss: 0.5957606434822083, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7448/10000, Training Loss: 0.6650502681732178, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7907469272613525, Validation Accuracy: 0.5\n",
      "Epoch 7449/10000, Training Loss: 0.676941990852356, Training Accuracy: 0.5637254901960784, Validation Loss: 0.651932954788208, Validation Accuracy: 0.5\n",
      "Epoch 7450/10000, Training Loss: 0.6479095816612244, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0889928340911865, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7451/10000, Training Loss: 0.6311763525009155, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8395877480506897, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7452/10000, Training Loss: 0.62210613489151, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6770028471946716, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7453/10000, Training Loss: 0.6581847071647644, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6904272437095642, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7454/10000, Training Loss: 0.6315315365791321, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6442801356315613, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7455/10000, Training Loss: 0.6306787133216858, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7974469065666199, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7456/10000, Training Loss: 0.6860762238502502, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8928718566894531, Validation Accuracy: 0.25\n",
      "Epoch 7457/10000, Training Loss: 0.643002986907959, Training Accuracy: 0.6102941176470589, Validation Loss: 1.029518961906433, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7458/10000, Training Loss: 0.6662008166313171, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6886915564537048, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7459/10000, Training Loss: 0.655167281627655, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7436291575431824, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7460/10000, Training Loss: 0.6631677746772766, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6622145175933838, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7461/10000, Training Loss: 0.657487154006958, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0115137100219727, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7462/10000, Training Loss: 0.6254158020019531, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8107423782348633, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7463/10000, Training Loss: 0.6309521794319153, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7561481595039368, Validation Accuracy: 0.5\n",
      "Epoch 7464/10000, Training Loss: 0.6513002514839172, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7356314659118652, Validation Accuracy: 0.5\n",
      "Epoch 7465/10000, Training Loss: 0.6691187024116516, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7623238563537598, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7466/10000, Training Loss: 0.639162540435791, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9785523414611816, Validation Accuracy: 0.5\n",
      "Epoch 7467/10000, Training Loss: 0.6759229898452759, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8886573314666748, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7468/10000, Training Loss: 0.6710370182991028, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7937930226325989, Validation Accuracy: 0.5\n",
      "Epoch 7469/10000, Training Loss: 0.6087509393692017, Training Accuracy: 0.678921568627451, Validation Loss: 1.1348947286605835, Validation Accuracy: 0.5\n",
      "Epoch 7470/10000, Training Loss: 0.6615153551101685, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6921445727348328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7471/10000, Training Loss: 0.6588333249092102, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7737128138542175, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7472/10000, Training Loss: 0.6328590512275696, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8564791679382324, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7473/10000, Training Loss: 0.6500969529151917, Training Accuracy: 0.5563725490196079, Validation Loss: 1.0892223119735718, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7474/10000, Training Loss: 0.6575875282287598, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6366164088249207, Validation Accuracy: 0.5\n",
      "Epoch 7475/10000, Training Loss: 0.6871634125709534, Training Accuracy: 0.5784313725490197, Validation Loss: 0.726581871509552, Validation Accuracy: 0.5\n",
      "Epoch 7476/10000, Training Loss: 0.6662018895149231, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8620926737785339, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7477/10000, Training Loss: 0.6658445000648499, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9161842465400696, Validation Accuracy: 0.25\n",
      "Epoch 7478/10000, Training Loss: 0.6608552932739258, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6943969130516052, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7479/10000, Training Loss: 0.6539536118507385, Training Accuracy: 0.5955882352941176, Validation Loss: 0.755327045917511, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7480/10000, Training Loss: 0.6185230612754822, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7395108342170715, Validation Accuracy: 0.5\n",
      "Epoch 7481/10000, Training Loss: 0.649408757686615, Training Accuracy: 0.571078431372549, Validation Loss: 0.7195816040039062, Validation Accuracy: 0.5\n",
      "Epoch 7482/10000, Training Loss: 0.6551640033721924, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7790188193321228, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7483/10000, Training Loss: 0.6642906069755554, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7195687890052795, Validation Accuracy: 0.5\n",
      "Epoch 7484/10000, Training Loss: 0.6358450055122375, Training Accuracy: 0.625, Validation Loss: 0.7829872965812683, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7485/10000, Training Loss: 0.6348795890808105, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6924905776977539, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7486/10000, Training Loss: 0.6705718636512756, Training Accuracy: 0.5759803921568627, Validation Loss: 1.1818913221359253, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7487/10000, Training Loss: 0.6930119395256042, Training Accuracy: 0.6029411764705882, Validation Loss: 1.028246283531189, Validation Accuracy: 0.25\n",
      "Epoch 7488/10000, Training Loss: 0.679009735584259, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8053197264671326, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7489/10000, Training Loss: 0.6389535069465637, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0697531700134277, Validation Accuracy: 0.5\n",
      "Epoch 7490/10000, Training Loss: 0.6280447840690613, Training Accuracy: 0.6102941176470589, Validation Loss: 0.749055802822113, Validation Accuracy: 0.5\n",
      "Epoch 7491/10000, Training Loss: 0.5903443694114685, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8957632184028625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7492/10000, Training Loss: 0.6371064782142639, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7449024319648743, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7493/10000, Training Loss: 0.6598724126815796, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6962811946868896, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7494/10000, Training Loss: 0.6366981267929077, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7657942771911621, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7495/10000, Training Loss: 0.6613962650299072, Training Accuracy: 0.5759803921568627, Validation Loss: 0.6891492009162903, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7496/10000, Training Loss: 0.6563137173652649, Training Accuracy: 0.6029411764705882, Validation Loss: 1.2194875478744507, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7497/10000, Training Loss: 0.700772762298584, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8223109841346741, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7498/10000, Training Loss: 0.6462795734405518, Training Accuracy: 0.571078431372549, Validation Loss: 0.6965107321739197, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7499/10000, Training Loss: 0.6594429612159729, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9675658345222473, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7500/10000, Training Loss: 0.6419587135314941, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7633808255195618, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7501/10000, Training Loss: 0.6059781908988953, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7075029015541077, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7502/10000, Training Loss: 0.666137158870697, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6401544809341431, Validation Accuracy: 0.5\n",
      "Epoch 7503/10000, Training Loss: 0.6268747448921204, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7310752272605896, Validation Accuracy: 0.5\n",
      "Epoch 7504/10000, Training Loss: 0.640145480632782, Training Accuracy: 0.6397058823529411, Validation Loss: 0.5820505023002625, Validation Accuracy: 0.75\n",
      "Epoch 7505/10000, Training Loss: 0.6715474128723145, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8001055121421814, Validation Accuracy: 0.5\n",
      "Epoch 7506/10000, Training Loss: 0.6864350438117981, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8477628827095032, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7507/10000, Training Loss: 0.6373395919799805, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8143308758735657, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7508/10000, Training Loss: 0.709734320640564, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9979568123817444, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7509/10000, Training Loss: 0.6350916028022766, Training Accuracy: 0.6470588235294118, Validation Loss: 0.943666934967041, Validation Accuracy: 0.5\n",
      "Epoch 7510/10000, Training Loss: 0.6511461138725281, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7652065753936768, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7511/10000, Training Loss: 0.6696750521659851, Training Accuracy: 0.5955882352941176, Validation Loss: 0.739673376083374, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7512/10000, Training Loss: 0.6735022068023682, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7342321872711182, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7513/10000, Training Loss: 0.6229392290115356, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9170377850532532, Validation Accuracy: 0.5\n",
      "Epoch 7514/10000, Training Loss: 0.666904091835022, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9620542526245117, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7515/10000, Training Loss: 0.6748537421226501, Training Accuracy: 0.5441176470588235, Validation Loss: 0.804576575756073, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7516/10000, Training Loss: 0.6566942930221558, Training Accuracy: 0.6004901960784313, Validation Loss: 0.609180748462677, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7517/10000, Training Loss: 0.6831235885620117, Training Accuracy: 0.5759803921568627, Validation Loss: 0.855267345905304, Validation Accuracy: 0.25\n",
      "Epoch 7518/10000, Training Loss: 0.6333950161933899, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7045278549194336, Validation Accuracy: 0.75\n",
      "Epoch 7519/10000, Training Loss: 0.694305956363678, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8088247179985046, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7520/10000, Training Loss: 0.6211391687393188, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6137014627456665, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7521/10000, Training Loss: 0.6518853902816772, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9768064618110657, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7522/10000, Training Loss: 0.6280454993247986, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8712408542633057, Validation Accuracy: 0.5\n",
      "Epoch 7523/10000, Training Loss: 0.6237795948982239, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7161983847618103, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7524/10000, Training Loss: 0.6709407567977905, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8224599361419678, Validation Accuracy: 0.5\n",
      "Epoch 7525/10000, Training Loss: 0.65739905834198, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7234843373298645, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7526/10000, Training Loss: 0.6764429807662964, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8226731419563293, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7527/10000, Training Loss: 0.6800366640090942, Training Accuracy: 0.625, Validation Loss: 0.7619302272796631, Validation Accuracy: 0.5\n",
      "Epoch 7528/10000, Training Loss: 0.6259666085243225, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7836291193962097, Validation Accuracy: 0.5\n",
      "Epoch 7529/10000, Training Loss: 0.6289013028144836, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9194442629814148, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7530/10000, Training Loss: 0.630362331867218, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6531946063041687, Validation Accuracy: 0.5\n",
      "Epoch 7531/10000, Training Loss: 0.6686592698097229, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7322652339935303, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7532/10000, Training Loss: 0.6594516634941101, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7003455758094788, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7533/10000, Training Loss: 0.6311297416687012, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8533454537391663, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7534/10000, Training Loss: 0.6926175355911255, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6164465546607971, Validation Accuracy: 0.5\n",
      "Epoch 7535/10000, Training Loss: 0.6594273447990417, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6471123695373535, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7536/10000, Training Loss: 0.6411746740341187, Training Accuracy: 0.6348039215686274, Validation Loss: 1.063454031944275, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7537/10000, Training Loss: 0.6359546184539795, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6155200600624084, Validation Accuracy: 0.75\n",
      "Epoch 7538/10000, Training Loss: 0.6626937985420227, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8051366806030273, Validation Accuracy: 0.5\n",
      "Epoch 7539/10000, Training Loss: 0.6550399661064148, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7156221866607666, Validation Accuracy: 0.5\n",
      "Epoch 7540/10000, Training Loss: 0.6477957963943481, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0123409032821655, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7541/10000, Training Loss: 0.6986531019210815, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9397565722465515, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7542/10000, Training Loss: 0.6671791076660156, Training Accuracy: 0.5661764705882353, Validation Loss: 0.5416871905326843, Validation Accuracy: 0.75\n",
      "Epoch 7543/10000, Training Loss: 0.6516465544700623, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8924217224121094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7544/10000, Training Loss: 0.6602662801742554, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8657312393188477, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7545/10000, Training Loss: 0.7437902688980103, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7641631960868835, Validation Accuracy: 0.5\n",
      "Epoch 7546/10000, Training Loss: 0.642315685749054, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7197344899177551, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7547/10000, Training Loss: 0.6557643413543701, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8454220294952393, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7548/10000, Training Loss: 0.6647658348083496, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0216318368911743, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7549/10000, Training Loss: 0.6276675462722778, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7689731121063232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7550/10000, Training Loss: 0.6761084198951721, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8276225924491882, Validation Accuracy: 0.5\n",
      "Epoch 7551/10000, Training Loss: 0.7147157788276672, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7761778831481934, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7552/10000, Training Loss: 0.6392481327056885, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6777028441429138, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7553/10000, Training Loss: 0.6210153102874756, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9394235014915466, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7554/10000, Training Loss: 0.6589416861534119, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9277183413505554, Validation Accuracy: 0.25\n",
      "Epoch 7555/10000, Training Loss: 0.6701351404190063, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8493203520774841, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7556/10000, Training Loss: 0.6967777013778687, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7817535400390625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7557/10000, Training Loss: 0.6934778690338135, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7064683437347412, Validation Accuracy: 0.5\n",
      "Epoch 7558/10000, Training Loss: 0.666115403175354, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8187012076377869, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7559/10000, Training Loss: 0.6463673710823059, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9529635906219482, Validation Accuracy: 0.25\n",
      "Epoch 7560/10000, Training Loss: 0.6674666404724121, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9671940207481384, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7561/10000, Training Loss: 0.6823539137840271, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7842137217521667, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7562/10000, Training Loss: 0.6579328179359436, Training Accuracy: 0.6372549019607843, Validation Loss: 1.407614827156067, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7563/10000, Training Loss: 0.6218835711479187, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6874370574951172, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7564/10000, Training Loss: 0.63665372133255, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8017780780792236, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7565/10000, Training Loss: 0.6533313989639282, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8382062315940857, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7566/10000, Training Loss: 0.6672786474227905, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7140283584594727, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7567/10000, Training Loss: 0.6441183090209961, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6156004667282104, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7568/10000, Training Loss: 0.6745747327804565, Training Accuracy: 0.571078431372549, Validation Loss: 0.853931188583374, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7569/10000, Training Loss: 0.6390922665596008, Training Accuracy: 0.6691176470588235, Validation Loss: 0.839832603931427, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7570/10000, Training Loss: 0.6083119511604309, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9061259627342224, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7571/10000, Training Loss: 0.5915223956108093, Training Accuracy: 0.6838235294117647, Validation Loss: 1.0370469093322754, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7572/10000, Training Loss: 0.6320958733558655, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7274760603904724, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7573/10000, Training Loss: 0.6522725224494934, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0222407579421997, Validation Accuracy: 0.25\n",
      "Epoch 7574/10000, Training Loss: 0.646057665348053, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7707715034484863, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7575/10000, Training Loss: 0.6556704640388489, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8632993698120117, Validation Accuracy: 0.25\n",
      "Epoch 7576/10000, Training Loss: 0.6184645891189575, Training Accuracy: 0.6691176470588235, Validation Loss: 0.6614763140678406, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7577/10000, Training Loss: 0.6133342981338501, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0036126375198364, Validation Accuracy: 0.5\n",
      "Epoch 7578/10000, Training Loss: 0.6502084136009216, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6630335450172424, Validation Accuracy: 0.5\n",
      "Epoch 7579/10000, Training Loss: 0.6288275718688965, Training Accuracy: 0.6519607843137255, Validation Loss: 1.0953420400619507, Validation Accuracy: 0.25\n",
      "Epoch 7580/10000, Training Loss: 0.6122380495071411, Training Accuracy: 0.6740196078431373, Validation Loss: 0.6090826988220215, Validation Accuracy: 0.75\n",
      "Epoch 7581/10000, Training Loss: 0.675118088722229, Training Accuracy: 0.5980392156862745, Validation Loss: 0.894571840763092, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7582/10000, Training Loss: 0.681826114654541, Training Accuracy: 0.6078431372549019, Validation Loss: 0.5964143872261047, Validation Accuracy: 0.75\n",
      "Epoch 7583/10000, Training Loss: 0.7071293592453003, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8148655891418457, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7584/10000, Training Loss: 0.6326354742050171, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7555174231529236, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7585/10000, Training Loss: 0.6445679664611816, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7414447665214539, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7586/10000, Training Loss: 0.638032078742981, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9592750668525696, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7587/10000, Training Loss: 0.6114288568496704, Training Accuracy: 0.6838235294117647, Validation Loss: 1.2264477014541626, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7588/10000, Training Loss: 0.6691160798072815, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8826513290405273, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7589/10000, Training Loss: 0.6809260249137878, Training Accuracy: 0.5857843137254902, Validation Loss: 0.712556779384613, Validation Accuracy: 0.5\n",
      "Epoch 7590/10000, Training Loss: 0.6777003407478333, Training Accuracy: 0.5441176470588235, Validation Loss: 0.7967002391815186, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7591/10000, Training Loss: 0.6429275870323181, Training Accuracy: 0.5661764705882353, Validation Loss: 0.6239631772041321, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7592/10000, Training Loss: 0.6157575249671936, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9525225162506104, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7593/10000, Training Loss: 0.6595876216888428, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7850465774536133, Validation Accuracy: 0.5\n",
      "Epoch 7594/10000, Training Loss: 0.6390536427497864, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9780877232551575, Validation Accuracy: 0.5\n",
      "Epoch 7595/10000, Training Loss: 0.6792036890983582, Training Accuracy: 0.5563725490196079, Validation Loss: 0.8321903347969055, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7596/10000, Training Loss: 0.6321112513542175, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6567689776420593, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7597/10000, Training Loss: 0.6644290685653687, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9303285479545593, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7598/10000, Training Loss: 0.6482226252555847, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9498713612556458, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7599/10000, Training Loss: 0.6588675379753113, Training Accuracy: 0.6274509803921569, Validation Loss: 1.1453074216842651, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7600/10000, Training Loss: 0.6589481830596924, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7265965938568115, Validation Accuracy: 0.5\n",
      "Epoch 7601/10000, Training Loss: 0.6157833337783813, Training Accuracy: 0.6642156862745098, Validation Loss: 0.663606584072113, Validation Accuracy: 0.5\n",
      "Epoch 7602/10000, Training Loss: 0.6555829644203186, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9751415848731995, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7603/10000, Training Loss: 0.6263431310653687, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9052457809448242, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7604/10000, Training Loss: 0.6604927182197571, Training Accuracy: 0.6004901960784313, Validation Loss: 0.772935152053833, Validation Accuracy: 0.5\n",
      "Epoch 7605/10000, Training Loss: 0.6637898087501526, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7407627105712891, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7606/10000, Training Loss: 0.6704750657081604, Training Accuracy: 0.625, Validation Loss: 0.556668221950531, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7607/10000, Training Loss: 0.6238834857940674, Training Accuracy: 0.6887254901960784, Validation Loss: 0.9730067253112793, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7608/10000, Training Loss: 0.6638476848602295, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1331734657287598, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7609/10000, Training Loss: 0.6283079385757446, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6941919326782227, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7610/10000, Training Loss: 0.6851834058761597, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7191103100776672, Validation Accuracy: 0.5\n",
      "Epoch 7611/10000, Training Loss: 0.6647497415542603, Training Accuracy: 0.6838235294117647, Validation Loss: 0.8203312754631042, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7612/10000, Training Loss: 0.6711205244064331, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7055127024650574, Validation Accuracy: 0.5\n",
      "Epoch 7613/10000, Training Loss: 0.6438686847686768, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7735073566436768, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7614/10000, Training Loss: 0.6617835760116577, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7948480248451233, Validation Accuracy: 0.5\n",
      "Epoch 7615/10000, Training Loss: 0.6431304812431335, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8317162990570068, Validation Accuracy: 0.5\n",
      "Epoch 7616/10000, Training Loss: 0.7085095643997192, Training Accuracy: 0.5367647058823529, Validation Loss: 0.6183109879493713, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7617/10000, Training Loss: 0.6539050936698914, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8129661679267883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7618/10000, Training Loss: 0.6728655695915222, Training Accuracy: 0.571078431372549, Validation Loss: 0.7851717472076416, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7619/10000, Training Loss: 0.6630331873893738, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6644384860992432, Validation Accuracy: 0.5\n",
      "Epoch 7620/10000, Training Loss: 0.6270114779472351, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7553302645683289, Validation Accuracy: 0.25\n",
      "Epoch 7621/10000, Training Loss: 0.6156606674194336, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9063149094581604, Validation Accuracy: 0.5\n",
      "Epoch 7622/10000, Training Loss: 0.6601535677909851, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8153309226036072, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7623/10000, Training Loss: 0.6335687637329102, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7580834031105042, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7624/10000, Training Loss: 0.6559179425239563, Training Accuracy: 0.6029411764705882, Validation Loss: 0.75604248046875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7625/10000, Training Loss: 0.6534640192985535, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8077521324157715, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7626/10000, Training Loss: 0.6381204128265381, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7792713046073914, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7627/10000, Training Loss: 0.6694397926330566, Training Accuracy: 0.6029411764705882, Validation Loss: 0.815756618976593, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7628/10000, Training Loss: 0.6390255093574524, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7812767624855042, Validation Accuracy: 0.25\n",
      "Epoch 7629/10000, Training Loss: 0.6597277522087097, Training Accuracy: 0.6372549019607843, Validation Loss: 0.5903441309928894, Validation Accuracy: 0.75\n",
      "Epoch 7630/10000, Training Loss: 0.6176998019218445, Training Accuracy: 0.6617647058823529, Validation Loss: 0.5908192992210388, Validation Accuracy: 0.75\n",
      "Epoch 7631/10000, Training Loss: 0.6279425621032715, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8972278237342834, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7632/10000, Training Loss: 0.6436970829963684, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7789719104766846, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7633/10000, Training Loss: 0.7596731185913086, Training Accuracy: 0.5049019607843137, Validation Loss: 0.5900347828865051, Validation Accuracy: 0.75\n",
      "Epoch 7634/10000, Training Loss: 0.6940701007843018, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6911278367042542, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7635/10000, Training Loss: 0.6554597020149231, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8706154823303223, Validation Accuracy: 0.5\n",
      "Epoch 7636/10000, Training Loss: 0.6761370897293091, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7737521529197693, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7637/10000, Training Loss: 0.6349242925643921, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9200024604797363, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7638/10000, Training Loss: 0.6898845434188843, Training Accuracy: 0.571078431372549, Validation Loss: 0.680567741394043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7639/10000, Training Loss: 0.6296984553337097, Training Accuracy: 0.6151960784313726, Validation Loss: 0.736844539642334, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7640/10000, Training Loss: 0.6598134636878967, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7862644195556641, Validation Accuracy: 0.5\n",
      "Epoch 7641/10000, Training Loss: 0.6607574820518494, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6798272132873535, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7642/10000, Training Loss: 0.6600160598754883, Training Accuracy: 0.6568627450980392, Validation Loss: 0.873962938785553, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7643/10000, Training Loss: 0.6456344723701477, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8991649746894836, Validation Accuracy: 0.25\n",
      "Epoch 7644/10000, Training Loss: 0.6235780119895935, Training Accuracy: 0.6936274509803921, Validation Loss: 0.7752699851989746, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7645/10000, Training Loss: 0.6561806797981262, Training Accuracy: 0.5980392156862745, Validation Loss: 0.865305483341217, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7646/10000, Training Loss: 0.6658190488815308, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7488294243812561, Validation Accuracy: 0.5\n",
      "Epoch 7647/10000, Training Loss: 0.6495978236198425, Training Accuracy: 0.6053921568627451, Validation Loss: 0.701718807220459, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7648/10000, Training Loss: 0.6265131235122681, Training Accuracy: 0.6495098039215687, Validation Loss: 1.1489118337631226, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7649/10000, Training Loss: 0.6308510899543762, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9596124291419983, Validation Accuracy: 0.5\n",
      "Epoch 7650/10000, Training Loss: 0.6283351182937622, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7034886479377747, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7651/10000, Training Loss: 0.6578934788703918, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0951813459396362, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7652/10000, Training Loss: 0.6827715039253235, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0625933408737183, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7653/10000, Training Loss: 0.6719747185707092, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1521496772766113, Validation Accuracy: 0.5\n",
      "Epoch 7654/10000, Training Loss: 0.7113465070724487, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9083626866340637, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7655/10000, Training Loss: 0.6836341619491577, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7846901416778564, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7656/10000, Training Loss: 0.6545109748840332, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6280983090400696, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7657/10000, Training Loss: 0.7034962177276611, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7699225544929504, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7658/10000, Training Loss: 0.6632249355316162, Training Accuracy: 0.5661764705882353, Validation Loss: 1.0157407522201538, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7659/10000, Training Loss: 0.6267667412757874, Training Accuracy: 0.6495098039215687, Validation Loss: 1.232025146484375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7660/10000, Training Loss: 0.645395815372467, Training Accuracy: 0.6470588235294118, Validation Loss: 0.665873110294342, Validation Accuracy: 0.5\n",
      "Epoch 7661/10000, Training Loss: 0.6685912013053894, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7661371231079102, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7662/10000, Training Loss: 0.6848663687705994, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7384684085845947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7663/10000, Training Loss: 0.6228190660476685, Training Accuracy: 0.6985294117647058, Validation Loss: 0.8798179626464844, Validation Accuracy: 0.5\n",
      "Epoch 7664/10000, Training Loss: 0.7005970478057861, Training Accuracy: 0.553921568627451, Validation Loss: 0.6520460247993469, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7665/10000, Training Loss: 0.6379374265670776, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7324476838111877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7666/10000, Training Loss: 0.6520860195159912, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0196019411087036, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7667/10000, Training Loss: 0.6267076134681702, Training Accuracy: 0.625, Validation Loss: 0.9600195288658142, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7668/10000, Training Loss: 0.622012197971344, Training Accuracy: 0.6691176470588235, Validation Loss: 0.686604917049408, Validation Accuracy: 0.75\n",
      "Epoch 7669/10000, Training Loss: 0.6661972403526306, Training Accuracy: 0.6372549019607843, Validation Loss: 1.1426007747650146, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7670/10000, Training Loss: 0.6308650374412537, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7961615920066833, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7671/10000, Training Loss: 0.6228193044662476, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9227347373962402, Validation Accuracy: 0.5\n",
      "Epoch 7672/10000, Training Loss: 0.6389701962471008, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7897090911865234, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7673/10000, Training Loss: 0.6662561297416687, Training Accuracy: 0.6176470588235294, Validation Loss: 1.0460971593856812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7674/10000, Training Loss: 0.6401636600494385, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7996761202812195, Validation Accuracy: 0.25\n",
      "Epoch 7675/10000, Training Loss: 0.6469086408615112, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7249723076820374, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7676/10000, Training Loss: 0.6747098565101624, Training Accuracy: 0.5637254901960784, Validation Loss: 1.0461114645004272, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7677/10000, Training Loss: 0.6718473434448242, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7490000128746033, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7678/10000, Training Loss: 0.6636172533035278, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6328442692756653, Validation Accuracy: 0.75\n",
      "Epoch 7679/10000, Training Loss: 0.6285957098007202, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7568798661231995, Validation Accuracy: 0.5\n",
      "Epoch 7680/10000, Training Loss: 0.6707400679588318, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8020603060722351, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7681/10000, Training Loss: 0.6651365756988525, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8370937705039978, Validation Accuracy: 0.5\n",
      "Epoch 7682/10000, Training Loss: 0.6709344983100891, Training Accuracy: 0.5882352941176471, Validation Loss: 0.903770387172699, Validation Accuracy: 0.5\n",
      "Epoch 7683/10000, Training Loss: 0.674757719039917, Training Accuracy: 0.571078431372549, Validation Loss: 0.7724197506904602, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7684/10000, Training Loss: 0.6676551699638367, Training Accuracy: 0.5980392156862745, Validation Loss: 0.821171760559082, Validation Accuracy: 0.5\n",
      "Epoch 7685/10000, Training Loss: 0.6614326238632202, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9065527319908142, Validation Accuracy: 0.25\n",
      "Epoch 7686/10000, Training Loss: 0.6568052172660828, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6198268532752991, Validation Accuracy: 0.5\n",
      "Epoch 7687/10000, Training Loss: 0.6638572812080383, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7051673531532288, Validation Accuracy: 0.5\n",
      "Epoch 7688/10000, Training Loss: 0.6547417640686035, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7639564871788025, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7689/10000, Training Loss: 0.6363454461097717, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6989055275917053, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7690/10000, Training Loss: 0.654620349407196, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7596319317817688, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7691/10000, Training Loss: 0.6684068441390991, Training Accuracy: 0.5220588235294118, Validation Loss: 0.6405118107795715, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7692/10000, Training Loss: 0.6375358700752258, Training Accuracy: 0.6862745098039216, Validation Loss: 1.087408185005188, Validation Accuracy: 0.5\n",
      "Epoch 7693/10000, Training Loss: 0.6416373252868652, Training Accuracy: 0.625, Validation Loss: 0.663122296333313, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7694/10000, Training Loss: 0.6428179144859314, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7659983038902283, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7695/10000, Training Loss: 0.620656430721283, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7670095562934875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7696/10000, Training Loss: 0.6625409126281738, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9325854778289795, Validation Accuracy: 0.25\n",
      "Epoch 7697/10000, Training Loss: 0.6228618025779724, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7248880863189697, Validation Accuracy: 0.75\n",
      "Epoch 7698/10000, Training Loss: 0.6339064240455627, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8055246472358704, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7699/10000, Training Loss: 0.6631572246551514, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9807175993919373, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7700/10000, Training Loss: 0.6283158659934998, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8944306373596191, Validation Accuracy: 0.5\n",
      "Epoch 7701/10000, Training Loss: 0.6503698229789734, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6445087194442749, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7702/10000, Training Loss: 0.6651910543441772, Training Accuracy: 0.6348039215686274, Validation Loss: 0.5011846423149109, Validation Accuracy: 0.75\n",
      "Epoch 7703/10000, Training Loss: 0.6099196672439575, Training Accuracy: 0.6764705882352942, Validation Loss: 1.0500487089157104, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7704/10000, Training Loss: 0.6029312014579773, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6598932147026062, Validation Accuracy: 0.5\n",
      "Epoch 7705/10000, Training Loss: 0.639803409576416, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8483749032020569, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7706/10000, Training Loss: 0.5890873074531555, Training Accuracy: 0.6911764705882353, Validation Loss: 0.8159831166267395, Validation Accuracy: 0.5\n",
      "Epoch 7707/10000, Training Loss: 0.6864327788352966, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8355181217193604, Validation Accuracy: 0.5\n",
      "Epoch 7708/10000, Training Loss: 0.6203069686889648, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0577815771102905, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7709/10000, Training Loss: 0.685495913028717, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7592031359672546, Validation Accuracy: 0.5\n",
      "Epoch 7710/10000, Training Loss: 0.6278372406959534, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7789373993873596, Validation Accuracy: 0.5\n",
      "Epoch 7711/10000, Training Loss: 0.6742680668830872, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8049724102020264, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7712/10000, Training Loss: 0.6802595257759094, Training Accuracy: 0.5857843137254902, Validation Loss: 0.536294162273407, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7713/10000, Training Loss: 0.6460713148117065, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8235499262809753, Validation Accuracy: 0.5\n",
      "Epoch 7714/10000, Training Loss: 0.6248897314071655, Training Accuracy: 0.625, Validation Loss: 0.9862574934959412, Validation Accuracy: 0.25\n",
      "Epoch 7715/10000, Training Loss: 0.6301217675209045, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9392675757408142, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7716/10000, Training Loss: 0.6268777847290039, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7205290198326111, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7717/10000, Training Loss: 0.6411070823669434, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9659523963928223, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7718/10000, Training Loss: 0.6817294955253601, Training Accuracy: 0.6642156862745098, Validation Loss: 1.3744454383850098, Validation Accuracy: 0.25\n",
      "Epoch 7719/10000, Training Loss: 0.653430163860321, Training Accuracy: 0.6421568627450981, Validation Loss: 1.0206984281539917, Validation Accuracy: 0.5\n",
      "Epoch 7720/10000, Training Loss: 0.6510328650474548, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7518937587738037, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7721/10000, Training Loss: 0.6351391673088074, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9914615154266357, Validation Accuracy: 0.5\n",
      "Epoch 7722/10000, Training Loss: 0.6733256578445435, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8999710083007812, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7723/10000, Training Loss: 0.6146740913391113, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7460305690765381, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7724/10000, Training Loss: 0.6652294993400574, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8605124354362488, Validation Accuracy: 0.5\n",
      "Epoch 7725/10000, Training Loss: 0.677649974822998, Training Accuracy: 0.5735294117647058, Validation Loss: 0.8543491363525391, Validation Accuracy: 0.25\n",
      "Epoch 7726/10000, Training Loss: 0.7219828963279724, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8847518563270569, Validation Accuracy: 0.5\n",
      "Epoch 7727/10000, Training Loss: 0.6105291247367859, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6866186261177063, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7728/10000, Training Loss: 0.6429170370101929, Training Accuracy: 0.6299019607843137, Validation Loss: 0.5927799344062805, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7729/10000, Training Loss: 0.6699330806732178, Training Accuracy: 0.5931372549019608, Validation Loss: 1.2214285135269165, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7730/10000, Training Loss: 0.6580603122711182, Training Accuracy: 0.5980392156862745, Validation Loss: 0.648135781288147, Validation Accuracy: 0.75\n",
      "Epoch 7731/10000, Training Loss: 0.612352728843689, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7248223423957825, Validation Accuracy: 0.5\n",
      "Epoch 7732/10000, Training Loss: 0.646190345287323, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8216755986213684, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7733/10000, Training Loss: 0.6623986959457397, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6487517356872559, Validation Accuracy: 0.75\n",
      "Epoch 7734/10000, Training Loss: 0.6500109434127808, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8381687998771667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7735/10000, Training Loss: 0.6186316609382629, Training Accuracy: 0.6691176470588235, Validation Loss: 0.6603438258171082, Validation Accuracy: 0.5\n",
      "Epoch 7736/10000, Training Loss: 0.6733766198158264, Training Accuracy: 0.6323529411764706, Validation Loss: 1.1786508560180664, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7737/10000, Training Loss: 0.6442165970802307, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6209840178489685, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7738/10000, Training Loss: 0.6645961999893188, Training Accuracy: 0.5955882352941176, Validation Loss: 0.700070858001709, Validation Accuracy: 0.5\n",
      "Epoch 7739/10000, Training Loss: 0.6564533114433289, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0308500528335571, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7740/10000, Training Loss: 0.6105186343193054, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9625635743141174, Validation Accuracy: 0.25\n",
      "Epoch 7741/10000, Training Loss: 0.6220400929450989, Training Accuracy: 0.6691176470588235, Validation Loss: 1.0738900899887085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7742/10000, Training Loss: 0.6514134407043457, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7282175421714783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7743/10000, Training Loss: 0.7012851238250732, Training Accuracy: 0.5735294117647058, Validation Loss: 1.3333078622817993, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 7744/10000, Training Loss: 0.631786048412323, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7641395926475525, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7745/10000, Training Loss: 0.6730552315711975, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7529473304748535, Validation Accuracy: 0.25\n",
      "Epoch 7746/10000, Training Loss: 0.6573905944824219, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9572641253471375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7747/10000, Training Loss: 0.6606227159500122, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8153939247131348, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7748/10000, Training Loss: 0.6447064280509949, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7374186515808105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7749/10000, Training Loss: 0.6487755179405212, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7585129141807556, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7750/10000, Training Loss: 0.622266948223114, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9837811589241028, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7751/10000, Training Loss: 0.6258090734481812, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7397618889808655, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7752/10000, Training Loss: 0.6648544073104858, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0644659996032715, Validation Accuracy: 0.25\n",
      "Epoch 7753/10000, Training Loss: 0.676970899105072, Training Accuracy: 0.5882352941176471, Validation Loss: 0.887385368347168, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7754/10000, Training Loss: 0.6343237161636353, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8671069145202637, Validation Accuracy: 0.25\n",
      "Epoch 7755/10000, Training Loss: 0.6470782160758972, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7097094655036926, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7756/10000, Training Loss: 0.6794806122779846, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0791314840316772, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7757/10000, Training Loss: 0.649190366268158, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1096919775009155, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7758/10000, Training Loss: 0.6546977162361145, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7835825085639954, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7759/10000, Training Loss: 0.6560075879096985, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8416566252708435, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7760/10000, Training Loss: 0.6563567519187927, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7818488478660583, Validation Accuracy: 0.5\n",
      "Epoch 7761/10000, Training Loss: 0.678705096244812, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6951456665992737, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7762/10000, Training Loss: 0.6269330382347107, Training Accuracy: 0.6691176470588235, Validation Loss: 0.711845338344574, Validation Accuracy: 0.5\n",
      "Epoch 7763/10000, Training Loss: 0.5891244411468506, Training Accuracy: 0.6911764705882353, Validation Loss: 0.6891714930534363, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7764/10000, Training Loss: 0.6806365847587585, Training Accuracy: 0.5318627450980392, Validation Loss: 0.9398303627967834, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7765/10000, Training Loss: 0.6234055161476135, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7409772276878357, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7766/10000, Training Loss: 0.604941189289093, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6469783782958984, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7767/10000, Training Loss: 0.6588942408561707, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0672277212142944, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7768/10000, Training Loss: 0.5989150404930115, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6851599812507629, Validation Accuracy: 0.5\n",
      "Epoch 7769/10000, Training Loss: 0.6670831441879272, Training Accuracy: 0.5588235294117647, Validation Loss: 0.6668607592582703, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7770/10000, Training Loss: 0.6110778450965881, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8233397006988525, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7771/10000, Training Loss: 0.668386697769165, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8348956108093262, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7772/10000, Training Loss: 0.6321685910224915, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8692514896392822, Validation Accuracy: 0.5\n",
      "Epoch 7773/10000, Training Loss: 0.7218148708343506, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6750850677490234, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7774/10000, Training Loss: 0.6763370037078857, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8510560393333435, Validation Accuracy: 0.5\n",
      "Epoch 7775/10000, Training Loss: 0.6466574668884277, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0341986417770386, Validation Accuracy: 0.25\n",
      "Epoch 7776/10000, Training Loss: 0.6759205460548401, Training Accuracy: 0.5931372549019608, Validation Loss: 0.775554358959198, Validation Accuracy: 0.5\n",
      "Epoch 7777/10000, Training Loss: 0.6290186643600464, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7588575482368469, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7778/10000, Training Loss: 0.6801822185516357, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8261120319366455, Validation Accuracy: 0.5\n",
      "Epoch 7779/10000, Training Loss: 0.6334372758865356, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9450724720954895, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7780/10000, Training Loss: 0.6743138432502747, Training Accuracy: 0.5931372549019608, Validation Loss: 1.1868592500686646, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7781/10000, Training Loss: 0.6792536973953247, Training Accuracy: 0.6299019607843137, Validation Loss: 0.892223596572876, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7782/10000, Training Loss: 0.6292480826377869, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7955467104911804, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7783/10000, Training Loss: 0.6711651682853699, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6985118389129639, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7784/10000, Training Loss: 0.6037203073501587, Training Accuracy: 0.678921568627451, Validation Loss: 0.7286849021911621, Validation Accuracy: 0.5\n",
      "Epoch 7785/10000, Training Loss: 0.6280787587165833, Training Accuracy: 0.6936274509803921, Validation Loss: 0.730108916759491, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7786/10000, Training Loss: 0.6404255628585815, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6889984011650085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7787/10000, Training Loss: 0.6441335678100586, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9558343887329102, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7788/10000, Training Loss: 0.6719756722450256, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7189123034477234, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7789/10000, Training Loss: 0.637371301651001, Training Accuracy: 0.6544117647058824, Validation Loss: 0.777374267578125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7790/10000, Training Loss: 0.6658725142478943, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8328830599784851, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7791/10000, Training Loss: 0.6532040238380432, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7916013598442078, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7792/10000, Training Loss: 0.6899921298027039, Training Accuracy: 0.6225490196078431, Validation Loss: 1.2058258056640625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7793/10000, Training Loss: 0.6685290336608887, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9522385597229004, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7794/10000, Training Loss: 0.6118159294128418, Training Accuracy: 0.678921568627451, Validation Loss: 0.8634162545204163, Validation Accuracy: 0.25\n",
      "Epoch 7795/10000, Training Loss: 0.6641015410423279, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8503977656364441, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7796/10000, Training Loss: 0.6703474521636963, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7895446419715881, Validation Accuracy: 0.5\n",
      "Epoch 7797/10000, Training Loss: 0.6390206813812256, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8215046525001526, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7798/10000, Training Loss: 0.6175878047943115, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7748015522956848, Validation Accuracy: 0.5\n",
      "Epoch 7799/10000, Training Loss: 0.6793541312217712, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7804775238037109, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7800/10000, Training Loss: 0.6546164155006409, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7355101108551025, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7801/10000, Training Loss: 0.6459606885910034, Training Accuracy: 0.6029411764705882, Validation Loss: 1.210724115371704, Validation Accuracy: 0.5\n",
      "Epoch 7802/10000, Training Loss: 0.6276180744171143, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8764128684997559, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7803/10000, Training Loss: 0.7193266749382019, Training Accuracy: 0.571078431372549, Validation Loss: 0.8220810890197754, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7804/10000, Training Loss: 0.6211355328559875, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6902700066566467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7805/10000, Training Loss: 0.6242423057556152, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7765946388244629, Validation Accuracy: 0.5\n",
      "Epoch 7806/10000, Training Loss: 0.6372905969619751, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7153070569038391, Validation Accuracy: 0.5\n",
      "Epoch 7807/10000, Training Loss: 0.656106173992157, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8413442969322205, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7808/10000, Training Loss: 0.6259273886680603, Training Accuracy: 0.6004901960784313, Validation Loss: 0.676625669002533, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7809/10000, Training Loss: 0.6085429787635803, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1694239377975464, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7810/10000, Training Loss: 0.6105580925941467, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7462945580482483, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7811/10000, Training Loss: 0.624764621257782, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9262426495552063, Validation Accuracy: 0.5\n",
      "Epoch 7812/10000, Training Loss: 0.6548869013786316, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6729548573493958, Validation Accuracy: 0.75\n",
      "Epoch 7813/10000, Training Loss: 0.6629730463027954, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8082981705665588, Validation Accuracy: 0.5\n",
      "Epoch 7814/10000, Training Loss: 0.6678736209869385, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6601026654243469, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7815/10000, Training Loss: 0.6392627954483032, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9185534119606018, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7816/10000, Training Loss: 0.6680915951728821, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9548518061637878, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7817/10000, Training Loss: 0.6130191683769226, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8534266948699951, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7818/10000, Training Loss: 0.6656808853149414, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7492212653160095, Validation Accuracy: 0.5\n",
      "Epoch 7819/10000, Training Loss: 0.6569687128067017, Training Accuracy: 0.6200980392156863, Validation Loss: 0.637096643447876, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7820/10000, Training Loss: 0.632230281829834, Training Accuracy: 0.6299019607843137, Validation Loss: 0.978510856628418, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7821/10000, Training Loss: 0.6655223965644836, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7215502858161926, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7822/10000, Training Loss: 0.5928082466125488, Training Accuracy: 0.6936274509803921, Validation Loss: 0.8363611698150635, Validation Accuracy: 0.5\n",
      "Epoch 7823/10000, Training Loss: 0.5794390439987183, Training Accuracy: 0.7058823529411765, Validation Loss: 0.9947977066040039, Validation Accuracy: 0.25\n",
      "Epoch 7824/10000, Training Loss: 0.6468446850776672, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9179542064666748, Validation Accuracy: 0.5\n",
      "Epoch 7825/10000, Training Loss: 0.6403835415840149, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0199925899505615, Validation Accuracy: 0.25\n",
      "Epoch 7826/10000, Training Loss: 0.6445356011390686, Training Accuracy: 0.6078431372549019, Validation Loss: 0.5548236966133118, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7827/10000, Training Loss: 0.6327638626098633, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9824965596199036, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7828/10000, Training Loss: 0.6071540713310242, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6548061370849609, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7829/10000, Training Loss: 0.6841835975646973, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6387080550193787, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7830/10000, Training Loss: 0.650238037109375, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7435566782951355, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7831/10000, Training Loss: 0.6471267342567444, Training Accuracy: 0.625, Validation Loss: 0.8713674545288086, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7832/10000, Training Loss: 0.6672304272651672, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0830281972885132, Validation Accuracy: 0.5\n",
      "Epoch 7833/10000, Training Loss: 0.6402990818023682, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7760844826698303, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7834/10000, Training Loss: 0.666921854019165, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8642093539237976, Validation Accuracy: 0.25\n",
      "Epoch 7835/10000, Training Loss: 0.6087884306907654, Training Accuracy: 0.6887254901960784, Validation Loss: 1.0907536745071411, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7836/10000, Training Loss: 0.6453976631164551, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7402718663215637, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7837/10000, Training Loss: 0.6469494104385376, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7185598015785217, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7838/10000, Training Loss: 0.6901945471763611, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7422144412994385, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7839/10000, Training Loss: 0.6200771927833557, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7406490445137024, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7840/10000, Training Loss: 0.6646760106086731, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6792951226234436, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7841/10000, Training Loss: 0.6475735306739807, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9266800284385681, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7842/10000, Training Loss: 0.6287652850151062, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8356494903564453, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7843/10000, Training Loss: 0.6604792475700378, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7457664608955383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7844/10000, Training Loss: 0.6206265091896057, Training Accuracy: 0.6176470588235294, Validation Loss: 1.133711576461792, Validation Accuracy: 0.5\n",
      "Epoch 7845/10000, Training Loss: 0.6616038084030151, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7828376293182373, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7846/10000, Training Loss: 0.6518504023551941, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6865420937538147, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7847/10000, Training Loss: 0.6282745003700256, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7244817614555359, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7848/10000, Training Loss: 0.6468198895454407, Training Accuracy: 0.6053921568627451, Validation Loss: 0.652926504611969, Validation Accuracy: 0.5\n",
      "Epoch 7849/10000, Training Loss: 0.6417139768600464, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9366164803504944, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7850/10000, Training Loss: 0.6620745658874512, Training Accuracy: 0.678921568627451, Validation Loss: 0.8947272300720215, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7851/10000, Training Loss: 0.6558931469917297, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7112498879432678, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7852/10000, Training Loss: 0.6665136218070984, Training Accuracy: 0.5833333333333334, Validation Loss: 1.1677387952804565, Validation Accuracy: 0.25\n",
      "Epoch 7853/10000, Training Loss: 0.6369420886039734, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8384339213371277, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7854/10000, Training Loss: 0.6564686298370361, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7194914221763611, Validation Accuracy: 0.5\n",
      "Epoch 7855/10000, Training Loss: 0.6320061683654785, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7220764756202698, Validation Accuracy: 0.5\n",
      "Epoch 7856/10000, Training Loss: 0.6630721688270569, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8965334296226501, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7857/10000, Training Loss: 0.6512022018432617, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9053306579589844, Validation Accuracy: 0.5\n",
      "Epoch 7858/10000, Training Loss: 0.6473903059959412, Training Accuracy: 0.5808823529411765, Validation Loss: 1.1071208715438843, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7859/10000, Training Loss: 0.6408061385154724, Training Accuracy: 0.625, Validation Loss: 0.6584266424179077, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7860/10000, Training Loss: 0.696650505065918, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7418681979179382, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7861/10000, Training Loss: 0.6143134236335754, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6685226559638977, Validation Accuracy: 0.75\n",
      "Epoch 7862/10000, Training Loss: 0.6783108711242676, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8553187251091003, Validation Accuracy: 0.25\n",
      "Epoch 7863/10000, Training Loss: 0.59831702709198, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8371197581291199, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7864/10000, Training Loss: 0.6555307507514954, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9369070529937744, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7865/10000, Training Loss: 0.6776826977729797, Training Accuracy: 0.5833333333333334, Validation Loss: 0.813955545425415, Validation Accuracy: 0.25\n",
      "Epoch 7866/10000, Training Loss: 0.6690384149551392, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6819449067115784, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7867/10000, Training Loss: 0.6629596948623657, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7803959250450134, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7868/10000, Training Loss: 0.6486225724220276, Training Accuracy: 0.6862745098039216, Validation Loss: 0.924292802810669, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7869/10000, Training Loss: 0.6786630749702454, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7149125933647156, Validation Accuracy: 0.5\n",
      "Epoch 7870/10000, Training Loss: 0.6220120191574097, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8848002552986145, Validation Accuracy: 0.5\n",
      "Epoch 7871/10000, Training Loss: 0.684083878993988, Training Accuracy: 0.5735294117647058, Validation Loss: 1.1043044328689575, Validation Accuracy: 0.5\n",
      "Epoch 7872/10000, Training Loss: 0.6511620283126831, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7773535251617432, Validation Accuracy: 0.5\n",
      "Epoch 7873/10000, Training Loss: 0.6201974749565125, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6686918139457703, Validation Accuracy: 0.5\n",
      "Epoch 7874/10000, Training Loss: 0.6483691334724426, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7614505887031555, Validation Accuracy: 0.5\n",
      "Epoch 7875/10000, Training Loss: 0.6590887904167175, Training Accuracy: 0.571078431372549, Validation Loss: 0.765842854976654, Validation Accuracy: 0.25\n",
      "Epoch 7876/10000, Training Loss: 0.6308950781822205, Training Accuracy: 0.6004901960784313, Validation Loss: 0.9471654891967773, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7877/10000, Training Loss: 0.632453978061676, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6517866253852844, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 7878/10000, Training Loss: 0.6720703840255737, Training Accuracy: 0.5808823529411765, Validation Loss: 0.868608295917511, Validation Accuracy: 0.5\n",
      "Epoch 7879/10000, Training Loss: 0.6492906212806702, Training Accuracy: 0.6200980392156863, Validation Loss: 0.76712566614151, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7880/10000, Training Loss: 0.6504906415939331, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8645365238189697, Validation Accuracy: 0.5\n",
      "Epoch 7881/10000, Training Loss: 0.6368158459663391, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7547542452812195, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7882/10000, Training Loss: 0.6582753658294678, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8270975947380066, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7883/10000, Training Loss: 0.6339923739433289, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8116164207458496, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7884/10000, Training Loss: 0.660728394985199, Training Accuracy: 0.6004901960784313, Validation Loss: 0.822624146938324, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7885/10000, Training Loss: 0.6612824201583862, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7503638863563538, Validation Accuracy: 0.5\n",
      "Epoch 7886/10000, Training Loss: 0.650653600692749, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8932772278785706, Validation Accuracy: 0.5\n",
      "Epoch 7887/10000, Training Loss: 0.6815763115882874, Training Accuracy: 0.5784313725490197, Validation Loss: 0.9604897499084473, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7888/10000, Training Loss: 0.6730310320854187, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8907947540283203, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7889/10000, Training Loss: 0.6115027070045471, Training Accuracy: 0.6397058823529411, Validation Loss: 1.171007752418518, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 7890/10000, Training Loss: 0.6810106635093689, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8909194469451904, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7891/10000, Training Loss: 0.6556367874145508, Training Accuracy: 0.5857843137254902, Validation Loss: 0.9141973853111267, Validation Accuracy: 0.25\n",
      "Epoch 7892/10000, Training Loss: 0.6504207849502563, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7527737617492676, Validation Accuracy: 0.5\n",
      "Epoch 7893/10000, Training Loss: 0.692965030670166, Training Accuracy: 0.5808823529411765, Validation Loss: 0.572185218334198, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7894/10000, Training Loss: 0.6086374521255493, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7250792384147644, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7895/10000, Training Loss: 0.6388852000236511, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9186757206916809, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7896/10000, Training Loss: 0.6105539798736572, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8041947484016418, Validation Accuracy: 0.5\n",
      "Epoch 7897/10000, Training Loss: 0.6380769610404968, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9881901741027832, Validation Accuracy: 0.5\n",
      "Epoch 7898/10000, Training Loss: 0.6575395464897156, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9834524989128113, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7899/10000, Training Loss: 0.6262402534484863, Training Accuracy: 0.6715686274509803, Validation Loss: 1.3564468622207642, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7900/10000, Training Loss: 0.639350414276123, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8666925430297852, Validation Accuracy: 0.25\n",
      "Epoch 7901/10000, Training Loss: 0.6410119533538818, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8702578544616699, Validation Accuracy: 0.5\n",
      "Epoch 7902/10000, Training Loss: 0.6129153370857239, Training Accuracy: 0.696078431372549, Validation Loss: 0.7715992331504822, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7903/10000, Training Loss: 0.629854679107666, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0746287107467651, Validation Accuracy: 0.5\n",
      "Epoch 7904/10000, Training Loss: 0.6519933342933655, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6671072840690613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7905/10000, Training Loss: 0.6346215605735779, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8174416422843933, Validation Accuracy: 0.5\n",
      "Epoch 7906/10000, Training Loss: 0.6220158934593201, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8618590235710144, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7907/10000, Training Loss: 0.6265997886657715, Training Accuracy: 0.6470588235294118, Validation Loss: 1.2660012245178223, Validation Accuracy: 0.0\n",
      "Epoch 7908/10000, Training Loss: 0.6615644097328186, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7980227470397949, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7909/10000, Training Loss: 0.6613785028457642, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7025346755981445, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7910/10000, Training Loss: 0.6631609797477722, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6937992572784424, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7911/10000, Training Loss: 0.6662392616271973, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7438834309577942, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7912/10000, Training Loss: 0.651439905166626, Training Accuracy: 0.6372549019607843, Validation Loss: 1.0033830404281616, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7913/10000, Training Loss: 0.6879230737686157, Training Accuracy: 0.571078431372549, Validation Loss: 0.9015931487083435, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7914/10000, Training Loss: 0.6478782892227173, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8719258904457092, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7915/10000, Training Loss: 0.6438637375831604, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6860848069190979, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7916/10000, Training Loss: 0.6363429427146912, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8313872218132019, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7917/10000, Training Loss: 0.6263400912284851, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8986706137657166, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7918/10000, Training Loss: 0.6741544604301453, Training Accuracy: 0.6519607843137255, Validation Loss: 1.0583003759384155, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7919/10000, Training Loss: 0.6510538458824158, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6813585758209229, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7920/10000, Training Loss: 0.6193045973777771, Training Accuracy: 0.7132352941176471, Validation Loss: 0.8595230579376221, Validation Accuracy: 0.25\n",
      "Epoch 7921/10000, Training Loss: 0.6003204584121704, Training Accuracy: 0.6887254901960784, Validation Loss: 0.912371814250946, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7922/10000, Training Loss: 0.6433025598526001, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6845082640647888, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7923/10000, Training Loss: 0.6089218854904175, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8937971591949463, Validation Accuracy: 0.5\n",
      "Epoch 7924/10000, Training Loss: 0.6474087834358215, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0297024250030518, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7925/10000, Training Loss: 0.6474754214286804, Training Accuracy: 0.6813725490196079, Validation Loss: 0.9237041473388672, Validation Accuracy: 0.5\n",
      "Epoch 7926/10000, Training Loss: 0.6359002590179443, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1905022859573364, Validation Accuracy: 0.25\n",
      "Epoch 7927/10000, Training Loss: 0.6426737308502197, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7346208691596985, Validation Accuracy: 0.5\n",
      "Epoch 7928/10000, Training Loss: 0.5933281183242798, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7913839221000671, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7929/10000, Training Loss: 0.6457793116569519, Training Accuracy: 0.6372549019607843, Validation Loss: 1.1132826805114746, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7930/10000, Training Loss: 0.5874360203742981, Training Accuracy: 0.6813725490196079, Validation Loss: 1.133017659187317, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7931/10000, Training Loss: 0.6808048486709595, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8201282024383545, Validation Accuracy: 0.5\n",
      "Epoch 7932/10000, Training Loss: 0.6735235452651978, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6696856617927551, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7933/10000, Training Loss: 0.6597856879234314, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6442484259605408, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7934/10000, Training Loss: 0.6460185050964355, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6729219555854797, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7935/10000, Training Loss: 0.632020115852356, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8022250533103943, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7936/10000, Training Loss: 0.6367578506469727, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8966779112815857, Validation Accuracy: 0.5\n",
      "Epoch 7937/10000, Training Loss: 0.6984766125679016, Training Accuracy: 0.5196078431372549, Validation Loss: 0.7327296137809753, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7938/10000, Training Loss: 0.6473752856254578, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7979676127433777, Validation Accuracy: 0.25\n",
      "Epoch 7939/10000, Training Loss: 0.676851212978363, Training Accuracy: 0.5392156862745098, Validation Loss: 0.6781092286109924, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7940/10000, Training Loss: 0.6343031525611877, Training Accuracy: 0.6617647058823529, Validation Loss: 1.194138526916504, Validation Accuracy: 0.5\n",
      "Epoch 7941/10000, Training Loss: 0.6822254061698914, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8397446274757385, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7942/10000, Training Loss: 0.6502634882926941, Training Accuracy: 0.6568627450980392, Validation Loss: 1.1383987665176392, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7943/10000, Training Loss: 0.6226778030395508, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8879860043525696, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7944/10000, Training Loss: 0.639104962348938, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9758687019348145, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7945/10000, Training Loss: 0.6475595235824585, Training Accuracy: 0.6323529411764706, Validation Loss: 0.783498227596283, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7946/10000, Training Loss: 0.6642524600028992, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8743793368339539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7947/10000, Training Loss: 0.6418811082839966, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9599102139472961, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7948/10000, Training Loss: 0.6401487588882446, Training Accuracy: 0.6495098039215687, Validation Loss: 1.2355027198791504, Validation Accuracy: 0.25\n",
      "Epoch 7949/10000, Training Loss: 0.6530297994613647, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7068236470222473, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7950/10000, Training Loss: 0.6430517435073853, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7959480285644531, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7951/10000, Training Loss: 0.6164233088493347, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6403998136520386, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7952/10000, Training Loss: 0.5910813212394714, Training Accuracy: 0.6985294117647058, Validation Loss: 0.6752328872680664, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7953/10000, Training Loss: 0.6553654670715332, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8348379731178284, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7954/10000, Training Loss: 0.6553654670715332, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9082362651824951, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7955/10000, Training Loss: 0.6314787268638611, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9825912117958069, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7956/10000, Training Loss: 0.6464450359344482, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7324013113975525, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7957/10000, Training Loss: 0.6368600726127625, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9129438996315002, Validation Accuracy: 0.5\n",
      "Epoch 7958/10000, Training Loss: 0.6600857973098755, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6411110758781433, Validation Accuracy: 0.75\n",
      "Epoch 7959/10000, Training Loss: 0.6153774857521057, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8557586073875427, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7960/10000, Training Loss: 0.6875783205032349, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8844466209411621, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 7961/10000, Training Loss: 0.6581432223320007, Training Accuracy: 0.6495098039215687, Validation Loss: 0.75140380859375, Validation Accuracy: 0.5\n",
      "Epoch 7962/10000, Training Loss: 0.618618905544281, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8276694416999817, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7963/10000, Training Loss: 0.6280683875083923, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8160808682441711, Validation Accuracy: 0.5\n",
      "Epoch 7964/10000, Training Loss: 0.623409628868103, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9046069979667664, Validation Accuracy: 0.25\n",
      "Epoch 7965/10000, Training Loss: 0.6640083193778992, Training Accuracy: 0.6397058823529411, Validation Loss: 0.736849308013916, Validation Accuracy: 0.5\n",
      "Epoch 7966/10000, Training Loss: 0.6888457536697388, Training Accuracy: 0.5661764705882353, Validation Loss: 0.6612215638160706, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7967/10000, Training Loss: 0.62935870885849, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8121673464775085, Validation Accuracy: 0.25\n",
      "Epoch 7968/10000, Training Loss: 0.672704815864563, Training Accuracy: 0.571078431372549, Validation Loss: 0.671180248260498, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7969/10000, Training Loss: 0.6778523921966553, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7485398650169373, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7970/10000, Training Loss: 0.626191258430481, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8923941254615784, Validation Accuracy: 0.25\n",
      "Epoch 7971/10000, Training Loss: 0.6052950024604797, Training Accuracy: 0.696078431372549, Validation Loss: 0.5982541441917419, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7972/10000, Training Loss: 0.6610248684883118, Training Accuracy: 0.5906862745098039, Validation Loss: 0.5646007657051086, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7973/10000, Training Loss: 0.6552700996398926, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6048191785812378, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7974/10000, Training Loss: 0.6188965439796448, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7298622131347656, Validation Accuracy: 0.5\n",
      "Epoch 7975/10000, Training Loss: 0.6627106070518494, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6641931533813477, Validation Accuracy: 0.5\n",
      "Epoch 7976/10000, Training Loss: 0.6314506530761719, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8609933853149414, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7977/10000, Training Loss: 0.6274627447128296, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7377573847770691, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7978/10000, Training Loss: 0.6340183019638062, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9678125381469727, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7979/10000, Training Loss: 0.6584534049034119, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7919420599937439, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7980/10000, Training Loss: 0.6684141159057617, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9106962084770203, Validation Accuracy: 0.5\n",
      "Epoch 7981/10000, Training Loss: 0.6892304420471191, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6972822546958923, Validation Accuracy: 0.5\n",
      "Epoch 7982/10000, Training Loss: 0.6089521050453186, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6310551166534424, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7983/10000, Training Loss: 0.6373000144958496, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7591748833656311, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7984/10000, Training Loss: 0.6764006614685059, Training Accuracy: 0.553921568627451, Validation Loss: 0.72515469789505, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7985/10000, Training Loss: 0.7305288910865784, Training Accuracy: 0.6691176470588235, Validation Loss: 1.904092788696289, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7986/10000, Training Loss: 0.6336629986763, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7768917083740234, Validation Accuracy: 0.25\n",
      "Epoch 7987/10000, Training Loss: 0.6706980466842651, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0714658498764038, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7988/10000, Training Loss: 0.6246846914291382, Training Accuracy: 0.6323529411764706, Validation Loss: 0.713437557220459, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7989/10000, Training Loss: 0.671343982219696, Training Accuracy: 0.6176470588235294, Validation Loss: 1.0700315237045288, Validation Accuracy: 0.5\n",
      "Epoch 7990/10000, Training Loss: 0.6950061917304993, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7869580388069153, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 7991/10000, Training Loss: 0.633025586605072, Training Accuracy: 0.6446078431372549, Validation Loss: 0.662815511226654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7992/10000, Training Loss: 0.6617986559867859, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9187952876091003, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 7993/10000, Training Loss: 0.6667064428329468, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8812665939331055, Validation Accuracy: 0.5\n",
      "Epoch 7994/10000, Training Loss: 0.6238574385643005, Training Accuracy: 0.6470588235294118, Validation Loss: 0.697364091873169, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 7995/10000, Training Loss: 0.6300421357154846, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7860824465751648, Validation Accuracy: 0.5\n",
      "Epoch 7996/10000, Training Loss: 0.6230039000511169, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7571048736572266, Validation Accuracy: 0.75\n",
      "Epoch 7997/10000, Training Loss: 0.7004113793373108, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0493003129959106, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 7998/10000, Training Loss: 0.6455627679824829, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7524660229682922, Validation Accuracy: 0.5\n",
      "Epoch 7999/10000, Training Loss: 0.6650125980377197, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8206449151039124, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8000/10000, Training Loss: 0.6498082280158997, Training Accuracy: 0.6446078431372549, Validation Loss: 0.5778017640113831, Validation Accuracy: 0.75\n",
      "Epoch 8001/10000, Training Loss: 0.655768871307373, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8065645098686218, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8002/10000, Training Loss: 0.6576347947120667, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7691679000854492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8003/10000, Training Loss: 0.6679794192314148, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7375921607017517, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8004/10000, Training Loss: 0.6548644304275513, Training Accuracy: 0.625, Validation Loss: 0.7996181845664978, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8005/10000, Training Loss: 0.6187703609466553, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6706485152244568, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8006/10000, Training Loss: 0.6683514714241028, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6554886698722839, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8007/10000, Training Loss: 0.6525721549987793, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8199108242988586, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8008/10000, Training Loss: 0.6433378458023071, Training Accuracy: 0.6323529411764706, Validation Loss: 0.5763588547706604, Validation Accuracy: 0.75\n",
      "Epoch 8009/10000, Training Loss: 0.6290263533592224, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8014937043190002, Validation Accuracy: 0.5\n",
      "Epoch 8010/10000, Training Loss: 0.6637130379676819, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8490050435066223, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8011/10000, Training Loss: 0.6223570704460144, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8210199475288391, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8012/10000, Training Loss: 0.6330011487007141, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7511658072471619, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8013/10000, Training Loss: 0.5842581987380981, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8917360901832581, Validation Accuracy: 0.25\n",
      "Epoch 8014/10000, Training Loss: 0.6419352889060974, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7339134812355042, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8015/10000, Training Loss: 0.6146218776702881, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9145390391349792, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8016/10000, Training Loss: 0.6295433640480042, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7258875370025635, Validation Accuracy: 0.5\n",
      "Epoch 8017/10000, Training Loss: 0.6431342959403992, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7852352261543274, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8018/10000, Training Loss: 0.6555156111717224, Training Accuracy: 0.6127450980392157, Validation Loss: 1.1960681676864624, Validation Accuracy: 0.25\n",
      "Epoch 8019/10000, Training Loss: 0.5936306715011597, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6504952311515808, Validation Accuracy: 0.75\n",
      "Epoch 8020/10000, Training Loss: 0.6118178963661194, Training Accuracy: 0.6691176470588235, Validation Loss: 0.6702749729156494, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8021/10000, Training Loss: 0.6115043759346008, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9124755859375, Validation Accuracy: 0.25\n",
      "Epoch 8022/10000, Training Loss: 0.6491337418556213, Training Accuracy: 0.5980392156862745, Validation Loss: 1.1273131370544434, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8023/10000, Training Loss: 0.66415935754776, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8237079977989197, Validation Accuracy: 0.25\n",
      "Epoch 8024/10000, Training Loss: 0.6484510898590088, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8558055758476257, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8025/10000, Training Loss: 0.6250052452087402, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8256340026855469, Validation Accuracy: 0.5\n",
      "Epoch 8026/10000, Training Loss: 0.611361026763916, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7279012799263, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8027/10000, Training Loss: 0.6447495222091675, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9058879017829895, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8028/10000, Training Loss: 0.6105093359947205, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6149111390113831, Validation Accuracy: 0.5\n",
      "Epoch 8029/10000, Training Loss: 0.5982842445373535, Training Accuracy: 0.6862745098039216, Validation Loss: 0.5531117916107178, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8030/10000, Training Loss: 0.6765058636665344, Training Accuracy: 0.571078431372549, Validation Loss: 0.7625400424003601, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8031/10000, Training Loss: 0.6568601131439209, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7426413893699646, Validation Accuracy: 0.5\n",
      "Epoch 8032/10000, Training Loss: 0.6551434397697449, Training Accuracy: 0.6397058823529411, Validation Loss: 0.829018771648407, Validation Accuracy: 0.5\n",
      "Epoch 8033/10000, Training Loss: 0.6742110848426819, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6951329708099365, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8034/10000, Training Loss: 0.7106168866157532, Training Accuracy: 0.5245098039215687, Validation Loss: 0.846405029296875, Validation Accuracy: 0.5\n",
      "Epoch 8035/10000, Training Loss: 0.6638802886009216, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8086287379264832, Validation Accuracy: 0.5\n",
      "Epoch 8036/10000, Training Loss: 0.629792332649231, Training Accuracy: 0.678921568627451, Validation Loss: 0.9149954915046692, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8037/10000, Training Loss: 0.7038130760192871, Training Accuracy: 0.5269607843137255, Validation Loss: 1.0158368349075317, Validation Accuracy: 0.5\n",
      "Epoch 8038/10000, Training Loss: 0.6313615441322327, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7607882618904114, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8039/10000, Training Loss: 0.6537473797798157, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9138479828834534, Validation Accuracy: 0.25\n",
      "Epoch 8040/10000, Training Loss: 0.5944036245346069, Training Accuracy: 0.6985294117647058, Validation Loss: 0.8641529083251953, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8041/10000, Training Loss: 0.7205321192741394, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7675116658210754, Validation Accuracy: 0.5\n",
      "Epoch 8042/10000, Training Loss: 0.5879626274108887, Training Accuracy: 0.6936274509803921, Validation Loss: 0.9242520332336426, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8043/10000, Training Loss: 0.6388822793960571, Training Accuracy: 0.6397058823529411, Validation Loss: 0.5334745049476624, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8044/10000, Training Loss: 0.6773446202278137, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6225329637527466, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8045/10000, Training Loss: 0.6501739621162415, Training Accuracy: 0.6397058823529411, Validation Loss: 0.5584539771080017, Validation Accuracy: 0.75\n",
      "Epoch 8046/10000, Training Loss: 0.6414807438850403, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7419009804725647, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8047/10000, Training Loss: 0.6292785406112671, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7305068969726562, Validation Accuracy: 0.5\n",
      "Epoch 8048/10000, Training Loss: 0.6217013597488403, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6771883964538574, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8049/10000, Training Loss: 0.6686469316482544, Training Accuracy: 0.6421568627450981, Validation Loss: 0.958746612071991, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8050/10000, Training Loss: 0.6211267113685608, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7048694491386414, Validation Accuracy: 0.75\n",
      "Epoch 8051/10000, Training Loss: 0.7040872573852539, Training Accuracy: 0.6176470588235294, Validation Loss: 1.067515254020691, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8052/10000, Training Loss: 0.6667454838752747, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6461682915687561, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8053/10000, Training Loss: 0.6392960548400879, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8714084625244141, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8054/10000, Training Loss: 0.6638650298118591, Training Accuracy: 0.6102941176470589, Validation Loss: 0.893995463848114, Validation Accuracy: 0.5\n",
      "Epoch 8055/10000, Training Loss: 0.6712843775749207, Training Accuracy: 0.5833333333333334, Validation Loss: 0.8051843643188477, Validation Accuracy: 0.5\n",
      "Epoch 8056/10000, Training Loss: 0.6553964018821716, Training Accuracy: 0.5784313725490197, Validation Loss: 0.607046902179718, Validation Accuracy: 0.75\n",
      "Epoch 8057/10000, Training Loss: 0.6568936109542847, Training Accuracy: 0.6642156862745098, Validation Loss: 0.928154468536377, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8058/10000, Training Loss: 0.6459531784057617, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6606046557426453, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8059/10000, Training Loss: 0.6534947156906128, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7977734208106995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8060/10000, Training Loss: 0.6466487646102905, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7887447476387024, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8061/10000, Training Loss: 0.6343919634819031, Training Accuracy: 0.625, Validation Loss: 0.604107677936554, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8062/10000, Training Loss: 0.6606557369232178, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7634568810462952, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8063/10000, Training Loss: 0.6271888613700867, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8536455035209656, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8064/10000, Training Loss: 0.6281824111938477, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0430289506912231, Validation Accuracy: 0.25\n",
      "Epoch 8065/10000, Training Loss: 0.6922414302825928, Training Accuracy: 0.625, Validation Loss: 0.7627100944519043, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8066/10000, Training Loss: 0.6769172549247742, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7055861353874207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8067/10000, Training Loss: 0.6948166489601135, Training Accuracy: 0.5588235294117647, Validation Loss: 1.0342718362808228, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8068/10000, Training Loss: 0.6397832036018372, Training Accuracy: 0.6519607843137255, Validation Loss: 0.842719554901123, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8069/10000, Training Loss: 0.6638227701187134, Training Accuracy: 0.553921568627451, Validation Loss: 0.853318989276886, Validation Accuracy: 0.5\n",
      "Epoch 8070/10000, Training Loss: 0.6945571303367615, Training Accuracy: 0.5514705882352942, Validation Loss: 0.9553802013397217, Validation Accuracy: 0.25\n",
      "Epoch 8071/10000, Training Loss: 0.6163318753242493, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9377313256263733, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8072/10000, Training Loss: 0.6162524819374084, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8438906669616699, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8073/10000, Training Loss: 0.6504971981048584, Training Accuracy: 0.6470588235294118, Validation Loss: 0.5985597968101501, Validation Accuracy: 0.75\n",
      "Epoch 8074/10000, Training Loss: 0.6612866520881653, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9601185321807861, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8075/10000, Training Loss: 0.6287937760353088, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9714665412902832, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8076/10000, Training Loss: 0.6359323263168335, Training Accuracy: 0.6274509803921569, Validation Loss: 0.657720148563385, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8077/10000, Training Loss: 0.6674111485481262, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7057302594184875, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8078/10000, Training Loss: 0.6467467546463013, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7165396213531494, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8079/10000, Training Loss: 0.6640589833259583, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7888252139091492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8080/10000, Training Loss: 0.6277794241905212, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8023130893707275, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8081/10000, Training Loss: 0.6421176195144653, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6902467608451843, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8082/10000, Training Loss: 0.6539679169654846, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8832553029060364, Validation Accuracy: 0.5\n",
      "Epoch 8083/10000, Training Loss: 0.6727192401885986, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6800444722175598, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8084/10000, Training Loss: 0.6819283962249756, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8284007906913757, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8085/10000, Training Loss: 0.6097482442855835, Training Accuracy: 0.678921568627451, Validation Loss: 0.8991129994392395, Validation Accuracy: 0.5\n",
      "Epoch 8086/10000, Training Loss: 0.6606598496437073, Training Accuracy: 0.553921568627451, Validation Loss: 0.7483944892883301, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8087/10000, Training Loss: 0.6441720128059387, Training Accuracy: 0.6225490196078431, Validation Loss: 0.922004222869873, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8088/10000, Training Loss: 0.6529425978660583, Training Accuracy: 0.625, Validation Loss: 0.7102658152580261, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8089/10000, Training Loss: 0.6575953364372253, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6684597134590149, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8090/10000, Training Loss: 0.6225934624671936, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8316040635108948, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8091/10000, Training Loss: 0.6087976098060608, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8009281754493713, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8092/10000, Training Loss: 0.6469378471374512, Training Accuracy: 0.5759803921568627, Validation Loss: 0.734940230846405, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8093/10000, Training Loss: 0.6489595174789429, Training Accuracy: 0.5906862745098039, Validation Loss: 0.9319122433662415, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8094/10000, Training Loss: 0.6653682589530945, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7670738697052002, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8095/10000, Training Loss: 0.6364938616752625, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6055710911750793, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8096/10000, Training Loss: 0.6415291428565979, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6825082302093506, Validation Accuracy: 0.5\n",
      "Epoch 8097/10000, Training Loss: 0.6488595604896545, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6482502818107605, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8098/10000, Training Loss: 0.6356885433197021, Training Accuracy: 0.625, Validation Loss: 0.6934607625007629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8099/10000, Training Loss: 0.6574435234069824, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6153389811515808, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8100/10000, Training Loss: 0.6226315498352051, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7844007015228271, Validation Accuracy: 0.5\n",
      "Epoch 8101/10000, Training Loss: 0.6180636882781982, Training Accuracy: 0.6495098039215687, Validation Loss: 0.672234058380127, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8102/10000, Training Loss: 0.691606342792511, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6961545348167419, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8103/10000, Training Loss: 0.669031023979187, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6740329265594482, Validation Accuracy: 0.5\n",
      "Epoch 8104/10000, Training Loss: 0.6335842609405518, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8337422013282776, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8105/10000, Training Loss: 0.6117150783538818, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9437759518623352, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8106/10000, Training Loss: 0.6770997643470764, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8765507340431213, Validation Accuracy: 0.5\n",
      "Epoch 8107/10000, Training Loss: 0.6289705634117126, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8298243880271912, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8108/10000, Training Loss: 0.5946775078773499, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7002344727516174, Validation Accuracy: 0.5\n",
      "Epoch 8109/10000, Training Loss: 0.6510151624679565, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6124014258384705, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8110/10000, Training Loss: 0.698686957359314, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8600170612335205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8111/10000, Training Loss: 0.638821542263031, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8275503516197205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8112/10000, Training Loss: 0.6299241781234741, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7722129225730896, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8113/10000, Training Loss: 0.694701611995697, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8851278424263, Validation Accuracy: 0.5\n",
      "Epoch 8114/10000, Training Loss: 0.6600762009620667, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7633836269378662, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8115/10000, Training Loss: 0.6622484922409058, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7490999698638916, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8116/10000, Training Loss: 0.7037306427955627, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8920214176177979, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8117/10000, Training Loss: 0.6273905634880066, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9106596112251282, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8118/10000, Training Loss: 0.6542919874191284, Training Accuracy: 0.5955882352941176, Validation Loss: 1.2630680799484253, Validation Accuracy: 0.25\n",
      "Epoch 8119/10000, Training Loss: 0.660088062286377, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7573761343955994, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8120/10000, Training Loss: 0.6333627700805664, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6866108775138855, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8121/10000, Training Loss: 0.6236116886138916, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7096097469329834, Validation Accuracy: 0.5\n",
      "Epoch 8122/10000, Training Loss: 0.6702678799629211, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7051641941070557, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8123/10000, Training Loss: 0.6361846327781677, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6872835159301758, Validation Accuracy: 0.5\n",
      "Epoch 8124/10000, Training Loss: 0.6474546790122986, Training Accuracy: 0.6176470588235294, Validation Loss: 0.696160614490509, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8125/10000, Training Loss: 0.6339074969291687, Training Accuracy: 0.6372549019607843, Validation Loss: 0.962616503238678, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8126/10000, Training Loss: 0.6707944869995117, Training Accuracy: 0.5563725490196079, Validation Loss: 0.743898332118988, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8127/10000, Training Loss: 0.5988092422485352, Training Accuracy: 0.6838235294117647, Validation Loss: 0.8683266043663025, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8128/10000, Training Loss: 0.655189573764801, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8912265300750732, Validation Accuracy: 0.5\n",
      "Epoch 8129/10000, Training Loss: 0.6627511382102966, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7777276635169983, Validation Accuracy: 0.5\n",
      "Epoch 8130/10000, Training Loss: 0.6401727795600891, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6942065358161926, Validation Accuracy: 0.5\n",
      "Epoch 8131/10000, Training Loss: 0.6273524165153503, Training Accuracy: 0.6274509803921569, Validation Loss: 1.1789554357528687, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8132/10000, Training Loss: 0.6543406844139099, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7021310925483704, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8133/10000, Training Loss: 0.650739312171936, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9803385734558105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8134/10000, Training Loss: 0.6379998326301575, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8082718253135681, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8135/10000, Training Loss: 0.666744589805603, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6957542896270752, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8136/10000, Training Loss: 0.620099663734436, Training Accuracy: 0.6862745098039216, Validation Loss: 1.1453584432601929, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8137/10000, Training Loss: 0.635923445224762, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7034091949462891, Validation Accuracy: 0.5\n",
      "Epoch 8138/10000, Training Loss: 0.6141534447669983, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8027897477149963, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8139/10000, Training Loss: 0.6322625279426575, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8597800135612488, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8140/10000, Training Loss: 0.6251319646835327, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8943606019020081, Validation Accuracy: 0.5\n",
      "Epoch 8141/10000, Training Loss: 0.6543285846710205, Training Accuracy: 0.625, Validation Loss: 0.6485092043876648, Validation Accuracy: 0.75\n",
      "Epoch 8142/10000, Training Loss: 0.6186686754226685, Training Accuracy: 0.6053921568627451, Validation Loss: 0.970909833908081, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8143/10000, Training Loss: 0.6302841901779175, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8063668608665466, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8144/10000, Training Loss: 0.6133338809013367, Training Accuracy: 0.6421568627450981, Validation Loss: 0.810019314289093, Validation Accuracy: 0.5\n",
      "Epoch 8145/10000, Training Loss: 0.6564205288887024, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7956643104553223, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8146/10000, Training Loss: 0.639582097530365, Training Accuracy: 0.6127450980392157, Validation Loss: 0.947952926158905, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8147/10000, Training Loss: 0.6266050338745117, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8529357314109802, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8148/10000, Training Loss: 0.6508346796035767, Training Accuracy: 0.6740196078431373, Validation Loss: 0.9650285840034485, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 8149/10000, Training Loss: 0.6303991675376892, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0136185884475708, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8150/10000, Training Loss: 0.6518898010253906, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6746465563774109, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8151/10000, Training Loss: 0.6519972681999207, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7592501044273376, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8152/10000, Training Loss: 0.6282093524932861, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6191394925117493, Validation Accuracy: 0.75\n",
      "Epoch 8153/10000, Training Loss: 0.6193437576293945, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7346324920654297, Validation Accuracy: 0.5\n",
      "Epoch 8154/10000, Training Loss: 0.646917462348938, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6434532403945923, Validation Accuracy: 0.75\n",
      "Epoch 8155/10000, Training Loss: 0.6704339981079102, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6584781408309937, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8156/10000, Training Loss: 0.6357214450836182, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8875746130943298, Validation Accuracy: 0.25\n",
      "Epoch 8157/10000, Training Loss: 0.6319600343704224, Training Accuracy: 0.678921568627451, Validation Loss: 1.5846433639526367, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8158/10000, Training Loss: 0.6280891299247742, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6674611568450928, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8159/10000, Training Loss: 0.6848249435424805, Training Accuracy: 0.6715686274509803, Validation Loss: 1.5004568099975586, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8160/10000, Training Loss: 0.6340919137001038, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0558598041534424, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8161/10000, Training Loss: 0.628399133682251, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9801785349845886, Validation Accuracy: 0.75\n",
      "Epoch 8162/10000, Training Loss: 0.6704211235046387, Training Accuracy: 0.5808823529411765, Validation Loss: 0.5709618926048279, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8163/10000, Training Loss: 0.6443478465080261, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9425020217895508, Validation Accuracy: 0.25\n",
      "Epoch 8164/10000, Training Loss: 0.627692699432373, Training Accuracy: 0.6372549019607843, Validation Loss: 0.647711455821991, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8165/10000, Training Loss: 0.641141951084137, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6804430484771729, Validation Accuracy: 0.5\n",
      "Epoch 8166/10000, Training Loss: 0.5754391551017761, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8993491530418396, Validation Accuracy: 0.5\n",
      "Epoch 8167/10000, Training Loss: 0.6757318377494812, Training Accuracy: 0.5367647058823529, Validation Loss: 0.6646820902824402, Validation Accuracy: 0.5\n",
      "Epoch 8168/10000, Training Loss: 0.6104443669319153, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7836112976074219, Validation Accuracy: 0.5\n",
      "Epoch 8169/10000, Training Loss: 0.6095567345619202, Training Accuracy: 0.6470588235294118, Validation Loss: 0.5880047082901001, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8170/10000, Training Loss: 0.6338350176811218, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7658938765525818, Validation Accuracy: 0.5\n",
      "Epoch 8171/10000, Training Loss: 0.6213272213935852, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6785110831260681, Validation Accuracy: 0.5\n",
      "Epoch 8172/10000, Training Loss: 0.6330151557922363, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7520909309387207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8173/10000, Training Loss: 0.6399343609809875, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7609729170799255, Validation Accuracy: 0.5\n",
      "Epoch 8174/10000, Training Loss: 0.6262398958206177, Training Accuracy: 0.7009803921568627, Validation Loss: 0.7353282570838928, Validation Accuracy: 0.5\n",
      "Epoch 8175/10000, Training Loss: 0.6673471927642822, Training Accuracy: 0.5563725490196079, Validation Loss: 0.7098329067230225, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8176/10000, Training Loss: 0.6621119379997253, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7541294693946838, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8177/10000, Training Loss: 0.6517571806907654, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7842319011688232, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8178/10000, Training Loss: 0.6296125650405884, Training Accuracy: 0.625, Validation Loss: 0.953929603099823, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8179/10000, Training Loss: 0.6550117135047913, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8979772925376892, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8180/10000, Training Loss: 0.6735329627990723, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7487924098968506, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8181/10000, Training Loss: 0.6187724471092224, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6213902235031128, Validation Accuracy: 0.75\n",
      "Epoch 8182/10000, Training Loss: 0.675595760345459, Training Accuracy: 0.5343137254901961, Validation Loss: 0.7882265448570251, Validation Accuracy: 0.25\n",
      "Epoch 8183/10000, Training Loss: 0.613960862159729, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7038548588752747, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8184/10000, Training Loss: 0.6719401478767395, Training Accuracy: 0.5588235294117647, Validation Loss: 0.85044264793396, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8185/10000, Training Loss: 0.6515719294548035, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8026277422904968, Validation Accuracy: 0.5\n",
      "Epoch 8186/10000, Training Loss: 0.6376017928123474, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7864308953285217, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8187/10000, Training Loss: 0.6463751792907715, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8936727046966553, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8188/10000, Training Loss: 0.6387998461723328, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8754854798316956, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8189/10000, Training Loss: 0.6382774114608765, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7246501445770264, Validation Accuracy: 0.5\n",
      "Epoch 8190/10000, Training Loss: 0.6375011205673218, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0328127145767212, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8191/10000, Training Loss: 0.6248687505722046, Training Accuracy: 0.6617647058823529, Validation Loss: 1.613070011138916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8192/10000, Training Loss: 0.6299893856048584, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7343336939811707, Validation Accuracy: 0.5\n",
      "Epoch 8193/10000, Training Loss: 0.615670382976532, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7467634081840515, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8194/10000, Training Loss: 0.6552070379257202, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9011033177375793, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8195/10000, Training Loss: 0.640344500541687, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8748356699943542, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8196/10000, Training Loss: 0.6985980868339539, Training Accuracy: 0.5514705882352942, Validation Loss: 0.9361424446105957, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8197/10000, Training Loss: 0.6749158501625061, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6494612097740173, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8198/10000, Training Loss: 0.6456192135810852, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6305177807807922, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8199/10000, Training Loss: 0.6224311590194702, Training Accuracy: 0.6397058823529411, Validation Loss: 0.649734616279602, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8200/10000, Training Loss: 0.6422792077064514, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6135460734367371, Validation Accuracy: 0.75\n",
      "Epoch 8201/10000, Training Loss: 0.6994614005088806, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7094958424568176, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8202/10000, Training Loss: 0.6589416265487671, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7250121235847473, Validation Accuracy: 0.5\n",
      "Epoch 8203/10000, Training Loss: 0.6918403506278992, Training Accuracy: 0.625, Validation Loss: 1.3352543115615845, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8204/10000, Training Loss: 0.6872514486312866, Training Accuracy: 0.5637254901960784, Validation Loss: 0.6786172389984131, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8205/10000, Training Loss: 0.6349232196807861, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8374833464622498, Validation Accuracy: 0.5\n",
      "Epoch 8206/10000, Training Loss: 0.6514093279838562, Training Accuracy: 0.6519607843137255, Validation Loss: 1.303660273551941, Validation Accuracy: 0.5\n",
      "Epoch 8207/10000, Training Loss: 0.5987083911895752, Training Accuracy: 0.7181372549019608, Validation Loss: 1.2440851926803589, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8208/10000, Training Loss: 0.6288698315620422, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7014439702033997, Validation Accuracy: 0.75\n",
      "Epoch 8209/10000, Training Loss: 0.6437268257141113, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8782551884651184, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8210/10000, Training Loss: 0.6409227252006531, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7976384162902832, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8211/10000, Training Loss: 0.6815863847732544, Training Accuracy: 0.5612745098039216, Validation Loss: 0.7152390480041504, Validation Accuracy: 0.5\n",
      "Epoch 8212/10000, Training Loss: 0.658807635307312, Training Accuracy: 0.6274509803921569, Validation Loss: 0.755385160446167, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8213/10000, Training Loss: 0.6268884539604187, Training Accuracy: 0.6102941176470589, Validation Loss: 0.904461681842804, Validation Accuracy: 0.25\n",
      "Epoch 8214/10000, Training Loss: 0.634373664855957, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7550145983695984, Validation Accuracy: 0.5\n",
      "Epoch 8215/10000, Training Loss: 0.6278904676437378, Training Accuracy: 0.6176470588235294, Validation Loss: 0.673327624797821, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8216/10000, Training Loss: 0.6418682336807251, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7755030989646912, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8217/10000, Training Loss: 0.6572710871696472, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8731091618537903, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8218/10000, Training Loss: 0.6172324419021606, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6813101768493652, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8219/10000, Training Loss: 0.6380445957183838, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6639577746391296, Validation Accuracy: 0.5\n",
      "Epoch 8220/10000, Training Loss: 0.714264452457428, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6811398863792419, Validation Accuracy: 0.75\n",
      "Epoch 8221/10000, Training Loss: 0.6627742648124695, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8901241421699524, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8222/10000, Training Loss: 0.6727944016456604, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7245942950248718, Validation Accuracy: 0.5\n",
      "Epoch 8223/10000, Training Loss: 0.6021334528923035, Training Accuracy: 0.696078431372549, Validation Loss: 0.8693093657493591, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8224/10000, Training Loss: 0.6684830784797668, Training Accuracy: 0.6372549019607843, Validation Loss: 1.142284870147705, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8225/10000, Training Loss: 0.6256644129753113, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8380289673805237, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8226/10000, Training Loss: 0.6216686367988586, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8271996378898621, Validation Accuracy: 0.5\n",
      "Epoch 8227/10000, Training Loss: 0.6522587537765503, Training Accuracy: 0.5612745098039216, Validation Loss: 0.8493199348449707, Validation Accuracy: 0.25\n",
      "Epoch 8228/10000, Training Loss: 0.6171456575393677, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8229406476020813, Validation Accuracy: 0.5\n",
      "Epoch 8229/10000, Training Loss: 0.6463406085968018, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7125561833381653, Validation Accuracy: 0.5\n",
      "Epoch 8230/10000, Training Loss: 0.6365591883659363, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7736756205558777, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8231/10000, Training Loss: 0.6480824947357178, Training Accuracy: 0.6323529411764706, Validation Loss: 0.736236572265625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8232/10000, Training Loss: 0.6487496495246887, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9489156603813171, Validation Accuracy: 0.5\n",
      "Epoch 8233/10000, Training Loss: 0.635776698589325, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8394059538841248, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8234/10000, Training Loss: 0.6262043714523315, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7804022431373596, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8235/10000, Training Loss: 0.6542555689811707, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9492121338844299, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 8236/10000, Training Loss: 0.6143337488174438, Training Accuracy: 0.6519607843137255, Validation Loss: 0.664365828037262, Validation Accuracy: 0.5\n",
      "Epoch 8237/10000, Training Loss: 0.669616162776947, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7892275452613831, Validation Accuracy: 0.25\n",
      "Epoch 8238/10000, Training Loss: 0.6000873446464539, Training Accuracy: 0.7107843137254902, Validation Loss: 0.8165619969367981, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8239/10000, Training Loss: 0.6943703293800354, Training Accuracy: 0.5612745098039216, Validation Loss: 1.0285362005233765, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8240/10000, Training Loss: 0.6429680585861206, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7009884715080261, Validation Accuracy: 0.5\n",
      "Epoch 8241/10000, Training Loss: 0.6450988054275513, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7025027275085449, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8242/10000, Training Loss: 0.6321023106575012, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8683059215545654, Validation Accuracy: 0.5\n",
      "Epoch 8243/10000, Training Loss: 0.65352463722229, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7441575527191162, Validation Accuracy: 0.5\n",
      "Epoch 8244/10000, Training Loss: 0.6111647486686707, Training Accuracy: 0.6936274509803921, Validation Loss: 1.136120080947876, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8245/10000, Training Loss: 0.6009135246276855, Training Accuracy: 0.6887254901960784, Validation Loss: 1.0126880407333374, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8246/10000, Training Loss: 0.5964341759681702, Training Accuracy: 0.6740196078431373, Validation Loss: 1.397231936454773, Validation Accuracy: 0.5\n",
      "Epoch 8247/10000, Training Loss: 0.6060991287231445, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6140077710151672, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8248/10000, Training Loss: 0.6706912517547607, Training Accuracy: 0.5882352941176471, Validation Loss: 0.6811134219169617, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8249/10000, Training Loss: 0.6439654231071472, Training Accuracy: 0.6985294117647058, Validation Loss: 1.0859310626983643, Validation Accuracy: 0.5\n",
      "Epoch 8250/10000, Training Loss: 0.6301426887512207, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9722766280174255, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8251/10000, Training Loss: 0.6474763751029968, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8495063185691833, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8252/10000, Training Loss: 0.6360155940055847, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7510212063789368, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8253/10000, Training Loss: 0.6842625737190247, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7060184478759766, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8254/10000, Training Loss: 0.652259349822998, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8054463863372803, Validation Accuracy: 0.5\n",
      "Epoch 8255/10000, Training Loss: 0.6685299873352051, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8421910405158997, Validation Accuracy: 0.25\n",
      "Epoch 8256/10000, Training Loss: 0.6262061595916748, Training Accuracy: 0.6519607843137255, Validation Loss: 1.1007202863693237, Validation Accuracy: 0.25\n",
      "Epoch 8257/10000, Training Loss: 0.6275660395622253, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7419164180755615, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8258/10000, Training Loss: 0.6208404302597046, Training Accuracy: 0.7058823529411765, Validation Loss: 0.6263039708137512, Validation Accuracy: 0.75\n",
      "Epoch 8259/10000, Training Loss: 0.6532463431358337, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9604697823524475, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8260/10000, Training Loss: 0.6569189429283142, Training Accuracy: 0.6029411764705882, Validation Loss: 0.680025041103363, Validation Accuracy: 0.75\n",
      "Epoch 8261/10000, Training Loss: 0.5988827347755432, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9169937968254089, Validation Accuracy: 0.5\n",
      "Epoch 8262/10000, Training Loss: 0.6371386051177979, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7639859318733215, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8263/10000, Training Loss: 0.6086334586143494, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6748111844062805, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8264/10000, Training Loss: 0.6439809799194336, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8608255386352539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8265/10000, Training Loss: 0.6537010073661804, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6294407248497009, Validation Accuracy: 0.75\n",
      "Epoch 8266/10000, Training Loss: 0.629022479057312, Training Accuracy: 0.6887254901960784, Validation Loss: 0.8892881274223328, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8267/10000, Training Loss: 0.6442265510559082, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7029757499694824, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8268/10000, Training Loss: 0.6223957538604736, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7573583126068115, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8269/10000, Training Loss: 0.646537184715271, Training Accuracy: 0.625, Validation Loss: 0.7945879101753235, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8270/10000, Training Loss: 0.6432290077209473, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9533973336219788, Validation Accuracy: 0.25\n",
      "Epoch 8271/10000, Training Loss: 0.6526821851730347, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7867181301116943, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8272/10000, Training Loss: 0.6719845533370972, Training Accuracy: 0.571078431372549, Validation Loss: 0.788461446762085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8273/10000, Training Loss: 0.6496453285217285, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7143142819404602, Validation Accuracy: 0.5\n",
      "Epoch 8274/10000, Training Loss: 0.5962812304496765, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7388187050819397, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8275/10000, Training Loss: 0.6287485957145691, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8181040287017822, Validation Accuracy: 0.5\n",
      "Epoch 8276/10000, Training Loss: 0.6352224946022034, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6996621489524841, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8277/10000, Training Loss: 0.659511923789978, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9469348788261414, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8278/10000, Training Loss: 0.6335721611976624, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8756557106971741, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8279/10000, Training Loss: 0.6135457158088684, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8350186944007874, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8280/10000, Training Loss: 0.6168110966682434, Training Accuracy: 0.6544117647058824, Validation Loss: 1.1913996934890747, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8281/10000, Training Loss: 0.5837833285331726, Training Accuracy: 0.7205882352941176, Validation Loss: 0.653066873550415, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8282/10000, Training Loss: 0.6208698749542236, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8499295115470886, Validation Accuracy: 0.5\n",
      "Epoch 8283/10000, Training Loss: 0.6283263564109802, Training Accuracy: 0.6397058823529411, Validation Loss: 0.5839518904685974, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8284/10000, Training Loss: 0.6774286031723022, Training Accuracy: 0.6029411764705882, Validation Loss: 0.928230345249176, Validation Accuracy: 0.5\n",
      "Epoch 8285/10000, Training Loss: 0.6193126440048218, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7929535508155823, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8286/10000, Training Loss: 0.7597849369049072, Training Accuracy: 0.5465686274509803, Validation Loss: 0.8491901755332947, Validation Accuracy: 0.5\n",
      "Epoch 8287/10000, Training Loss: 0.6284002661705017, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0089716911315918, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8288/10000, Training Loss: 0.6740083694458008, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6869790554046631, Validation Accuracy: 0.5\n",
      "Epoch 8289/10000, Training Loss: 0.6162842512130737, Training Accuracy: 0.5980392156862745, Validation Loss: 1.2469218969345093, Validation Accuracy: 0.25\n",
      "Epoch 8290/10000, Training Loss: 0.6103889346122742, Training Accuracy: 0.696078431372549, Validation Loss: 0.9047560691833496, Validation Accuracy: 0.5\n",
      "Epoch 8291/10000, Training Loss: 0.6476302742958069, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8320662379264832, Validation Accuracy: 0.25\n",
      "Epoch 8292/10000, Training Loss: 0.6616506576538086, Training Accuracy: 0.6225490196078431, Validation Loss: 1.4201326370239258, Validation Accuracy: 0.25\n",
      "Epoch 8293/10000, Training Loss: 0.615003228187561, Training Accuracy: 0.6813725490196079, Validation Loss: 0.801719605922699, Validation Accuracy: 0.5\n",
      "Epoch 8294/10000, Training Loss: 0.6717919111251831, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8340387344360352, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8295/10000, Training Loss: 0.6540294885635376, Training Accuracy: 0.6397058823529411, Validation Loss: 1.003677248954773, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8296/10000, Training Loss: 0.6641024947166443, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8671813011169434, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8297/10000, Training Loss: 0.6386851072311401, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8255157470703125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8298/10000, Training Loss: 0.6379746794700623, Training Accuracy: 0.6348039215686274, Validation Loss: 0.67529296875, Validation Accuracy: 0.5\n",
      "Epoch 8299/10000, Training Loss: 0.6486657857894897, Training Accuracy: 0.625, Validation Loss: 1.0407894849777222, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8300/10000, Training Loss: 0.6536219120025635, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6704440712928772, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8301/10000, Training Loss: 0.6452661156654358, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7366933822631836, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8302/10000, Training Loss: 0.6495816111564636, Training Accuracy: 0.6102941176470589, Validation Loss: 1.3390694856643677, Validation Accuracy: 0.25\n",
      "Epoch 8303/10000, Training Loss: 0.6560620069503784, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6063303351402283, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8304/10000, Training Loss: 0.67018061876297, Training Accuracy: 0.5980392156862745, Validation Loss: 1.0282776355743408, Validation Accuracy: 0.5\n",
      "Epoch 8305/10000, Training Loss: 0.6616554856300354, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7096381187438965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8306/10000, Training Loss: 0.6329908967018127, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8084476590156555, Validation Accuracy: 0.5\n",
      "Epoch 8307/10000, Training Loss: 0.6442205905914307, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7448686957359314, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8308/10000, Training Loss: 0.6409556269645691, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8131682872772217, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8309/10000, Training Loss: 0.7058700323104858, Training Accuracy: 0.6151960784313726, Validation Loss: 0.688528835773468, Validation Accuracy: 0.5\n",
      "Epoch 8310/10000, Training Loss: 0.6664505004882812, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7032759189605713, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8311/10000, Training Loss: 0.605807900428772, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7893825173377991, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8312/10000, Training Loss: 0.6242431998252869, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0634219646453857, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8313/10000, Training Loss: 0.6400900483131409, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6685181260108948, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8314/10000, Training Loss: 0.666750431060791, Training Accuracy: 0.6053921568627451, Validation Loss: 0.763738214969635, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8315/10000, Training Loss: 0.6697395443916321, Training Accuracy: 0.5759803921568627, Validation Loss: 0.5573058724403381, Validation Accuracy: 0.75\n",
      "Epoch 8316/10000, Training Loss: 0.6496288776397705, Training Accuracy: 0.6127450980392157, Validation Loss: 0.857565701007843, Validation Accuracy: 0.25\n",
      "Epoch 8317/10000, Training Loss: 0.6219937205314636, Training Accuracy: 0.6838235294117647, Validation Loss: 0.910955011844635, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8318/10000, Training Loss: 0.634232223033905, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9925348162651062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8319/10000, Training Loss: 0.6569944620132446, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8592298626899719, Validation Accuracy: 0.5\n",
      "Epoch 8320/10000, Training Loss: 0.634157121181488, Training Accuracy: 0.6691176470588235, Validation Loss: 1.2221471071243286, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8321/10000, Training Loss: 0.6213976740837097, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9905900359153748, Validation Accuracy: 0.5\n",
      "Epoch 8322/10000, Training Loss: 0.6503374576568604, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6257333755493164, Validation Accuracy: 0.75\n",
      "Epoch 8323/10000, Training Loss: 0.6332772970199585, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8982524871826172, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8324/10000, Training Loss: 0.6661127805709839, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6655372977256775, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8325/10000, Training Loss: 0.624220073223114, Training Accuracy: 0.6862745098039216, Validation Loss: 0.6774957776069641, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8326/10000, Training Loss: 0.6018540859222412, Training Accuracy: 0.7009803921568627, Validation Loss: 1.1088447570800781, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8327/10000, Training Loss: 0.700023889541626, Training Accuracy: 0.625, Validation Loss: 0.8675501346588135, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8328/10000, Training Loss: 0.7573282122612, Training Accuracy: 0.6102941176470589, Validation Loss: 1.1729685068130493, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8329/10000, Training Loss: 0.6425010561943054, Training Accuracy: 0.625, Validation Loss: 0.9615922570228577, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8330/10000, Training Loss: 0.6633599996566772, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7150048613548279, Validation Accuracy: 0.5\n",
      "Epoch 8331/10000, Training Loss: 0.6646220088005066, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7533138394355774, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8332/10000, Training Loss: 0.6505376696586609, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6746892333030701, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8333/10000, Training Loss: 0.6231401562690735, Training Accuracy: 0.6397058823529411, Validation Loss: 0.5194718241691589, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 8334/10000, Training Loss: 0.6369909644126892, Training Accuracy: 0.6568627450980392, Validation Loss: 0.770063579082489, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8335/10000, Training Loss: 0.6453231573104858, Training Accuracy: 0.625, Validation Loss: 1.0966719388961792, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8336/10000, Training Loss: 0.6279422044754028, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9938099980354309, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8337/10000, Training Loss: 0.6195399165153503, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8787077069282532, Validation Accuracy: 0.25\n",
      "Epoch 8338/10000, Training Loss: 0.6457421779632568, Training Accuracy: 0.625, Validation Loss: 0.9801132678985596, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8339/10000, Training Loss: 0.6211369633674622, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8376660346984863, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8340/10000, Training Loss: 0.6377965211868286, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7982969284057617, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8341/10000, Training Loss: 0.6442471742630005, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7430204749107361, Validation Accuracy: 0.5\n",
      "Epoch 8342/10000, Training Loss: 0.6652535796165466, Training Accuracy: 0.625, Validation Loss: 0.8395538926124573, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8343/10000, Training Loss: 0.6627991795539856, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7362509369850159, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8344/10000, Training Loss: 0.6272522211074829, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7645261287689209, Validation Accuracy: 0.5\n",
      "Epoch 8345/10000, Training Loss: 0.6137208342552185, Training Accuracy: 0.6887254901960784, Validation Loss: 1.2536615133285522, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8346/10000, Training Loss: 0.66507887840271, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7034267783164978, Validation Accuracy: 0.5\n",
      "Epoch 8347/10000, Training Loss: 0.5969398617744446, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8371312022209167, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8348/10000, Training Loss: 0.6466204524040222, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8324387669563293, Validation Accuracy: 0.5\n",
      "Epoch 8349/10000, Training Loss: 0.6228352785110474, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9757494926452637, Validation Accuracy: 0.25\n",
      "Epoch 8350/10000, Training Loss: 0.6891247630119324, Training Accuracy: 0.553921568627451, Validation Loss: 0.6980655789375305, Validation Accuracy: 0.5\n",
      "Epoch 8351/10000, Training Loss: 0.6072037220001221, Training Accuracy: 0.696078431372549, Validation Loss: 1.0824424028396606, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8352/10000, Training Loss: 0.7090849876403809, Training Accuracy: 0.5833333333333334, Validation Loss: 1.0907306671142578, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8353/10000, Training Loss: 0.61240553855896, Training Accuracy: 0.696078431372549, Validation Loss: 0.9419496059417725, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8354/10000, Training Loss: 0.660886287689209, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7944691777229309, Validation Accuracy: 0.5\n",
      "Epoch 8355/10000, Training Loss: 0.6597577929496765, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8532393574714661, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8356/10000, Training Loss: 0.6185320615768433, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8064245581626892, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8357/10000, Training Loss: 0.6158066391944885, Training Accuracy: 0.6421568627450981, Validation Loss: 1.0409611463546753, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8358/10000, Training Loss: 0.6871340870857239, Training Accuracy: 0.5490196078431373, Validation Loss: 0.6762844920158386, Validation Accuracy: 0.75\n",
      "Epoch 8359/10000, Training Loss: 0.6066134572029114, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8604488372802734, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8360/10000, Training Loss: 0.6099735498428345, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8070889115333557, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8361/10000, Training Loss: 0.6277512311935425, Training Accuracy: 0.6593137254901961, Validation Loss: 0.796807587146759, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8362/10000, Training Loss: 0.6461485028266907, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6669250130653381, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8363/10000, Training Loss: 0.6265044212341309, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8994587063789368, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8364/10000, Training Loss: 0.6517934799194336, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6909441351890564, Validation Accuracy: 0.5\n",
      "Epoch 8365/10000, Training Loss: 0.6599960923194885, Training Accuracy: 0.6151960784313726, Validation Loss: 0.744083821773529, Validation Accuracy: 0.75\n",
      "Epoch 8366/10000, Training Loss: 0.5629768967628479, Training Accuracy: 0.7181372549019608, Validation Loss: 1.433761477470398, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8367/10000, Training Loss: 0.6295329928398132, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6757398247718811, Validation Accuracy: 0.75\n",
      "Epoch 8368/10000, Training Loss: 0.5868610143661499, Training Accuracy: 0.678921568627451, Validation Loss: 0.757661759853363, Validation Accuracy: 0.75\n",
      "Epoch 8369/10000, Training Loss: 0.645258903503418, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7578708529472351, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8370/10000, Training Loss: 0.6357305645942688, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7626549601554871, Validation Accuracy: 0.5\n",
      "Epoch 8371/10000, Training Loss: 0.653528094291687, Training Accuracy: 0.5612745098039216, Validation Loss: 0.797427237033844, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8372/10000, Training Loss: 0.6885663270950317, Training Accuracy: 0.5637254901960784, Validation Loss: 0.912151038646698, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8373/10000, Training Loss: 0.7080618143081665, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6804494857788086, Validation Accuracy: 0.75\n",
      "Epoch 8374/10000, Training Loss: 0.7003106474876404, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9675893187522888, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8375/10000, Training Loss: 0.6259127855300903, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9189068675041199, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8376/10000, Training Loss: 0.6133444309234619, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7230682969093323, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8377/10000, Training Loss: 0.643961489200592, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8121848106384277, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8378/10000, Training Loss: 0.6705541610717773, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7385039925575256, Validation Accuracy: 0.5\n",
      "Epoch 8379/10000, Training Loss: 0.6549530625343323, Training Accuracy: 0.6323529411764706, Validation Loss: 0.5957483649253845, Validation Accuracy: 0.5\n",
      "Epoch 8380/10000, Training Loss: 0.6276406645774841, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8842792510986328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8381/10000, Training Loss: 0.6468538641929626, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6647396087646484, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8382/10000, Training Loss: 0.6533620357513428, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8323329091072083, Validation Accuracy: 0.5\n",
      "Epoch 8383/10000, Training Loss: 0.6487485766410828, Training Accuracy: 0.5612745098039216, Validation Loss: 0.6604301333427429, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8384/10000, Training Loss: 0.6587321758270264, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0008386373519897, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8385/10000, Training Loss: 0.6490533947944641, Training Accuracy: 0.625, Validation Loss: 0.6719745993614197, Validation Accuracy: 0.75\n",
      "Epoch 8386/10000, Training Loss: 0.662977933883667, Training Accuracy: 0.625, Validation Loss: 1.076086163520813, Validation Accuracy: 0.5\n",
      "Epoch 8387/10000, Training Loss: 0.6401107907295227, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8253685832023621, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8388/10000, Training Loss: 0.650280773639679, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8193650245666504, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8389/10000, Training Loss: 0.6209893226623535, Training Accuracy: 0.625, Validation Loss: 1.0649083852767944, Validation Accuracy: 0.25\n",
      "Epoch 8390/10000, Training Loss: 0.6456462144851685, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8186648488044739, Validation Accuracy: 0.5\n",
      "Epoch 8391/10000, Training Loss: 0.6279842257499695, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8138718008995056, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8392/10000, Training Loss: 0.6057243347167969, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7768171429634094, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8393/10000, Training Loss: 0.6445562243461609, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7957621216773987, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8394/10000, Training Loss: 0.6709451079368591, Training Accuracy: 0.5392156862745098, Validation Loss: 0.685605525970459, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8395/10000, Training Loss: 0.6020705103874207, Training Accuracy: 0.6544117647058824, Validation Loss: 1.2125368118286133, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8396/10000, Training Loss: 0.6553218364715576, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8183866143226624, Validation Accuracy: 0.5\n",
      "Epoch 8397/10000, Training Loss: 0.6190406084060669, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7734259963035583, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8398/10000, Training Loss: 0.5709448456764221, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9970492720603943, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8399/10000, Training Loss: 0.6496284604072571, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8960927128791809, Validation Accuracy: 0.5\n",
      "Epoch 8400/10000, Training Loss: 0.6567904353141785, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6049222946166992, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8401/10000, Training Loss: 0.595014214515686, Training Accuracy: 0.7132352941176471, Validation Loss: 0.7305868268013, Validation Accuracy: 0.75\n",
      "Epoch 8402/10000, Training Loss: 0.5886703729629517, Training Accuracy: 0.7181372549019608, Validation Loss: 0.677223265171051, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8403/10000, Training Loss: 0.660982072353363, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7284142971038818, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8404/10000, Training Loss: 0.6566698551177979, Training Accuracy: 0.7107843137254902, Validation Loss: 1.1736598014831543, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8405/10000, Training Loss: 0.6780796647071838, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7866544723510742, Validation Accuracy: 0.25\n",
      "Epoch 8406/10000, Training Loss: 0.6346309185028076, Training Accuracy: 0.6274509803921569, Validation Loss: 0.685742199420929, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8407/10000, Training Loss: 0.6379919648170471, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6368444561958313, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8408/10000, Training Loss: 0.6056462526321411, Training Accuracy: 0.6887254901960784, Validation Loss: 0.8397442698478699, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8409/10000, Training Loss: 0.6569169163703918, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8043913841247559, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8410/10000, Training Loss: 0.6605124473571777, Training Accuracy: 0.6029411764705882, Validation Loss: 0.9324276447296143, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8411/10000, Training Loss: 0.680785596370697, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8237617611885071, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8412/10000, Training Loss: 0.6500347852706909, Training Accuracy: 0.571078431372549, Validation Loss: 0.8491642475128174, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8413/10000, Training Loss: 0.6190348863601685, Training Accuracy: 0.6813725490196079, Validation Loss: 1.030410647392273, Validation Accuracy: 0.25\n",
      "Epoch 8414/10000, Training Loss: 0.6604833602905273, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7772812843322754, Validation Accuracy: 0.5\n",
      "Epoch 8415/10000, Training Loss: 0.5956280827522278, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8507423400878906, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8416/10000, Training Loss: 0.6294748187065125, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7932582497596741, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8417/10000, Training Loss: 0.6373270750045776, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8334736227989197, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8418/10000, Training Loss: 0.6584925651550293, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7186270356178284, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8419/10000, Training Loss: 0.63187575340271, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8836548924446106, Validation Accuracy: 0.5\n",
      "Epoch 8420/10000, Training Loss: 0.6258469223976135, Training Accuracy: 0.678921568627451, Validation Loss: 0.7170665860176086, Validation Accuracy: 0.5\n",
      "Epoch 8421/10000, Training Loss: 0.6384297609329224, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6757559180259705, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8422/10000, Training Loss: 0.6563499569892883, Training Accuracy: 0.6348039215686274, Validation Loss: 0.848825216293335, Validation Accuracy: 0.5\n",
      "Epoch 8423/10000, Training Loss: 0.6410976648330688, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8926659226417542, Validation Accuracy: 0.5\n",
      "Epoch 8424/10000, Training Loss: 0.6480703949928284, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6078683137893677, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8425/10000, Training Loss: 0.6920590400695801, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7940043807029724, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8426/10000, Training Loss: 0.633664071559906, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8096721768379211, Validation Accuracy: 0.5\n",
      "Epoch 8427/10000, Training Loss: 0.6105713844299316, Training Accuracy: 0.678921568627451, Validation Loss: 0.8655237555503845, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8428/10000, Training Loss: 0.6542732119560242, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7719864249229431, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8429/10000, Training Loss: 0.6420849561691284, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9435842037200928, Validation Accuracy: 0.5\n",
      "Epoch 8430/10000, Training Loss: 0.6550567746162415, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6429587006568909, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8431/10000, Training Loss: 0.625334620475769, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6664491295814514, Validation Accuracy: 0.5\n",
      "Epoch 8432/10000, Training Loss: 0.6391473412513733, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9055072665214539, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8433/10000, Training Loss: 0.6290275454521179, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7395803332328796, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8434/10000, Training Loss: 0.6114546656608582, Training Accuracy: 0.6691176470588235, Validation Loss: 1.0576473474502563, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8435/10000, Training Loss: 0.6539183855056763, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6656338572502136, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8436/10000, Training Loss: 0.6338728070259094, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6615682244300842, Validation Accuracy: 0.5\n",
      "Epoch 8437/10000, Training Loss: 0.606484591960907, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6458069086074829, Validation Accuracy: 0.75\n",
      "Epoch 8438/10000, Training Loss: 0.6899756789207458, Training Accuracy: 0.5441176470588235, Validation Loss: 0.6744677424430847, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8439/10000, Training Loss: 0.6575362086296082, Training Accuracy: 0.6102941176470589, Validation Loss: 1.1684106588363647, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8440/10000, Training Loss: 0.5921789407730103, Training Accuracy: 0.6813725490196079, Validation Loss: 1.6891132593154907, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8441/10000, Training Loss: 0.659725546836853, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6383363604545593, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8442/10000, Training Loss: 0.6704558730125427, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6784833073616028, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8443/10000, Training Loss: 0.6027944684028625, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8299753665924072, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8444/10000, Training Loss: 0.6663445830345154, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7905074954032898, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8445/10000, Training Loss: 0.6330363154411316, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8336599469184875, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8446/10000, Training Loss: 0.6409701108932495, Training Accuracy: 0.6127450980392157, Validation Loss: 0.5702298283576965, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8447/10000, Training Loss: 0.6807488799095154, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7783406376838684, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8448/10000, Training Loss: 0.6315179467201233, Training Accuracy: 0.6127450980392157, Validation Loss: 1.081641674041748, Validation Accuracy: 0.5\n",
      "Epoch 8449/10000, Training Loss: 0.6397191882133484, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8527679443359375, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8450/10000, Training Loss: 0.6079831719398499, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6067072153091431, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8451/10000, Training Loss: 0.6279659867286682, Training Accuracy: 0.6691176470588235, Validation Loss: 1.2830015420913696, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8452/10000, Training Loss: 0.6434187293052673, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8253753185272217, Validation Accuracy: 0.5\n",
      "Epoch 8453/10000, Training Loss: 0.7001093626022339, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7882182598114014, Validation Accuracy: 0.5\n",
      "Epoch 8454/10000, Training Loss: 0.6610566973686218, Training Accuracy: 0.625, Validation Loss: 1.251588225364685, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8455/10000, Training Loss: 0.6271448135375977, Training Accuracy: 0.6764705882352942, Validation Loss: 0.5395187735557556, Validation Accuracy: 0.75\n",
      "Epoch 8456/10000, Training Loss: 0.6116405725479126, Training Accuracy: 0.6593137254901961, Validation Loss: 0.643783450126648, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8457/10000, Training Loss: 0.6149446964263916, Training Accuracy: 0.678921568627451, Validation Loss: 0.6884186267852783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8458/10000, Training Loss: 0.5753538608551025, Training Accuracy: 0.7058823529411765, Validation Loss: 0.744516134262085, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8459/10000, Training Loss: 0.6558975577354431, Training Accuracy: 0.6225490196078431, Validation Loss: 1.1949392557144165, Validation Accuracy: 0.25\n",
      "Epoch 8460/10000, Training Loss: 0.6438636183738708, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8109288811683655, Validation Accuracy: 0.5\n",
      "Epoch 8461/10000, Training Loss: 0.6264963150024414, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7321677207946777, Validation Accuracy: 0.5\n",
      "Epoch 8462/10000, Training Loss: 0.624463677406311, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8561676144599915, Validation Accuracy: 0.5\n",
      "Epoch 8463/10000, Training Loss: 0.6437069773674011, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7650813460350037, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8464/10000, Training Loss: 0.6227884292602539, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9299671649932861, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8465/10000, Training Loss: 0.6097577214241028, Training Accuracy: 0.6666666666666666, Validation Loss: 1.1223682165145874, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8466/10000, Training Loss: 0.7134686708450317, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8476006984710693, Validation Accuracy: 0.5\n",
      "Epoch 8467/10000, Training Loss: 0.6147977709770203, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8096707463264465, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8468/10000, Training Loss: 0.6446400284767151, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8373352885246277, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8469/10000, Training Loss: 0.625676155090332, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7319605350494385, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8470/10000, Training Loss: 0.6608642935752869, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7339209914207458, Validation Accuracy: 0.5\n",
      "Epoch 8471/10000, Training Loss: 0.6707285642623901, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7264535427093506, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8472/10000, Training Loss: 0.6189565658569336, Training Accuracy: 0.6372549019607843, Validation Loss: 1.018060564994812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8473/10000, Training Loss: 0.627693772315979, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6879262924194336, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8474/10000, Training Loss: 0.6451290249824524, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8128113150596619, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8475/10000, Training Loss: 0.6043892502784729, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9701671004295349, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8476/10000, Training Loss: 0.6437478065490723, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7068085670471191, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8477/10000, Training Loss: 0.6437110900878906, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7857952117919922, Validation Accuracy: 0.25\n",
      "Epoch 8478/10000, Training Loss: 0.6624048352241516, Training Accuracy: 0.5661764705882353, Validation Loss: 0.4967459738254547, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8479/10000, Training Loss: 0.6425694227218628, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0848002433776855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8480/10000, Training Loss: 0.6961343288421631, Training Accuracy: 0.571078431372549, Validation Loss: 0.7164454460144043, Validation Accuracy: 0.75\n",
      "Epoch 8481/10000, Training Loss: 0.5944584608078003, Training Accuracy: 0.6862745098039216, Validation Loss: 0.787753164768219, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8482/10000, Training Loss: 0.6234922409057617, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8116228580474854, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8483/10000, Training Loss: 0.656046986579895, Training Accuracy: 0.6102941176470589, Validation Loss: 1.1442692279815674, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8484/10000, Training Loss: 0.6475982069969177, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7704296112060547, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8485/10000, Training Loss: 0.6275416612625122, Training Accuracy: 0.696078431372549, Validation Loss: 0.8567357063293457, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8486/10000, Training Loss: 0.644644021987915, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6428918838500977, Validation Accuracy: 0.75\n",
      "Epoch 8487/10000, Training Loss: 0.6294326186180115, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9855060577392578, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8488/10000, Training Loss: 0.6291203498840332, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8739964365959167, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8489/10000, Training Loss: 0.6661413311958313, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7936859726905823, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8490/10000, Training Loss: 0.6347285509109497, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8186489939689636, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8491/10000, Training Loss: 0.631319522857666, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7721552848815918, Validation Accuracy: 0.5\n",
      "Epoch 8492/10000, Training Loss: 0.6373351812362671, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8649705052375793, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8493/10000, Training Loss: 0.6068375706672668, Training Accuracy: 0.6568627450980392, Validation Loss: 0.947521984577179, Validation Accuracy: 0.5\n",
      "Epoch 8494/10000, Training Loss: 0.6765652894973755, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7846478819847107, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8495/10000, Training Loss: 0.6578152775764465, Training Accuracy: 0.6151960784313726, Validation Loss: 1.3088353872299194, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8496/10000, Training Loss: 0.6554677486419678, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0572806596755981, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8497/10000, Training Loss: 0.6722537875175476, Training Accuracy: 0.5808823529411765, Validation Loss: 1.0557079315185547, Validation Accuracy: 0.25\n",
      "Epoch 8498/10000, Training Loss: 0.6438631415367126, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6815374493598938, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8499/10000, Training Loss: 0.6538740992546082, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7805936932563782, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8500/10000, Training Loss: 0.6459515690803528, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7581866383552551, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8501/10000, Training Loss: 0.626572847366333, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7613341212272644, Validation Accuracy: 0.5\n",
      "Epoch 8502/10000, Training Loss: 0.6314100623130798, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6914735436439514, Validation Accuracy: 0.5\n",
      "Epoch 8503/10000, Training Loss: 0.6426728963851929, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9579643607139587, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8504/10000, Training Loss: 0.655281126499176, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0149694681167603, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8505/10000, Training Loss: 0.6533999443054199, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8812596201896667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8506/10000, Training Loss: 0.6411457657814026, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6476311087608337, Validation Accuracy: 0.5\n",
      "Epoch 8507/10000, Training Loss: 0.6355611681938171, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9690513610839844, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8508/10000, Training Loss: 0.646207332611084, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7287207245826721, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8509/10000, Training Loss: 0.6351759433746338, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9289960265159607, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8510/10000, Training Loss: 0.6534496545791626, Training Accuracy: 0.625, Validation Loss: 0.5939167141914368, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8511/10000, Training Loss: 0.60880446434021, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9148011207580566, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8512/10000, Training Loss: 0.6429603695869446, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8307991027832031, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8513/10000, Training Loss: 0.6173902153968811, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7018060684204102, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8514/10000, Training Loss: 0.6616560816764832, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7468551993370056, Validation Accuracy: 0.75\n",
      "Epoch 8515/10000, Training Loss: 0.6745277643203735, Training Accuracy: 0.5980392156862745, Validation Loss: 0.753190279006958, Validation Accuracy: 0.5\n",
      "Epoch 8516/10000, Training Loss: 0.6209067702293396, Training Accuracy: 0.6838235294117647, Validation Loss: 0.985593318939209, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8517/10000, Training Loss: 0.6592791676521301, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8083100914955139, Validation Accuracy: 0.5\n",
      "Epoch 8518/10000, Training Loss: 0.6260501146316528, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0063928365707397, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8519/10000, Training Loss: 0.6197528839111328, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7355093955993652, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8520/10000, Training Loss: 0.6308925747871399, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8197936415672302, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8521/10000, Training Loss: 0.6227601766586304, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7896531224250793, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8522/10000, Training Loss: 0.6530026197433472, Training Accuracy: 0.6397058823529411, Validation Loss: 1.256744384765625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8523/10000, Training Loss: 0.643170177936554, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8821852207183838, Validation Accuracy: 0.25\n",
      "Epoch 8524/10000, Training Loss: 0.6419182419776917, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8490643501281738, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8525/10000, Training Loss: 0.6035251021385193, Training Accuracy: 0.678921568627451, Validation Loss: 0.6490292549133301, Validation Accuracy: 0.75\n",
      "Epoch 8526/10000, Training Loss: 0.6361062526702881, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7589171528816223, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8527/10000, Training Loss: 0.6354120969772339, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8614604473114014, Validation Accuracy: 0.5\n",
      "Epoch 8528/10000, Training Loss: 0.6882694363594055, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7934525609016418, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8529/10000, Training Loss: 0.6543189883232117, Training Accuracy: 0.5955882352941176, Validation Loss: 0.765749990940094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8530/10000, Training Loss: 0.6466333866119385, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7487801909446716, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8531/10000, Training Loss: 0.6596688032150269, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9204766154289246, Validation Accuracy: 0.5\n",
      "Epoch 8532/10000, Training Loss: 0.6802613735198975, Training Accuracy: 0.625, Validation Loss: 0.7497209906578064, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8533/10000, Training Loss: 0.5947799682617188, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8101534843444824, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8534/10000, Training Loss: 0.6677659749984741, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7828912734985352, Validation Accuracy: 0.25\n",
      "Epoch 8535/10000, Training Loss: 0.5859840512275696, Training Accuracy: 0.6862745098039216, Validation Loss: 0.6753042340278625, Validation Accuracy: 0.5\n",
      "Epoch 8536/10000, Training Loss: 0.6337898969650269, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7072345614433289, Validation Accuracy: 0.5\n",
      "Epoch 8537/10000, Training Loss: 0.6117193698883057, Training Accuracy: 0.7083333333333334, Validation Loss: 0.7107997536659241, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8538/10000, Training Loss: 0.6420328617095947, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7258141040802002, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8539/10000, Training Loss: 0.6535893678665161, Training Accuracy: 0.6813725490196079, Validation Loss: 0.915608823299408, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8540/10000, Training Loss: 0.6408836245536804, Training Accuracy: 0.6151960784313726, Validation Loss: 0.868346631526947, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8541/10000, Training Loss: 0.6567478775978088, Training Accuracy: 0.6495098039215687, Validation Loss: 3.1339542865753174, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8542/10000, Training Loss: 0.6335709691047668, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7503774166107178, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8543/10000, Training Loss: 0.6748639345169067, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7751684784889221, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8544/10000, Training Loss: 0.689103364944458, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7611780166625977, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8545/10000, Training Loss: 0.6533780097961426, Training Accuracy: 0.6348039215686274, Validation Loss: 1.258775234222412, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8546/10000, Training Loss: 0.6485422253608704, Training Accuracy: 0.5980392156862745, Validation Loss: 0.748710572719574, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8547/10000, Training Loss: 0.6301054358482361, Training Accuracy: 0.6617647058823529, Validation Loss: 0.6661660671234131, Validation Accuracy: 0.5\n",
      "Epoch 8548/10000, Training Loss: 0.6450672745704651, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8937227725982666, Validation Accuracy: 0.5\n",
      "Epoch 8549/10000, Training Loss: 0.6696788668632507, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8108754754066467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8550/10000, Training Loss: 0.6632717847824097, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7334816455841064, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8551/10000, Training Loss: 0.6376407742500305, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8588897585868835, Validation Accuracy: 0.25\n",
      "Epoch 8552/10000, Training Loss: 0.6132510900497437, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9493072628974915, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8553/10000, Training Loss: 0.615181028842926, Training Accuracy: 0.6691176470588235, Validation Loss: 0.5938142538070679, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8554/10000, Training Loss: 0.6447484493255615, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7614100575447083, Validation Accuracy: 0.5\n",
      "Epoch 8555/10000, Training Loss: 0.6413783431053162, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7447023391723633, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8556/10000, Training Loss: 0.6454018354415894, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8654201030731201, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8557/10000, Training Loss: 0.6414331197738647, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8728452324867249, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8558/10000, Training Loss: 0.6659263968467712, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7181888222694397, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8559/10000, Training Loss: 0.6670874953269958, Training Accuracy: 0.5833333333333334, Validation Loss: 0.735548198223114, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8560/10000, Training Loss: 0.640650749206543, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7076207995414734, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8561/10000, Training Loss: 0.6426385045051575, Training Accuracy: 0.625, Validation Loss: 0.7891480922698975, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8562/10000, Training Loss: 0.6302866339683533, Training Accuracy: 0.6323529411764706, Validation Loss: 0.678919792175293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8563/10000, Training Loss: 0.6212912797927856, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7345762848854065, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8564/10000, Training Loss: 0.6295356750488281, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7478938698768616, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8565/10000, Training Loss: 0.6387109756469727, Training Accuracy: 0.6151960784313726, Validation Loss: 1.112929344177246, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8566/10000, Training Loss: 0.6416964530944824, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7773294448852539, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8567/10000, Training Loss: 0.6816051602363586, Training Accuracy: 0.6519607843137255, Validation Loss: 1.0247794389724731, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8568/10000, Training Loss: 0.626930296421051, Training Accuracy: 0.6495098039215687, Validation Loss: 0.771845281124115, Validation Accuracy: 0.5\n",
      "Epoch 8569/10000, Training Loss: 0.612194836139679, Training Accuracy: 0.6985294117647058, Validation Loss: 0.9420209527015686, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8570/10000, Training Loss: 0.6178116798400879, Training Accuracy: 0.6593137254901961, Validation Loss: 0.847109317779541, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8571/10000, Training Loss: 0.6353117227554321, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9233582615852356, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8572/10000, Training Loss: 0.5997616648674011, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9263222813606262, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8573/10000, Training Loss: 0.6331071853637695, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6679821610450745, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8574/10000, Training Loss: 0.6492899060249329, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6814239025115967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8575/10000, Training Loss: 0.633925199508667, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6287059187889099, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8576/10000, Training Loss: 0.6505210995674133, Training Accuracy: 0.625, Validation Loss: 0.8178309798240662, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8577/10000, Training Loss: 0.647878110408783, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8525635600090027, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8578/10000, Training Loss: 0.6062869429588318, Training Accuracy: 0.7034313725490197, Validation Loss: 0.6770547032356262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8579/10000, Training Loss: 0.6154208779335022, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9925879836082458, Validation Accuracy: 0.75\n",
      "Epoch 8580/10000, Training Loss: 0.6218321323394775, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6617264747619629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8581/10000, Training Loss: 0.6660267114639282, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9922581315040588, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8582/10000, Training Loss: 0.6293513774871826, Training Accuracy: 0.6397058823529411, Validation Loss: 0.754535973072052, Validation Accuracy: 0.25\n",
      "Epoch 8583/10000, Training Loss: 0.6862660646438599, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6675824522972107, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8584/10000, Training Loss: 0.6457168459892273, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9284421801567078, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8585/10000, Training Loss: 0.6384633183479309, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9884546399116516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8586/10000, Training Loss: 0.6113728880882263, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9905675053596497, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8587/10000, Training Loss: 0.6170971393585205, Training Accuracy: 0.6470588235294118, Validation Loss: 0.659061849117279, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8588/10000, Training Loss: 0.6431567072868347, Training Accuracy: 0.6372549019607843, Validation Loss: 0.857316255569458, Validation Accuracy: 0.5\n",
      "Epoch 8589/10000, Training Loss: 0.670539379119873, Training Accuracy: 0.678921568627451, Validation Loss: 0.7995169162750244, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8590/10000, Training Loss: 0.6308921575546265, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7928606867790222, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8591/10000, Training Loss: 0.623204231262207, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6860785484313965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8592/10000, Training Loss: 0.6416233777999878, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8041539788246155, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8593/10000, Training Loss: 0.65558922290802, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8268504738807678, Validation Accuracy: 0.5\n",
      "Epoch 8594/10000, Training Loss: 0.6320117115974426, Training Accuracy: 0.6446078431372549, Validation Loss: 0.805482804775238, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8595/10000, Training Loss: 0.6413122415542603, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6336895823478699, Validation Accuracy: 0.5\n",
      "Epoch 8596/10000, Training Loss: 0.6269771456718445, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6628199219703674, Validation Accuracy: 0.5\n",
      "Epoch 8597/10000, Training Loss: 0.6390798091888428, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8936472535133362, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8598/10000, Training Loss: 0.6454864144325256, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6282341480255127, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8599/10000, Training Loss: 0.6498295664787292, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7327129244804382, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8600/10000, Training Loss: 0.6647056341171265, Training Accuracy: 0.5465686274509803, Validation Loss: 0.7939803600311279, Validation Accuracy: 0.5\n",
      "Epoch 8601/10000, Training Loss: 0.6635833382606506, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7713844776153564, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8602/10000, Training Loss: 0.6098098158836365, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0092417001724243, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8603/10000, Training Loss: 0.662900984287262, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0578711032867432, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8604/10000, Training Loss: 0.6593469977378845, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8715535998344421, Validation Accuracy: 0.25\n",
      "Epoch 8605/10000, Training Loss: 0.6056833267211914, Training Accuracy: 0.7058823529411765, Validation Loss: 0.81496262550354, Validation Accuracy: 0.5\n",
      "Epoch 8606/10000, Training Loss: 0.6381001472473145, Training Accuracy: 0.6838235294117647, Validation Loss: 0.6820806860923767, Validation Accuracy: 0.5\n",
      "Epoch 8607/10000, Training Loss: 0.6461673974990845, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7920827865600586, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8608/10000, Training Loss: 0.6412920951843262, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8933812975883484, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8609/10000, Training Loss: 0.5973464250564575, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7194056510925293, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8610/10000, Training Loss: 0.68498694896698, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0212174654006958, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8611/10000, Training Loss: 0.6436372399330139, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7522500157356262, Validation Accuracy: 0.75\n",
      "Epoch 8612/10000, Training Loss: 0.6548828482627869, Training Accuracy: 0.6151960784313726, Validation Loss: 0.5591942667961121, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8613/10000, Training Loss: 0.6170673966407776, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8782206177711487, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8614/10000, Training Loss: 0.6536073088645935, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8034288883209229, Validation Accuracy: 0.5\n",
      "Epoch 8615/10000, Training Loss: 0.6830853223800659, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6956658363342285, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8616/10000, Training Loss: 0.6721988916397095, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7216601371765137, Validation Accuracy: 0.5\n",
      "Epoch 8617/10000, Training Loss: 0.6622403264045715, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7971453070640564, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8618/10000, Training Loss: 0.6453132629394531, Training Accuracy: 0.6666666666666666, Validation Loss: 0.803952157497406, Validation Accuracy: 0.5\n",
      "Epoch 8619/10000, Training Loss: 0.6097234487533569, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7588591575622559, Validation Accuracy: 0.5\n",
      "Epoch 8620/10000, Training Loss: 0.6224644184112549, Training Accuracy: 0.625, Validation Loss: 0.7803595066070557, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8621/10000, Training Loss: 0.6453626155853271, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7219798564910889, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8622/10000, Training Loss: 0.6594200730323792, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6309047341346741, Validation Accuracy: 0.5\n",
      "Epoch 8623/10000, Training Loss: 0.6394650936126709, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8013017773628235, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8624/10000, Training Loss: 0.6709233522415161, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7144621014595032, Validation Accuracy: 0.5\n",
      "Epoch 8625/10000, Training Loss: 0.6293857097625732, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7004484534263611, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8626/10000, Training Loss: 0.6376756429672241, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8360884785652161, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8627/10000, Training Loss: 0.6299159526824951, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7179172039031982, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8628/10000, Training Loss: 0.6118060350418091, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9887972474098206, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8629/10000, Training Loss: 0.6496350765228271, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8930894732475281, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8630/10000, Training Loss: 0.6679142117500305, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8022997975349426, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8631/10000, Training Loss: 0.6192402243614197, Training Accuracy: 0.6593137254901961, Validation Loss: 0.5992478728294373, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8632/10000, Training Loss: 0.6198123097419739, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7566905617713928, Validation Accuracy: 0.5\n",
      "Epoch 8633/10000, Training Loss: 0.5960938930511475, Training Accuracy: 0.6911764705882353, Validation Loss: 0.7644550204277039, Validation Accuracy: 0.5\n",
      "Epoch 8634/10000, Training Loss: 0.6304432153701782, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8017676472663879, Validation Accuracy: 0.5\n",
      "Epoch 8635/10000, Training Loss: 0.6138321161270142, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0254043340682983, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8636/10000, Training Loss: 0.6473726630210876, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0956107378005981, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8637/10000, Training Loss: 0.6208406090736389, Training Accuracy: 0.6593137254901961, Validation Loss: 1.041359543800354, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8638/10000, Training Loss: 0.630820631980896, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7290323376655579, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8639/10000, Training Loss: 0.6532420516014099, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7990209460258484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8640/10000, Training Loss: 0.6329923868179321, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8755679726600647, Validation Accuracy: 0.5\n",
      "Epoch 8641/10000, Training Loss: 0.636336624622345, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9566287994384766, Validation Accuracy: 0.25\n",
      "Epoch 8642/10000, Training Loss: 0.6238237023353577, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6734542846679688, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8643/10000, Training Loss: 0.6155433058738708, Training Accuracy: 0.6593137254901961, Validation Loss: 0.805077075958252, Validation Accuracy: 0.5\n",
      "Epoch 8644/10000, Training Loss: 0.6315088272094727, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8579735159873962, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8645/10000, Training Loss: 0.5799180865287781, Training Accuracy: 0.7058823529411765, Validation Loss: 0.8089333176612854, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8646/10000, Training Loss: 0.6541467308998108, Training Accuracy: 0.5980392156862745, Validation Loss: 0.5252271294593811, Validation Accuracy: 0.75\n",
      "Epoch 8647/10000, Training Loss: 0.6249966621398926, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6900004744529724, Validation Accuracy: 0.5\n",
      "Epoch 8648/10000, Training Loss: 0.6304464936256409, Training Accuracy: 0.6495098039215687, Validation Loss: 0.613919198513031, Validation Accuracy: 0.75\n",
      "Epoch 8649/10000, Training Loss: 0.6237834095954895, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8142046332359314, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8650/10000, Training Loss: 0.6542788743972778, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7548490166664124, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8651/10000, Training Loss: 0.6456165909767151, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7527022957801819, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8652/10000, Training Loss: 0.637656569480896, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9184966087341309, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8653/10000, Training Loss: 0.6175069808959961, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9501975178718567, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8654/10000, Training Loss: 0.6800094246864319, Training Accuracy: 0.625, Validation Loss: 0.6863732933998108, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8655/10000, Training Loss: 0.5980457067489624, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9441505074501038, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8656/10000, Training Loss: 0.6033024191856384, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8946435451507568, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8657/10000, Training Loss: 0.665830671787262, Training Accuracy: 0.6887254901960784, Validation Loss: 1.8193516731262207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8658/10000, Training Loss: 0.6421071887016296, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7337427735328674, Validation Accuracy: 0.5\n",
      "Epoch 8659/10000, Training Loss: 0.6240904331207275, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0891571044921875, Validation Accuracy: 0.5\n",
      "Epoch 8660/10000, Training Loss: 0.6515948176383972, Training Accuracy: 0.6151960784313726, Validation Loss: 0.754213809967041, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8661/10000, Training Loss: 0.5946341753005981, Training Accuracy: 0.6936274509803921, Validation Loss: 0.7044076323509216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8662/10000, Training Loss: 0.5903766751289368, Training Accuracy: 0.7352941176470589, Validation Loss: 0.6810031533241272, Validation Accuracy: 0.75\n",
      "Epoch 8663/10000, Training Loss: 0.5853285789489746, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7458219528198242, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8664/10000, Training Loss: 0.676551342010498, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7315310835838318, Validation Accuracy: 0.5\n",
      "Epoch 8665/10000, Training Loss: 0.6329628229141235, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7121239304542542, Validation Accuracy: 0.75\n",
      "Epoch 8666/10000, Training Loss: 0.6317481398582458, Training Accuracy: 0.6519607843137255, Validation Loss: 0.760758638381958, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8667/10000, Training Loss: 0.6574977040290833, Training Accuracy: 0.625, Validation Loss: 0.6189508438110352, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8668/10000, Training Loss: 0.6253771185874939, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8437612056732178, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8669/10000, Training Loss: 0.6060560345649719, Training Accuracy: 0.6642156862745098, Validation Loss: 0.6834328174591064, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8670/10000, Training Loss: 0.6400114297866821, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7072697281837463, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8671/10000, Training Loss: 0.6716160774230957, Training Accuracy: 0.6102941176470589, Validation Loss: 1.0476006269454956, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8672/10000, Training Loss: 0.6169771552085876, Training Accuracy: 0.6691176470588235, Validation Loss: 0.665390133857727, Validation Accuracy: 0.5\n",
      "Epoch 8673/10000, Training Loss: 0.6174702644348145, Training Accuracy: 0.6936274509803921, Validation Loss: 0.7304385304450989, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8674/10000, Training Loss: 0.6293794512748718, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7693659663200378, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8675/10000, Training Loss: 0.640126645565033, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6570305228233337, Validation Accuracy: 0.5\n",
      "Epoch 8676/10000, Training Loss: 0.6471635699272156, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7132986187934875, Validation Accuracy: 0.5\n",
      "Epoch 8677/10000, Training Loss: 0.6631411910057068, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7104170322418213, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8678/10000, Training Loss: 0.69155353307724, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1890164613723755, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8679/10000, Training Loss: 0.6470773220062256, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8066930174827576, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8680/10000, Training Loss: 0.618848979473114, Training Accuracy: 0.7328431372549019, Validation Loss: 0.7260327935218811, Validation Accuracy: 0.5\n",
      "Epoch 8681/10000, Training Loss: 0.6757875084877014, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8258325457572937, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8682/10000, Training Loss: 0.6261650323867798, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7093259692192078, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8683/10000, Training Loss: 0.6745880842208862, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7185359001159668, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8684/10000, Training Loss: 0.6247466206550598, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6891138553619385, Validation Accuracy: 0.5\n",
      "Epoch 8685/10000, Training Loss: 0.6480005383491516, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7362974286079407, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8686/10000, Training Loss: 0.6238098740577698, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7338957190513611, Validation Accuracy: 0.5\n",
      "Epoch 8687/10000, Training Loss: 0.627970814704895, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6429807543754578, Validation Accuracy: 0.75\n",
      "Epoch 8688/10000, Training Loss: 0.646561861038208, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9004228711128235, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8689/10000, Training Loss: 0.6382125616073608, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9334554672241211, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8690/10000, Training Loss: 0.6424569487571716, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6595724821090698, Validation Accuracy: 0.5\n",
      "Epoch 8691/10000, Training Loss: 0.6076657176017761, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9721460938453674, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8692/10000, Training Loss: 0.6561737060546875, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6263042688369751, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8693/10000, Training Loss: 0.6368813514709473, Training Accuracy: 0.6299019607843137, Validation Loss: 0.927602231502533, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8694/10000, Training Loss: 0.6018899083137512, Training Accuracy: 0.7034313725490197, Validation Loss: 0.5867366790771484, Validation Accuracy: 0.75\n",
      "Epoch 8695/10000, Training Loss: 0.646852433681488, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7490575909614563, Validation Accuracy: 0.5\n",
      "Epoch 8696/10000, Training Loss: 0.614142656326294, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9053630828857422, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8697/10000, Training Loss: 0.633527398109436, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9623555541038513, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8698/10000, Training Loss: 0.6244615912437439, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9519268870353699, Validation Accuracy: 0.5\n",
      "Epoch 8699/10000, Training Loss: 0.6358247399330139, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9341003894805908, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8700/10000, Training Loss: 0.6140426993370056, Training Accuracy: 0.6911764705882353, Validation Loss: 0.8443117141723633, Validation Accuracy: 0.5\n",
      "Epoch 8701/10000, Training Loss: 0.6425049901008606, Training Accuracy: 0.6470588235294118, Validation Loss: 0.860200822353363, Validation Accuracy: 0.25\n",
      "Epoch 8702/10000, Training Loss: 0.617970883846283, Training Accuracy: 0.6936274509803921, Validation Loss: 0.7737938761711121, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8703/10000, Training Loss: 0.6263783574104309, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7150434851646423, Validation Accuracy: 0.5\n",
      "Epoch 8704/10000, Training Loss: 0.6408219933509827, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8323517441749573, Validation Accuracy: 0.5\n",
      "Epoch 8705/10000, Training Loss: 0.704486072063446, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6921560764312744, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8706/10000, Training Loss: 0.6140109896659851, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7422118782997131, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8707/10000, Training Loss: 0.6198983192443848, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6444209814071655, Validation Accuracy: 0.5\n",
      "Epoch 8708/10000, Training Loss: 0.5833892226219177, Training Accuracy: 0.7058823529411765, Validation Loss: 1.0743776559829712, Validation Accuracy: 0.5\n",
      "Epoch 8709/10000, Training Loss: 0.6284013390541077, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9290966391563416, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8710/10000, Training Loss: 0.6508025527000427, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8138335347175598, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8711/10000, Training Loss: 0.6300109624862671, Training Accuracy: 0.625, Validation Loss: 0.8446393013000488, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8712/10000, Training Loss: 0.6019777059555054, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7120373845100403, Validation Accuracy: 0.5\n",
      "Epoch 8713/10000, Training Loss: 0.637794554233551, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7446553707122803, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8714/10000, Training Loss: 0.6334384679794312, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9489801526069641, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8715/10000, Training Loss: 0.6741584539413452, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6944308876991272, Validation Accuracy: 0.5\n",
      "Epoch 8716/10000, Training Loss: 0.6230241060256958, Training Accuracy: 0.6838235294117647, Validation Loss: 0.8428632616996765, Validation Accuracy: 0.25\n",
      "Epoch 8717/10000, Training Loss: 0.6246795058250427, Training Accuracy: 0.6421568627450981, Validation Loss: 1.071782112121582, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8718/10000, Training Loss: 0.59663987159729, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7085060477256775, Validation Accuracy: 0.5\n",
      "Epoch 8719/10000, Training Loss: 0.641699492931366, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8808222413063049, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8720/10000, Training Loss: 0.6052361130714417, Training Accuracy: 0.7303921568627451, Validation Loss: 1.293774962425232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8721/10000, Training Loss: 0.6388124823570251, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6675205826759338, Validation Accuracy: 0.5\n",
      "Epoch 8722/10000, Training Loss: 0.6525881290435791, Training Accuracy: 0.6274509803921569, Validation Loss: 1.1414413452148438, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8723/10000, Training Loss: 0.6441644430160522, Training Accuracy: 0.5906862745098039, Validation Loss: 0.860557496547699, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8724/10000, Training Loss: 0.6427716016769409, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8855622410774231, Validation Accuracy: 0.5\n",
      "Epoch 8725/10000, Training Loss: 0.6612325310707092, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7095096707344055, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8726/10000, Training Loss: 0.6312658786773682, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8097624182701111, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8727/10000, Training Loss: 0.7395463585853577, Training Accuracy: 0.6078431372549019, Validation Loss: 1.1545418500900269, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8728/10000, Training Loss: 0.7029220461845398, Training Accuracy: 0.5686274509803921, Validation Loss: 1.167710781097412, Validation Accuracy: 0.5\n",
      "Epoch 8729/10000, Training Loss: 0.633083164691925, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8373899459838867, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8730/10000, Training Loss: 0.6301636099815369, Training Accuracy: 0.6495098039215687, Validation Loss: 1.1969331502914429, Validation Accuracy: 0.5\n",
      "Epoch 8731/10000, Training Loss: 0.6240139603614807, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6209423542022705, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8732/10000, Training Loss: 0.6727283000946045, Training Accuracy: 0.625, Validation Loss: 0.7413603663444519, Validation Accuracy: 0.25\n",
      "Epoch 8733/10000, Training Loss: 0.6163000464439392, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7287167906761169, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8734/10000, Training Loss: 0.6344141364097595, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9083911776542664, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8735/10000, Training Loss: 0.6667976379394531, Training Accuracy: 0.5808823529411765, Validation Loss: 0.878497302532196, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8736/10000, Training Loss: 0.6139054298400879, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8299443125724792, Validation Accuracy: 0.25\n",
      "Epoch 8737/10000, Training Loss: 0.6118912696838379, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7747681736946106, Validation Accuracy: 0.5\n",
      "Epoch 8738/10000, Training Loss: 0.6728979349136353, Training Accuracy: 0.571078431372549, Validation Loss: 0.7182412147521973, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8739/10000, Training Loss: 0.6317842602729797, Training Accuracy: 0.6593137254901961, Validation Loss: 1.1678889989852905, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8740/10000, Training Loss: 0.6703376770019531, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0210267305374146, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8741/10000, Training Loss: 0.6410266160964966, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9704082608222961, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8742/10000, Training Loss: 0.6255217790603638, Training Accuracy: 0.7156862745098039, Validation Loss: 1.013306975364685, Validation Accuracy: 0.5\n",
      "Epoch 8743/10000, Training Loss: 0.619139552116394, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9490501284599304, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8744/10000, Training Loss: 0.6482082605361938, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0315414667129517, Validation Accuracy: 0.25\n",
      "Epoch 8745/10000, Training Loss: 0.6291874051094055, Training Accuracy: 0.6568627450980392, Validation Loss: 0.755612313747406, Validation Accuracy: 0.5\n",
      "Epoch 8746/10000, Training Loss: 0.6511552333831787, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9372337460517883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8747/10000, Training Loss: 0.6143778562545776, Training Accuracy: 0.6102941176470589, Validation Loss: 1.073163390159607, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8748/10000, Training Loss: 0.6859877109527588, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7666018605232239, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8749/10000, Training Loss: 0.6154203414916992, Training Accuracy: 0.6470588235294118, Validation Loss: 0.5358108282089233, Validation Accuracy: 0.75\n",
      "Epoch 8750/10000, Training Loss: 0.6340637803077698, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8408489227294922, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8751/10000, Training Loss: 0.5965380072593689, Training Accuracy: 0.6911764705882353, Validation Loss: 0.7377291321754456, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8752/10000, Training Loss: 0.6362844705581665, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8204540610313416, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8753/10000, Training Loss: 0.6373740434646606, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0364183187484741, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8754/10000, Training Loss: 0.6323442459106445, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7813027501106262, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8755/10000, Training Loss: 0.649336576461792, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6007683873176575, Validation Accuracy: 0.75\n",
      "Epoch 8756/10000, Training Loss: 0.6328648328781128, Training Accuracy: 0.625, Validation Loss: 0.8221595883369446, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8757/10000, Training Loss: 0.627918541431427, Training Accuracy: 0.7034313725490197, Validation Loss: 0.860048770904541, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8758/10000, Training Loss: 0.6195982098579407, Training Accuracy: 0.6372549019607843, Validation Loss: 0.966485321521759, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8759/10000, Training Loss: 0.655032217502594, Training Accuracy: 0.6200980392156863, Validation Loss: 1.035518765449524, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8760/10000, Training Loss: 0.6140971779823303, Training Accuracy: 0.678921568627451, Validation Loss: 0.8831866383552551, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8761/10000, Training Loss: 0.67844158411026, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8421618938446045, Validation Accuracy: 0.5\n",
      "Epoch 8762/10000, Training Loss: 0.5931103825569153, Training Accuracy: 0.678921568627451, Validation Loss: 0.7652521729469299, Validation Accuracy: 0.5\n",
      "Epoch 8763/10000, Training Loss: 0.6602900624275208, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9924662709236145, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8764/10000, Training Loss: 0.6271752715110779, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0037071704864502, Validation Accuracy: 0.5\n",
      "Epoch 8765/10000, Training Loss: 0.6771633625030518, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8081478476524353, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8766/10000, Training Loss: 0.577311635017395, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7377724051475525, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8767/10000, Training Loss: 0.6210545301437378, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9059733748435974, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8768/10000, Training Loss: 0.6458065509796143, Training Accuracy: 0.6691176470588235, Validation Loss: 0.913151204586029, Validation Accuracy: 0.5\n",
      "Epoch 8769/10000, Training Loss: 0.6293562054634094, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7980130314826965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8770/10000, Training Loss: 0.6078376770019531, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7823089957237244, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8771/10000, Training Loss: 0.640137791633606, Training Accuracy: 0.6421568627450981, Validation Loss: 1.1937875747680664, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8772/10000, Training Loss: 0.651150643825531, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7448923587799072, Validation Accuracy: 0.5\n",
      "Epoch 8773/10000, Training Loss: 0.6236296892166138, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0914536714553833, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8774/10000, Training Loss: 0.6472042798995972, Training Accuracy: 0.6666666666666666, Validation Loss: 0.766491711139679, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8775/10000, Training Loss: 0.6040641069412231, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8906077742576599, Validation Accuracy: 0.5\n",
      "Epoch 8776/10000, Training Loss: 0.6215777397155762, Training Accuracy: 0.678921568627451, Validation Loss: 0.8042203783988953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8777/10000, Training Loss: 0.6646714210510254, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7487576007843018, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8778/10000, Training Loss: 0.6458156704902649, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7186726927757263, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8779/10000, Training Loss: 0.6380594968795776, Training Accuracy: 0.6642156862745098, Validation Loss: 0.772763192653656, Validation Accuracy: 0.25\n",
      "Epoch 8780/10000, Training Loss: 0.6560794115066528, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6999642252922058, Validation Accuracy: 0.5\n",
      "Epoch 8781/10000, Training Loss: 0.6185504198074341, Training Accuracy: 0.6887254901960784, Validation Loss: 1.024927020072937, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8782/10000, Training Loss: 0.6853830814361572, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9425706267356873, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8783/10000, Training Loss: 0.5913257002830505, Training Accuracy: 0.6691176470588235, Validation Loss: 1.042554259300232, Validation Accuracy: 0.5\n",
      "Epoch 8784/10000, Training Loss: 0.6419075131416321, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8902556896209717, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8785/10000, Training Loss: 0.6735943555831909, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7521491050720215, Validation Accuracy: 0.75\n",
      "Epoch 8786/10000, Training Loss: 0.6087426543235779, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9955963492393494, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8787/10000, Training Loss: 0.6448512077331543, Training Accuracy: 0.6593137254901961, Validation Loss: 1.3099063634872437, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8788/10000, Training Loss: 0.6205781102180481, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9682576656341553, Validation Accuracy: 0.25\n",
      "Epoch 8789/10000, Training Loss: 0.6073460578918457, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7542038559913635, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8790/10000, Training Loss: 0.6194263100624084, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6940729022026062, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8791/10000, Training Loss: 0.6287362575531006, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6375296115875244, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8792/10000, Training Loss: 0.6339243054389954, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7576083540916443, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8793/10000, Training Loss: 0.685332179069519, Training Accuracy: 0.5759803921568627, Validation Loss: 0.744594395160675, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8794/10000, Training Loss: 0.6107247471809387, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7369229793548584, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8795/10000, Training Loss: 0.6137831211090088, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8181024193763733, Validation Accuracy: 0.5\n",
      "Epoch 8796/10000, Training Loss: 0.6502422094345093, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8225016593933105, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8797/10000, Training Loss: 0.6354548931121826, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0996876955032349, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8798/10000, Training Loss: 0.6800892353057861, Training Accuracy: 0.5245098039215687, Validation Loss: 0.7890141010284424, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8799/10000, Training Loss: 0.6763632297515869, Training Accuracy: 0.553921568627451, Validation Loss: 0.7098352909088135, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8800/10000, Training Loss: 0.6755499243736267, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7649093270301819, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8801/10000, Training Loss: 0.6481146216392517, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7608461380004883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8802/10000, Training Loss: 0.6144901514053345, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7083154320716858, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8803/10000, Training Loss: 0.6149780750274658, Training Accuracy: 0.678921568627451, Validation Loss: 0.8978821635246277, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8804/10000, Training Loss: 0.5962605476379395, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7209944725036621, Validation Accuracy: 0.5\n",
      "Epoch 8805/10000, Training Loss: 0.6407104134559631, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6938397288322449, Validation Accuracy: 0.5\n",
      "Epoch 8806/10000, Training Loss: 0.6216843724250793, Training Accuracy: 0.696078431372549, Validation Loss: 1.1587754487991333, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8807/10000, Training Loss: 0.605211079120636, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7320041060447693, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8808/10000, Training Loss: 0.6581944227218628, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8830516338348389, Validation Accuracy: 0.5\n",
      "Epoch 8809/10000, Training Loss: 0.5972718000411987, Training Accuracy: 0.696078431372549, Validation Loss: 0.7618899345397949, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8810/10000, Training Loss: 0.6332963109016418, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8051042556762695, Validation Accuracy: 0.5\n",
      "Epoch 8811/10000, Training Loss: 0.6884401440620422, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8632128834724426, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8812/10000, Training Loss: 0.6045345664024353, Training Accuracy: 0.6691176470588235, Validation Loss: 1.1473124027252197, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8813/10000, Training Loss: 0.6330559849739075, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9800954461097717, Validation Accuracy: 0.25\n",
      "Epoch 8814/10000, Training Loss: 0.6450506448745728, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0000652074813843, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8815/10000, Training Loss: 0.6060512065887451, Training Accuracy: 0.6985294117647058, Validation Loss: 0.9202604293823242, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8816/10000, Training Loss: 0.64546138048172, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6526385545730591, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8817/10000, Training Loss: 0.620241105556488, Training Accuracy: 0.6544117647058824, Validation Loss: 0.707938015460968, Validation Accuracy: 0.5\n",
      "Epoch 8818/10000, Training Loss: 0.6519320607185364, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8144974708557129, Validation Accuracy: 0.5\n",
      "Epoch 8819/10000, Training Loss: 0.665804922580719, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9625329971313477, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8820/10000, Training Loss: 0.623212993144989, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9401549696922302, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8821/10000, Training Loss: 0.6554277539253235, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7416746616363525, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8822/10000, Training Loss: 0.6224278211593628, Training Accuracy: 0.6862745098039216, Validation Loss: 0.919749915599823, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8823/10000, Training Loss: 0.6127336025238037, Training Accuracy: 0.7009803921568627, Validation Loss: 0.7750499844551086, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8824/10000, Training Loss: 0.6576443314552307, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7669520974159241, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8825/10000, Training Loss: 0.6309168338775635, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9352384209632874, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8826/10000, Training Loss: 0.6381756067276001, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7572379112243652, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8827/10000, Training Loss: 0.6493495106697083, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8832222819328308, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8828/10000, Training Loss: 0.6379226446151733, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7658390402793884, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8829/10000, Training Loss: 0.6635680198669434, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9736611843109131, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8830/10000, Training Loss: 0.6508566737174988, Training Accuracy: 0.625, Validation Loss: 1.0101557970046997, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8831/10000, Training Loss: 0.6243873834609985, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8087727427482605, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8832/10000, Training Loss: 0.6457131505012512, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1162558794021606, Validation Accuracy: 0.5\n",
      "Epoch 8833/10000, Training Loss: 0.6489596366882324, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8451265692710876, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8834/10000, Training Loss: 0.6403741240501404, Training Accuracy: 0.625, Validation Loss: 1.3943120241165161, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8835/10000, Training Loss: 0.6466171145439148, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9625544548034668, Validation Accuracy: 0.25\n",
      "Epoch 8836/10000, Training Loss: 0.635675847530365, Training Accuracy: 0.625, Validation Loss: 0.6901833415031433, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8837/10000, Training Loss: 0.6348639130592346, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8326041102409363, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8838/10000, Training Loss: 0.6216102838516235, Training Accuracy: 0.625, Validation Loss: 0.882457435131073, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8839/10000, Training Loss: 0.6265790462493896, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7504398226737976, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8840/10000, Training Loss: 0.5918315649032593, Training Accuracy: 0.7009803921568627, Validation Loss: 0.7380816340446472, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8841/10000, Training Loss: 0.6518874764442444, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9201866984367371, Validation Accuracy: 0.25\n",
      "Epoch 8842/10000, Training Loss: 0.6263613104820251, Training Accuracy: 0.6936274509803921, Validation Loss: 1.0286228656768799, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8843/10000, Training Loss: 0.6119390726089478, Training Accuracy: 0.7058823529411765, Validation Loss: 0.8592624068260193, Validation Accuracy: 0.5\n",
      "Epoch 8844/10000, Training Loss: 0.6159102320671082, Training Accuracy: 0.6862745098039216, Validation Loss: 0.6469027996063232, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8845/10000, Training Loss: 0.6819742918014526, Training Accuracy: 0.5784313725490197, Validation Loss: 0.6844558715820312, Validation Accuracy: 0.75\n",
      "Epoch 8846/10000, Training Loss: 0.6475223302841187, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7228884100914001, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8847/10000, Training Loss: 0.6510317325592041, Training Accuracy: 0.6813725490196079, Validation Loss: 0.9869370460510254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8848/10000, Training Loss: 0.6444805860519409, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9462400078773499, Validation Accuracy: 0.5\n",
      "Epoch 8849/10000, Training Loss: 0.6356666684150696, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8300433158874512, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8850/10000, Training Loss: 0.6297628283500671, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8220016360282898, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8851/10000, Training Loss: 0.6117915511131287, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8767067790031433, Validation Accuracy: 0.25\n",
      "Epoch 8852/10000, Training Loss: 0.6240202784538269, Training Accuracy: 0.6985294117647058, Validation Loss: 1.1002788543701172, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8853/10000, Training Loss: 0.6224651336669922, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9769783020019531, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8854/10000, Training Loss: 0.6526161432266235, Training Accuracy: 0.6004901960784313, Validation Loss: 0.999269962310791, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8855/10000, Training Loss: 0.6163783073425293, Training Accuracy: 0.678921568627451, Validation Loss: 0.8463468551635742, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8856/10000, Training Loss: 0.6420103907585144, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6928521990776062, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8857/10000, Training Loss: 0.6324105858802795, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9044992923736572, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8858/10000, Training Loss: 0.6171921491622925, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0348764657974243, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8859/10000, Training Loss: 0.649203360080719, Training Accuracy: 0.6274509803921569, Validation Loss: 0.5531798601150513, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8860/10000, Training Loss: 0.6234933137893677, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8029482960700989, Validation Accuracy: 0.5\n",
      "Epoch 8861/10000, Training Loss: 0.5982061624526978, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7803619503974915, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8862/10000, Training Loss: 0.6143249273300171, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7803072929382324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8863/10000, Training Loss: 0.6640906929969788, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0739381313323975, Validation Accuracy: 0.5\n",
      "Epoch 8864/10000, Training Loss: 0.5944943428039551, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8356034755706787, Validation Accuracy: 0.5\n",
      "Epoch 8865/10000, Training Loss: 0.6373787522315979, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8907871842384338, Validation Accuracy: 0.5\n",
      "Epoch 8866/10000, Training Loss: 0.6635791659355164, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7984695434570312, Validation Accuracy: 0.5\n",
      "Epoch 8867/10000, Training Loss: 0.6510764360427856, Training Accuracy: 0.5955882352941176, Validation Loss: 1.1932686567306519, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8868/10000, Training Loss: 0.6689743399620056, Training Accuracy: 0.6176470588235294, Validation Loss: 0.901197612285614, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8869/10000, Training Loss: 0.5858255624771118, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8934744000434875, Validation Accuracy: 0.5\n",
      "Epoch 8870/10000, Training Loss: 0.6389147639274597, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7580209374427795, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8871/10000, Training Loss: 0.6280806064605713, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8751012682914734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8872/10000, Training Loss: 0.633951723575592, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8062753677368164, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8873/10000, Training Loss: 0.6547815799713135, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6716790795326233, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8874/10000, Training Loss: 0.6213805079460144, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9327418208122253, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8875/10000, Training Loss: 0.6494781374931335, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7300028800964355, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8876/10000, Training Loss: 0.6513371467590332, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6366057991981506, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 8877/10000, Training Loss: 0.5893355011940002, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9286801218986511, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8878/10000, Training Loss: 0.6928792595863342, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7966210246086121, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8879/10000, Training Loss: 0.6461036801338196, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6370826363563538, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8880/10000, Training Loss: 0.6080619096755981, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6832084655761719, Validation Accuracy: 0.5\n",
      "Epoch 8881/10000, Training Loss: 0.6277308464050293, Training Accuracy: 0.696078431372549, Validation Loss: 1.0793873071670532, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8882/10000, Training Loss: 0.6335399746894836, Training Accuracy: 0.6225490196078431, Validation Loss: 0.846578061580658, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8883/10000, Training Loss: 0.5695712566375732, Training Accuracy: 0.7009803921568627, Validation Loss: 1.2737581729888916, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8884/10000, Training Loss: 0.631624698638916, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8863679766654968, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8885/10000, Training Loss: 0.6119840741157532, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8748893141746521, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8886/10000, Training Loss: 0.618782103061676, Training Accuracy: 0.6936274509803921, Validation Loss: 0.6307352185249329, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8887/10000, Training Loss: 0.6109992265701294, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9743514657020569, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8888/10000, Training Loss: 0.6329873204231262, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7194719910621643, Validation Accuracy: 0.5\n",
      "Epoch 8889/10000, Training Loss: 0.651089072227478, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6618320345878601, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8890/10000, Training Loss: 0.6290489435195923, Training Accuracy: 0.6274509803921569, Validation Loss: 0.839447557926178, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8891/10000, Training Loss: 0.6183498501777649, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1521517038345337, Validation Accuracy: 0.25\n",
      "Epoch 8892/10000, Training Loss: 0.6211017370223999, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8448261618614197, Validation Accuracy: 0.5\n",
      "Epoch 8893/10000, Training Loss: 0.6439683437347412, Training Accuracy: 0.6495098039215687, Validation Loss: 1.198447346687317, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8894/10000, Training Loss: 0.6443549394607544, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6782099604606628, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8895/10000, Training Loss: 0.6589866280555725, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7183024287223816, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8896/10000, Training Loss: 0.6314920783042908, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8226606249809265, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8897/10000, Training Loss: 0.6152636408805847, Training Accuracy: 0.6813725490196079, Validation Loss: 1.136817455291748, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8898/10000, Training Loss: 0.6266459226608276, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6625340580940247, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8899/10000, Training Loss: 0.6790371537208557, Training Accuracy: 0.625, Validation Loss: 0.7976996302604675, Validation Accuracy: 0.75\n",
      "Epoch 8900/10000, Training Loss: 0.5781735777854919, Training Accuracy: 0.7009803921568627, Validation Loss: 1.1893553733825684, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8901/10000, Training Loss: 0.6297842860221863, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8587062954902649, Validation Accuracy: 0.5\n",
      "Epoch 8902/10000, Training Loss: 0.6311519145965576, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8699362277984619, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8903/10000, Training Loss: 0.6589998602867126, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8653011918067932, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8904/10000, Training Loss: 0.618845522403717, Training Accuracy: 0.6740196078431373, Validation Loss: 1.0297675132751465, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8905/10000, Training Loss: 0.651858389377594, Training Accuracy: 0.625, Validation Loss: 0.6966946125030518, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8906/10000, Training Loss: 0.6451791524887085, Training Accuracy: 0.625, Validation Loss: 1.146271824836731, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8907/10000, Training Loss: 0.6185271143913269, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7711639404296875, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8908/10000, Training Loss: 0.6769461035728455, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9311590194702148, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8909/10000, Training Loss: 0.643942654132843, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8654548525810242, Validation Accuracy: 0.5\n",
      "Epoch 8910/10000, Training Loss: 0.6314555406570435, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8289313912391663, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8911/10000, Training Loss: 0.6311046481132507, Training Accuracy: 0.6838235294117647, Validation Loss: 0.8650090098381042, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8912/10000, Training Loss: 0.5960841178894043, Training Accuracy: 0.7156862745098039, Validation Loss: 0.9665964245796204, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8913/10000, Training Loss: 0.6570196747779846, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9261520504951477, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8914/10000, Training Loss: 0.6346691250801086, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9844310283660889, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8915/10000, Training Loss: 0.6026087403297424, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7491725087165833, Validation Accuracy: 0.5\n",
      "Epoch 8916/10000, Training Loss: 0.650084376335144, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6121904850006104, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8917/10000, Training Loss: 0.6286848187446594, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9701337218284607, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8918/10000, Training Loss: 0.6457231044769287, Training Accuracy: 0.7205882352941176, Validation Loss: 1.1507593393325806, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8919/10000, Training Loss: 0.6527220606803894, Training Accuracy: 0.6372549019607843, Validation Loss: 0.5323665738105774, Validation Accuracy: 0.75\n",
      "Epoch 8920/10000, Training Loss: 0.6726784110069275, Training Accuracy: 0.6127450980392157, Validation Loss: 1.2627754211425781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8921/10000, Training Loss: 0.6615488529205322, Training Accuracy: 0.5833333333333334, Validation Loss: 0.77443927526474, Validation Accuracy: 0.5\n",
      "Epoch 8922/10000, Training Loss: 0.6416535377502441, Training Accuracy: 0.6151960784313726, Validation Loss: 0.725231409072876, Validation Accuracy: 0.5\n",
      "Epoch 8923/10000, Training Loss: 0.6354373693466187, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7138305306434631, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8924/10000, Training Loss: 0.5934197306632996, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9820465445518494, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8925/10000, Training Loss: 0.6545672416687012, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8607919812202454, Validation Accuracy: 0.5\n",
      "Epoch 8926/10000, Training Loss: 0.630750298500061, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6689847111701965, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8927/10000, Training Loss: 0.6205219030380249, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8707695603370667, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 8928/10000, Training Loss: 0.615662157535553, Training Accuracy: 0.6715686274509803, Validation Loss: 0.47678712010383606, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 8929/10000, Training Loss: 0.6297222375869751, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7219974398612976, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8930/10000, Training Loss: 0.6834350228309631, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6748127937316895, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8931/10000, Training Loss: 0.6490212082862854, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6881265640258789, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8932/10000, Training Loss: 0.6453359127044678, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8013898730278015, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8933/10000, Training Loss: 0.6454291939735413, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6600683331489563, Validation Accuracy: 0.5\n",
      "Epoch 8934/10000, Training Loss: 0.6676173210144043, Training Accuracy: 0.5906862745098039, Validation Loss: 0.953055202960968, Validation Accuracy: 0.25\n",
      "Epoch 8935/10000, Training Loss: 0.6343732476234436, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9115347862243652, Validation Accuracy: 0.5\n",
      "Epoch 8936/10000, Training Loss: 0.6327192783355713, Training Accuracy: 0.6691176470588235, Validation Loss: 0.6495051980018616, Validation Accuracy: 0.75\n",
      "Epoch 8937/10000, Training Loss: 0.6633926033973694, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6674559116363525, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8938/10000, Training Loss: 0.6543788313865662, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6774680018424988, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8939/10000, Training Loss: 0.6330334544181824, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6102253794670105, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8940/10000, Training Loss: 0.6142290830612183, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7689022421836853, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8941/10000, Training Loss: 0.6172512769699097, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9768412709236145, Validation Accuracy: 0.25\n",
      "Epoch 8942/10000, Training Loss: 0.6673313975334167, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7629051208496094, Validation Accuracy: 0.5\n",
      "Epoch 8943/10000, Training Loss: 0.6369370222091675, Training Accuracy: 0.625, Validation Loss: 0.9011172652244568, Validation Accuracy: 0.25\n",
      "Epoch 8944/10000, Training Loss: 0.6499250531196594, Training Accuracy: 0.5735294117647058, Validation Loss: 0.6976616382598877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8945/10000, Training Loss: 0.6394408941268921, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6722618937492371, Validation Accuracy: 0.5\n",
      "Epoch 8946/10000, Training Loss: 0.6176496148109436, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8642761707305908, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8947/10000, Training Loss: 0.6330376267433167, Training Accuracy: 0.678921568627451, Validation Loss: 0.9316597580909729, Validation Accuracy: 0.25\n",
      "Epoch 8948/10000, Training Loss: 0.6374881863594055, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9230837225914001, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8949/10000, Training Loss: 0.614716649055481, Training Accuracy: 0.696078431372549, Validation Loss: 0.8056454062461853, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8950/10000, Training Loss: 0.606553316116333, Training Accuracy: 0.6666666666666666, Validation Loss: 0.696883499622345, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8951/10000, Training Loss: 0.607597291469574, Training Accuracy: 0.6813725490196079, Validation Loss: 0.9017696976661682, Validation Accuracy: 0.25\n",
      "Epoch 8952/10000, Training Loss: 0.6747082471847534, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7388596534729004, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8953/10000, Training Loss: 0.6370707750320435, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7381307482719421, Validation Accuracy: 0.5\n",
      "Epoch 8954/10000, Training Loss: 0.6549313068389893, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0757008790969849, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8955/10000, Training Loss: 0.6986149549484253, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8417301177978516, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8956/10000, Training Loss: 0.6291959881782532, Training Accuracy: 0.7058823529411765, Validation Loss: 1.0561785697937012, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8957/10000, Training Loss: 0.6505895256996155, Training Accuracy: 0.5735294117647058, Validation Loss: 0.5686320662498474, Validation Accuracy: 0.75\n",
      "Epoch 8958/10000, Training Loss: 0.6323162913322449, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7817581295967102, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8959/10000, Training Loss: 0.6358839273452759, Training Accuracy: 0.6372549019607843, Validation Loss: 0.632602870464325, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8960/10000, Training Loss: 0.6651832461357117, Training Accuracy: 0.6029411764705882, Validation Loss: 1.127824306488037, Validation Accuracy: 0.5\n",
      "Epoch 8961/10000, Training Loss: 0.6320111751556396, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9939460754394531, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 8962/10000, Training Loss: 0.6385257244110107, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6560118794441223, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8963/10000, Training Loss: 0.6308720111846924, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7450534701347351, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8964/10000, Training Loss: 0.614167332649231, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6641743183135986, Validation Accuracy: 0.5\n",
      "Epoch 8965/10000, Training Loss: 0.6524496674537659, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7485629916191101, Validation Accuracy: 0.5\n",
      "Epoch 8966/10000, Training Loss: 0.6135638356208801, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8067291378974915, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8967/10000, Training Loss: 0.6720607876777649, Training Accuracy: 0.5955882352941176, Validation Loss: 0.8103093504905701, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8968/10000, Training Loss: 0.633439302444458, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8611277937889099, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8969/10000, Training Loss: 0.6573255658149719, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8969383239746094, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8970/10000, Training Loss: 0.6998924016952515, Training Accuracy: 0.5490196078431373, Validation Loss: 0.8167040944099426, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8971/10000, Training Loss: 0.6099548935890198, Training Accuracy: 0.6813725490196079, Validation Loss: 0.9522866606712341, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8972/10000, Training Loss: 0.6036321520805359, Training Accuracy: 0.6176470588235294, Validation Loss: 1.197204828262329, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8973/10000, Training Loss: 0.6426351070404053, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6740005612373352, Validation Accuracy: 0.5\n",
      "Epoch 8974/10000, Training Loss: 0.6404778957366943, Training Accuracy: 0.625, Validation Loss: 0.8733897805213928, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8975/10000, Training Loss: 0.6406840085983276, Training Accuracy: 0.6372549019607843, Validation Loss: 1.2034341096878052, Validation Accuracy: 0.25\n",
      "Epoch 8976/10000, Training Loss: 0.6285824775695801, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7528108954429626, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8977/10000, Training Loss: 0.6597492694854736, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6937713027000427, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8978/10000, Training Loss: 0.6256842017173767, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7524380087852478, Validation Accuracy: 0.5\n",
      "Epoch 8979/10000, Training Loss: 0.6266065239906311, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7398141026496887, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8980/10000, Training Loss: 0.6746408343315125, Training Accuracy: 0.6372549019607843, Validation Loss: 0.855297327041626, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 8981/10000, Training Loss: 0.6345890164375305, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6634621024131775, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8982/10000, Training Loss: 0.6443930268287659, Training Accuracy: 0.6495098039215687, Validation Loss: 0.5750487446784973, Validation Accuracy: 0.75\n",
      "Epoch 8983/10000, Training Loss: 0.635320246219635, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8139955997467041, Validation Accuracy: 0.5\n",
      "Epoch 8984/10000, Training Loss: 0.622625470161438, Training Accuracy: 0.6838235294117647, Validation Loss: 0.868540346622467, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8985/10000, Training Loss: 0.6305850148200989, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7468991279602051, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8986/10000, Training Loss: 0.6139359474182129, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0593417882919312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8987/10000, Training Loss: 0.6315624117851257, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9201431274414062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8988/10000, Training Loss: 0.6390594244003296, Training Accuracy: 0.6127450980392157, Validation Loss: 0.7531879544258118, Validation Accuracy: 0.5\n",
      "Epoch 8989/10000, Training Loss: 0.6096304059028625, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7788640856742859, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8990/10000, Training Loss: 0.6104245185852051, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9582473635673523, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8991/10000, Training Loss: 0.6333364844322205, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6911582350730896, Validation Accuracy: 0.5\n",
      "Epoch 8992/10000, Training Loss: 0.6087190508842468, Training Accuracy: 0.696078431372549, Validation Loss: 0.8337421417236328, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8993/10000, Training Loss: 0.6530212163925171, Training Accuracy: 0.5857843137254902, Validation Loss: 1.0265100002288818, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8994/10000, Training Loss: 0.6690770387649536, Training Accuracy: 0.6078431372549019, Validation Loss: 0.7401630282402039, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8995/10000, Training Loss: 0.645659327507019, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8461819291114807, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8996/10000, Training Loss: 0.6337247490882874, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6742706298828125, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 8997/10000, Training Loss: 0.6447101831436157, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8573747277259827, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 8998/10000, Training Loss: 0.624687671661377, Training Accuracy: 0.6593137254901961, Validation Loss: 1.046613097190857, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 8999/10000, Training Loss: 0.6564276218414307, Training Accuracy: 0.6740196078431373, Validation Loss: 1.2550451755523682, Validation Accuracy: 0.5\n",
      "Epoch 9000/10000, Training Loss: 0.6276447772979736, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6972095370292664, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9001/10000, Training Loss: 0.6357986330986023, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7289257645606995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9002/10000, Training Loss: 0.6452595591545105, Training Accuracy: 0.6200980392156863, Validation Loss: 0.5944287180900574, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9003/10000, Training Loss: 0.6211841106414795, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9582746624946594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9004/10000, Training Loss: 0.6218510270118713, Training Accuracy: 0.6470588235294118, Validation Loss: 0.937611997127533, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9005/10000, Training Loss: 0.6512317061424255, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7247573733329773, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9006/10000, Training Loss: 0.6180411577224731, Training Accuracy: 0.6985294117647058, Validation Loss: 0.9227893948554993, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9007/10000, Training Loss: 0.6218857765197754, Training Accuracy: 0.6666666666666666, Validation Loss: 1.2860206365585327, Validation Accuracy: 0.5\n",
      "Epoch 9008/10000, Training Loss: 0.6175485253334045, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8539328575134277, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9009/10000, Training Loss: 0.6168659925460815, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9030681252479553, Validation Accuracy: 0.5\n",
      "Epoch 9010/10000, Training Loss: 0.6490417122840881, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8110051155090332, Validation Accuracy: 0.5\n",
      "Epoch 9011/10000, Training Loss: 0.617908239364624, Training Accuracy: 0.7107843137254902, Validation Loss: 0.9053862690925598, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9012/10000, Training Loss: 0.5817019939422607, Training Accuracy: 0.7156862745098039, Validation Loss: 1.1490654945373535, Validation Accuracy: 0.25\n",
      "Epoch 9013/10000, Training Loss: 0.6315926909446716, Training Accuracy: 0.6372549019607843, Validation Loss: 0.766888439655304, Validation Accuracy: 0.5\n",
      "Epoch 9014/10000, Training Loss: 0.6399756073951721, Training Accuracy: 0.6642156862745098, Validation Loss: 1.4290560483932495, Validation Accuracy: 0.5\n",
      "Epoch 9015/10000, Training Loss: 0.634000837802887, Training Accuracy: 0.6299019607843137, Validation Loss: 1.1265209913253784, Validation Accuracy: 0.5\n",
      "Epoch 9016/10000, Training Loss: 0.632615327835083, Training Accuracy: 0.6348039215686274, Validation Loss: 1.0136505365371704, Validation Accuracy: 0.5\n",
      "Epoch 9017/10000, Training Loss: 0.597883403301239, Training Accuracy: 0.7230392156862745, Validation Loss: 0.9860897660255432, Validation Accuracy: 0.5\n",
      "Epoch 9018/10000, Training Loss: 0.610698401927948, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8112695813179016, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9019/10000, Training Loss: 0.6186665296554565, Training Accuracy: 0.6862745098039216, Validation Loss: 1.1253780126571655, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9020/10000, Training Loss: 0.6375716924667358, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8241124749183655, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9021/10000, Training Loss: 0.6479887962341309, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8971004486083984, Validation Accuracy: 0.5\n",
      "Epoch 9022/10000, Training Loss: 0.6048645377159119, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7785187363624573, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9023/10000, Training Loss: 0.6190679669380188, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8577759861946106, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9024/10000, Training Loss: 0.6327860951423645, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7778084874153137, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9025/10000, Training Loss: 0.6528234481811523, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8965298533439636, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9026/10000, Training Loss: 0.6211956739425659, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9264433979988098, Validation Accuracy: 0.5\n",
      "Epoch 9027/10000, Training Loss: 0.5715022087097168, Training Accuracy: 0.696078431372549, Validation Loss: 1.024231195449829, Validation Accuracy: 0.75\n",
      "Epoch 9028/10000, Training Loss: 0.6313419938087463, Training Accuracy: 0.6544117647058824, Validation Loss: 1.206851601600647, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9029/10000, Training Loss: 0.6326614022254944, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9838207364082336, Validation Accuracy: 0.5\n",
      "Epoch 9030/10000, Training Loss: 0.6006613969802856, Training Accuracy: 0.7279411764705882, Validation Loss: 0.6727511286735535, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9031/10000, Training Loss: 0.6343924403190613, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6892842650413513, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9032/10000, Training Loss: 0.6222809553146362, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8193710446357727, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9033/10000, Training Loss: 0.6653721928596497, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9155681729316711, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9034/10000, Training Loss: 0.6666602492332458, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7009017467498779, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9035/10000, Training Loss: 0.6683308482170105, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6267654299736023, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9036/10000, Training Loss: 0.6326649188995361, Training Accuracy: 0.6740196078431373, Validation Loss: 1.2621945142745972, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9037/10000, Training Loss: 0.6586403846740723, Training Accuracy: 0.6397058823529411, Validation Loss: 0.845253050327301, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9038/10000, Training Loss: 0.652132511138916, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8601799011230469, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9039/10000, Training Loss: 0.625180721282959, Training Accuracy: 0.6936274509803921, Validation Loss: 0.9853017330169678, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9040/10000, Training Loss: 0.6528765559196472, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7889504432678223, Validation Accuracy: 0.5\n",
      "Epoch 9041/10000, Training Loss: 0.6551645398139954, Training Accuracy: 0.625, Validation Loss: 0.7081161141395569, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9042/10000, Training Loss: 0.6050136685371399, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8109108805656433, Validation Accuracy: 0.5\n",
      "Epoch 9043/10000, Training Loss: 0.6988950967788696, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7764323353767395, Validation Accuracy: 0.75\n",
      "Epoch 9044/10000, Training Loss: 0.6990153193473816, Training Accuracy: 0.6887254901960784, Validation Loss: 1.517548680305481, Validation Accuracy: 0.5\n",
      "Epoch 9045/10000, Training Loss: 0.6340548992156982, Training Accuracy: 0.6299019607843137, Validation Loss: 0.751324474811554, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9046/10000, Training Loss: 0.6877050995826721, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9167018532752991, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9047/10000, Training Loss: 0.5994403958320618, Training Accuracy: 0.7107843137254902, Validation Loss: 0.716057300567627, Validation Accuracy: 0.75\n",
      "Epoch 9048/10000, Training Loss: 0.6242110729217529, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8860134482383728, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9049/10000, Training Loss: 0.6374191045761108, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7799298167228699, Validation Accuracy: 0.5\n",
      "Epoch 9050/10000, Training Loss: 0.641581654548645, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8440346121788025, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9051/10000, Training Loss: 0.674099862575531, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7833508849143982, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9052/10000, Training Loss: 0.6261284947395325, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8550652861595154, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9053/10000, Training Loss: 0.6479501128196716, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8255863785743713, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9054/10000, Training Loss: 0.6579058766365051, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8520960807800293, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9055/10000, Training Loss: 0.6112392544746399, Training Accuracy: 0.7181372549019608, Validation Loss: 0.8587307929992676, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9056/10000, Training Loss: 0.6430908441543579, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7656481266021729, Validation Accuracy: 0.5\n",
      "Epoch 9057/10000, Training Loss: 0.613940417766571, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6071803569793701, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9058/10000, Training Loss: 0.630990207195282, Training Accuracy: 0.6838235294117647, Validation Loss: 0.6539677977561951, Validation Accuracy: 0.5\n",
      "Epoch 9059/10000, Training Loss: 0.6194653511047363, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7242088913917542, Validation Accuracy: 0.5\n",
      "Epoch 9060/10000, Training Loss: 0.6428112983703613, Training Accuracy: 0.6495098039215687, Validation Loss: 0.664505660533905, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9061/10000, Training Loss: 0.6414264440536499, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7438389658927917, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9062/10000, Training Loss: 0.6557733416557312, Training Accuracy: 0.6323529411764706, Validation Loss: 0.978449285030365, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9063/10000, Training Loss: 0.6368234157562256, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8888644576072693, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9064/10000, Training Loss: 0.6308761239051819, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6713874936103821, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9065/10000, Training Loss: 0.6378288865089417, Training Accuracy: 0.6593137254901961, Validation Loss: 0.833578884601593, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9066/10000, Training Loss: 0.6472814679145813, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7274876236915588, Validation Accuracy: 0.5\n",
      "Epoch 9067/10000, Training Loss: 0.644788384437561, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8008038997650146, Validation Accuracy: 0.5\n",
      "Epoch 9068/10000, Training Loss: 0.6375596523284912, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8535653948783875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9069/10000, Training Loss: 0.6209172010421753, Training Accuracy: 0.678921568627451, Validation Loss: 0.8650348782539368, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9070/10000, Training Loss: 0.6508853435516357, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9335768222808838, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9071/10000, Training Loss: 0.652924120426178, Training Accuracy: 0.6446078431372549, Validation Loss: 1.014933705329895, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9072/10000, Training Loss: 0.6582644581794739, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6266884803771973, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9073/10000, Training Loss: 0.6691275835037231, Training Accuracy: 0.5661764705882353, Validation Loss: 0.8107579350471497, Validation Accuracy: 0.5\n",
      "Epoch 9074/10000, Training Loss: 0.6395778059959412, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6619346737861633, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9075/10000, Training Loss: 0.6406821608543396, Training Accuracy: 0.6666666666666666, Validation Loss: 1.179456353187561, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9076/10000, Training Loss: 0.6162761449813843, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8650466799736023, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9077/10000, Training Loss: 0.6295950412750244, Training Accuracy: 0.6372549019607843, Validation Loss: 0.84428471326828, Validation Accuracy: 0.25\n",
      "Epoch 9078/10000, Training Loss: 0.6316264271736145, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6952941417694092, Validation Accuracy: 0.5\n",
      "Epoch 9079/10000, Training Loss: 0.6212480664253235, Training Accuracy: 0.6691176470588235, Validation Loss: 1.014451503753662, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9080/10000, Training Loss: 0.6438795328140259, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7809147238731384, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9081/10000, Training Loss: 0.6482931971549988, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8267373442649841, Validation Accuracy: 0.5\n",
      "Epoch 9082/10000, Training Loss: 0.5934808254241943, Training Accuracy: 0.6887254901960784, Validation Loss: 1.179030179977417, Validation Accuracy: 0.5\n",
      "Epoch 9083/10000, Training Loss: 0.6484582424163818, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0445863008499146, Validation Accuracy: 0.5\n",
      "Epoch 9084/10000, Training Loss: 0.6499660015106201, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0735855102539062, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9085/10000, Training Loss: 0.6565663814544678, Training Accuracy: 0.6397058823529411, Validation Loss: 0.6781825423240662, Validation Accuracy: 0.75\n",
      "Epoch 9086/10000, Training Loss: 0.6105440258979797, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7435844540596008, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9087/10000, Training Loss: 0.6333737373352051, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7972120642662048, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9088/10000, Training Loss: 0.6168540716171265, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6752820611000061, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9089/10000, Training Loss: 0.6552723050117493, Training Accuracy: 0.5588235294117647, Validation Loss: 0.7941648960113525, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9090/10000, Training Loss: 0.6299249529838562, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8244834542274475, Validation Accuracy: 0.5\n",
      "Epoch 9091/10000, Training Loss: 0.5961125493049622, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8454334735870361, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9092/10000, Training Loss: 0.6274330019950867, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7009574770927429, Validation Accuracy: 0.5\n",
      "Epoch 9093/10000, Training Loss: 0.6406658291816711, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8177414536476135, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9094/10000, Training Loss: 0.5786817073822021, Training Accuracy: 0.7181372549019608, Validation Loss: 1.06680428981781, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9095/10000, Training Loss: 0.5991325974464417, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6784575581550598, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9096/10000, Training Loss: 0.6257703304290771, Training Accuracy: 0.6838235294117647, Validation Loss: 1.0602434873580933, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9097/10000, Training Loss: 0.6929898858070374, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6839752793312073, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9098/10000, Training Loss: 0.6360865831375122, Training Accuracy: 0.6200980392156863, Validation Loss: 1.132415533065796, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9099/10000, Training Loss: 0.6423222422599792, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8589236736297607, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9100/10000, Training Loss: 0.6667840480804443, Training Accuracy: 0.625, Validation Loss: 0.8996781706809998, Validation Accuracy: 0.25\n",
      "Epoch 9101/10000, Training Loss: 0.6306448578834534, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9285626411437988, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9102/10000, Training Loss: 0.6334220767021179, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8999833464622498, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9103/10000, Training Loss: 0.6346650719642639, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9144361615180969, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9104/10000, Training Loss: 0.6301953792572021, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7819107174873352, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9105/10000, Training Loss: 0.677850604057312, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7492690682411194, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9106/10000, Training Loss: 0.6195409297943115, Training Accuracy: 0.7107843137254902, Validation Loss: 0.9298054575920105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9107/10000, Training Loss: 0.6371544003486633, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7073270678520203, Validation Accuracy: 0.5\n",
      "Epoch 9108/10000, Training Loss: 0.6240292191505432, Training Accuracy: 0.6200980392156863, Validation Loss: 0.651198148727417, Validation Accuracy: 0.5\n",
      "Epoch 9109/10000, Training Loss: 0.6200650334358215, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7728061676025391, Validation Accuracy: 0.5\n",
      "Epoch 9110/10000, Training Loss: 0.6426980495452881, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6731706261634827, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9111/10000, Training Loss: 0.6393505334854126, Training Accuracy: 0.5980392156862745, Validation Loss: 0.6932989954948425, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9112/10000, Training Loss: 0.568061888217926, Training Accuracy: 0.7107843137254902, Validation Loss: 0.848726749420166, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9113/10000, Training Loss: 0.6314855813980103, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7871343493461609, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9114/10000, Training Loss: 0.6187708973884583, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8548725247383118, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9115/10000, Training Loss: 0.6377979516983032, Training Accuracy: 0.6936274509803921, Validation Loss: 0.6640579104423523, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9116/10000, Training Loss: 0.6229525804519653, Training Accuracy: 0.6740196078431373, Validation Loss: 0.741276741027832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9117/10000, Training Loss: 0.6362122297286987, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7931127548217773, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9118/10000, Training Loss: 0.6588883399963379, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7484232783317566, Validation Accuracy: 0.5\n",
      "Epoch 9119/10000, Training Loss: 0.6202788352966309, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8188585638999939, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9120/10000, Training Loss: 0.5963852405548096, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7689197659492493, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9121/10000, Training Loss: 0.6067212820053101, Training Accuracy: 0.7156862745098039, Validation Loss: 1.043439269065857, Validation Accuracy: 0.5\n",
      "Epoch 9122/10000, Training Loss: 0.6313562393188477, Training Accuracy: 0.6838235294117647, Validation Loss: 0.5335021615028381, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9123/10000, Training Loss: 0.6219450831413269, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8210247159004211, Validation Accuracy: 0.5\n",
      "Epoch 9124/10000, Training Loss: 0.6542277336120605, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7922428250312805, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9125/10000, Training Loss: 0.6150164008140564, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7318522334098816, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9126/10000, Training Loss: 0.5721933245658875, Training Accuracy: 0.696078431372549, Validation Loss: 0.803290069103241, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9127/10000, Training Loss: 0.6660687327384949, Training Accuracy: 0.5882352941176471, Validation Loss: 0.9251754879951477, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9128/10000, Training Loss: 0.6404830813407898, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8358305096626282, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9129/10000, Training Loss: 0.6709020137786865, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7309255599975586, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9130/10000, Training Loss: 0.6137585043907166, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7506260871887207, Validation Accuracy: 0.5\n",
      "Epoch 9131/10000, Training Loss: 0.6341825127601624, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0406184196472168, Validation Accuracy: 0.5\n",
      "Epoch 9132/10000, Training Loss: 0.6613132953643799, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6534186005592346, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9133/10000, Training Loss: 0.5908252596855164, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8545122146606445, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9134/10000, Training Loss: 0.6122972369194031, Training Accuracy: 0.625, Validation Loss: 0.8906559348106384, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9135/10000, Training Loss: 0.6532460451126099, Training Accuracy: 0.6053921568627451, Validation Loss: 1.2515560388565063, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9136/10000, Training Loss: 0.6249046325683594, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8757203221321106, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9137/10000, Training Loss: 0.6180621981620789, Training Accuracy: 0.6348039215686274, Validation Loss: 1.2499386072158813, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9138/10000, Training Loss: 0.6036847233772278, Training Accuracy: 0.678921568627451, Validation Loss: 0.893311083316803, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9139/10000, Training Loss: 0.6095534563064575, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7640037536621094, Validation Accuracy: 0.5\n",
      "Epoch 9140/10000, Training Loss: 0.6287133693695068, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8822491765022278, Validation Accuracy: 0.5\n",
      "Epoch 9141/10000, Training Loss: 0.6558949947357178, Training Accuracy: 0.678921568627451, Validation Loss: 1.025643229484558, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9142/10000, Training Loss: 0.6223670840263367, Training Accuracy: 0.7058823529411765, Validation Loss: 0.8498260378837585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9143/10000, Training Loss: 0.6810810565948486, Training Accuracy: 0.5490196078431373, Validation Loss: 0.9650148749351501, Validation Accuracy: 0.25\n",
      "Epoch 9144/10000, Training Loss: 0.6426084637641907, Training Accuracy: 0.6004901960784313, Validation Loss: 0.8570871353149414, Validation Accuracy: 0.5\n",
      "Epoch 9145/10000, Training Loss: 0.6793509125709534, Training Accuracy: 0.5833333333333334, Validation Loss: 0.9626298546791077, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9146/10000, Training Loss: 0.6079959273338318, Training Accuracy: 0.696078431372549, Validation Loss: 0.6464452147483826, Validation Accuracy: 0.75\n",
      "Epoch 9147/10000, Training Loss: 0.676601767539978, Training Accuracy: 0.6078431372549019, Validation Loss: 1.0702869892120361, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9148/10000, Training Loss: 0.6280432343482971, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6990393996238708, Validation Accuracy: 0.5\n",
      "Epoch 9149/10000, Training Loss: 0.6865375638008118, Training Accuracy: 0.6544117647058824, Validation Loss: 1.1115891933441162, Validation Accuracy: 0.25\n",
      "Epoch 9150/10000, Training Loss: 0.641596257686615, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8131220936775208, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9151/10000, Training Loss: 0.6744081377983093, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7269852161407471, Validation Accuracy: 0.5\n",
      "Epoch 9152/10000, Training Loss: 0.6509264707565308, Training Accuracy: 0.6225490196078431, Validation Loss: 0.905694305896759, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9153/10000, Training Loss: 0.5975619554519653, Training Accuracy: 0.678921568627451, Validation Loss: 1.0239757299423218, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9154/10000, Training Loss: 0.6948406100273132, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6140925288200378, Validation Accuracy: 0.75\n",
      "Epoch 9155/10000, Training Loss: 0.6601340174674988, Training Accuracy: 0.5637254901960784, Validation Loss: 0.8413038849830627, Validation Accuracy: 0.5\n",
      "Epoch 9156/10000, Training Loss: 0.6237582564353943, Training Accuracy: 0.7009803921568627, Validation Loss: 0.618920624256134, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9157/10000, Training Loss: 0.6317654848098755, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7021636962890625, Validation Accuracy: 0.75\n",
      "Epoch 9158/10000, Training Loss: 0.6352130770683289, Training Accuracy: 0.6029411764705882, Validation Loss: 0.5800604224205017, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9159/10000, Training Loss: 0.6427693963050842, Training Accuracy: 0.6102941176470589, Validation Loss: 0.813987672328949, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9160/10000, Training Loss: 0.6096158027648926, Training Accuracy: 0.6397058823529411, Validation Loss: 0.866054117679596, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9161/10000, Training Loss: 0.6507442593574524, Training Accuracy: 0.6029411764705882, Validation Loss: 0.694892406463623, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9162/10000, Training Loss: 0.6434128880500793, Training Accuracy: 0.6715686274509803, Validation Loss: 0.8199735283851624, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9163/10000, Training Loss: 0.672549307346344, Training Accuracy: 0.625, Validation Loss: 0.8100457191467285, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9164/10000, Training Loss: 0.6440248489379883, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7553451657295227, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9165/10000, Training Loss: 0.622896134853363, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6598744988441467, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9166/10000, Training Loss: 0.6468462347984314, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7010529637336731, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9167/10000, Training Loss: 0.6382557153701782, Training Accuracy: 0.625, Validation Loss: 0.8078110814094543, Validation Accuracy: 0.5\n",
      "Epoch 9168/10000, Training Loss: 0.6197500824928284, Training Accuracy: 0.7058823529411765, Validation Loss: 0.9355440139770508, Validation Accuracy: 0.25\n",
      "Epoch 9169/10000, Training Loss: 0.6450212597846985, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9147768616676331, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9170/10000, Training Loss: 0.6430403590202332, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6434432864189148, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9171/10000, Training Loss: 0.66082364320755, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7265298962593079, Validation Accuracy: 0.5\n",
      "Epoch 9172/10000, Training Loss: 0.6519426107406616, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7528838515281677, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9173/10000, Training Loss: 0.6264219284057617, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0086613893508911, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9174/10000, Training Loss: 0.6335009336471558, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7393085360527039, Validation Accuracy: 0.5\n",
      "Epoch 9175/10000, Training Loss: 0.626406192779541, Training Accuracy: 0.6421568627450981, Validation Loss: 0.913454532623291, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9176/10000, Training Loss: 0.6451089382171631, Training Accuracy: 0.6421568627450981, Validation Loss: 1.4142403602600098, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9177/10000, Training Loss: 0.6507468819618225, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6540598273277283, Validation Accuracy: 0.75\n",
      "Epoch 9178/10000, Training Loss: 0.6534515023231506, Training Accuracy: 0.625, Validation Loss: 0.8361595273017883, Validation Accuracy: 0.5\n",
      "Epoch 9179/10000, Training Loss: 0.6450921893119812, Training Accuracy: 0.6176470588235294, Validation Loss: 0.6657187342643738, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9180/10000, Training Loss: 0.6040433049201965, Training Accuracy: 0.6323529411764706, Validation Loss: 0.5844375491142273, Validation Accuracy: 0.75\n",
      "Epoch 9181/10000, Training Loss: 0.6277152299880981, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7295346260070801, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9182/10000, Training Loss: 0.6121851801872253, Training Accuracy: 0.7034313725490197, Validation Loss: 0.8476912975311279, Validation Accuracy: 0.5\n",
      "Epoch 9183/10000, Training Loss: 0.6688771843910217, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8591155409812927, Validation Accuracy: 0.5\n",
      "Epoch 9184/10000, Training Loss: 0.6701124310493469, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6534042954444885, Validation Accuracy: 0.5\n",
      "Epoch 9185/10000, Training Loss: 0.6507619023323059, Training Accuracy: 0.5784313725490197, Validation Loss: 0.7300279140472412, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9186/10000, Training Loss: 0.6087156534194946, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7714993357658386, Validation Accuracy: 0.5\n",
      "Epoch 9187/10000, Training Loss: 0.6246352195739746, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9117597937583923, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9188/10000, Training Loss: 0.6159772872924805, Training Accuracy: 0.6446078431372549, Validation Loss: 1.1825753450393677, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9189/10000, Training Loss: 0.5777326822280884, Training Accuracy: 0.696078431372549, Validation Loss: 1.0162729024887085, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9190/10000, Training Loss: 0.587024450302124, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8422753214836121, Validation Accuracy: 0.5\n",
      "Epoch 9191/10000, Training Loss: 0.674579381942749, Training Accuracy: 0.6936274509803921, Validation Loss: 1.2321783304214478, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9192/10000, Training Loss: 0.6185495853424072, Training Accuracy: 0.696078431372549, Validation Loss: 0.7271749973297119, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9193/10000, Training Loss: 0.6365842819213867, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8453273177146912, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9194/10000, Training Loss: 0.6035292148590088, Training Accuracy: 0.678921568627451, Validation Loss: 0.6830000877380371, Validation Accuracy: 0.5\n",
      "Epoch 9195/10000, Training Loss: 0.5971221327781677, Training Accuracy: 0.7058823529411765, Validation Loss: 0.7226844429969788, Validation Accuracy: 0.5\n",
      "Epoch 9196/10000, Training Loss: 0.6239778995513916, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9580996036529541, Validation Accuracy: 0.5\n",
      "Epoch 9197/10000, Training Loss: 0.6468597054481506, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6134223341941833, Validation Accuracy: 0.75\n",
      "Epoch 9198/10000, Training Loss: 0.6538851857185364, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6681622862815857, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9199/10000, Training Loss: 0.6196109652519226, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8474865555763245, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9200/10000, Training Loss: 0.6429740786552429, Training Accuracy: 0.625, Validation Loss: 0.9402397274971008, Validation Accuracy: 0.5\n",
      "Epoch 9201/10000, Training Loss: 0.5896130204200745, Training Accuracy: 0.6887254901960784, Validation Loss: 1.169382929801941, Validation Accuracy: 0.5\n",
      "Epoch 9202/10000, Training Loss: 0.608379602432251, Training Accuracy: 0.6936274509803921, Validation Loss: 0.926734209060669, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9203/10000, Training Loss: 0.5951478481292725, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0336834192276, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9204/10000, Training Loss: 0.6751653552055359, Training Accuracy: 0.5392156862745098, Validation Loss: 0.9017626643180847, Validation Accuracy: 0.25\n",
      "Epoch 9205/10000, Training Loss: 0.6412643194198608, Training Accuracy: 0.678921568627451, Validation Loss: 0.6781561374664307, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9206/10000, Training Loss: 0.6335523128509521, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8713862895965576, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9207/10000, Training Loss: 0.6281898617744446, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8007963299751282, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9208/10000, Training Loss: 0.641575038433075, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9038509726524353, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9209/10000, Training Loss: 0.6574201583862305, Training Accuracy: 0.6568627450980392, Validation Loss: 0.6841881275177002, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9210/10000, Training Loss: 0.6331814527511597, Training Accuracy: 0.6887254901960784, Validation Loss: 1.090934157371521, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9211/10000, Training Loss: 0.6552891731262207, Training Accuracy: 0.678921568627451, Validation Loss: 0.8800191879272461, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9212/10000, Training Loss: 0.6485554575920105, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7220275402069092, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9213/10000, Training Loss: 0.7086930871009827, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7526461482048035, Validation Accuracy: 0.5\n",
      "Epoch 9214/10000, Training Loss: 0.619135856628418, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9080719947814941, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9215/10000, Training Loss: 0.6294693350791931, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7522227168083191, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9216/10000, Training Loss: 0.6610734462738037, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9608666300773621, Validation Accuracy: 0.5\n",
      "Epoch 9217/10000, Training Loss: 0.6503211855888367, Training Accuracy: 0.6323529411764706, Validation Loss: 0.676994800567627, Validation Accuracy: 0.5\n",
      "Epoch 9218/10000, Training Loss: 0.6139654517173767, Training Accuracy: 0.7132352941176471, Validation Loss: 0.7717428803443909, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9219/10000, Training Loss: 0.6549256443977356, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0353726148605347, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9220/10000, Training Loss: 0.6832994222640991, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6729580760002136, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9221/10000, Training Loss: 0.6367082595825195, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7649405598640442, Validation Accuracy: 0.5\n",
      "Epoch 9222/10000, Training Loss: 0.6015139818191528, Training Accuracy: 0.6593137254901961, Validation Loss: 1.3338342905044556, Validation Accuracy: 0.25\n",
      "Epoch 9223/10000, Training Loss: 0.6956391930580139, Training Accuracy: 0.6053921568627451, Validation Loss: 1.0694701671600342, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9224/10000, Training Loss: 0.6269379258155823, Training Accuracy: 0.6446078431372549, Validation Loss: 0.4271618127822876, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 9225/10000, Training Loss: 0.6578838229179382, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7181382179260254, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9226/10000, Training Loss: 0.6392057538032532, Training Accuracy: 0.6593137254901961, Validation Loss: 0.735649585723877, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9227/10000, Training Loss: 0.5998346209526062, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7116777896881104, Validation Accuracy: 0.5\n",
      "Epoch 9228/10000, Training Loss: 0.657135009765625, Training Accuracy: 0.6200980392156863, Validation Loss: 1.1380912065505981, Validation Accuracy: 0.25\n",
      "Epoch 9229/10000, Training Loss: 0.6144605875015259, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7819733619689941, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9230/10000, Training Loss: 0.6318897008895874, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7343165874481201, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9231/10000, Training Loss: 0.6041858196258545, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9755262732505798, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9232/10000, Training Loss: 0.6074628829956055, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6965062618255615, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9233/10000, Training Loss: 0.6492802500724792, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7802968621253967, Validation Accuracy: 0.5\n",
      "Epoch 9234/10000, Training Loss: 0.6020780205726624, Training Accuracy: 0.696078431372549, Validation Loss: 0.8735682964324951, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9235/10000, Training Loss: 0.6216714382171631, Training Accuracy: 0.6642156862745098, Validation Loss: 0.960882842540741, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9236/10000, Training Loss: 0.6612077355384827, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7258628010749817, Validation Accuracy: 0.5\n",
      "Epoch 9237/10000, Training Loss: 0.6358319520950317, Training Accuracy: 0.6372549019607843, Validation Loss: 0.663261353969574, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9238/10000, Training Loss: 0.6216580867767334, Training Accuracy: 0.6764705882352942, Validation Loss: 1.0467729568481445, Validation Accuracy: 0.5\n",
      "Epoch 9239/10000, Training Loss: 0.6285236477851868, Training Accuracy: 0.6446078431372549, Validation Loss: 1.0060149431228638, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9240/10000, Training Loss: 0.6272597312927246, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0000660419464111, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9241/10000, Training Loss: 0.6276283860206604, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9806920886039734, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9242/10000, Training Loss: 0.6111388206481934, Training Accuracy: 0.7009803921568627, Validation Loss: 0.8811714053153992, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9243/10000, Training Loss: 0.6586547493934631, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0183706283569336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9244/10000, Training Loss: 0.6493128538131714, Training Accuracy: 0.6323529411764706, Validation Loss: 0.769763708114624, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9245/10000, Training Loss: 0.5946476459503174, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8706381916999817, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9246/10000, Training Loss: 0.6430010199546814, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1251851320266724, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9247/10000, Training Loss: 0.6090549230575562, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9446864724159241, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9248/10000, Training Loss: 0.6410199403762817, Training Accuracy: 0.6568627450980392, Validation Loss: 0.898986279964447, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9249/10000, Training Loss: 0.6355047821998596, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7769744992256165, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9250/10000, Training Loss: 0.6876097321510315, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7439975738525391, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9251/10000, Training Loss: 0.6290637254714966, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7419655919075012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9252/10000, Training Loss: 0.644597053527832, Training Accuracy: 0.6446078431372549, Validation Loss: 0.80348140001297, Validation Accuracy: 0.5\n",
      "Epoch 9253/10000, Training Loss: 0.6687272787094116, Training Accuracy: 0.678921568627451, Validation Loss: 1.2333253622055054, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9254/10000, Training Loss: 0.6205136775970459, Training Accuracy: 0.6200980392156863, Validation Loss: 0.677670419216156, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9255/10000, Training Loss: 0.6120964884757996, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8065452575683594, Validation Accuracy: 0.5\n",
      "Epoch 9256/10000, Training Loss: 0.6917025446891785, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6797495484352112, Validation Accuracy: 0.5\n",
      "Epoch 9257/10000, Training Loss: 0.6266430020332336, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7865241169929504, Validation Accuracy: 0.5\n",
      "Epoch 9258/10000, Training Loss: 0.6459753513336182, Training Accuracy: 0.6470588235294118, Validation Loss: 0.738633394241333, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9259/10000, Training Loss: 0.606974720954895, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0621997117996216, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9260/10000, Training Loss: 0.6301260590553284, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9930132031440735, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9261/10000, Training Loss: 0.6305515766143799, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6760109066963196, Validation Accuracy: 0.5\n",
      "Epoch 9262/10000, Training Loss: 0.6884127855300903, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7528555989265442, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9263/10000, Training Loss: 0.650104284286499, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7800704836845398, Validation Accuracy: 0.5\n",
      "Epoch 9264/10000, Training Loss: 0.6337919235229492, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7414383292198181, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9265/10000, Training Loss: 0.6037620306015015, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7999305129051208, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9266/10000, Training Loss: 0.6626220345497131, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8330489993095398, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9267/10000, Training Loss: 0.620227575302124, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7678456902503967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9268/10000, Training Loss: 0.6466050744056702, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7142632603645325, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9269/10000, Training Loss: 0.6293725371360779, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7473214268684387, Validation Accuracy: 0.25\n",
      "Epoch 9270/10000, Training Loss: 0.6362117528915405, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8453556895256042, Validation Accuracy: 0.5\n",
      "Epoch 9271/10000, Training Loss: 0.6209445595741272, Training Accuracy: 0.6593137254901961, Validation Loss: 0.647291362285614, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9272/10000, Training Loss: 0.6512027978897095, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9336654543876648, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9273/10000, Training Loss: 0.6631184220314026, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7603084444999695, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9274/10000, Training Loss: 0.591495156288147, Training Accuracy: 0.6911764705882353, Validation Loss: 0.6833670139312744, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9275/10000, Training Loss: 0.6277812719345093, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7790349125862122, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9276/10000, Training Loss: 0.5863578915596008, Training Accuracy: 0.7034313725490197, Validation Loss: 0.9692954421043396, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9277/10000, Training Loss: 0.6395970582962036, Training Accuracy: 0.625, Validation Loss: 0.5745793581008911, Validation Accuracy: 0.75\n",
      "Epoch 9278/10000, Training Loss: 0.5982866287231445, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9493209719657898, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9279/10000, Training Loss: 0.6750378608703613, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0893765687942505, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9280/10000, Training Loss: 0.576648473739624, Training Accuracy: 0.6936274509803921, Validation Loss: 1.1518332958221436, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9281/10000, Training Loss: 0.6593389511108398, Training Accuracy: 0.5686274509803921, Validation Loss: 0.6543141007423401, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9282/10000, Training Loss: 0.6486096978187561, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7388330101966858, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9283/10000, Training Loss: 0.595153272151947, Training Accuracy: 0.7009803921568627, Validation Loss: 0.8591098189353943, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9284/10000, Training Loss: 0.6474392414093018, Training Accuracy: 0.553921568627451, Validation Loss: 0.9241719841957092, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9285/10000, Training Loss: 0.6628966331481934, Training Accuracy: 0.5735294117647058, Validation Loss: 0.9659380912780762, Validation Accuracy: 0.25\n",
      "Epoch 9286/10000, Training Loss: 0.6056951880455017, Training Accuracy: 0.6691176470588235, Validation Loss: 1.4611204862594604, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9287/10000, Training Loss: 0.6147922277450562, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8267185688018799, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9288/10000, Training Loss: 0.6367366909980774, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8717363476753235, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9289/10000, Training Loss: 0.6750157475471497, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7634018063545227, Validation Accuracy: 0.25\n",
      "Epoch 9290/10000, Training Loss: 0.6251977682113647, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9379796981811523, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9291/10000, Training Loss: 0.5849155187606812, Training Accuracy: 0.7205882352941176, Validation Loss: 1.0725964307785034, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9292/10000, Training Loss: 0.6360743641853333, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7135984301567078, Validation Accuracy: 0.5\n",
      "Epoch 9293/10000, Training Loss: 0.6105644106864929, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8467276096343994, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9294/10000, Training Loss: 0.6287698149681091, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7002754211425781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9295/10000, Training Loss: 0.6715453863143921, Training Accuracy: 0.6372549019607843, Validation Loss: 0.794677734375, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9296/10000, Training Loss: 0.6475530862808228, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8253920674324036, Validation Accuracy: 0.5\n",
      "Epoch 9297/10000, Training Loss: 0.6648867130279541, Training Accuracy: 0.5931372549019608, Validation Loss: 0.9262189865112305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9298/10000, Training Loss: 0.6229076981544495, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7702453136444092, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9299/10000, Training Loss: 0.6338727474212646, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6924360394477844, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9300/10000, Training Loss: 0.6360690593719482, Training Accuracy: 0.6495098039215687, Validation Loss: 0.680852472782135, Validation Accuracy: 0.5\n",
      "Epoch 9301/10000, Training Loss: 0.6669421195983887, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0951119661331177, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9302/10000, Training Loss: 0.6701141595840454, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6127267479896545, Validation Accuracy: 0.75\n",
      "Epoch 9303/10000, Training Loss: 0.5985586643218994, Training Accuracy: 0.6764705882352942, Validation Loss: 0.785595715045929, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9304/10000, Training Loss: 0.644853413105011, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6299958825111389, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9305/10000, Training Loss: 0.6353960037231445, Training Accuracy: 0.678921568627451, Validation Loss: 0.7334391474723816, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9306/10000, Training Loss: 0.6571250557899475, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8935635685920715, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9307/10000, Training Loss: 0.5845978260040283, Training Accuracy: 0.7156862745098039, Validation Loss: 0.9295592904090881, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9308/10000, Training Loss: 0.6478949785232544, Training Accuracy: 0.6176470588235294, Validation Loss: 0.550678551197052, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9309/10000, Training Loss: 0.6270308494567871, Training Accuracy: 0.6470588235294118, Validation Loss: 1.209794282913208, Validation Accuracy: 0.5\n",
      "Epoch 9310/10000, Training Loss: 0.675492525100708, Training Accuracy: 0.6029411764705882, Validation Loss: 0.943866491317749, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9311/10000, Training Loss: 0.6065576076507568, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6901991367340088, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9312/10000, Training Loss: 0.6571053862571716, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7310473918914795, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9313/10000, Training Loss: 0.6570168137550354, Training Accuracy: 0.6274509803921569, Validation Loss: 1.0630316734313965, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9314/10000, Training Loss: 0.6311149597167969, Training Accuracy: 0.6617647058823529, Validation Loss: 1.156768560409546, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9315/10000, Training Loss: 0.6272737979888916, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7281322479248047, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9316/10000, Training Loss: 0.6954017281532288, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8388257026672363, Validation Accuracy: 0.5\n",
      "Epoch 9317/10000, Training Loss: 0.6354520320892334, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6943498253822327, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9318/10000, Training Loss: 0.6442167162895203, Training Accuracy: 0.5808823529411765, Validation Loss: 0.7444828152656555, Validation Accuracy: 0.5\n",
      "Epoch 9319/10000, Training Loss: 0.5967345833778381, Training Accuracy: 0.6715686274509803, Validation Loss: 0.825914204120636, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9320/10000, Training Loss: 0.6162519454956055, Training Accuracy: 0.6887254901960784, Validation Loss: 0.9445016384124756, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9321/10000, Training Loss: 0.5842926502227783, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9563352465629578, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9322/10000, Training Loss: 0.6345025897026062, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7560701966285706, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9323/10000, Training Loss: 0.6112385392189026, Training Accuracy: 0.696078431372549, Validation Loss: 1.0131694078445435, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9324/10000, Training Loss: 0.6371062994003296, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9634110331535339, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9325/10000, Training Loss: 0.6371340155601501, Training Accuracy: 0.6299019607843137, Validation Loss: 1.0560444593429565, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9326/10000, Training Loss: 0.6091335415840149, Training Accuracy: 0.6642156862745098, Validation Loss: 1.068869948387146, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9327/10000, Training Loss: 0.6417555212974548, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6800674796104431, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9328/10000, Training Loss: 0.6352746486663818, Training Accuracy: 0.5857843137254902, Validation Loss: 0.6600958704948425, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9329/10000, Training Loss: 0.6279432773590088, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1842756271362305, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9330/10000, Training Loss: 0.6454209685325623, Training Accuracy: 0.6004901960784313, Validation Loss: 0.932809054851532, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9331/10000, Training Loss: 0.6038563251495361, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7200155258178711, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9332/10000, Training Loss: 0.6160803437232971, Training Accuracy: 0.6985294117647058, Validation Loss: 0.9228167533874512, Validation Accuracy: 0.5\n",
      "Epoch 9333/10000, Training Loss: 0.6126893758773804, Training Accuracy: 0.7058823529411765, Validation Loss: 0.7183434367179871, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9334/10000, Training Loss: 0.6460068821907043, Training Accuracy: 0.625, Validation Loss: 0.7229411602020264, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9335/10000, Training Loss: 0.6553617119789124, Training Accuracy: 0.6911764705882353, Validation Loss: 1.0136253833770752, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9336/10000, Training Loss: 0.6411699652671814, Training Accuracy: 0.625, Validation Loss: 0.7222709059715271, Validation Accuracy: 0.75\n",
      "Epoch 9337/10000, Training Loss: 0.6697912812232971, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6959418654441833, Validation Accuracy: 0.5\n",
      "Epoch 9338/10000, Training Loss: 0.638745903968811, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7022207379341125, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9339/10000, Training Loss: 0.6139070391654968, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7617689967155457, Validation Accuracy: 0.5\n",
      "Epoch 9340/10000, Training Loss: 0.6327683925628662, Training Accuracy: 0.6838235294117647, Validation Loss: 1.0133267641067505, Validation Accuracy: 0.5\n",
      "Epoch 9341/10000, Training Loss: 0.6022598147392273, Training Accuracy: 0.6862745098039216, Validation Loss: 1.4871662855148315, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9342/10000, Training Loss: 0.6287941932678223, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9933732151985168, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9343/10000, Training Loss: 0.6442177891731262, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8239182829856873, Validation Accuracy: 0.5\n",
      "Epoch 9344/10000, Training Loss: 0.6416105628013611, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7113532423973083, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9345/10000, Training Loss: 0.628473162651062, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0617239475250244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9346/10000, Training Loss: 0.6178063154220581, Training Accuracy: 0.6323529411764706, Validation Loss: 0.721318781375885, Validation Accuracy: 0.5\n",
      "Epoch 9347/10000, Training Loss: 0.6435146927833557, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9096307158470154, Validation Accuracy: 0.5\n",
      "Epoch 9348/10000, Training Loss: 0.6194790005683899, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8515264391899109, Validation Accuracy: 0.25\n",
      "Epoch 9349/10000, Training Loss: 0.571037232875824, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7817876935005188, Validation Accuracy: 0.5\n",
      "Epoch 9350/10000, Training Loss: 0.6669611930847168, Training Accuracy: 0.6127450980392157, Validation Loss: 0.673637866973877, Validation Accuracy: 0.5\n",
      "Epoch 9351/10000, Training Loss: 0.7420583963394165, Training Accuracy: 0.6691176470588235, Validation Loss: 1.0969231128692627, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9352/10000, Training Loss: 0.671079695224762, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8286533355712891, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9353/10000, Training Loss: 0.6561062932014465, Training Accuracy: 0.5686274509803921, Validation Loss: 0.9123868942260742, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9354/10000, Training Loss: 0.6443800330162048, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7114906311035156, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9355/10000, Training Loss: 0.6189802289009094, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6531049013137817, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9356/10000, Training Loss: 0.6525871157646179, Training Accuracy: 0.6029411764705882, Validation Loss: 0.730747401714325, Validation Accuracy: 0.5\n",
      "Epoch 9357/10000, Training Loss: 0.6389991641044617, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8611565232276917, Validation Accuracy: 0.5\n",
      "Epoch 9358/10000, Training Loss: 0.6135730147361755, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8763180375099182, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9359/10000, Training Loss: 0.6381626725196838, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8966482281684875, Validation Accuracy: 0.5\n",
      "Epoch 9360/10000, Training Loss: 0.6294434666633606, Training Accuracy: 0.625, Validation Loss: 0.8117618560791016, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9361/10000, Training Loss: 0.6627532243728638, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7135744690895081, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9362/10000, Training Loss: 0.6476558446884155, Training Accuracy: 0.6323529411764706, Validation Loss: 0.711123526096344, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9363/10000, Training Loss: 0.6158017516136169, Training Accuracy: 0.6470588235294118, Validation Loss: 1.1371676921844482, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9364/10000, Training Loss: 0.623894989490509, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7605525851249695, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9365/10000, Training Loss: 0.6567537784576416, Training Accuracy: 0.6176470588235294, Validation Loss: 0.742003858089447, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9366/10000, Training Loss: 0.6414716243743896, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8140225410461426, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9367/10000, Training Loss: 0.6497726440429688, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7233824729919434, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9368/10000, Training Loss: 0.6217519044876099, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7755621075630188, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9369/10000, Training Loss: 0.638819694519043, Training Accuracy: 0.5980392156862745, Validation Loss: 0.8872227668762207, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9370/10000, Training Loss: 0.633386492729187, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7368505597114563, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9371/10000, Training Loss: 0.6366812586784363, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9898198246955872, Validation Accuracy: 0.25\n",
      "Epoch 9372/10000, Training Loss: 0.6396200060844421, Training Accuracy: 0.6470588235294118, Validation Loss: 1.4486502408981323, Validation Accuracy: 0.5\n",
      "Epoch 9373/10000, Training Loss: 0.6445756554603577, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7909749150276184, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9374/10000, Training Loss: 0.6602663397789001, Training Accuracy: 0.6151960784313726, Validation Loss: 1.0440559387207031, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9375/10000, Training Loss: 0.6201062202453613, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7953124046325684, Validation Accuracy: 0.5\n",
      "Epoch 9376/10000, Training Loss: 0.6245486736297607, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9075675010681152, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9377/10000, Training Loss: 0.6423380970954895, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8897745609283447, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9378/10000, Training Loss: 0.6196902990341187, Training Accuracy: 0.678921568627451, Validation Loss: 0.6626740097999573, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9379/10000, Training Loss: 0.6344195604324341, Training Accuracy: 0.625, Validation Loss: 0.9626984000205994, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9380/10000, Training Loss: 0.6454917788505554, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7456474304199219, Validation Accuracy: 0.75\n",
      "Epoch 9381/10000, Training Loss: 0.672410249710083, Training Accuracy: 0.7230392156862745, Validation Loss: 1.0644387006759644, Validation Accuracy: 0.5\n",
      "Epoch 9382/10000, Training Loss: 0.6017314791679382, Training Accuracy: 0.6985294117647058, Validation Loss: 0.8682809472084045, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9383/10000, Training Loss: 0.6178369522094727, Training Accuracy: 0.6666666666666666, Validation Loss: 0.761728048324585, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9384/10000, Training Loss: 0.6353184580802917, Training Accuracy: 0.6495098039215687, Validation Loss: 0.931182324886322, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9385/10000, Training Loss: 0.6267634630203247, Training Accuracy: 0.678921568627451, Validation Loss: 1.094617486000061, Validation Accuracy: 0.25\n",
      "Epoch 9386/10000, Training Loss: 0.6173140406608582, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7432622313499451, Validation Accuracy: 0.5\n",
      "Epoch 9387/10000, Training Loss: 0.6156360507011414, Training Accuracy: 0.7132352941176471, Validation Loss: 0.7870920300483704, Validation Accuracy: 0.5\n",
      "Epoch 9388/10000, Training Loss: 0.6451278328895569, Training Accuracy: 0.6274509803921569, Validation Loss: 0.878227710723877, Validation Accuracy: 0.5\n",
      "Epoch 9389/10000, Training Loss: 0.6141691207885742, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9858450889587402, Validation Accuracy: 0.5\n",
      "Epoch 9390/10000, Training Loss: 0.6431331038475037, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7259540557861328, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9391/10000, Training Loss: 0.6600925922393799, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6761243939399719, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9392/10000, Training Loss: 0.611444890499115, Training Accuracy: 0.6911764705882353, Validation Loss: 1.0085161924362183, Validation Accuracy: 0.5\n",
      "Epoch 9393/10000, Training Loss: 0.6101223230361938, Training Accuracy: 0.6666666666666666, Validation Loss: 0.664823591709137, Validation Accuracy: 0.5\n",
      "Epoch 9394/10000, Training Loss: 0.6334668397903442, Training Accuracy: 0.6764705882352942, Validation Loss: 0.99753338098526, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9395/10000, Training Loss: 0.6474554538726807, Training Accuracy: 0.6764705882352942, Validation Loss: 1.1735605001449585, Validation Accuracy: 0.5\n",
      "Epoch 9396/10000, Training Loss: 0.622087836265564, Training Accuracy: 0.6887254901960784, Validation Loss: 1.0542982816696167, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9397/10000, Training Loss: 0.6551141738891602, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7414211630821228, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9398/10000, Training Loss: 0.6073076128959656, Training Accuracy: 0.6617647058823529, Validation Loss: 0.5334951877593994, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 9399/10000, Training Loss: 0.6120392084121704, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7223374247550964, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9400/10000, Training Loss: 0.6098610758781433, Training Accuracy: 0.678921568627451, Validation Loss: 0.6408688426017761, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9401/10000, Training Loss: 0.655225396156311, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6570335030555725, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9402/10000, Training Loss: 0.5932588577270508, Training Accuracy: 0.6715686274509803, Validation Loss: 0.779120683670044, Validation Accuracy: 0.5\n",
      "Epoch 9403/10000, Training Loss: 0.6412623524665833, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8943179249763489, Validation Accuracy: 0.5\n",
      "Epoch 9404/10000, Training Loss: 0.640535295009613, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8306359648704529, Validation Accuracy: 0.5\n",
      "Epoch 9405/10000, Training Loss: 0.6602101922035217, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6510064005851746, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9406/10000, Training Loss: 0.6244162321090698, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7617462277412415, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9407/10000, Training Loss: 0.6532342433929443, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9346023201942444, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9408/10000, Training Loss: 0.6979781985282898, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8007909655570984, Validation Accuracy: 0.5\n",
      "Epoch 9409/10000, Training Loss: 0.6241315007209778, Training Accuracy: 0.625, Validation Loss: 0.9811143279075623, Validation Accuracy: 0.5\n",
      "Epoch 9410/10000, Training Loss: 0.6436283588409424, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9386207461357117, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9411/10000, Training Loss: 0.656158447265625, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7240977883338928, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9412/10000, Training Loss: 0.6397400498390198, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7523362636566162, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9413/10000, Training Loss: 0.6312026381492615, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6993829607963562, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9414/10000, Training Loss: 0.6332170367240906, Training Accuracy: 0.6568627450980392, Validation Loss: 0.755054771900177, Validation Accuracy: 0.5\n",
      "Epoch 9415/10000, Training Loss: 0.66306072473526, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7260289788246155, Validation Accuracy: 0.75\n",
      "Epoch 9416/10000, Training Loss: 0.6438682675361633, Training Accuracy: 0.5808823529411765, Validation Loss: 0.8700747489929199, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9417/10000, Training Loss: 0.6015790700912476, Training Accuracy: 0.6887254901960784, Validation Loss: 0.6693637371063232, Validation Accuracy: 0.5\n",
      "Epoch 9418/10000, Training Loss: 0.6134790778160095, Training Accuracy: 0.6740196078431373, Validation Loss: 0.834445059299469, Validation Accuracy: 0.5\n",
      "Epoch 9419/10000, Training Loss: 0.6579568982124329, Training Accuracy: 0.6176470588235294, Validation Loss: 1.0614885091781616, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9420/10000, Training Loss: 0.6720111966133118, Training Accuracy: 0.5980392156862745, Validation Loss: 1.2749783992767334, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9421/10000, Training Loss: 0.653445839881897, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7770516276359558, Validation Accuracy: 0.5\n",
      "Epoch 9422/10000, Training Loss: 0.6548892855644226, Training Accuracy: 0.6053921568627451, Validation Loss: 0.855565071105957, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9423/10000, Training Loss: 0.6105341911315918, Training Accuracy: 0.6911764705882353, Validation Loss: 0.7728684544563293, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9424/10000, Training Loss: 0.6322378516197205, Training Accuracy: 0.6642156862745098, Validation Loss: 1.5599555969238281, Validation Accuracy: 0.5\n",
      "Epoch 9425/10000, Training Loss: 0.6624051332473755, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8912658095359802, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9426/10000, Training Loss: 0.6494419574737549, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7459140419960022, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9427/10000, Training Loss: 0.6288470029830933, Training Accuracy: 0.625, Validation Loss: 0.6324189305305481, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9428/10000, Training Loss: 0.6363423466682434, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0379271507263184, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9429/10000, Training Loss: 0.6306010484695435, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7902879118919373, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9430/10000, Training Loss: 0.6229662299156189, Training Accuracy: 0.6887254901960784, Validation Loss: 0.649496853351593, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9431/10000, Training Loss: 0.6010965704917908, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6003356575965881, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9432/10000, Training Loss: 0.6321223378181458, Training Accuracy: 0.7279411764705882, Validation Loss: 0.754103422164917, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9433/10000, Training Loss: 0.6416350603103638, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6752066016197205, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9434/10000, Training Loss: 0.6718904376029968, Training Accuracy: 0.5955882352941176, Validation Loss: 0.6794831156730652, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9435/10000, Training Loss: 0.6294110417366028, Training Accuracy: 0.7083333333333334, Validation Loss: 0.8423416018486023, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9436/10000, Training Loss: 0.6265996098518372, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8083958029747009, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9437/10000, Training Loss: 0.66995769739151, Training Accuracy: 0.6200980392156863, Validation Loss: 1.0500837564468384, Validation Accuracy: 0.5\n",
      "Epoch 9438/10000, Training Loss: 0.6163467764854431, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9527475833892822, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9439/10000, Training Loss: 0.5882251858711243, Training Accuracy: 0.678921568627451, Validation Loss: 0.8916911482810974, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9440/10000, Training Loss: 0.6163105368614197, Training Accuracy: 0.6838235294117647, Validation Loss: 1.272786259651184, Validation Accuracy: 0.5\n",
      "Epoch 9441/10000, Training Loss: 0.6193081736564636, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8202724456787109, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9442/10000, Training Loss: 0.6271466016769409, Training Accuracy: 0.6397058823529411, Validation Loss: 1.1704577207565308, Validation Accuracy: 0.25\n",
      "Epoch 9443/10000, Training Loss: 0.6699808239936829, Training Accuracy: 0.5735294117647058, Validation Loss: 1.001710295677185, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9444/10000, Training Loss: 0.6282802820205688, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6587188243865967, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9445/10000, Training Loss: 0.6280552744865417, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7283309102058411, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9446/10000, Training Loss: 0.6403389573097229, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8277352452278137, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9447/10000, Training Loss: 0.625608503818512, Training Accuracy: 0.6715686274509803, Validation Loss: 0.9853044152259827, Validation Accuracy: 0.25\n",
      "Epoch 9448/10000, Training Loss: 0.6638945937156677, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8332622647285461, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9449/10000, Training Loss: 0.6547421216964722, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9691590666770935, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9450/10000, Training Loss: 0.6312441825866699, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6676986813545227, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9451/10000, Training Loss: 0.6706297397613525, Training Accuracy: 0.5759803921568627, Validation Loss: 0.816926896572113, Validation Accuracy: 0.25\n",
      "Epoch 9452/10000, Training Loss: 0.6146842837333679, Training Accuracy: 0.6887254901960784, Validation Loss: 0.8575167059898376, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9453/10000, Training Loss: 0.6372985243797302, Training Accuracy: 0.678921568627451, Validation Loss: 0.6733974814414978, Validation Accuracy: 0.5\n",
      "Epoch 9454/10000, Training Loss: 0.6116683483123779, Training Accuracy: 0.6911764705882353, Validation Loss: 0.7338277697563171, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9455/10000, Training Loss: 0.6160128116607666, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7665472030639648, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9456/10000, Training Loss: 0.5669875741004944, Training Accuracy: 0.7181372549019608, Validation Loss: 1.2149206399917603, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9457/10000, Training Loss: 0.6772247552871704, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9340794086456299, Validation Accuracy: 0.25\n",
      "Epoch 9458/10000, Training Loss: 0.7440686821937561, Training Accuracy: 0.6691176470588235, Validation Loss: 1.3830574750900269, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9459/10000, Training Loss: 0.6170502305030823, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6823157668113708, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9460/10000, Training Loss: 0.6499801874160767, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6868783831596375, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9461/10000, Training Loss: 0.647512674331665, Training Accuracy: 0.6544117647058824, Validation Loss: 1.1979738473892212, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9462/10000, Training Loss: 0.6361794471740723, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9875834584236145, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9463/10000, Training Loss: 0.6229417324066162, Training Accuracy: 0.6544117647058824, Validation Loss: 0.726064920425415, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9464/10000, Training Loss: 0.6509695649147034, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8250224590301514, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9465/10000, Training Loss: 0.6301991939544678, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6244542002677917, Validation Accuracy: 0.75\n",
      "Epoch 9466/10000, Training Loss: 0.5691690444946289, Training Accuracy: 0.7230392156862745, Validation Loss: 0.7363195419311523, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9467/10000, Training Loss: 0.6401822566986084, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6728296875953674, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9468/10000, Training Loss: 0.6685493588447571, Training Accuracy: 0.6127450980392157, Validation Loss: 0.74528568983078, Validation Accuracy: 0.25\n",
      "Epoch 9469/10000, Training Loss: 0.6091103553771973, Training Accuracy: 0.7205882352941176, Validation Loss: 0.5794593691825867, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9470/10000, Training Loss: 0.6547693014144897, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6830120086669922, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9471/10000, Training Loss: 0.6255730390548706, Training Accuracy: 0.6764705882352942, Validation Loss: 0.9825417399406433, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9472/10000, Training Loss: 0.653944194316864, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9554681181907654, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9473/10000, Training Loss: 0.662607729434967, Training Accuracy: 0.5759803921568627, Validation Loss: 0.8229436278343201, Validation Accuracy: 0.5\n",
      "Epoch 9474/10000, Training Loss: 0.6629223823547363, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7533761858940125, Validation Accuracy: 0.5\n",
      "Epoch 9475/10000, Training Loss: 0.6395193934440613, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6521999835968018, Validation Accuracy: 0.5\n",
      "Epoch 9476/10000, Training Loss: 0.6336470246315002, Training Accuracy: 0.6593137254901961, Validation Loss: 1.0679353475570679, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9477/10000, Training Loss: 0.6324108242988586, Training Accuracy: 0.6642156862745098, Validation Loss: 1.170235276222229, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9478/10000, Training Loss: 0.6080415844917297, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7819117903709412, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9479/10000, Training Loss: 0.6398043036460876, Training Accuracy: 0.5882352941176471, Validation Loss: 0.8391789793968201, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9480/10000, Training Loss: 0.6474369764328003, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0662895441055298, Validation Accuracy: 0.25\n",
      "Epoch 9481/10000, Training Loss: 0.6489444971084595, Training Accuracy: 0.6691176470588235, Validation Loss: 1.1972459554672241, Validation Accuracy: 0.25\n",
      "Epoch 9482/10000, Training Loss: 0.6465204954147339, Training Accuracy: 0.6397058823529411, Validation Loss: 1.0892635583877563, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9483/10000, Training Loss: 0.6560263633728027, Training Accuracy: 0.5686274509803921, Validation Loss: 0.7228896617889404, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9484/10000, Training Loss: 0.638084888458252, Training Accuracy: 0.5980392156862745, Validation Loss: 0.68295818567276, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9485/10000, Training Loss: 0.6233205199241638, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7414360642433167, Validation Accuracy: 0.75\n",
      "Epoch 9486/10000, Training Loss: 0.6148250699043274, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7390940189361572, Validation Accuracy: 0.5\n",
      "Epoch 9487/10000, Training Loss: 0.5734919905662537, Training Accuracy: 0.696078431372549, Validation Loss: 1.1493440866470337, Validation Accuracy: 0.5\n",
      "Epoch 9488/10000, Training Loss: 0.6525017023086548, Training Accuracy: 0.6470588235294118, Validation Loss: 1.0594207048416138, Validation Accuracy: 0.25\n",
      "Epoch 9489/10000, Training Loss: 0.6137601733207703, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6456875801086426, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9490/10000, Training Loss: 0.6803815364837646, Training Accuracy: 0.5686274509803921, Validation Loss: 0.5917307734489441, Validation Accuracy: 0.75\n",
      "Epoch 9491/10000, Training Loss: 0.6052365899085999, Training Accuracy: 0.6642156862745098, Validation Loss: 0.917138397693634, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9492/10000, Training Loss: 0.6504656672477722, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7473809123039246, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9493/10000, Training Loss: 0.6116964221000671, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6935344338417053, Validation Accuracy: 0.5\n",
      "Epoch 9494/10000, Training Loss: 0.5880289077758789, Training Accuracy: 0.6813725490196079, Validation Loss: 1.114579677581787, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9495/10000, Training Loss: 0.6218163967132568, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9875919222831726, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9496/10000, Training Loss: 0.6254708766937256, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7942416071891785, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9497/10000, Training Loss: 0.6692272424697876, Training Accuracy: 0.5808823529411765, Validation Loss: 0.737398624420166, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9498/10000, Training Loss: 0.6080917716026306, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7929739356040955, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9499/10000, Training Loss: 0.6202616095542908, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9094200730323792, Validation Accuracy: 0.5\n",
      "Epoch 9500/10000, Training Loss: 0.6407860517501831, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7793057560920715, Validation Accuracy: 0.5\n",
      "Epoch 9501/10000, Training Loss: 0.6094845533370972, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0831098556518555, Validation Accuracy: 0.25\n",
      "Epoch 9502/10000, Training Loss: 0.6613581776618958, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7976491451263428, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9503/10000, Training Loss: 0.6779948472976685, Training Accuracy: 0.6029411764705882, Validation Loss: 0.7476999163627625, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9504/10000, Training Loss: 0.601679801940918, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8102639317512512, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9505/10000, Training Loss: 0.6873008608818054, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9168474078178406, Validation Accuracy: 0.5\n",
      "Epoch 9506/10000, Training Loss: 0.6560284495353699, Training Accuracy: 0.6617647058823529, Validation Loss: 0.725591242313385, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9507/10000, Training Loss: 0.6669970750808716, Training Accuracy: 0.5931372549019608, Validation Loss: 0.7391757369041443, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9508/10000, Training Loss: 0.6513773798942566, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6840519905090332, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9509/10000, Training Loss: 0.66707444190979, Training Accuracy: 0.6568627450980392, Validation Loss: 1.1975818872451782, Validation Accuracy: 0.25\n",
      "Epoch 9510/10000, Training Loss: 0.627014696598053, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8160240054130554, Validation Accuracy: 0.5\n",
      "Epoch 9511/10000, Training Loss: 0.6235133409500122, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8100202679634094, Validation Accuracy: 0.5\n",
      "Epoch 9512/10000, Training Loss: 0.6469772458076477, Training Accuracy: 0.6176470588235294, Validation Loss: 0.772064745426178, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9513/10000, Training Loss: 0.6377102732658386, Training Accuracy: 0.6102941176470589, Validation Loss: 0.9369710087776184, Validation Accuracy: 0.5\n",
      "Epoch 9514/10000, Training Loss: 0.6288264393806458, Training Accuracy: 0.6470588235294118, Validation Loss: 1.052554726600647, Validation Accuracy: 0.25\n",
      "Epoch 9515/10000, Training Loss: 0.6548698544502258, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8986232876777649, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9516/10000, Training Loss: 0.5700753331184387, Training Accuracy: 0.7205882352941176, Validation Loss: 0.8178746104240417, Validation Accuracy: 0.5\n",
      "Epoch 9517/10000, Training Loss: 0.6078471541404724, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8920659422874451, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9518/10000, Training Loss: 0.637761652469635, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8388871550559998, Validation Accuracy: 0.5\n",
      "Epoch 9519/10000, Training Loss: 0.6555978655815125, Training Accuracy: 0.6985294117647058, Validation Loss: 0.6484268307685852, Validation Accuracy: 0.75\n",
      "Epoch 9520/10000, Training Loss: 0.6136698722839355, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7638174891471863, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9521/10000, Training Loss: 0.6434023380279541, Training Accuracy: 0.6568627450980392, Validation Loss: 0.67255038022995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9522/10000, Training Loss: 0.6526627540588379, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9245688319206238, Validation Accuracy: 0.25\n",
      "Epoch 9523/10000, Training Loss: 0.6391111612319946, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8233515620231628, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9524/10000, Training Loss: 0.6395143866539001, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7122021317481995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9525/10000, Training Loss: 0.6306578516960144, Training Accuracy: 0.6911764705882353, Validation Loss: 1.0092036724090576, Validation Accuracy: 0.5\n",
      "Epoch 9526/10000, Training Loss: 0.6254952549934387, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6289340853691101, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9527/10000, Training Loss: 0.6461480855941772, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6878802180290222, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9528/10000, Training Loss: 0.674201488494873, Training Accuracy: 0.6470588235294118, Validation Loss: 0.5988227128982544, Validation Accuracy: 0.75\n",
      "Epoch 9529/10000, Training Loss: 0.6393975019454956, Training Accuracy: 0.625, Validation Loss: 0.6836877465248108, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9530/10000, Training Loss: 0.6118842959403992, Training Accuracy: 0.6740196078431373, Validation Loss: 0.6783434748649597, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9531/10000, Training Loss: 0.672355592250824, Training Accuracy: 0.5563725490196079, Validation Loss: 0.9912539124488831, Validation Accuracy: 0.5\n",
      "Epoch 9532/10000, Training Loss: 0.6139673590660095, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8282954692840576, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9533/10000, Training Loss: 0.6081295609474182, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7321524620056152, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9534/10000, Training Loss: 0.6293945908546448, Training Accuracy: 0.6666666666666666, Validation Loss: 0.9516823887825012, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9535/10000, Training Loss: 0.6696814894676208, Training Accuracy: 0.571078431372549, Validation Loss: 0.7160583138465881, Validation Accuracy: 0.25\n",
      "Epoch 9536/10000, Training Loss: 0.5863572359085083, Training Accuracy: 0.6985294117647058, Validation Loss: 1.0992811918258667, Validation Accuracy: 0.5\n",
      "Epoch 9537/10000, Training Loss: 0.6422752141952515, Training Accuracy: 0.6666666666666666, Validation Loss: 0.757585346698761, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9538/10000, Training Loss: 0.6207426190376282, Training Accuracy: 0.6666666666666666, Validation Loss: 1.0748604536056519, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9539/10000, Training Loss: 0.6630792021751404, Training Accuracy: 0.5686274509803921, Validation Loss: 0.8868779540061951, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9540/10000, Training Loss: 0.6452401280403137, Training Accuracy: 0.6348039215686274, Validation Loss: 0.5989620685577393, Validation Accuracy: 0.75\n",
      "Epoch 9541/10000, Training Loss: 0.6454281806945801, Training Accuracy: 0.6519607843137255, Validation Loss: 0.6830071806907654, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9542/10000, Training Loss: 0.6280484795570374, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9030411839485168, Validation Accuracy: 0.5\n",
      "Epoch 9543/10000, Training Loss: 0.62006676197052, Training Accuracy: 0.6470588235294118, Validation Loss: 0.5594539046287537, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 9544/10000, Training Loss: 0.650770902633667, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6024639010429382, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9545/10000, Training Loss: 0.5994289517402649, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8652682900428772, Validation Accuracy: 0.5\n",
      "Epoch 9546/10000, Training Loss: 0.6148501634597778, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7714219093322754, Validation Accuracy: 0.5\n",
      "Epoch 9547/10000, Training Loss: 0.6179847121238708, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7036598324775696, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9548/10000, Training Loss: 0.653023362159729, Training Accuracy: 0.6127450980392157, Validation Loss: 1.0103340148925781, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9549/10000, Training Loss: 0.574564516544342, Training Accuracy: 0.7254901960784313, Validation Loss: 0.8288609385490417, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9550/10000, Training Loss: 0.6177414655685425, Training Accuracy: 0.6519607843137255, Validation Loss: 1.1156166791915894, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9551/10000, Training Loss: 0.6195705533027649, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1267815828323364, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9552/10000, Training Loss: 0.6551499962806702, Training Accuracy: 0.6666666666666666, Validation Loss: 0.660447895526886, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9553/10000, Training Loss: 0.6390488743782043, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8039401173591614, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9554/10000, Training Loss: 0.6687606573104858, Training Accuracy: 0.6323529411764706, Validation Loss: 0.9400663375854492, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9555/10000, Training Loss: 0.6338520646095276, Training Accuracy: 0.678921568627451, Validation Loss: 1.0777207612991333, Validation Accuracy: 0.5\n",
      "Epoch 9556/10000, Training Loss: 0.6136385798454285, Training Accuracy: 0.6593137254901961, Validation Loss: 0.89432293176651, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9557/10000, Training Loss: 0.5938344597816467, Training Accuracy: 0.7279411764705882, Validation Loss: 0.7093618512153625, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9558/10000, Training Loss: 0.6130033135414124, Training Accuracy: 0.6838235294117647, Validation Loss: 1.0166503190994263, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9559/10000, Training Loss: 0.6308120489120483, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8074917197227478, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9560/10000, Training Loss: 0.639151930809021, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0224276781082153, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9561/10000, Training Loss: 0.6437114477157593, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7094882130622864, Validation Accuracy: 0.5\n",
      "Epoch 9562/10000, Training Loss: 0.6636959314346313, Training Accuracy: 0.5857843137254902, Validation Loss: 0.8012840151786804, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9563/10000, Training Loss: 0.6058364510536194, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7336437106132507, Validation Accuracy: 0.5\n",
      "Epoch 9564/10000, Training Loss: 0.6497790217399597, Training Accuracy: 0.6200980392156863, Validation Loss: 0.8406040072441101, Validation Accuracy: 0.5\n",
      "Epoch 9565/10000, Training Loss: 0.644005298614502, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7655609250068665, Validation Accuracy: 0.5\n",
      "Epoch 9566/10000, Training Loss: 0.6594257950782776, Training Accuracy: 0.6053921568627451, Validation Loss: 0.9016602039337158, Validation Accuracy: 0.5\n",
      "Epoch 9567/10000, Training Loss: 0.6443909406661987, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8180277943611145, Validation Accuracy: 0.5\n",
      "Epoch 9568/10000, Training Loss: 0.664781928062439, Training Accuracy: 0.696078431372549, Validation Loss: 0.5888045430183411, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9569/10000, Training Loss: 0.616430401802063, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9001420140266418, Validation Accuracy: 0.5\n",
      "Epoch 9570/10000, Training Loss: 0.6763255596160889, Training Accuracy: 0.5980392156862745, Validation Loss: 0.7485756278038025, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9571/10000, Training Loss: 0.6701744794845581, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7798555493354797, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9572/10000, Training Loss: 0.6277990937232971, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7127706408500671, Validation Accuracy: 0.75\n",
      "Epoch 9573/10000, Training Loss: 0.6274684071540833, Training Accuracy: 0.6544117647058824, Validation Loss: 0.9849668145179749, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9574/10000, Training Loss: 0.6244444251060486, Training Accuracy: 0.6004901960784313, Validation Loss: 1.0419460535049438, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9575/10000, Training Loss: 0.6532959938049316, Training Accuracy: 0.6053921568627451, Validation Loss: 0.7828153967857361, Validation Accuracy: 0.25\n",
      "Epoch 9576/10000, Training Loss: 0.6298511624336243, Training Accuracy: 0.6544117647058824, Validation Loss: 0.8144347071647644, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9577/10000, Training Loss: 0.5978890657424927, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9217851758003235, Validation Accuracy: 0.5\n",
      "Epoch 9578/10000, Training Loss: 0.6441947221755981, Training Accuracy: 0.6421568627450981, Validation Loss: 0.5923852324485779, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9579/10000, Training Loss: 0.6358622312545776, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7523114085197449, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9580/10000, Training Loss: 0.6629724502563477, Training Accuracy: 0.5784313725490197, Validation Loss: 0.798856794834137, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9581/10000, Training Loss: 0.6279909014701843, Training Accuracy: 0.6911764705882353, Validation Loss: 0.8254191875457764, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9582/10000, Training Loss: 0.6237236857414246, Training Accuracy: 0.6544117647058824, Validation Loss: 1.4677762985229492, Validation Accuracy: 0.25\n",
      "Epoch 9583/10000, Training Loss: 0.6370174884796143, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7788793444633484, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9584/10000, Training Loss: 0.6100305914878845, Training Accuracy: 0.6666666666666666, Validation Loss: 0.6479035019874573, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9585/10000, Training Loss: 0.6836914420127869, Training Accuracy: 0.6544117647058824, Validation Loss: 1.0156346559524536, Validation Accuracy: 0.5\n",
      "Epoch 9586/10000, Training Loss: 0.6449177861213684, Training Accuracy: 0.6495098039215687, Validation Loss: 1.2156749963760376, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9587/10000, Training Loss: 0.6395953893661499, Training Accuracy: 0.6151960784313726, Validation Loss: 0.9498805999755859, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9588/10000, Training Loss: 0.6618379950523376, Training Accuracy: 0.6127450980392157, Validation Loss: 0.6455603241920471, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9589/10000, Training Loss: 0.6540122032165527, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9305152893066406, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9590/10000, Training Loss: 0.6108369827270508, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7514154314994812, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9591/10000, Training Loss: 0.6360980868339539, Training Accuracy: 0.6176470588235294, Validation Loss: 0.8808878064155579, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9592/10000, Training Loss: 0.6477487087249756, Training Accuracy: 0.6495098039215687, Validation Loss: 0.6791277527809143, Validation Accuracy: 0.5\n",
      "Epoch 9593/10000, Training Loss: 0.6306094527244568, Training Accuracy: 0.678921568627451, Validation Loss: 0.8248557448387146, Validation Accuracy: 0.25\n",
      "Epoch 9594/10000, Training Loss: 0.633326530456543, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8610027432441711, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9595/10000, Training Loss: 0.6130406856536865, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7100148797035217, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 9596/10000, Training Loss: 0.6253448724746704, Training Accuracy: 0.625, Validation Loss: 0.8288456797599792, Validation Accuracy: 0.5\n",
      "Epoch 9597/10000, Training Loss: 0.6307536363601685, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7819201946258545, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9598/10000, Training Loss: 0.5930637717247009, Training Accuracy: 0.6838235294117647, Validation Loss: 1.4235690832138062, Validation Accuracy: 0.5\n",
      "Epoch 9599/10000, Training Loss: 0.627176821231842, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8079609870910645, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9600/10000, Training Loss: 0.6812905073165894, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8826467990875244, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9601/10000, Training Loss: 0.6128014326095581, Training Accuracy: 0.6740196078431373, Validation Loss: 0.6517127752304077, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9602/10000, Training Loss: 0.6204833388328552, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8165333271026611, Validation Accuracy: 0.5\n",
      "Epoch 9603/10000, Training Loss: 0.6327645778656006, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7473515868186951, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9604/10000, Training Loss: 0.6481271386146545, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7513688206672668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9605/10000, Training Loss: 0.6217157244682312, Training Accuracy: 0.6740196078431373, Validation Loss: 0.9025186896324158, Validation Accuracy: 0.5\n",
      "Epoch 9606/10000, Training Loss: 0.609552800655365, Training Accuracy: 0.7205882352941176, Validation Loss: 0.8501957058906555, Validation Accuracy: 0.5\n",
      "Epoch 9607/10000, Training Loss: 0.6267105340957642, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7868863940238953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9608/10000, Training Loss: 0.6050082445144653, Training Accuracy: 0.6642156862745098, Validation Loss: 1.0643869638442993, Validation Accuracy: 0.5\n",
      "Epoch 9609/10000, Training Loss: 0.5814939141273499, Training Accuracy: 0.6519607843137255, Validation Loss: 0.8167893290519714, Validation Accuracy: 0.5\n",
      "Epoch 9610/10000, Training Loss: 0.5963873267173767, Training Accuracy: 0.678921568627451, Validation Loss: 1.0444265604019165, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9611/10000, Training Loss: 0.6741486191749573, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7289669513702393, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9612/10000, Training Loss: 0.6351600289344788, Training Accuracy: 0.696078431372549, Validation Loss: 0.7496662735939026, Validation Accuracy: 0.5\n",
      "Epoch 9613/10000, Training Loss: 0.6275007724761963, Training Accuracy: 0.678921568627451, Validation Loss: 0.9410014152526855, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9614/10000, Training Loss: 0.632965624332428, Training Accuracy: 0.6372549019607843, Validation Loss: 0.725644052028656, Validation Accuracy: 0.5\n",
      "Epoch 9615/10000, Training Loss: 0.6652095317840576, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8365132212638855, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9616/10000, Training Loss: 0.6136438250541687, Training Accuracy: 0.6764705882352942, Validation Loss: 0.6598248481750488, Validation Accuracy: 0.5\n",
      "Epoch 9617/10000, Training Loss: 0.6152740716934204, Training Accuracy: 0.678921568627451, Validation Loss: 1.0124260187149048, Validation Accuracy: 0.25\n",
      "Epoch 9618/10000, Training Loss: 0.6399263739585876, Training Accuracy: 0.6323529411764706, Validation Loss: 1.0110951662063599, Validation Accuracy: 0.25\n",
      "Epoch 9619/10000, Training Loss: 0.633100152015686, Training Accuracy: 0.6446078431372549, Validation Loss: 0.8143987059593201, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9620/10000, Training Loss: 0.6622886061668396, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6684032082557678, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9621/10000, Training Loss: 0.6406481266021729, Training Accuracy: 0.6225490196078431, Validation Loss: 0.6977031826972961, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9622/10000, Training Loss: 0.6304597854614258, Training Accuracy: 0.6519607843137255, Validation Loss: 0.9948111176490784, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9623/10000, Training Loss: 0.5884050726890564, Training Accuracy: 0.7058823529411765, Validation Loss: 0.7724571824073792, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9624/10000, Training Loss: 0.6256012916564941, Training Accuracy: 0.6323529411764706, Validation Loss: 0.6201773285865784, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9625/10000, Training Loss: 0.6636316180229187, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6983776092529297, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9626/10000, Training Loss: 0.6819416284561157, Training Accuracy: 0.5882352941176471, Validation Loss: 1.030853033065796, Validation Accuracy: 0.25\n",
      "Epoch 9627/10000, Training Loss: 0.6267099380493164, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7477765083312988, Validation Accuracy: 0.5\n",
      "Epoch 9628/10000, Training Loss: 0.6400408148765564, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7162275910377502, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9629/10000, Training Loss: 0.6436837911605835, Training Accuracy: 0.5955882352941176, Validation Loss: 1.0554245710372925, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9630/10000, Training Loss: 0.6146144866943359, Training Accuracy: 0.6519607843137255, Validation Loss: 0.7562205195426941, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9631/10000, Training Loss: 0.6183741688728333, Training Accuracy: 0.6911764705882353, Validation Loss: 0.6960084438323975, Validation Accuracy: 0.75\n",
      "Epoch 9632/10000, Training Loss: 0.6272360682487488, Training Accuracy: 0.6274509803921569, Validation Loss: 0.798217236995697, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9633/10000, Training Loss: 0.6449030041694641, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8023500442504883, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9634/10000, Training Loss: 0.5682811737060547, Training Accuracy: 0.6936274509803921, Validation Loss: 0.8974998593330383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9635/10000, Training Loss: 0.5811543464660645, Training Accuracy: 0.7303921568627451, Validation Loss: 0.8187442421913147, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9636/10000, Training Loss: 0.679902195930481, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7009981274604797, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9637/10000, Training Loss: 0.640842080116272, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7628331184387207, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9638/10000, Training Loss: 0.6059194207191467, Training Accuracy: 0.6911764705882353, Validation Loss: 0.9743962287902832, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9639/10000, Training Loss: 0.6151633262634277, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9267163872718811, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9640/10000, Training Loss: 0.648353636264801, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7024214863777161, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9641/10000, Training Loss: 0.6359802484512329, Training Accuracy: 0.6421568627450981, Validation Loss: 0.918839693069458, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9642/10000, Training Loss: 0.6679298281669617, Training Accuracy: 0.6421568627450981, Validation Loss: 0.9302381873130798, Validation Accuracy: 0.5\n",
      "Epoch 9643/10000, Training Loss: 0.5964470505714417, Training Accuracy: 0.7058823529411765, Validation Loss: 0.8491179943084717, Validation Accuracy: 0.75\n",
      "Epoch 9644/10000, Training Loss: 0.6136957406997681, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7244153618812561, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9645/10000, Training Loss: 0.6157757043838501, Training Accuracy: 0.6715686274509803, Validation Loss: 1.2001802921295166, Validation Accuracy: 0.5\n",
      "Epoch 9646/10000, Training Loss: 0.6685632467269897, Training Accuracy: 0.6200980392156863, Validation Loss: 0.740489661693573, Validation Accuracy: 0.5\n",
      "Epoch 9647/10000, Training Loss: 0.6302135586738586, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7552974820137024, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9648/10000, Training Loss: 0.6483315825462341, Training Accuracy: 0.5857843137254902, Validation Loss: 0.7358357310295105, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9649/10000, Training Loss: 0.620558500289917, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7474163174629211, Validation Accuracy: 0.5\n",
      "Epoch 9650/10000, Training Loss: 0.6792015433311462, Training Accuracy: 0.6078431372549019, Validation Loss: 0.8276030421257019, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9651/10000, Training Loss: 0.6501270532608032, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7148410677909851, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9652/10000, Training Loss: 0.6390202641487122, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7296535968780518, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9653/10000, Training Loss: 0.6075826287269592, Training Accuracy: 0.6666666666666666, Validation Loss: 0.7903966903686523, Validation Accuracy: 0.5\n",
      "Epoch 9654/10000, Training Loss: 0.688559353351593, Training Accuracy: 0.6348039215686274, Validation Loss: 0.9748594164848328, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9655/10000, Training Loss: 0.6607826352119446, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7498796582221985, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9656/10000, Training Loss: 0.6174302101135254, Training Accuracy: 0.6274509803921569, Validation Loss: 0.8496167659759521, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9657/10000, Training Loss: 0.6266575455665588, Training Accuracy: 0.6813725490196079, Validation Loss: 0.8748132586479187, Validation Accuracy: 0.5\n",
      "Epoch 9658/10000, Training Loss: 0.6075213551521301, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9351286888122559, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9659/10000, Training Loss: 0.6212220788002014, Training Accuracy: 0.6519607843137255, Validation Loss: 0.798591136932373, Validation Accuracy: 0.5\n",
      "Epoch 9660/10000, Training Loss: 0.6047044396400452, Training Accuracy: 0.6911764705882353, Validation Loss: 1.0912752151489258, Validation Accuracy: 0.25\n",
      "Epoch 9661/10000, Training Loss: 0.6570437550544739, Training Accuracy: 0.5833333333333334, Validation Loss: 0.7294653058052063, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9662/10000, Training Loss: 0.64700847864151, Training Accuracy: 0.6127450980392157, Validation Loss: 1.073928713798523, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9663/10000, Training Loss: 0.644195556640625, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7893611788749695, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9664/10000, Training Loss: 0.6370731592178345, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7565566897392273, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9665/10000, Training Loss: 0.6106957197189331, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0939055681228638, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9666/10000, Training Loss: 0.6469594240188599, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1419748067855835, Validation Accuracy: 0.25\n",
      "Epoch 9667/10000, Training Loss: 0.6251681447029114, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8153675198554993, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9668/10000, Training Loss: 0.6172696948051453, Training Accuracy: 0.696078431372549, Validation Loss: 0.7795788645744324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9669/10000, Training Loss: 0.5887380242347717, Training Accuracy: 0.7230392156862745, Validation Loss: 0.6897503733634949, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9670/10000, Training Loss: 0.6426209211349487, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8586518168449402, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9671/10000, Training Loss: 0.6496098637580872, Training Accuracy: 0.6740196078431373, Validation Loss: 0.9983261227607727, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9672/10000, Training Loss: 0.6363587379455566, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8285893797874451, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9673/10000, Training Loss: 0.6497803330421448, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7283596396446228, Validation Accuracy: 0.5\n",
      "Epoch 9674/10000, Training Loss: 0.6342618465423584, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9150061011314392, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9675/10000, Training Loss: 0.6191146969795227, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9674872756004333, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9676/10000, Training Loss: 0.6175378561019897, Training Accuracy: 0.6495098039215687, Validation Loss: 1.016503930091858, Validation Accuracy: 0.5\n",
      "Epoch 9677/10000, Training Loss: 0.6283977031707764, Training Accuracy: 0.6617647058823529, Validation Loss: 1.7101918458938599, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9678/10000, Training Loss: 0.6178503036499023, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9270033240318298, Validation Accuracy: 0.25\n",
      "Epoch 9679/10000, Training Loss: 0.6503058075904846, Training Accuracy: 0.5759803921568627, Validation Loss: 0.7745658755302429, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9680/10000, Training Loss: 0.6088177561759949, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7394940853118896, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9681/10000, Training Loss: 0.6145338416099548, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0201984643936157, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9682/10000, Training Loss: 0.6512163877487183, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7840675711631775, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9683/10000, Training Loss: 0.6504765748977661, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8671104907989502, Validation Accuracy: 0.5\n",
      "Epoch 9684/10000, Training Loss: 0.607732892036438, Training Accuracy: 0.6225490196078431, Validation Loss: 0.8488898277282715, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9685/10000, Training Loss: 0.6598957180976868, Training Accuracy: 0.6593137254901961, Validation Loss: 0.7105290293693542, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9686/10000, Training Loss: 0.6279628872871399, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6635836958885193, Validation Accuracy: 0.5\n",
      "Epoch 9687/10000, Training Loss: 0.5846191048622131, Training Accuracy: 0.6862745098039216, Validation Loss: 0.958728551864624, Validation Accuracy: 0.5\n",
      "Epoch 9688/10000, Training Loss: 0.613721489906311, Training Accuracy: 0.7034313725490197, Validation Loss: 0.7372645735740662, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9689/10000, Training Loss: 0.6290542483329773, Training Accuracy: 0.6299019607843137, Validation Loss: 0.8058857321739197, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9690/10000, Training Loss: 0.6674180626869202, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9447767734527588, Validation Accuracy: 0.5\n",
      "Epoch 9691/10000, Training Loss: 0.6296328902244568, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8774654865264893, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9692/10000, Training Loss: 0.618034303188324, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9176141619682312, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9693/10000, Training Loss: 0.687609076499939, Training Accuracy: 0.5906862745098039, Validation Loss: 0.58237224817276, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 9694/10000, Training Loss: 0.615778386592865, Training Accuracy: 0.6568627450980392, Validation Loss: 1.1438490152359009, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9695/10000, Training Loss: 0.6189486384391785, Training Accuracy: 0.678921568627451, Validation Loss: 1.101246953010559, Validation Accuracy: 0.25\n",
      "Epoch 9696/10000, Training Loss: 0.6411610245704651, Training Accuracy: 0.625, Validation Loss: 0.986152708530426, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9697/10000, Training Loss: 0.6517007946968079, Training Accuracy: 0.6200980392156863, Validation Loss: 0.9249624609947205, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9698/10000, Training Loss: 0.600316047668457, Training Accuracy: 0.6813725490196079, Validation Loss: 1.0106257200241089, Validation Accuracy: 0.5\n",
      "Epoch 9699/10000, Training Loss: 0.6679699420928955, Training Accuracy: 0.5980392156862745, Validation Loss: 0.9004226326942444, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9700/10000, Training Loss: 0.6432735323905945, Training Accuracy: 0.6397058823529411, Validation Loss: 0.885585367679596, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9701/10000, Training Loss: 0.6499584317207336, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7753019332885742, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9702/10000, Training Loss: 0.6459152102470398, Training Accuracy: 0.7083333333333334, Validation Loss: 1.1839908361434937, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9703/10000, Training Loss: 0.6385261416435242, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7805817723274231, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9704/10000, Training Loss: 0.6068426966667175, Training Accuracy: 0.6593137254901961, Validation Loss: 0.9217987060546875, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9705/10000, Training Loss: 0.6058642864227295, Training Accuracy: 0.6715686274509803, Validation Loss: 0.885725736618042, Validation Accuracy: 0.5\n",
      "Epoch 9706/10000, Training Loss: 0.6494900584220886, Training Accuracy: 0.6176470588235294, Validation Loss: 1.0969383716583252, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9707/10000, Training Loss: 0.6345493197441101, Training Accuracy: 0.6004901960784313, Validation Loss: 0.7671580910682678, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9708/10000, Training Loss: 0.6456832885742188, Training Accuracy: 0.6004901960784313, Validation Loss: 0.6939094066619873, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9709/10000, Training Loss: 0.6454324126243591, Training Accuracy: 0.5906862745098039, Validation Loss: 0.8611418604850769, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9710/10000, Training Loss: 0.6410120129585266, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1189359426498413, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9711/10000, Training Loss: 0.5994783639907837, Training Accuracy: 0.6666666666666666, Validation Loss: 0.987000048160553, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9712/10000, Training Loss: 0.6113203167915344, Training Accuracy: 0.6666666666666666, Validation Loss: 1.0289713144302368, Validation Accuracy: 0.5\n",
      "Epoch 9713/10000, Training Loss: 0.6363705396652222, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9192607998847961, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9714/10000, Training Loss: 0.6548858284950256, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7739784717559814, Validation Accuracy: 0.5\n",
      "Epoch 9715/10000, Training Loss: 0.633209228515625, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7525234222412109, Validation Accuracy: 0.5\n",
      "Epoch 9716/10000, Training Loss: 0.5918266177177429, Training Accuracy: 0.6887254901960784, Validation Loss: 0.6404759287834167, Validation Accuracy: 0.75\n",
      "Epoch 9717/10000, Training Loss: 0.6547132134437561, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8793969750404358, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9718/10000, Training Loss: 0.630326509475708, Training Accuracy: 0.6691176470588235, Validation Loss: 0.9748552441596985, Validation Accuracy: 0.25\n",
      "Epoch 9719/10000, Training Loss: 0.6418928503990173, Training Accuracy: 0.6568627450980392, Validation Loss: 1.027713656425476, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9720/10000, Training Loss: 0.6619349718093872, Training Accuracy: 0.6397058823529411, Validation Loss: 0.9256162643432617, Validation Accuracy: 0.5\n",
      "Epoch 9721/10000, Training Loss: 0.6359789371490479, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7080373167991638, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9722/10000, Training Loss: 0.6372431516647339, Training Accuracy: 0.6372549019607843, Validation Loss: 1.2715368270874023, Validation Accuracy: 0.5\n",
      "Epoch 9723/10000, Training Loss: 0.6167114973068237, Training Accuracy: 0.7058823529411765, Validation Loss: 0.718989372253418, Validation Accuracy: 0.5\n",
      "Epoch 9724/10000, Training Loss: 0.6528220176696777, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8474721908569336, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9725/10000, Training Loss: 0.6942881345748901, Training Accuracy: 0.6372549019607843, Validation Loss: 0.8579971194267273, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9726/10000, Training Loss: 0.6439080238342285, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7307548522949219, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9727/10000, Training Loss: 0.6443513631820679, Training Accuracy: 0.6593137254901961, Validation Loss: 0.6010008454322815, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9728/10000, Training Loss: 0.6262104511260986, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8784636855125427, Validation Accuracy: 0.5\n",
      "Epoch 9729/10000, Training Loss: 0.6312555074691772, Training Accuracy: 0.6127450980392157, Validation Loss: 0.9163066744804382, Validation Accuracy: 0.5\n",
      "Epoch 9730/10000, Training Loss: 0.6351458430290222, Training Accuracy: 0.6397058823529411, Validation Loss: 0.7293959259986877, Validation Accuracy: 0.5\n",
      "Epoch 9731/10000, Training Loss: 0.6445421576499939, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7955679893493652, Validation Accuracy: 0.5\n",
      "Epoch 9732/10000, Training Loss: 0.6358320116996765, Training Accuracy: 0.6397058823529411, Validation Loss: 0.703616201877594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9733/10000, Training Loss: 0.623892605304718, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6799201965332031, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9734/10000, Training Loss: 0.6595156788825989, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7004820704460144, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9735/10000, Training Loss: 0.6381579637527466, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7542683482170105, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9736/10000, Training Loss: 0.6024371385574341, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7997891306877136, Validation Accuracy: 0.5\n",
      "Epoch 9737/10000, Training Loss: 0.6147357821464539, Training Accuracy: 0.6813725490196079, Validation Loss: 0.6763589978218079, Validation Accuracy: 0.5\n",
      "Epoch 9738/10000, Training Loss: 0.6561293005943298, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7919034361839294, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9739/10000, Training Loss: 0.6101322770118713, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6724504828453064, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9740/10000, Training Loss: 0.6406794786453247, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7009453177452087, Validation Accuracy: 0.75\n",
      "Epoch 9741/10000, Training Loss: 0.6554607152938843, Training Accuracy: 0.6911764705882353, Validation Loss: 0.8107917308807373, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9742/10000, Training Loss: 0.6465083956718445, Training Accuracy: 0.6446078431372549, Validation Loss: 0.6750719547271729, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9743/10000, Training Loss: 0.6773737668991089, Training Accuracy: 0.5588235294117647, Validation Loss: 0.8396404385566711, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9744/10000, Training Loss: 0.6814863085746765, Training Accuracy: 0.5955882352941176, Validation Loss: 0.9022927284240723, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9745/10000, Training Loss: 0.60701584815979, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8922538757324219, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9746/10000, Training Loss: 0.578508734703064, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9256700873374939, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9747/10000, Training Loss: 0.6741224527359009, Training Accuracy: 0.6544117647058824, Validation Loss: 0.828219473361969, Validation Accuracy: 0.5\n",
      "Epoch 9748/10000, Training Loss: 0.635375440120697, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6855915188789368, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9749/10000, Training Loss: 0.6483311653137207, Training Accuracy: 0.6593137254901961, Validation Loss: 1.2529187202453613, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9750/10000, Training Loss: 0.6559173464775085, Training Accuracy: 0.6053921568627451, Validation Loss: 0.6031516194343567, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9751/10000, Training Loss: 0.6611160039901733, Training Accuracy: 0.5955882352941176, Validation Loss: 0.7933059334754944, Validation Accuracy: 0.5\n",
      "Epoch 9752/10000, Training Loss: 0.6365088820457458, Training Accuracy: 0.625, Validation Loss: 1.1968907117843628, Validation Accuracy: 0.5\n",
      "Epoch 9753/10000, Training Loss: 0.6346763968467712, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7758792042732239, Validation Accuracy: 0.5\n",
      "Epoch 9754/10000, Training Loss: 0.5721315741539001, Training Accuracy: 0.7156862745098039, Validation Loss: 1.0946558713912964, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9755/10000, Training Loss: 0.6142395734786987, Training Accuracy: 0.6495098039215687, Validation Loss: 0.5502280592918396, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9756/10000, Training Loss: 0.6474794745445251, Training Accuracy: 0.6225490196078431, Validation Loss: 0.792450487613678, Validation Accuracy: 0.5\n",
      "Epoch 9757/10000, Training Loss: 0.6066858172416687, Training Accuracy: 0.696078431372549, Validation Loss: 1.079856038093567, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9758/10000, Training Loss: 0.6814964413642883, Training Accuracy: 0.5367647058823529, Validation Loss: 0.7736880779266357, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9759/10000, Training Loss: 0.6155155301094055, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7934131622314453, Validation Accuracy: 0.5\n",
      "Epoch 9760/10000, Training Loss: 0.644890308380127, Training Accuracy: 0.6151960784313726, Validation Loss: 1.4690423011779785, Validation Accuracy: 0.25\n",
      "Epoch 9761/10000, Training Loss: 0.6369739770889282, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8978201746940613, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9762/10000, Training Loss: 0.6568921208381653, Training Accuracy: 0.6127450980392157, Validation Loss: 1.3137210607528687, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9763/10000, Training Loss: 0.6035668849945068, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9104653000831604, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9764/10000, Training Loss: 0.6517606973648071, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8356612324714661, Validation Accuracy: 0.5\n",
      "Epoch 9765/10000, Training Loss: 0.6722458004951477, Training Accuracy: 0.6299019607843137, Validation Loss: 0.898708164691925, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9766/10000, Training Loss: 0.6290270686149597, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8530628681182861, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9767/10000, Training Loss: 0.6612052917480469, Training Accuracy: 0.6053921568627451, Validation Loss: 0.726050078868866, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9768/10000, Training Loss: 0.6157580614089966, Training Accuracy: 0.6764705882352942, Validation Loss: 0.8113757967948914, Validation Accuracy: 0.5\n",
      "Epoch 9769/10000, Training Loss: 0.6420109272003174, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7192084193229675, Validation Accuracy: 0.5\n",
      "Epoch 9770/10000, Training Loss: 0.6147298812866211, Training Accuracy: 0.6715686274509803, Validation Loss: 0.7808921933174133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9771/10000, Training Loss: 0.6114625930786133, Training Accuracy: 0.6740196078431373, Validation Loss: 0.9455417990684509, Validation Accuracy: 0.5\n",
      "Epoch 9772/10000, Training Loss: 0.6219062805175781, Training Accuracy: 0.6495098039215687, Validation Loss: 0.8288426995277405, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9773/10000, Training Loss: 0.6197400093078613, Training Accuracy: 0.6887254901960784, Validation Loss: 0.6972724795341492, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9774/10000, Training Loss: 0.585327684879303, Training Accuracy: 0.6985294117647058, Validation Loss: 0.7481088042259216, Validation Accuracy: 0.5\n",
      "Epoch 9775/10000, Training Loss: 0.6108872890472412, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8026764392852783, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9776/10000, Training Loss: 0.6313502192497253, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7090706825256348, Validation Accuracy: 0.75\n",
      "Epoch 9777/10000, Training Loss: 0.5823903679847717, Training Accuracy: 0.6813725490196079, Validation Loss: 1.063791036605835, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9778/10000, Training Loss: 0.6181154847145081, Training Accuracy: 0.7132352941176471, Validation Loss: 0.9933852553367615, Validation Accuracy: 0.5\n",
      "Epoch 9779/10000, Training Loss: 0.615792989730835, Training Accuracy: 0.6715686274509803, Validation Loss: 1.0577425956726074, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9780/10000, Training Loss: 0.6620515584945679, Training Accuracy: 0.6348039215686274, Validation Loss: 1.1662591695785522, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9781/10000, Training Loss: 0.5884849429130554, Training Accuracy: 0.6862745098039216, Validation Loss: 0.7287418246269226, Validation Accuracy: 0.5\n",
      "Epoch 9782/10000, Training Loss: 0.6723212599754333, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7892497181892395, Validation Accuracy: 0.5\n",
      "Epoch 9783/10000, Training Loss: 0.5819287300109863, Training Accuracy: 0.6985294117647058, Validation Loss: 0.8219287991523743, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9784/10000, Training Loss: 0.6430249810218811, Training Accuracy: 0.6715686274509803, Validation Loss: 0.6306849718093872, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9785/10000, Training Loss: 0.6380193829536438, Training Accuracy: 0.6642156862745098, Validation Loss: 1.1880067586898804, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9786/10000, Training Loss: 0.617256224155426, Training Accuracy: 0.6200980392156863, Validation Loss: 0.7790965437889099, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9787/10000, Training Loss: 0.6143739223480225, Training Accuracy: 0.6666666666666666, Validation Loss: 1.265433669090271, Validation Accuracy: 0.5\n",
      "Epoch 9788/10000, Training Loss: 0.6633099317550659, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0355340242385864, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9789/10000, Training Loss: 0.7008681297302246, Training Accuracy: 0.6764705882352942, Validation Loss: 1.297129511833191, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9790/10000, Training Loss: 0.6223138570785522, Training Accuracy: 0.6764705882352942, Validation Loss: 0.7005934715270996, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9791/10000, Training Loss: 0.8603528141975403, Training Accuracy: 0.5906862745098039, Validation Loss: 1.6363887786865234, Validation Accuracy: 0.25\n",
      "Epoch 9792/10000, Training Loss: 0.6670526266098022, Training Accuracy: 0.6004901960784313, Validation Loss: 0.650062620639801, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 9793/10000, Training Loss: 0.6206212043762207, Training Accuracy: 0.6911764705882353, Validation Loss: 1.029265284538269, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9794/10000, Training Loss: 0.6773877143859863, Training Accuracy: 0.6053921568627451, Validation Loss: 0.8158695697784424, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9795/10000, Training Loss: 0.645214319229126, Training Accuracy: 0.6372549019607843, Validation Loss: 0.5984121561050415, Validation Accuracy: 0.75\n",
      "Epoch 9796/10000, Training Loss: 0.6153343319892883, Training Accuracy: 0.696078431372549, Validation Loss: 0.7558533549308777, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9797/10000, Training Loss: 0.6110920310020447, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8258931636810303, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9798/10000, Training Loss: 0.6596196293830872, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6502931714057922, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9799/10000, Training Loss: 0.6591248512268066, Training Accuracy: 0.6421568627450981, Validation Loss: 0.8067574501037598, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9800/10000, Training Loss: 0.6369746327400208, Training Accuracy: 0.6862745098039216, Validation Loss: 0.9032635688781738, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9801/10000, Training Loss: 0.6089591383934021, Training Accuracy: 0.6470588235294118, Validation Loss: 0.9270682334899902, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9802/10000, Training Loss: 0.6212631464004517, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7782292366027832, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9803/10000, Training Loss: 0.6471033096313477, Training Accuracy: 0.5857843137254902, Validation Loss: 1.2102638483047485, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9804/10000, Training Loss: 0.6343231797218323, Training Accuracy: 0.5931372549019608, Validation Loss: 0.8718640208244324, Validation Accuracy: 0.5\n",
      "Epoch 9805/10000, Training Loss: 0.6104637980461121, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9966850280761719, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9806/10000, Training Loss: 0.620418906211853, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6539623141288757, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9807/10000, Training Loss: 0.6387901306152344, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7475561499595642, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9808/10000, Training Loss: 0.6099598407745361, Training Accuracy: 0.6887254901960784, Validation Loss: 0.7922253608703613, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9809/10000, Training Loss: 0.7000278234481812, Training Accuracy: 0.5906862745098039, Validation Loss: 0.7747629284858704, Validation Accuracy: 0.25\n",
      "Epoch 9810/10000, Training Loss: 0.6075036525726318, Training Accuracy: 0.6813725490196079, Validation Loss: 1.11768639087677, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9811/10000, Training Loss: 0.6258413195610046, Training Accuracy: 0.6862745098039216, Validation Loss: 0.8073902726173401, Validation Accuracy: 0.5\n",
      "Epoch 9812/10000, Training Loss: 0.619787335395813, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7533783316612244, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9813/10000, Training Loss: 0.6687624454498291, Training Accuracy: 0.5906862745098039, Validation Loss: 0.634681224822998, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9814/10000, Training Loss: 0.6018547415733337, Training Accuracy: 0.7230392156862745, Validation Loss: 0.6946240067481995, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9815/10000, Training Loss: 0.6128481030464172, Training Accuracy: 0.6348039215686274, Validation Loss: 0.738176167011261, Validation Accuracy: 0.5\n",
      "Epoch 9816/10000, Training Loss: 0.619767963886261, Training Accuracy: 0.7058823529411765, Validation Loss: 0.8369848132133484, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9817/10000, Training Loss: 0.6067323684692383, Training Accuracy: 0.6519607843137255, Validation Loss: 0.687190592288971, Validation Accuracy: 0.5\n",
      "Epoch 9818/10000, Training Loss: 0.6260977983474731, Training Accuracy: 0.6225490196078431, Validation Loss: 0.9536092877388, Validation Accuracy: 0.5\n",
      "Epoch 9819/10000, Training Loss: 0.6208582520484924, Training Accuracy: 0.6617647058823529, Validation Loss: 0.8104142546653748, Validation Accuracy: 0.5\n",
      "Epoch 9820/10000, Training Loss: 0.6398634314537048, Training Accuracy: 0.6151960784313726, Validation Loss: 0.8279147148132324, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9821/10000, Training Loss: 0.6155868768692017, Training Accuracy: 0.6936274509803921, Validation Loss: 0.7834210991859436, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9822/10000, Training Loss: 0.6134056448936462, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8688511848449707, Validation Accuracy: 0.5\n",
      "Epoch 9823/10000, Training Loss: 0.6741216778755188, Training Accuracy: 0.6372549019607843, Validation Loss: 1.200299620628357, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9824/10000, Training Loss: 0.6175161004066467, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8090195059776306, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9825/10000, Training Loss: 0.66599440574646, Training Accuracy: 0.6102941176470589, Validation Loss: 0.6000189185142517, Validation Accuracy: 0.75\n",
      "Epoch 9826/10000, Training Loss: 0.6091597080230713, Training Accuracy: 0.6813725490196079, Validation Loss: 0.9630486965179443, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9827/10000, Training Loss: 0.6082212328910828, Training Accuracy: 0.6642156862745098, Validation Loss: 0.9873595833778381, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9828/10000, Training Loss: 0.6260234117507935, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8070220947265625, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9829/10000, Training Loss: 0.6379820108413696, Training Accuracy: 0.6862745098039216, Validation Loss: 0.6253388524055481, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9830/10000, Training Loss: 0.6207443475723267, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7683534026145935, Validation Accuracy: 0.5\n",
      "Epoch 9831/10000, Training Loss: 0.6255798935890198, Training Accuracy: 0.6617647058823529, Validation Loss: 0.9185923933982849, Validation Accuracy: 0.5\n",
      "Epoch 9832/10000, Training Loss: 0.6402319073677063, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7264072895050049, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9833/10000, Training Loss: 0.6852580904960632, Training Accuracy: 0.6348039215686274, Validation Loss: 0.7479041218757629, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9834/10000, Training Loss: 0.6574586629867554, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7394705414772034, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9835/10000, Training Loss: 0.5588003396987915, Training Accuracy: 0.7230392156862745, Validation Loss: 0.9805543422698975, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9836/10000, Training Loss: 0.6532005071640015, Training Accuracy: 0.6274509803921569, Validation Loss: 0.7369315028190613, Validation Accuracy: 0.5\n",
      "Epoch 9837/10000, Training Loss: 0.6504471898078918, Training Accuracy: 0.5808823529411765, Validation Loss: 0.6908749938011169, Validation Accuracy: 0.5\n",
      "Epoch 9838/10000, Training Loss: 0.6653928756713867, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6604623794555664, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9839/10000, Training Loss: 0.5999128222465515, Training Accuracy: 0.6666666666666666, Validation Loss: 1.0600976943969727, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9840/10000, Training Loss: 0.6183013319969177, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7228513360023499, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9841/10000, Training Loss: 0.6827139854431152, Training Accuracy: 0.6495098039215687, Validation Loss: 0.9412556290626526, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9842/10000, Training Loss: 0.614844799041748, Training Accuracy: 0.6397058823529411, Validation Loss: 0.8642255663871765, Validation Accuracy: 0.5\n",
      "Epoch 9843/10000, Training Loss: 0.6069933772087097, Training Accuracy: 0.696078431372549, Validation Loss: 0.893018901348114, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9844/10000, Training Loss: 0.6375921368598938, Training Accuracy: 0.6666666666666666, Validation Loss: 1.0289133787155151, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9845/10000, Training Loss: 0.6860936284065247, Training Accuracy: 0.5931372549019608, Validation Loss: 0.6307727098464966, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9846/10000, Training Loss: 0.6339457631111145, Training Accuracy: 0.6838235294117647, Validation Loss: 1.1966339349746704, Validation Accuracy: 0.5\n",
      "Epoch 9847/10000, Training Loss: 0.6197976469993591, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7107797265052795, Validation Accuracy: 0.5\n",
      "Epoch 9848/10000, Training Loss: 0.6336044669151306, Training Accuracy: 0.6446078431372549, Validation Loss: 0.886542022228241, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9849/10000, Training Loss: 0.6091262698173523, Training Accuracy: 0.6348039215686274, Validation Loss: 1.2081958055496216, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9850/10000, Training Loss: 0.6075568795204163, Training Accuracy: 0.6691176470588235, Validation Loss: 0.8077110648155212, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9851/10000, Training Loss: 0.6077730059623718, Training Accuracy: 0.6495098039215687, Validation Loss: 1.6071171760559082, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9852/10000, Training Loss: 0.6518489718437195, Training Accuracy: 0.625, Validation Loss: 0.775662899017334, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9853/10000, Training Loss: 0.6380552649497986, Training Accuracy: 0.6421568627450981, Validation Loss: 0.6808226108551025, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9854/10000, Training Loss: 0.6189236640930176, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8151856064796448, Validation Accuracy: 0.5\n",
      "Epoch 9855/10000, Training Loss: 0.6577629446983337, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8005110621452332, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9856/10000, Training Loss: 0.6376627087593079, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0944029092788696, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9857/10000, Training Loss: 0.6502790451049805, Training Accuracy: 0.5661764705882353, Validation Loss: 0.7129948139190674, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9858/10000, Training Loss: 0.6159489154815674, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7295342087745667, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9859/10000, Training Loss: 0.6199291348457336, Training Accuracy: 0.6617647058823529, Validation Loss: 1.089386224746704, Validation Accuracy: 0.5\n",
      "Epoch 9860/10000, Training Loss: 0.6460829973220825, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7671778202056885, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9861/10000, Training Loss: 0.5978772044181824, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7369033694267273, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9862/10000, Training Loss: 0.6677857041358948, Training Accuracy: 0.6225490196078431, Validation Loss: 1.0326356887817383, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9863/10000, Training Loss: 0.6304511427879333, Training Accuracy: 0.6127450980392157, Validation Loss: 0.8522714972496033, Validation Accuracy: 0.5\n",
      "Epoch 9864/10000, Training Loss: 0.6537017822265625, Training Accuracy: 0.6568627450980392, Validation Loss: 0.7762091159820557, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9865/10000, Training Loss: 0.6223059892654419, Training Accuracy: 0.6593137254901961, Validation Loss: 1.3566612005233765, Validation Accuracy: 0.5\n",
      "Epoch 9866/10000, Training Loss: 0.6527169942855835, Training Accuracy: 0.6372549019607843, Validation Loss: 1.4506675004959106, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9867/10000, Training Loss: 0.6169780492782593, Training Accuracy: 0.7009803921568627, Validation Loss: 0.9411253929138184, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9868/10000, Training Loss: 0.6673798561096191, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6501168608665466, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9869/10000, Training Loss: 0.6861111521720886, Training Accuracy: 0.6446078431372549, Validation Loss: 1.5405434370040894, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9870/10000, Training Loss: 0.6187799572944641, Training Accuracy: 0.6838235294117647, Validation Loss: 0.7058266997337341, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9871/10000, Training Loss: 0.6530454754829407, Training Accuracy: 0.6372549019607843, Validation Loss: 0.9584419131278992, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9872/10000, Training Loss: 0.6512036919593811, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6876820921897888, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9873/10000, Training Loss: 0.6296507120132446, Training Accuracy: 0.6348039215686274, Validation Loss: 0.8758063316345215, Validation Accuracy: 0.16666666666666666\n",
      "Epoch 9874/10000, Training Loss: 0.648781955242157, Training Accuracy: 0.625, Validation Loss: 0.7031291127204895, Validation Accuracy: 0.5\n",
      "Epoch 9875/10000, Training Loss: 0.6163148880004883, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7196791768074036, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9876/10000, Training Loss: 0.6334448456764221, Training Accuracy: 0.6838235294117647, Validation Loss: 0.9048855304718018, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9877/10000, Training Loss: 0.6074132919311523, Training Accuracy: 0.7009803921568627, Validation Loss: 0.9426442980766296, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9878/10000, Training Loss: 0.656827986240387, Training Accuracy: 0.6176470588235294, Validation Loss: 0.9222514629364014, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9879/10000, Training Loss: 0.6247394680976868, Training Accuracy: 0.6813725490196079, Validation Loss: 1.190657138824463, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9880/10000, Training Loss: 0.6557831168174744, Training Accuracy: 0.6029411764705882, Validation Loss: 0.6900386810302734, Validation Accuracy: 0.5\n",
      "Epoch 9881/10000, Training Loss: 0.6289348006248474, Training Accuracy: 0.696078431372549, Validation Loss: 0.7432535290718079, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9882/10000, Training Loss: 0.6191781163215637, Training Accuracy: 0.6642156862745098, Validation Loss: 0.8561579585075378, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9883/10000, Training Loss: 0.6649754047393799, Training Accuracy: 0.6421568627450981, Validation Loss: 1.10788893699646, Validation Accuracy: 0.25\n",
      "Epoch 9884/10000, Training Loss: 0.6531670689582825, Training Accuracy: 0.6176470588235294, Validation Loss: 0.767055332660675, Validation Accuracy: 0.5\n",
      "Epoch 9885/10000, Training Loss: 0.6087110042572021, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7624551653862, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9886/10000, Training Loss: 0.6292206048965454, Training Accuracy: 0.6348039215686274, Validation Loss: 1.1656726598739624, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9887/10000, Training Loss: 0.8211148381233215, Training Accuracy: 0.6053921568627451, Validation Loss: 0.5989248156547546, Validation Accuracy: 0.75\n",
      "Epoch 9888/10000, Training Loss: 0.6404327154159546, Training Accuracy: 0.6421568627450981, Validation Loss: 0.910243809223175, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9889/10000, Training Loss: 0.6660445928573608, Training Accuracy: 0.6911764705882353, Validation Loss: 1.144189715385437, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9890/10000, Training Loss: 0.6751030087471008, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6445447206497192, Validation Accuracy: 0.5\n",
      "Epoch 9891/10000, Training Loss: 0.627885103225708, Training Accuracy: 0.6617647058823529, Validation Loss: 1.0131889581680298, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9892/10000, Training Loss: 0.6395159959793091, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7704306244850159, Validation Accuracy: 0.5\n",
      "Epoch 9893/10000, Training Loss: 0.6051819920539856, Training Accuracy: 0.6887254901960784, Validation Loss: 0.8688228726387024, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9894/10000, Training Loss: 0.6530448198318481, Training Accuracy: 0.6029411764705882, Validation Loss: 1.0153542757034302, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9895/10000, Training Loss: 0.6221386194229126, Training Accuracy: 0.6691176470588235, Validation Loss: 0.7854118347167969, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9896/10000, Training Loss: 0.6556718349456787, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7222073078155518, Validation Accuracy: 0.5\n",
      "Epoch 9897/10000, Training Loss: 0.6045905351638794, Training Accuracy: 0.7156862745098039, Validation Loss: 0.7252686619758606, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9898/10000, Training Loss: 0.6470442414283752, Training Accuracy: 0.6544117647058824, Validation Loss: 0.6632266640663147, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9899/10000, Training Loss: 0.6273471713066101, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7933630347251892, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9900/10000, Training Loss: 0.6327300667762756, Training Accuracy: 0.6470588235294118, Validation Loss: 0.7316266894340515, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9901/10000, Training Loss: 0.6380019187927246, Training Accuracy: 0.6348039215686274, Validation Loss: 0.6184422373771667, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9902/10000, Training Loss: 0.608762800693512, Training Accuracy: 0.6666666666666666, Validation Loss: 0.8003026843070984, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9903/10000, Training Loss: 0.6525042057037354, Training Accuracy: 0.6151960784313726, Validation Loss: 0.6761793494224548, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9904/10000, Training Loss: 0.6678901314735413, Training Accuracy: 0.6078431372549019, Validation Loss: 0.9721452593803406, Validation Accuracy: 0.5\n",
      "Epoch 9905/10000, Training Loss: 0.6333056688308716, Training Accuracy: 0.6421568627450981, Validation Loss: 0.7735364437103271, Validation Accuracy: 0.5\n",
      "Epoch 9906/10000, Training Loss: 0.6206561326980591, Training Accuracy: 0.6642156862745098, Validation Loss: 0.7788675427436829, Validation Accuracy: 0.5\n",
      "Epoch 9907/10000, Training Loss: 0.6525837182998657, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7361912131309509, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9908/10000, Training Loss: 0.6626518368721008, Training Accuracy: 0.5906862745098039, Validation Loss: 0.6101664304733276, Validation Accuracy: 0.75\n",
      "Epoch 9909/10000, Training Loss: 0.6303476095199585, Training Accuracy: 0.6666666666666666, Validation Loss: 1.3167122602462769, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9910/10000, Training Loss: 0.6506224274635315, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7676960825920105, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9911/10000, Training Loss: 0.6162046194076538, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8508520722389221, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9912/10000, Training Loss: 0.6275256276130676, Training Accuracy: 0.6299019607843137, Validation Loss: 0.5895165801048279, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9913/10000, Training Loss: 0.6502403020858765, Training Accuracy: 0.6176470588235294, Validation Loss: 0.7944101691246033, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9914/10000, Training Loss: 1.0478204488754272, Training Accuracy: 0.6151960784313726, Validation Loss: 2.0425071716308594, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9915/10000, Training Loss: 0.6524679064750671, Training Accuracy: 0.625, Validation Loss: 0.7101626992225647, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9916/10000, Training Loss: 0.6017346978187561, Training Accuracy: 0.6740196078431373, Validation Loss: 0.8842516541481018, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9917/10000, Training Loss: 0.6241346001625061, Training Accuracy: 0.678921568627451, Validation Loss: 1.0685153007507324, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9918/10000, Training Loss: 0.6730552315711975, Training Accuracy: 0.7181372549019608, Validation Loss: 0.8597587943077087, Validation Accuracy: 0.5\n",
      "Epoch 9919/10000, Training Loss: 0.6100460886955261, Training Accuracy: 0.6813725490196079, Validation Loss: 0.7814471125602722, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9920/10000, Training Loss: 0.6396839022636414, Training Accuracy: 0.6397058823529411, Validation Loss: 0.4963319003582001, Validation Accuracy: 0.75\n",
      "Epoch 9921/10000, Training Loss: 0.6342231035232544, Training Accuracy: 0.6470588235294118, Validation Loss: 0.826893150806427, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9922/10000, Training Loss: 0.6490607261657715, Training Accuracy: 0.625, Validation Loss: 0.7542408108711243, Validation Accuracy: 0.25\n",
      "Epoch 9923/10000, Training Loss: 0.6581838726997375, Training Accuracy: 0.6225490196078431, Validation Loss: 0.7600493431091309, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9924/10000, Training Loss: 0.6082471609115601, Training Accuracy: 0.6666666666666666, Validation Loss: 1.071686029434204, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9925/10000, Training Loss: 0.6005793809890747, Training Accuracy: 0.6666666666666666, Validation Loss: 1.3672221899032593, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9926/10000, Training Loss: 0.7102532982826233, Training Accuracy: 0.6470588235294118, Validation Loss: 0.834419310092926, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9927/10000, Training Loss: 0.6673572659492493, Training Accuracy: 0.6274509803921569, Validation Loss: 1.5410374402999878, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9928/10000, Training Loss: 0.6244284510612488, Training Accuracy: 0.6617647058823529, Validation Loss: 0.7648969292640686, Validation Accuracy: 0.5\n",
      "Epoch 9929/10000, Training Loss: 0.7183597087860107, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8838340640068054, Validation Accuracy: 0.5\n",
      "Epoch 9930/10000, Training Loss: 0.815313458442688, Training Accuracy: 0.6102941176470589, Validation Loss: 1.1232413053512573, Validation Accuracy: 0.25\n",
      "Epoch 9931/10000, Training Loss: 0.7328241467475891, Training Accuracy: 0.6740196078431373, Validation Loss: 2.339782238006592, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9932/10000, Training Loss: 0.6635017395019531, Training Accuracy: 0.6274509803921569, Validation Loss: 0.6952428221702576, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9933/10000, Training Loss: 0.679418683052063, Training Accuracy: 0.6200980392156863, Validation Loss: 0.6449822783470154, Validation Accuracy: 0.5\n",
      "Epoch 9934/10000, Training Loss: 0.6379153728485107, Training Accuracy: 0.6740196078431373, Validation Loss: 0.7738595604896545, Validation Accuracy: 0.5\n",
      "Epoch 9935/10000, Training Loss: 0.6740901470184326, Training Accuracy: 0.5857843137254902, Validation Loss: 1.3129318952560425, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9936/10000, Training Loss: 0.7672761082649231, Training Accuracy: 0.6053921568627451, Validation Loss: 1.044413447380066, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9937/10000, Training Loss: 0.6837480664253235, Training Accuracy: 0.6372549019607843, Validation Loss: 0.6322596669197083, Validation Accuracy: 0.5\n",
      "Epoch 9938/10000, Training Loss: 0.6436458826065063, Training Accuracy: 0.6568627450980392, Validation Loss: 0.8154911994934082, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9939/10000, Training Loss: 0.6018438935279846, Training Accuracy: 0.6397058823529411, Validation Loss: 0.665636420249939, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9940/10000, Training Loss: 0.6113041043281555, Training Accuracy: 0.6495098039215687, Validation Loss: 0.7364752888679504, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9941/10000, Training Loss: 0.7459103465080261, Training Accuracy: 0.6176470588235294, Validation Loss: 1.1397747993469238, Validation Accuracy: 0.5\n",
      "Epoch 9942/10000, Training Loss: 0.6853642463684082, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7572386264801025, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9943/10000, Training Loss: 0.6896942257881165, Training Accuracy: 0.6029411764705882, Validation Loss: 0.8776171803474426, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9944/10000, Training Loss: 0.6767643094062805, Training Accuracy: 0.6323529411764706, Validation Loss: 0.7008323073387146, Validation Accuracy: 0.5\n",
      "Epoch 9945/10000, Training Loss: 0.7174652218818665, Training Accuracy: 0.5784313725490197, Validation Loss: 1.6566616296768188, Validation Accuracy: 0.25\n",
      "Epoch 9946/10000, Training Loss: 0.6309341788291931, Training Accuracy: 0.6299019607843137, Validation Loss: 0.7116319537162781, Validation Accuracy: 0.5\n",
      "Epoch 9947/10000, Training Loss: 0.6219671964645386, Training Accuracy: 0.7377450980392157, Validation Loss: 0.914476215839386, Validation Accuracy: 0.5\n",
      "Epoch 9948/10000, Training Loss: 0.7535392642021179, Training Accuracy: 0.5931372549019608, Validation Loss: 1.6761940717697144, Validation Accuracy: 0.25\n",
      "Epoch 9949/10000, Training Loss: 0.6837583184242249, Training Accuracy: 0.6397058823529411, Validation Loss: 1.2645606994628906, Validation Accuracy: 0.08333333333333333\n",
      "Epoch 9950/10000, Training Loss: 0.6872631311416626, Training Accuracy: 0.6519607843137255, Validation Loss: 1.2529597282409668, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9951/10000, Training Loss: 0.6140446662902832, Training Accuracy: 0.6372549019607843, Validation Loss: 0.7348203063011169, Validation Accuracy: 0.75\n",
      "Epoch 9952/10000, Training Loss: 0.6866998672485352, Training Accuracy: 0.6200980392156863, Validation Loss: 1.313894271850586, Validation Accuracy: 0.5\n",
      "Epoch 9953/10000, Training Loss: 0.603334903717041, Training Accuracy: 0.6936274509803921, Validation Loss: 1.0604228973388672, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9954/10000, Training Loss: 0.6424725651741028, Training Accuracy: 0.6495098039215687, Validation Loss: 1.0885497331619263, Validation Accuracy: 0.25\n",
      "Epoch 9955/10000, Training Loss: 0.6357623934745789, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7678939700126648, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9956/10000, Training Loss: 0.6245431900024414, Training Accuracy: 0.6274509803921569, Validation Loss: 0.9564546942710876, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9957/10000, Training Loss: 0.74552321434021, Training Accuracy: 0.6299019607843137, Validation Loss: 0.5899458527565002, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9958/10000, Training Loss: 0.6372196078300476, Training Accuracy: 0.6397058823529411, Validation Loss: 0.803177535533905, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9959/10000, Training Loss: 0.6511391401290894, Training Accuracy: 0.6470588235294118, Validation Loss: 1.3193222284317017, Validation Accuracy: 0.5\n",
      "Epoch 9960/10000, Training Loss: 0.6495126485824585, Training Accuracy: 0.6544117647058824, Validation Loss: 1.0233030319213867, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9961/10000, Training Loss: 0.7233216762542725, Training Accuracy: 0.6299019607843137, Validation Loss: 0.9843801856040955, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9962/10000, Training Loss: 0.6798619031906128, Training Accuracy: 0.6127450980392157, Validation Loss: 0.5869707465171814, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9963/10000, Training Loss: 0.6858291625976562, Training Accuracy: 0.6470588235294118, Validation Loss: 0.6618784070014954, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9964/10000, Training Loss: 0.6798985600471497, Training Accuracy: 0.6151960784313726, Validation Loss: 0.7713873982429504, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9965/10000, Training Loss: 1.1108254194259644, Training Accuracy: 0.6102941176470589, Validation Loss: 1.3868201971054077, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9966/10000, Training Loss: 0.6610166430473328, Training Accuracy: 0.7009803921568627, Validation Loss: 0.7251205444335938, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9967/10000, Training Loss: 0.643276035785675, Training Accuracy: 0.6470588235294118, Validation Loss: 0.8740485310554504, Validation Accuracy: 0.5\n",
      "Epoch 9968/10000, Training Loss: 0.6729801893234253, Training Accuracy: 0.6446078431372549, Validation Loss: 0.9358696937561035, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9969/10000, Training Loss: 0.6359781622886658, Training Accuracy: 0.6372549019607843, Validation Loss: 1.4810782670974731, Validation Accuracy: 0.25\n",
      "Epoch 9970/10000, Training Loss: 0.6507208347320557, Training Accuracy: 0.6078431372549019, Validation Loss: 0.6766102910041809, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9971/10000, Training Loss: 0.6477602124214172, Training Accuracy: 0.6323529411764706, Validation Loss: 0.8766387104988098, Validation Accuracy: 0.5\n",
      "Epoch 9972/10000, Training Loss: 0.6101477146148682, Training Accuracy: 0.6470588235294118, Validation Loss: 1.5083547830581665, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9973/10000, Training Loss: 0.7624324560165405, Training Accuracy: 0.6102941176470589, Validation Loss: 0.7199878692626953, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9974/10000, Training Loss: 0.6613062024116516, Training Accuracy: 0.5833333333333334, Validation Loss: 0.6926417946815491, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9975/10000, Training Loss: 0.7164195775985718, Training Accuracy: 0.5563725490196079, Validation Loss: 0.708344042301178, Validation Accuracy: 0.5\n",
      "Epoch 9976/10000, Training Loss: 0.7285267114639282, Training Accuracy: 0.5514705882352942, Validation Loss: 0.7896502614021301, Validation Accuracy: 0.5\n",
      "Epoch 9977/10000, Training Loss: 0.7677174806594849, Training Accuracy: 0.6299019607843137, Validation Loss: 1.5889734029769897, Validation Accuracy: 0.5\n",
      "Epoch 9978/10000, Training Loss: 0.6234450936317444, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7834102511405945, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9979/10000, Training Loss: 0.6800686717033386, Training Accuracy: 0.6568627450980392, Validation Loss: 0.9532658457756042, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9980/10000, Training Loss: 0.6750782132148743, Training Accuracy: 0.5784313725490197, Validation Loss: 0.8557619452476501, Validation Accuracy: 0.5\n",
      "Epoch 9981/10000, Training Loss: 0.8471153378486633, Training Accuracy: 0.5588235294117647, Validation Loss: 0.816154956817627, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9982/10000, Training Loss: 0.7359886765480042, Training Accuracy: 0.5416666666666666, Validation Loss: 0.6383455991744995, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9983/10000, Training Loss: 0.6635535955429077, Training Accuracy: 0.6446078431372549, Validation Loss: 0.7991244792938232, Validation Accuracy: 0.5\n",
      "Epoch 9984/10000, Training Loss: 0.9856879115104675, Training Accuracy: 0.6568627450980392, Validation Loss: 1.0776616334915161, Validation Accuracy: 0.5\n",
      "Epoch 9985/10000, Training Loss: 0.6381067037582397, Training Accuracy: 0.678921568627451, Validation Loss: 0.7600008845329285, Validation Accuracy: 0.5\n",
      "Epoch 9986/10000, Training Loss: 0.8252377510070801, Training Accuracy: 0.5735294117647058, Validation Loss: 0.7244274616241455, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9987/10000, Training Loss: 0.6741687655448914, Training Accuracy: 0.7009803921568627, Validation Loss: 0.8537833094596863, Validation Accuracy: 0.5\n",
      "Epoch 9988/10000, Training Loss: 0.9481602311134338, Training Accuracy: 0.6176470588235294, Validation Loss: 0.5811185240745544, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9989/10000, Training Loss: 0.7560455203056335, Training Accuracy: 0.5686274509803921, Validation Loss: 1.036424994468689, Validation Accuracy: 0.5\n",
      "Epoch 9990/10000, Training Loss: 0.6859313249588013, Training Accuracy: 0.6102941176470589, Validation Loss: 0.8079466223716736, Validation Accuracy: 0.5\n",
      "Epoch 9991/10000, Training Loss: 1.082991600036621, Training Accuracy: 0.5882352941176471, Validation Loss: 1.075406789779663, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9992/10000, Training Loss: 0.6533423066139221, Training Accuracy: 0.6544117647058824, Validation Loss: 0.7987669110298157, Validation Accuracy: 0.3333333333333333\n",
      "Epoch 9993/10000, Training Loss: 0.6491736769676208, Training Accuracy: 0.6348039215686274, Validation Loss: 0.5592283606529236, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9994/10000, Training Loss: 0.6809507608413696, Training Accuracy: 0.6299019607843137, Validation Loss: 0.6989173293113708, Validation Accuracy: 0.5833333333333334\n",
      "Epoch 9995/10000, Training Loss: 0.7300480604171753, Training Accuracy: 0.625, Validation Loss: 0.6037896871566772, Validation Accuracy: 0.75\n",
      "Epoch 9996/10000, Training Loss: 0.6803256869316101, Training Accuracy: 0.6348039215686274, Validation Loss: 1.4713258743286133, Validation Accuracy: 0.4166666666666667\n",
      "Epoch 9997/10000, Training Loss: 0.8438754081726074, Training Accuracy: 0.5588235294117647, Validation Loss: 1.1697129011154175, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 9998/10000, Training Loss: 0.7746129035949707, Training Accuracy: 0.5882352941176471, Validation Loss: 0.7006623148918152, Validation Accuracy: 0.5\n",
      "Epoch 9999/10000, Training Loss: 0.8502932786941528, Training Accuracy: 0.5661764705882353, Validation Loss: 0.9447467923164368, Validation Accuracy: 0.6666666666666666\n",
      "Epoch 10000/10000, Training Loss: 0.6573655605316162, Training Accuracy: 0.6593137254901961, Validation Loss: 0.8450621962547302, Validation Accuracy: 0.5\n",
      "Test Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\") + \"_\" + 'GAT' + f'_layers_{model.num_layers}_heads_{model.heads}_hidden_{model.hidden_channels}_dropout_{model.dropout}'\n",
    "writer = SummaryWriter(log_dir=f'./Graph/{timestr}')\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 2. Encode nodes using GAT layers\n",
    "    z = model.encode(node_features, data.train_pos_edge_index)\n",
    "    \n",
    "    # 3. Positive and negative samples for training\n",
    "    pos_edge_index = data.train_pos_edge_index  # Positive edges from training set\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index,\n",
    "        num_nodes=z.size(0),\n",
    "        num_neg_samples=pos_edge_index.size(1)\n",
    "    )  # Random negative samples\n",
    "    \n",
    "    # 4. Decode edges\n",
    "    pos_pred = model.decode(z, pos_edge_index)\n",
    "    neg_pred = model.decode(z, neg_edge_index)\n",
    "    \n",
    "    # 5. Create labels for positive and negative samples\n",
    "    pos_label = torch.ones(pos_pred.size(0), device=device)\n",
    "    neg_label = torch.zeros(neg_pred.size(0), device=device)\n",
    "    \n",
    "    # 6. Compute loss (binary cross-entropy)\n",
    "    loss = F.binary_cross_entropy_with_logits(torch.cat([pos_pred, neg_pred]), torch.cat([pos_label, neg_label]))\n",
    "    accuracy = ((torch.sigmoid(pos_pred) > 0.5).sum().item() + (torch.sigmoid(neg_pred) <= 0.5).sum().item()) / (pos_label.size(0) + neg_label.size(0))\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "    \n",
    "    # validation loss\n",
    "    val_pos_edge_index = data.val_pos_edge_index \n",
    "    val_neg_edge_index = negative_sampling(\n",
    "        edge_index=data.val_pos_edge_index,\n",
    "        num_nodes=z.size(0),\n",
    "        num_neg_samples=val_pos_edge_index.size(1)\n",
    "    )  # Random negative samples\n",
    "    \n",
    "    val_pos_pred = model.decode(z, val_pos_edge_index)\n",
    "    val_neg_pred = model.decode(z, val_neg_edge_index)\n",
    "    \n",
    "    val_pos_label = torch.ones(val_pos_pred.size(0), device=device)\n",
    "    val_neg_label = torch.zeros(val_neg_pred.size(0), device=device)\n",
    "    \n",
    "    val_loss = F.binary_cross_entropy_with_logits(torch.cat([val_pos_pred, val_neg_pred]), torch.cat([val_pos_label, val_neg_label]))\n",
    "    val_accuracy = ((torch.sigmoid(val_pos_pred) > 0.5).sum().item() + (torch.sigmoid(val_neg_pred) <= 0.5).sum().item()) / (val_pos_label.size(0) + val_neg_label.size(0))\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Training Accuracy: {accuracy}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(node_features, data.train_pos_edge_index)\n",
    "    pos_pred = model.decode(z, data.test_pos_edge_index)\n",
    "    neg_pred = model.decode(z, data.test_neg_edge_index)\n",
    "    \n",
    "    pos_label = torch.ones(pos_pred.size(0), device=device)\n",
    "    neg_label = torch.zeros(neg_pred.size(0), device=device)\n",
    "    \n",
    "    # Concatenate predictions and labels for evaluation\n",
    "    pred = torch.cat([pos_pred, neg_pred])\n",
    "    label = torch.cat([pos_label, neg_label])\n",
    "    \n",
    "    # Use a threshold (e.g., 0.5) on the sigmoid output to classify edges\n",
    "    pred_class = (torch.sigmoid(pred) > 0.5).float()\n",
    "    accuracy = (pred_class == label).sum().item() / label.size(0)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(teams))\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encode(node_features, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming `embeddings` is a tensor of shape [num_nodes, embedding_dim]\n",
    "embeddings_np = embeddings.cpu().numpy()  # Convert to NumPy for compatibility with sklearn\n",
    "tsne = TSNE(n_components=3, random_state=0)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Required for 3D plotting\n",
    "\n",
    "# Assuming `reduced_embeddings` has 3 dimensions (from t-SNE with `n_components=3`)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "ax.scatter(\n",
    "    reduced_embeddings[:, 0],  # X-axis\n",
    "    reduced_embeddings[:, 1],  # Y-axis\n",
    "    reduced_embeddings[:, 2],  # Z-axis\n",
    "    s=100, alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_title(\"GAT Embeddings Visualization (3D)\")\n",
    "ax.set_xlabel(\"Component 1\")\n",
    "ax.set_ylabel(\"Component 2\")\n",
    "ax.set_zlabel(\"Component 3\")\n",
    "\n",
    "for i, team in enumerate(teams):\n",
    "    ax.text(\n",
    "        reduced_embeddings[i, 0],\n",
    "        reduced_embeddings[i, 1],\n",
    "        reduced_embeddings[i, 2],\n",
    "        team,\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
